<!DOCTYPE html>
<html lang="en" style="scroll-padding-top: 70px;">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">
    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="/static/expo/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
    <link rel="stylesheet" href="cards.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">

    <script src="https://code.jquery.com/jquery-3.6.1.min.js"
            integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>
    </script>

    <script>
        if (typeof jQuery === 'undefined') {
            var script = document.createElement('script');
            script.type = 'text/javascript';
            script.src = "/static/core/js/jquery-3.6.1.min.js";
            document.head.appendChild(script);
        }
    </script>

    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/corejs-typeahead/1.3.1/typeahead.bundle.min.js" integrity="sha512-lEb9Vp/rkl9g2E/LdHIMFTqz21+LA79f84gqP75fbimHqVTu6483JG1AwJlWLLQ8ezTehty78fObKupq3HSHPQ==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>
    <script src="/static/virtual/js/virtual.js"></script>

    <link rel="stylesheet" href="virtual.css">

    <style>
    body {
        background: #f6f6f6;
    }
    </style>

</head>

<body>
<!-- NAV -->

<!--
<nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="/">
            <img src="/static/core/img/ICML-logo.svg" height="40px">
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item ">
                    <a class="nav-link" href="/virtual/2022/events/tutorial">Tutorials</a>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Main Conference
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <a class="dropdown-item" href="/virtual/2022/events/oral">Orals</a>
                        <div class="dropdown-divider"></div>
                        <a class="dropdown-item" href="/virtual/2022/papers.html">Papers</a>
                    </div>
                </li>
            </ul>
    </div>
    </div>
</nav>
-->

    <!-- NAV -->

    <nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="">
            <img src="tmlr_logo.jpeg" height="40px">
            Transactions on Machine Learning Research
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">

            <!--
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Main Conference
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/oral">Orals</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/spotlight">Spotlights</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/papers.html">Papers</a>
                </div>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../">All Papers</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="">Papers with Videos</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../featured_papers.html">Featured Papers</a>
            </li>
            -->

    <!--
    <li class="nav-item ">
        <a class="nav-link" href="/virtual/2023/search"><i class="fas fa-search"></i> &nbsp;</a>
    </li>
    -->
        </ul>
    </div>
</div>
</nav>



    <div class="container">
        <br />
        <div class="row">
            <div class="col-md-12"></div>
            <div class="title-centered" style="text-align:center">TMLR Infinite Conference</div>
        </div>
    </div>

        <div class="row">
            <div class="col-sm-12">
                <div style="max-width: 1500px; margin:auto; border">
                    <div class="grid-displaycards">
                        <div class="displaycards touchup-date" id="event-ZRXwHRXm8i">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ZRXwHRXm8i.html">CREW: Facilitating Human-AI Teaming Research</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lingyu Zhang &middot; Zhengran Ji &middot; Boyuan Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ZRXwHRXm8i"></div>

    <a href="paper_pages/ZRXwHRXm8i.html">
        <img src="http://img.youtube.com/vi/RINSo3uI0dI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ZRXwHRXm8i" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ZRXwHRXm8i" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ZRXwHRXm8i">
                Abstract <i id="caret-ZRXwHRXm8i" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ZRXwHRXm8i">
        <div class="abstract-display">
            <p>With the increasing deployment of artificial intelligence (AI) technologies, the potential of humans working with AI agents has been growing at a great speed. Human-AI teaming is an important paradigm for studying various aspects when humans and AI agents work together. The unique aspect of Human-AI teaming research is the need to jointly study humans and AI agents, demanding multidisciplinary research efforts from machine learning to human-computer interaction, robotics, cognitive science, neuroscience, psychology, social science, and complex systems. However, existing platforms for Human-AI teaming research are limited, often supporting oversimplified scenarios and a single task, or specifically focusing on either human-teaming research or multi-agent AI algorithms. We introduce \textbf{CREW}, a platform to facilitate Human-AI teaming research in real-time decision-making scenarios and engage collaborations from multiple scientific disciplines, with a strong emphasis on human involvement. It includes pre-built tasks for cognitive studies and Human-AI teaming with expandable potentials from our modular design. Following conventional cognitive neuroscience research, CREW also supports multimodal human physiological signal recording for behavior analysis. Moreover, CREW benchmarks real-time human-guided reinforcement learning agents using state-of-the-art algorithms and well-tuned baselines. With CREW, we were able to conduct 50 human subject studies within a week to verify the effectiveness of our benchmark.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QezxDgd5hf">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QezxDgd5hf.html">Mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">João Bravo &middot; Jacopo Bono &middot; Hugo Ferreira &middot; Pedro Saleiro &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QezxDgd5hf"></div>

    <a href="paper_pages/QezxDgd5hf.html">
        <img src="http://img.youtube.com/vi/IdteTB8IzP8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QezxDgd5hf" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QezxDgd5hf" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QezxDgd5hf">
                Abstract <i id="caret-QezxDgd5hf" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QezxDgd5hf">
        <div class="abstract-display">
            <p>Systems characterized by evolving interactions, prevalent in social, financial, and biological domains, are effectively modeled as continuous-time dynamic graphs (CTDGs). To manage the scale and complexity of these graph datasets, machine learning (ML) approaches have become essential. However, CTDGs pose challenges for ML because traditional static graph methods fail to account for event timings naturally. Newer approaches, such as graph recurrent neural networks (GRNNs), are inherently time-aware and offer advantages over static methods for CTDGs. Yet, GRNNs face another issue: the short truncation of backpropagation-through-time (BPTT) whose impact has never been properly examined until now. In this work, we demonstrate that this truncation can limit the learning of dependencies more than a hop away, resulting in reduced performance. Through experiments on a novel synthetic task as well as real-world datasets, we reveal that there exists a performance gap between full backpropagation-through-time (F-BPTT) and the truncated backpropagation-through-time (T-BPTT) commonly used to train GRNN models. We term this gap the "truncation gap" and argue that understanding and addressing it is essential as the importance of CTDGs grows, discussing potential future directions of research for this type of models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MHJlFCqXdA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MHJlFCqXdA.html">Is Value Functions Estimation with Classification Plug-and- play for Offline Reinforcement Learning?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Denis Tarasov &middot; Kirill Brilliantov &middot; Dmitrii Kharlapenko</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MHJlFCqXdA"></div>

    <a href="paper_pages/MHJlFCqXdA.html">
        <img src="http://img.youtube.com/vi/xwfQ2Oa6ycs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MHJlFCqXdA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MHJlFCqXdA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MHJlFCqXdA">
                Abstract <i id="caret-MHJlFCqXdA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MHJlFCqXdA">
        <div class="abstract-display">
            <p>In deep Reinforcement Learning (RL), value functions are typically approximated using deep neural networks and trained via mean squared error regression objectives to fit the true value functions. Recent research has proposed an alternative approach, utilizing the cross-entropy classification objective, which has demonstrated improved performance and scalability of RL algorithms. However, existing study have not extensively benchmarked the effects of this replacement across various domains, as the primary objective was to demonstrate the efficacy of the concept across a broad spectrum of tasks, without delving into in-depth analysis. Our work seeks to empirically investigate the impact of such a replacement in an offline RL setup and analyze the effects of different aspects on performance. Through large-scale experiments conducted across a diverse range of tasks using different algorithms, we aim to gain deeper insights into the implications of this approach. Our results reveal that incorporating this change can lead to superior performance over state-of-the-art solutions for some algorithms in certain tasks, while maintaining comparable performance levels in other tasks, however for other algorithms this modification might lead to the dramatic performance drop. This findings are crucial for further application of classification approach in research and practical tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lIy0TEUou7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lIy0TEUou7.html">Modular Quantization-Aware Training for 6D Object Pose Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saqib Javed &middot; Chengkun Li &middot; Andrew Lawrence Price &middot; Yinlin Hu &middot; Mathieu Salzmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lIy0TEUou7"></div>

    <a href="paper_pages/lIy0TEUou7.html">
        <img src="http://img.youtube.com/vi/EBNr0qNem8U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lIy0TEUou7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lIy0TEUou7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lIy0TEUou7">
                Abstract <i id="caret-lIy0TEUou7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lIy0TEUou7">
        <div class="abstract-display">
            <p>Edge applications, such as collaborative robotics and spacecraft rendezvous, demand efficient 6D object pose estimation on resource-constrained embedded platforms. Existing 6D object pose estimation networks are often too large for such deployments, necessitating compression while maintaining reliable performance. To address this challenge, we introduce Modular Quantization-Aware Training (MQAT), an adaptive and mixed-precision quantization-aware training strategy that exploits the modular structure of modern 6D object pose estimation architectures. MQAT guides a systematic gradated modular quantization sequence and determines module-specific bit precisions, leading to quantized models that outperform those produced by state-of-the-art uniform and mixed-precision quantization techniques. Our experiments showcase the generality of MQAT across datasets, architectures, and quantization algorithms. Additionally, we observe that MQAT quantized models can achieve an accuracy boost (>7% ADI-0.1d) over the baseline full-precision network while reducing model size by a factor of 4x or more.
Project Page: https://saqibjaved1.github.io/MQAT_</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tYxRyNT0TC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tYxRyNT0TC.html">Perception Stitching: Zero-Shot Perception Encoder Transfer for Visuomotor Robot Policies</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pingcheng Jian &middot; Easop Lee &middot; Zachary I. Bell &middot; Michael M. Zavlanos &middot; Boyuan Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tYxRyNT0TC"></div>

    <a href="paper_pages/tYxRyNT0TC.html">
        <img src="http://img.youtube.com/vi/H6SD9Tcvhrg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tYxRyNT0TC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tYxRyNT0TC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tYxRyNT0TC">
                Abstract <i id="caret-tYxRyNT0TC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tYxRyNT0TC">
        <div class="abstract-display">
            <p>Vision-based imitation learning has shown promising capabilities of endowing robots with various motion skills given visual observation. However, current visuomotor policies fail to adapt to drastic changes in their visual observations. We present Perception Stitching that enables strong zero-shot adaptation to large visual changes by directly stitching novel combinations of visual encoders. Our key idea is to enforce modularity of visual encoders by aligning the latent visual features among different visuomotor policies. Our method disentangles the perceptual knowledge with the downstream motion skills and allows the reuse of the visual encoders by directly stitching them to a policy network trained with partially different visual conditions. We evaluate our method in various simulated and real-world manipulation tasks. While baseline methods failed at all attempts, our method could achieve zero-shot success in real-world visuomotor tasks. Our quantitative and qualitative analysis of the learned features of the policy network provides more insights into the high performance of our proposed method.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4c9UzDhg49">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4c9UzDhg49.html">On the theoretical limit of gradient descent for Simple Recurrent Neural Networks with finite precision</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Volodimir Mitarchuk &middot; Rémi Emonet &middot; Remi Eyraud &middot; Amaury Habrard</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4c9UzDhg49"></div>

    <a href="paper_pages/4c9UzDhg49.html">
        <img src="http://img.youtube.com/vi/ap6LOok_Vtk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4c9UzDhg49" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4c9UzDhg49" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4c9UzDhg49">
                Abstract <i id="caret-4c9UzDhg49" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4c9UzDhg49">
        <div class="abstract-display">
            <p>Despite their great practical successes, the understanding of neural network behavior is still
a topical research issue. In particular, the class of functions learnable in the context of a
finite precision configuration is an open question. In this paper, we propose to study the
limits of gradient descent when such a configuration is set for the class of Simple Recurrent
Networks (SRN). We exhibit conditions under which the gradient descend will provably fail.
We also design a class of SRN based on Deterministic finite State Automata (DFA) that
fulfills the failure requirements. The definition of this class is constructive: we propose an
algorithm that, from any DFA, constructs a SRN that computes exactly the same function,
a result of interest by its own.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-SP8DLl6jgb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/SP8DLl6jgb.html">Feature Distillation Improves Zero-Shot Transfer from Synthetic Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Niclas Popp &middot; Jan Hendrik Metzen &middot; Matthias Hein</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-SP8DLl6jgb"></div>

    <a href="paper_pages/SP8DLl6jgb.html">
        <img src="http://img.youtube.com/vi/KbdacNWGiAM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-SP8DLl6jgb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-SP8DLl6jgb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-SP8DLl6jgb">
                Abstract <i id="caret-SP8DLl6jgb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-SP8DLl6jgb">
        <div class="abstract-display">
            <p>Vision-language foundation models such as CLIP have showcased impressive zero-shot capabilities. However, their applicability in resource-constrained environments is limited due to their size and the resulting latency. Knowledge distillation allows to mitigate these challenges by distilling small image encoders that can replace the large CLIP image encoder. In a zero-shot setting, where only the class names are known, no real domain images can be used for this process. Instead, we investigate the use of synthetic images for this purpose. Unlike existing works that focus on improving the quality of synthetic images to bridge the performance gap compared to training on natural images, we find the choice of loss to be a crucial factor. Specifically, minimizing only the distance between the student and teacher image features, without incorporating image captions in the loss function, increases the robustness to spurious features and data corruptions. As a result, this feature distillation approach greatly improves the transfer performance from synthetic to real images. Leveraging these insights, we are able to train domain-specific students that achieve zero-shot performance comparable to a ViT-B/32 teacher on six fine-grained classification datasets while using up to 92% fewer parameters.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QdGtwjDgub">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QdGtwjDgub.html">Contaminated Online Convex Optimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tomoya Kamijima &middot; Shinji Ito</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QdGtwjDgub"></div>

    <a href="paper_pages/QdGtwjDgub.html">
        <img src="https://drive.google.com/thumbnail?id=1EwrCZxiGUj_iw5_i787d88x3Nqy-Kcij" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QdGtwjDgub" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QdGtwjDgub" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QdGtwjDgub">
                Abstract <i id="caret-QdGtwjDgub" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QdGtwjDgub">
        <div class="abstract-display">
            <p>In online convex optimization, some efficient algorithms have been designed for each of the individual classes of objective functions, e.g., convex, strongly convex, and exp-concave. However, existing regret analyses, including those of universal algorithms, are limited to cases in which the objective functions in all rounds belong to the same class and cannot be applied to cases in which the property of objective functions may change in each time step. This paper introduces a novel approach to address such cases, proposing a new regime we term as \textit{contaminated} online convex optimization. For the contaminated case, we demonstrate that the regret is lower bounded by $\Omega(\log T + \sqrt{k})$. Here, $k$ signifies the level of contamination in the objective functions. We also demonstrate that the regret is bounded by $O(\log T+\sqrt{k\log T})$ when universal algorithms are used. When our proposed algorithms with additional information are employed, the regret is bounded by $O(\log T+\sqrt{k})$, which matches the lower bound. These are intermediate bounds between a convex case and a strongly convex or exp-concave case.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lh6vOAHuvo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lh6vOAHuvo.html">AGaLiTe: Approximate Gated Linear Transformers for Online Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Subhojeet Pramanik &middot; Esraa Elelimy &middot; Marlos C. Machado &middot; Adam White</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lh6vOAHuvo"></div>

    <a href="paper_pages/lh6vOAHuvo.html">
        <img src="http://img.youtube.com/vi/-bTe48JIUds/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lh6vOAHuvo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lh6vOAHuvo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lh6vOAHuvo">
                Abstract <i id="caret-lh6vOAHuvo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lh6vOAHuvo">
        <div class="abstract-display">
            <p>In this paper we investigate transformer architectures designed for partially observable online reinforcement learning. The self-attention mechanism in the transformer architecture is capable of capturing long-range dependencies and it is the main reason behind its effectiveness in processing sequential data. Nevertheless, despite their success, transformers have two significant drawbacks that still limit their applicability in online reinforcement learning: (1) in order to remember all past information, the self-attention mechanism requires access to the whole history to be provided as context. (2) The inference cost in transformers is expensive. In this paper, we introduce recurrent alternatives to the transformer self-attention mechanism that offer context-independent inference cost, leverage long-range dependencies effectively, and performs well in online reinforcement learning task. We quantify the impact of the different components of our architecture in a diagnostic environment and assess performance gains in 2D and 3D pixel-based partially-observable environments (e.g. T-Maze, Mystery Path, Craftax, and Memory Maze). Compared with a state-of-the-art architecture, GTrXL, inference in our approach is at least 40% cheaper while reducing memory use more than 50%. Our approach either performs similarly or better than GTrXL, improving more than 37% upon GTrXL performance in harder tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0uwe0z2Hqm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0uwe0z2Hqm.html">Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ahmad Naser Eddin &middot; Jacopo Bono &middot; David Oliveira Aparicio &middot; Hugo Ferreira &middot; Pedro Manuel Pinto Ribeiro &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0uwe0z2Hqm"></div>

    <a href="paper_pages/0uwe0z2Hqm.html">
        <img src="http://img.youtube.com/vi/LU0324z6mHo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0uwe0z2Hqm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0uwe0z2Hqm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0uwe0z2Hqm">
                Abstract <i id="caret-0uwe0z2Hqm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0uwe0z2Hqm">
        <div class="abstract-display">
            <p>Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems. Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning. Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications. This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements. We benchmark DGS against state-of-the-art (SOTA) feature engineering and graph neural network methods using five diverse datasets. The results indicate that DGS achieves competitive performance while inference speed improves between 4x and 12x compared to other deep learning approaches on our benchmark datasets. Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fJEsas1z8J">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fJEsas1z8J.html">MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kemal Oksuz &middot; Selim Kuzucu &middot; Tom Joy &middot; Puneet K. Dokania</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fJEsas1z8J"></div>

    <a href="paper_pages/fJEsas1z8J.html">
        <img src="http://img.youtube.com/vi/PzyXl5VBrqE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fJEsas1z8J" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fJEsas1z8J" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fJEsas1z8J">
                Abstract <i id="caret-fJEsas1z8J" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fJEsas1z8J">
        <div class="abstract-display">
            <p>Combining the strengths of many existing predictors to obtain a Mixture of Experts which is superior to its individual components is an effective way to improve the performance without having to develop new architectures or train a model from scratch. However, surprisingly, we find that naively combining off-the-shelf object detectors in a similar way to Deep Ensembles, can often lead to degraded performance. We identify that the primary cause of this issue is that the predictions of the experts do not match their performance, a term referred to as miscalibration. Consequently, the most confident detector dominates the final predictions, preventing the mixture from leveraging all the predictions from the experts appropriately. To address this, when constructing the Mixture of Experts for object detection, we propose to combine their predictions in a manner which reflects the individual performance of the experts; an objective we achieve by first calibrating the predictions before filtering and refining them. We term this approach the Mixture of Calibrated Experts (MoCaE) and demonstrate its effectiveness through extensive experiments on 5 different detection tasks, showing that it: (i) improves object detectors on COCO and instance segmentation methods on LVIS by up to $\sim 2.5$ AP; (ii) reaches state-of-the-art on COCO test-dev with $65.1$ AP and on DOTA with $82.62$ $\mathrm{AP_{50}}$; (iii) outperforms single models consistently on recent detection tasks such as Open Vocabulary Object Detection. Code is available at: https://github.com/fiveai/MoCaE</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6j5M75iK3a">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6j5M75iK3a.html">Continual Learning in Open-vocabulary Classification with Complementary Memory Systems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zhen Zhu &middot; Weijie Lyu &middot; Yao Xiao &middot; Derek Hoiem</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6j5M75iK3a"></div>

    <a href="paper_pages/6j5M75iK3a.html">
        <img src="http://img.youtube.com/vi/RkmeJupwNkY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6j5M75iK3a" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6j5M75iK3a" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6j5M75iK3a">
                Abstract <i id="caret-6j5M75iK3a" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6j5M75iK3a">
        <div class="abstract-display">
            <p>We introduce a method for flexible and efficient continual learning in open-vocabulary image classification, drawing inspiration from the complementary learning systems observed in human cognition. Specifically, we propose to combine predictions from a CLIP zero-shot model and the exemplar-based model, using the zero-shot estimated probability that a sample's class is within the exemplar classes. We also propose a ``tree probe'' method, an adaption of lazy learning principles, which enables fast learning from new examples with competitive accuracy to batch-trained linear models. We test in data incremental, class incremental, and task incremental settings, as well as ability to perform flexible inference on varying subsets of zero-shot and learned categories. Our proposed method achieves a good balance of learning speed, target task effectiveness, and zero-shot effectiveness. Code is available at https://github.com/jessemelpolio/TreeProbe.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oG65SjZNIF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oG65SjZNIF.html">Expressive Higher-Order Link Prediction through Hypergraph Symmetry Breaking</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Simon Zhang &middot; Cheng Xin &middot; Tamal K. Dey</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oG65SjZNIF"></div>

    <a href="paper_pages/oG65SjZNIF.html">
        <img src="http://img.youtube.com/vi/ZRiaYiN6BNw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oG65SjZNIF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oG65SjZNIF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oG65SjZNIF">
                Abstract <i id="caret-oG65SjZNIF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oG65SjZNIF">
        <div class="abstract-display">
            <p>A hypergraph consists of a set of nodes along with a collection of subsets of the nodes called hyperedges. Higher order link prediction is the task of predicting the existence of a missing hyperedge in a hypergraph. A hyperedge representation learned for higher order link prediction is fully expressive when it does not lose distinguishing power up to an isomorphism. Many existing hypergraph representation learners, are bounded in expressive power by the Generalized Weisfeiler Lehman-1 (GWL-1) algorithm, a generalization of the Weisfeiler Lehman-1 (WL-1) algorithm. The WL-1 algorithm can approximately decide whether two graphs are isomorphic. However, GWL-1 has limited expressive power. In fact, GWL-1 can only view the hypergraph as a collection of trees rooted at each of the nodes in the hypergraph. Furthermore, message passing on hypergraphs can already be computationally expensive, particularly with limited GPU device memory. To address these limitations, we devise a preprocessing algorithm that can identify certain regular subhypergraphs exhibiting symmetry with respect to GWL-1. Our preprocessing algorithm runs once with the time complexity linear in the size of the input hypergraph. During training, we randomly drop the hyperedges of the subhypergraphs identifed by the algorithm and add  covering hyperedges to break symmetry. We show that our method improves the expressivity of GWL-1. Our extensive experiments 1 also demonstrate the effectiveness of our approach for higher-order link prediction on both graph and hypergraph datasets with negligible change in computation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mDGvrH7lju">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mDGvrH7lju.html">CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hee-Jun Jung &middot; Jaehyoung Jeong &middot; Kangil Kim</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mDGvrH7lju"></div>

    <a href="paper_pages/mDGvrH7lju.html">
        <img src="http://img.youtube.com/vi/R03AoD3SRZ8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mDGvrH7lju" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mDGvrH7lju" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mDGvrH7lju">
                Abstract <i id="caret-mDGvrH7lju" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mDGvrH7lju">
        <div class="abstract-display">
            <p>Symmetries of input and latent vectors have provided valuable insights for disentanglement learning in VAEs. However, only a few works were proposed as an unsupervised method, and even these works require known factor information in training data. We propose a
novel method, Composite Factor-Aligned Symmetry Learning (CFASL), which is integrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information. CFASL incorporates three novel features for learning symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learnable symmetry code-book 2) Learning a composite symmetry to express unknown factors change between two random samples by learning factor-aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we propose an extended evaluation metric for multi-factor changes in comparison to disentanglement evaluation in VAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a significant improvement of disentanglement in single-factor change, and multi-factor change conditions compared to state-of-the-art methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-IJlbuSrXmk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/IJlbuSrXmk.html">Audio-Visual Dataset Distillation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saksham Singh Kushwaha &middot; Siva Sai Nagender Vasireddy &middot; Kai Wang &middot; Yapeng Tian</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-IJlbuSrXmk"></div>

    <a href="paper_pages/IJlbuSrXmk.html">
        <img src="http://img.youtube.com/vi/SfXLu8D_K6o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-IJlbuSrXmk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-IJlbuSrXmk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-IJlbuSrXmk">
                Abstract <i id="caret-IJlbuSrXmk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-IJlbuSrXmk">
        <div class="abstract-display">
            <p>In this article, we introduce \textit{audio-visual dataset distillation}, a task to construct a smaller yet representative synthetic audio-visual dataset that maintains the cross-modal semantic association between audio and visual modalities. Dataset distillation techniques have primarily focused on image classification. However, with the growing capabilities of audio-visual models and the vast datasets required for their training, it is necessary to explore distillation methods beyond the visual modality. Our approach builds upon the foundation of Distribution Matching (DM), extending it to handle the unique challenges of audio-visual data. A key challenge is to jointly learn synthetic data that distills both the modality-wise information and natural alignment from real audio-visual data. We introduce a vanilla audio-visual distribution matching framework that separately trains visual-only and audio-only DM components, enabling us to investigate the effectiveness of audio-visual integration and various multimodal fusion methods. To address the limitations of unimodal distillation, we propose two novel matching losses: implicit cross-matching and cross-modal gap matching. These losses work in conjunction with the vanilla unimodal distribution matching loss to enforce cross-modal alignment and enhance the audio-visual dataset distillation process. Extensive audio-visual classification and retrieval experiments on four audio-visual datasets, AVE, MUSIC-21, VGGSound, and VGGSound-10K, demonstrate the effectiveness of our proposed matching approaches and validate the benefits of audio-visual integration with condensed data. This work establishes a new frontier in audio-visual dataset distillation, paving the way for further advancements in this exciting field. \textit{Our source code and pre-trained models will be released}.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3YlOr7BHkx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3YlOr7BHkx.html">Mislabeled examples detection viewed as probing machine learning models: concepts, survey and extensive benchmark</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Thomas George &middot; Pierre Nodet &middot; Alexis Bondu &middot; Vincent Lemaire</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3YlOr7BHkx"></div>

    <a href="paper_pages/3YlOr7BHkx.html">
        <img src="http://img.youtube.com/vi/fT9VZXs0nh8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3YlOr7BHkx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3YlOr7BHkx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3YlOr7BHkx">
                Abstract <i id="caret-3YlOr7BHkx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3YlOr7BHkx">
        <div class="abstract-display">
            <p>Mislabeled examples are ubiquitous in real-world machine learning datasets, advocating the development of techniques for automatic detection. We show that most mislabeled detection methods can be viewed as probing trained machine learning models using a few core principles. We formalize a modular framework that encompasses these methods, parameterized by only 4 building blocks, as well as a Python library that demonstrates that these principles can actually be implemented. The focus is on classifier-agnostic concepts, with an emphasis on adapting methods developed for deep learning models to non-deep classifiers for tabular data. We benchmark existing methods on (artificial) Completely At Random (NCAR) as well as (realistic) Not At Random (NNAR) labeling noise from a variety of tasks with imperfect labeling rules. This benchmark provides new insights as well as limitations of existing methods in this setup.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2noXK5KBbx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2noXK5KBbx.html">Graph Structure Learning with Interpretable Bayesian Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Max Wasserman &middot; Gonzalo Mateos</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2noXK5KBbx"></div>

    <a href="paper_pages/2noXK5KBbx.html">
        <img src="http://img.youtube.com/vi/zcYD-r8DlUI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2noXK5KBbx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2noXK5KBbx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2noXK5KBbx">
                Abstract <i id="caret-2noXK5KBbx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2noXK5KBbx">
        <div class="abstract-display">
            <p>Graphs serve as generic tools to encode the underlying relational structure of data. Often this graph is not given, and so the task of inferring it from nodal observations becomes important. Traditional approaches formulate a convex inverse problem with a smoothness promoting objective and rely on iterative methods to obtain a solution. In supervised settings where graph labels are available, one can unroll and truncate these iterations into a deep network that is trained end-to-end. Such a network is parameter efficient and inherits inductive bias from the optimization formulation, an appealing aspect for data constrained settings in, e.g., medicine, finance, and the natural sciences. But typically such settings care equally about \textit{uncertainty} over edge predictions, not just point estimates. Here we introduce novel iterations with \textit{independently interpretable parameters}, i.e., parameters whose values - independent of other parameters' settings - proportionally influence characteristics of the estimated graph, such as edge sparsity. After unrolling these iterations, prior knowledge over such graph characteristics shape \textit{prior distributions} over these independently interpretable network parameters to yield a Bayesian neural network (BNN) capable of graph structure learning (GSL) from smooth signal observations. Fast execution and parameter efficiency allow for high-fidelity posterior approximation via Markov Chain Monte Carlo (MCMC) and thus uncertainty quantification on edge predictions. Informative priors unlock modeling tools from Bayesian statistics like prior predictive checks. Synthetic and real data experiments corroborate this model's ability to provide well-calibrated estimates of uncertainty, in test cases that include unveiling economic sector modular structure from S$\&$P$500$ data and recovering pairwise digit similarities from MNIST images. Overall, this framework enables GSL in modest-scale applications where uncertainty on the data structure is paramount.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-hrKHkmLUFk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/hrKHkmLUFk.html">Multi-intention Inverse Q-learning for Interpretable Behavior Representation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hao Zhu &middot; Brice De La Crompe &middot; Gabriel Kalweit &middot; Artur Schneider &middot; Maria Kalweit &middot; Ilka Diester &middot; Joschka Boedecker</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-hrKHkmLUFk"></div>

    <a href="paper_pages/hrKHkmLUFk.html">
        <img src="http://img.youtube.com/vi/0u-fboAO6-I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-hrKHkmLUFk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-hrKHkmLUFk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-hrKHkmLUFk">
                Abstract <i id="caret-hrKHkmLUFk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-hrKHkmLUFk">
        <div class="abstract-display">
            <p>In advancing the understanding of natural decision-making processes, inverse reinforcement learning (IRL) methods have proven instrumental in reconstructing animal's intentions underlying complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To address this challenge, we introduce the class of hierarchical inverse Q-learning (HIQL) algorithms. Through an unsupervised learning process, HIQL divides expert trajectories into multiple intention segments, and solves the IRL problem independently for each. Applying HIQL to simulated experiments and several real animal behavior datasets, our approach outperforms current benchmarks in behavior prediction and produces interpretable reward functions. Our results suggest that the intention transition dynamics underlying complex decision-making behavior is better modeled by a step function instead of a smoothly varying function. This advancement holds promise for neuroscience and cognitive science, contributing to a deeper understanding of decision-making and uncovering underlying brain mechanisms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-kUuPUIPvJ6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/kUuPUIPvJ6.html">Support-Set Context Matters for Bongard Problems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nikhil Raghuraman &middot; Adam W Harley &middot; Leonidas Guibas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-kUuPUIPvJ6"></div>

    <a href="paper_pages/kUuPUIPvJ6.html">
        <img src="http://img.youtube.com/vi/JO00GQHp0mQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-kUuPUIPvJ6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-kUuPUIPvJ6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-kUuPUIPvJ6">
                Abstract <i id="caret-kUuPUIPvJ6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-kUuPUIPvJ6">
        <div class="abstract-display">
            <p>Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract “concept” from a set of positive and negative “support” images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, most existing methods have reached at best 69% accuracy (where chance is 50%). Low accuracy is often attributed to neural nets’ lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not adapt image features given information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because the “key concept” in a typical Bongard problem can often only be distinguished using multiple positives and multiple negatives. We explore simple methods to incorporate this context and show substantial gains over prior works, leading to new state-of-the-art accuracy on Bongard-LOGO (75.3%) and Bongard-HOI (76.4%) compared to methods with equivalent vision backbone architectures and strong performance on the original Bongard problem set (60.8%).  Code is available at https://github.com/nraghuraman/bongard-context.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-FNBv2vweBI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/FNBv2vweBI.html">Constraining Generative Models for Engineering Design with Negative Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lyle Regenwetter &middot; Giorgio Giannone &middot; Akash Srivastava &middot; Dan Gutfreund &middot; Faez Ahmed</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-FNBv2vweBI"></div>

    <a href="paper_pages/FNBv2vweBI.html">
        <img src="http://img.youtube.com/vi/dFwRUL2qB3o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-FNBv2vweBI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-FNBv2vweBI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-FNBv2vweBI">
                Abstract <i id="caret-FNBv2vweBI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-FNBv2vweBI">
        <div class="abstract-display">
            <p>Generative models have recently achieved remarkable success and widespread adoption in society, yet they still often struggle to generate realistic and accurate outputs. This challenge extends beyond language and vision into fields like engineering design, where safety-critical engineering standards and non-negotiable physical laws tightly constrain what outputs are considered acceptable. 
In this work, we introduce two approaches to guide models toward constraint-satisfying outputs using `negative data' -- examples of what to avoid. Our negative data generative models (NDGMs) outperform state-of-the-art NDGMs by 4x in constraint satisfaction and easily outperform classic generative models using 8x less data in certain problems. To demonstrate this, we rigorously benchmark our NDGMs against 14 baseline models across numerous synthetic and real engineering problems, such as ship hulls with hydrodynamic constraints and vehicle design with impact safety constraints. Our benchmarks showcase both the best-in-class performance of our new NDGM models and the widespread dominance of NDGMs over classic generative models in general. In doing so, we advocate for the more widespread use of NDGMs in engineering design tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-llQXLfbGOq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/llQXLfbGOq.html">Attention Normalization Impacts Cardinality Generalization in Slot Attention</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Markus Krimmel &middot; Jan Achterhold &middot; Joerg Stueckler</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-llQXLfbGOq"></div>

    <a href="paper_pages/llQXLfbGOq.html">
        <img src="http://img.youtube.com/vi/dnTrHyZgyCY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-llQXLfbGOq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-llQXLfbGOq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-llQXLfbGOq">
                Abstract <i id="caret-llQXLfbGOq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-llQXLfbGOq">
        <div class="abstract-display">
            <p>Object-centric scene decompositions are important representations for downstream tasks in fields such as computer vision and robotics. The recently proposed Slot Attention module, already leveraged by several derivative works for image segmentation and object tracking in videos, is a deep learning component which performs unsupervised object-centric scene decomposition on input images. It is based on an attention architecture, in which latent slot vectors, which hold compressed information on objects, attend to localized perceptual features from the input image. In this paper, we demonstrate that design decisions on normalizing the aggregated values in the attention architecture have considerable impact on the capabilities of Slot Attention to generalize to a higher number of slots and objects as seen during training. We propose and investigate alternatives to the original normalization scheme which increase the generalization capabilities of Slot Attention to varying slot and object counts, resulting in performance gains on the task of unsupervised image segmentation. The newly proposed normalizations represent minimal and easy to implement modifications of the usual Slot Attention module, changing the value aggregation mechanism from a weighted mean operation to a scaled weighted sum operation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2D36otXvBE">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2D36otXvBE.html">Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chiu-Chou Lin &middot; Yu-Wei Shih &middot; Kuei-Ting Kuo &middot; Yu-Cheng Chen &middot; Chien-Hua Chen &middot; Wei-Chen Chiu &middot; I-Chen Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2D36otXvBE"></div>

    <a href="paper_pages/2D36otXvBE.html">
        <img src="http://img.youtube.com/vi/CmgoUtRqmI8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2D36otXvBE" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2D36otXvBE" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2D36otXvBE">
                Abstract <i id="caret-2D36otXvBE" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2D36otXvBE">
        <div class="abstract-display">
            <p>\textbf{How can balance be quantified in game settings?} This question is crucial for game designers, especially in player-versus-player (PvP) games, where analyzing the strength relations among predefined team compositions—such as hero combinations in multiplayer online battle arena (MOBA) games or decks in card games—is essential for enhancing gameplay and achieving balance. We have developed two advanced measures that extend beyond the simplistic win rate to quantify balance in zero-sum competitive scenarios. These measures are derived from win value estimations, which employ strength rating approximations via the Bradley-Terry model and counter relationship approximations via vector quantization, significantly reducing the computational complexity associated with traditional win value estimations. Throughout the learning process of these models, we identify useful categories of compositions and pinpoint their counter relationships, aligning with the experiences of human players without requiring specific game knowledge. Our methodology hinges on a simple technique to enhance codebook utilization in discrete representation with a deterministic vector quantization process for an extremely small state space. Our framework has been validated in popular online games, including \textit{Age of Empires II}, \textit{Hearthstone}, \textit{Brawl Stars}, and \textit{League of Legends}. The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis. Ultimately, our findings contribute to a deeper understanding of PvP game dynamics and present a methodology that significantly improves game balance evaluation and design.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-IEKtMMSblm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/IEKtMMSblm.html">PLUM: Improving Inference Efficiency By Leveraging Repetition-Sparsity Trade-Off</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sachit Kuhar &middot; Yash Jain &middot; Alexey Tumanov</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-IEKtMMSblm"></div>

    <a href="paper_pages/IEKtMMSblm.html">
        <img src="http://img.youtube.com/vi/nE_CYDWqQ_I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-IEKtMMSblm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-IEKtMMSblm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-IEKtMMSblm">
                Abstract <i id="caret-IEKtMMSblm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-IEKtMMSblm">
        <div class="abstract-display">
            <p>Efficient inference of Deep Neural Networks (DNNs) on resource-constrained edge devices is essential. Quantization and sparsity are key techniques that translate to repetition and sparsity within tensors at the hardware-software interface. This paper introduces the concept of repetition-sparsity trade-off that helps explain computational efficiency during inference. We propose PLUM, a unified co-design framework that integrates DNN inference systems and quantization (forward and backward pass) to leverage the repetition-sparsity trade-off to improve inference efficiency. Our results demonstrate that PLUM’s quantization method is more accurate than binary quantization with the same number of non-zero weights. Detailed analysis indicates that signed binarization generates a smaller distribution of effectual (non-zero) parameters nested within a larger distribution of total parameters of latent full-precision weights for a DNN block. Finally, the proposed PLUM framework achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces density by 2.8× compared to binary methods while retaining top-1 accuracy when compared to prior-art methods for ResNets on ImageNet (by achieving 66.2% top-1 accuracy), presenting an alternative solution for deploying efficient models in resource-limited environments</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1WqLLYgBNt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1WqLLYgBNt.html">Do not trust what you trust: Miscalibration in Semisupervised Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shambhavi Mishra &middot; Balamurali Murugesan &middot; Ismail Ben Ayed &middot; Marco Pedersoli &middot; Jose Dolz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1WqLLYgBNt"></div>

    <a href="paper_pages/1WqLLYgBNt.html">
        <img src="http://img.youtube.com/vi/Gj3-NgXo9Wk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1WqLLYgBNt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1WqLLYgBNt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1WqLLYgBNt">
                Abstract <i id="caret-1WqLLYgBNt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1WqLLYgBNt">
        <div class="abstract-display">
            <p>State-of-the-art semi-supervised learning (SSL) approaches rely on highly confident predictions to serve as pseudo-labels that guide the training on unlabeled samples. An inherent drawback of this strategy stems from the quality of the uncertainty estimates, as pseudo-labels are filtered only based on their degree of uncertainty, regardless of the correctness of their predictions.  Thus, assessing and enhancing the uncertainty of network predictions is of paramount importance in the pseudo-labeling process. In this work, we empirically demonstrate that SSL methods based on pseudo-labels are significantly miscalibrated, and formally demonstrate the minimization of the min-entropy, a lower bound of the Shannon entropy, as a potential cause for miscalibration. To alleviate this issue, we integrate a simple penalty term, which enforces the logit distances of the predictions on unlabeled samples to remain low, preventing the network predictions to become overconfident. Comprehensive experiments on a variety of SSL image classification benchmarks demonstrate that the proposed solution systematically improves the calibration performance of relevant SSL models, while also enhancing their discriminative power, being an appealing addition to tackle SSL tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TB18G0w6Ld">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TB18G0w6Ld.html">Fairness Under Demographic Scarce Regime</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Patrik Joslin Kenfack &middot; Samira Ebrahimi Kahou &middot; Ulrich Aïvodji</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TB18G0w6Ld"></div>

    <a href="paper_pages/TB18G0w6Ld.html">
        <img src="http://img.youtube.com/vi/dLMC1IbR4LA/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TB18G0w6Ld" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TB18G0w6Ld" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TB18G0w6Ld">
                Abstract <i id="caret-TB18G0w6Ld" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TB18G0w6Ld">
        <div class="abstract-display">
            <p>Most existing works on fairness assume the model has full access to demographic information. However, there exist scenarios where demographic information is partially available because a record was not maintained throughout data collection or for privacy reasons. This setting is known as demographic scarce regime. Prior research has shown that training an attribute classifier to replace the missing sensitive attributes (proxy) can still improve fairness. However, using proxy-sensitive attributes worsens fairness-accuracy tradeoffs compared to true sensitive attributes. To address this limitation, we propose a framework to build attribute classifiers that achieve better fairness-accuracy tradeoffs. Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty.  We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes can negatively impact the fairness-accuracy tradeoff. Our experiments on five datasets showed that the proposed framework yields models with significantly better fairness-accuracy tradeoffs than classic attribute classifiers.  Surprisingly, our framework can outperform models trained with fairness constraints on the true sensitive attributes in most benchmarks. We also show that these findings are consistent with other uncertainty measures such as conformal prediction.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JxxkKt9yrx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JxxkKt9yrx.html">Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Raphael Lafargue &middot; Luke A Smith &middot; Franck VERMET &middot; Matthias Löwe &middot; Ian Reid &middot; Jack Valmadre &middot; Vincent Gripon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JxxkKt9yrx"></div>

    <a href="paper_pages/JxxkKt9yrx.html">
        <img src="http://img.youtube.com/vi/OB95-BLxE0s/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JxxkKt9yrx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JxxkKt9yrx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JxxkKt9yrx">
                Abstract <i id="caret-JxxkKt9yrx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JxxkKt9yrx">
        <div class="abstract-display">
            <p>The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i.e. allowing the same samples to appear in multiple tasks. This makes the CI misleading in that it takes into account the randomness of the sampler but not the data itself. To quantify the extent of this problem, we conduct a comparative analysis between CIs computed with and without replacement. These reveal a notable underestimation by the predominant method. This observation calls for a reevaluation of how we interpret confidence intervals and the resulting conclusions in FSL comparative studies. Our research demonstrates that the use of paired tests can partially address this issue. Additionally, we explore methods to further reduce the (size of the) CI by strategically sampling tasks of a specific size. We also introduce a new optimized benchmark, which can be accessed at https://github.com/RafLaf/FSL-benchmark-again</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-A6D3PYSyqJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/A6D3PYSyqJ.html">LINOCS: Lookahead Inference of Networked Operators for Continuous Stability</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Noga Mudrik &middot; Eva Yezerets &middot; Yenho Chen &middot; Christopher John Rozell &middot; Adam Shabti Charles</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-A6D3PYSyqJ"></div>

    <a href="paper_pages/A6D3PYSyqJ.html">
        <img src="http://img.youtube.com/vi/5XVYRHd5wGs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-A6D3PYSyqJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-A6D3PYSyqJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-A6D3PYSyqJ">
                Abstract <i id="caret-A6D3PYSyqJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-A6D3PYSyqJ">
        <div class="abstract-display">
            <p>Identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. For instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. Such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. Existing dynamical system identification methods often yield operators that accurately capture short-term behavior  but  fail to predict long-term trends, suggesting an incomplete capture of the underlying process. Methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. Here we introduce Lookahead-driven Inference of Networked Operators for Continuous Stability (LINOCS), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. LINOCS integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. We demonstrate LINOCS' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including  linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xI6cPQObp0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xI6cPQObp0.html">Incremental Spatial and Spectral Learning of Neural Operators for Solving Large-Scale PDEs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Robert Joseph George &middot; Jiawei Zhao &middot; Jean Kossaifi &middot; Zongyi Li &middot; Anima Anandkumar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xI6cPQObp0"></div>

    <a href="paper_pages/xI6cPQObp0.html">
        <img src="https://drive.google.com/thumbnail?id=1rCBmHPxSe_kVAdYX-PntVthA0g6nBYYv" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xI6cPQObp0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xI6cPQObp0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xI6cPQObp0">
                Abstract <i id="caret-xI6cPQObp0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xI6cPQObp0">
        <div class="abstract-display">
            <p>Fourier Neural Operators (FNO) offer a principled approach to solving challenging partial differential equations (PDE) such as turbulent flows. At the core of FNO is a spectral layer that leverages a discretization-convergent representation in the Fourier domain, and learns
weights over a fixed set of frequencies. However, training FNO presents two significant challenges, particularly in large-scale, high-resolution applications: (i) Computing Fourier transform on high-resolution inputs is computationally intensive but necessary since fine-scale details are needed for solving many PDEs, such as fluid flows, (ii) selecting the relevant set of frequencies in the spectral layers is challenging, and too many modes can lead to overfitting, while too few can lead to underfitting. To address these issues, we introduce
the Incremental Fourier Neural Operator (iFNO), which progressively increases both the number of frequency modes used by the model as well as the resolution of the training data. We empirically show that iFNO reduces total training time while maintaining or improving
generalization performance across various datasets. Our method demonstrates a 38% lower testing error, using 20% fewer frequency modes compared to the existing FNO, while also achieving up to 46% faster training and a 2.8x reduction in model size.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-38P40gJPrI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/38P40gJPrI.html">Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joo Young Choi &middot; Jaesung R. Park &middot; Inkyu Park &middot; Jaewoong Cho &middot; Albert No &middot; Ernest K. Ryu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-38P40gJPrI"></div>

    <a href="paper_pages/38P40gJPrI.html">
        <img src="http://img.youtube.com/vi/z-1LE2aNHak/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-38P40gJPrI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-38P40gJPrI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-38P40gJPrI">
                Abstract <i id="caret-38P40gJPrI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-38P40gJPrI">
        <div class="abstract-display">
            <p>Current state-of-the-art diffusion models employ U-Net architectures containing convolutional and (qkv) self-attention layers. The U-Net processes images while being conditioned on the time embedding input for each sampling step and the class or caption embedding input corresponding to the desired conditional generation. Such conditioning involves scale-and-shift operations to the convolutional layers but does not directly affect the attention layers. While these standard architectural choices are certainly effective, not conditioning the attention layers feels arbitrary and potentially suboptimal. In this work, we show that simply adding LoRA conditioning to the attention layers without changing or tuning the other parts of the U-Net architecture improves the image generation quality. For example, a drop-in addition of LoRA conditioning to EDM diffusion model yields FID scores of 1.91/1.75 for unconditional and class-conditional CIFAR-10 generation, improving upon the baseline of 1.97/1.79.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-30C9AWBW49">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/30C9AWBW49.html">Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chiu-Chou Lin &middot; Wei-Chen Chiu &middot; I-Chen Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-30C9AWBW49"></div>

    <a href="paper_pages/30C9AWBW49.html">
        <img src="http://img.youtube.com/vi/eR0Kx6xnH6Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-30C9AWBW49" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-30C9AWBW49" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-30C9AWBW49">
                Abstract <i id="caret-30C9AWBW49" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-30C9AWBW49">
        <div class="abstract-display">
            <p>Defining and measuring decision-making styles, also known as playstyles, is crucial in gaming, where these styles reflect a broad spectrum of individuality and diversity. However, finding a universally applicable measure for these styles poses a challenge. Building on $\textit{Playstyle Distance}$, the first unsupervised metric to measure playstyle similarity based on game screens and raw actions by identifying comparable states with discrete representations for computing policy distance, we introduce three enhancements to increase accuracy: multiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, and the utilization of the intersection-over-union method for efficient evaluation. These innovations not only advance measurement precision but also offer insights into human cognition of similarity. Across two racing games and seven Atari games, our techniques significantly improve the precision of zero-shot playstyle classification, achieving an accuracy exceeding 90\% with fewer than 512 observation-action pairs—less than half an episode of these games. Furthermore, our experiments with $\textit{2048}$ and $\textit{Go}$ demonstrate the potential of discrete playstyle measures in puzzle and board games. We also develop an algorithm for assessing decision-making diversity using these measures. Our findings improve the measurement of end-to-end game analysis and the evolution of artificial intelligence for diverse playstyles.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-cD209UgOX7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/cD209UgOX7.html">Scaling Up Bayesian Neural Networks with Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zahra Moslemi &middot; Yang Meng &middot; Shiwei Lan &middot; Babak Shahbaba</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-cD209UgOX7"></div>

    <a href="paper_pages/cD209UgOX7.html">
        <img src="https://drive.google.com/thumbnail?id=10cIAASi5ZN1O5MCm8ojIuTGZhEmygwE4" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-cD209UgOX7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-cD209UgOX7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-cD209UgOX7">
                Abstract <i id="caret-cD209UgOX7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-cD209UgOX7">
        <div class="abstract-display">
            <p>Bayesian Neural Networks (BNNs) offer a principled and natural framework for proper uncertainty quantification in the context of deep learning. They address the typical challenges associated with conventional deep learning methods, such as data insatiability, ad-hoc nature, and susceptibility to overfitting. However, their implementation typically either relies on Markov chain Monte Carlo (MCMC) methods, which are characterized by their computational intensity and inefficiency in a high-dimensional space, or variational inference methods, which tend to underestimate uncertainty. To address this issue, we propose a novel Calibration-Emulation-Sampling (CES) strategy to significantly enhance the computational efficiency of BNN. In this framework, during the initial calibration stage, we collect a small set of samples from the parameter space. These samples serve as training data for the emulator, which approximates the map between parameters and posterior probability. The trained emulator is then used for sampling from the posterior distribution at substantially higher speed compared to the standard BNN. Using simulated and real data, we demonstrate that our proposed method improves computational efficiency of BNN, while maintaining similar performance in terms of prediction accuracy and uncertainty quantification.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-cT8oOJ6Q6F">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/cT8oOJ6Q6F.html">Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jaedong Hwang &middot; Zhang-Wei Hong &middot; Eric R Chen &middot; Akhilan Boopathy &middot; Pulkit Agrawal &middot; Ila R Fiete</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-cT8oOJ6Q6F"></div>

    <a href="paper_pages/cT8oOJ6Q6F.html">
        <img src="http://img.youtube.com/vi/lV0clkUssvs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-cT8oOJ6Q6F" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-cT8oOJ6Q6F" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-cT8oOJ6Q6F">
                Abstract <i id="caret-cT8oOJ6Q6F" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-cT8oOJ6Q6F">
        <div class="abstract-display">
            <p>Animals and robots navigate through environments by building and refining maps of space. These maps enable functions including navigation back to home, planning, search and foraging. Here, we use observations from neuroscience, specifically the observed fragmentation of grid cell map in compartmentalized spaces, to propose and apply the concept of Fragmentation-and-Recall (FARMap) in the mapping of large spaces. Agents solve the mapping problem by building local maps via a surprisal-based clustering of space, which they use to set subgoals for spatial exploration. Agents build and use a local map to predict their observations; high surprisal leads to a "fragmentation event" that truncates the local map. At these events, the recent local map is placed into long-term memory (LTM) and a different local map is initialized. If observations at a fracture point match observations in one of the stored local maps, that map is recalled (and thus reused) from LTM. The fragmentation points induce a natural online clustering of the larger space, forming a set of intrinsic potential subgoals that are stored in LTM as a topological graph. Agents choose their next subgoal from the set of near and far potential subgoals from within the current local map or LTM, respectively. Thus, local maps guide exploration locally, while LTM promotes global exploration. We demonstrate that FARMap replicates the fragmentation points observed in animal studies. We evaluate FARMap on complex procedurally-generated spatial environments and realistic simulations to demonstrate that this mapping strategy much more rapidly covers the environment (number of agent steps and wall clock time) and is more efficient in active memory usage, without loss of performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dLaazW9zuF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dLaazW9zuF.html">Multi-Fidelity Active Learning with GFlowNets</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alex Hernández-García &middot; Nikita Saxena &middot; Moksh Jain &middot; Cheng-Hao Liu &middot; Yoshua Bengio</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dLaazW9zuF"></div>

    <a href="paper_pages/dLaazW9zuF.html">
        <img src="https://www.dailymotion.com/thumbnail/video/k1k8KKYS67DgFCB516w" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dLaazW9zuF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dLaazW9zuF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dLaazW9zuF">
                Abstract <i id="caret-dLaazW9zuF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dLaazW9zuF">
        <div class="abstract-display">
            <p>In the last decades, the capacity to generate large amounts of data in science and engineering applications has been growing steadily. Meanwhile, machine learning has progressed to become a suitable tool to process and utilise the available data. Nonetheless, many relevant scientific and engineering problems present challenges where current machine learning methods cannot yet efficiently leverage the available data and resources. For example, in scientific discovery, we are often faced with the problem of exploring very large, structured and high-dimensional spaces. Moreover, the high fidelity, black-box objective function is often very expensive to evaluate. Progress in machine learning methods that can efficiently tackle such challenges would help accelerate currently crucial areas such as drug and materials discovery. In this paper, we propose a multi-fidelity active learning algorithm with GFlowNets as a sampler, to efficiently discover diverse, high-scoring candidates where multiple approximations of the black-box function are available at lower fidelity and cost. Our evaluation on molecular discovery tasks shows that multi-fidelity active learning with GFlowNets can discover high-scoring candidates at a fraction of the budget of its single-fidelity counterpart while maintaining diversity, unlike RL-based alternatives. These results open new avenues for multi-fidelity active learning to accelerate scientific discovery and engineering design.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TAvGZm2Rqb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TAvGZm2Rqb.html">Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jean Vieira Alves &middot; Diogo Leitão &middot; Sérgio Jesus &middot; Marco O. P. Sampaio &middot; Javier Liébana &middot; Pedro Saleiro &middot; Mario A. T. Figueiredo &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TAvGZm2Rqb"></div>

    <a href="paper_pages/TAvGZm2Rqb.html">
        <img src="http://img.youtube.com/vi/R51SBj02RuU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TAvGZm2Rqb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TAvGZm2Rqb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TAvGZm2Rqb">
                Abstract <i id="caret-TAvGZm2Rqb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TAvGZm2Rqb">
        <div class="abstract-display">
            <p>Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key real-world aspects that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type I and type II errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset; and iii) not dealing with human work-capacity constraints. To address these issues, we propose the \textit{deferral under cost and capacity constraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost, subject to workload limitations. We test DeCCaF in a series of cost-sensitive fraud detection scenarios with different teams of 9 synthetic fraud analysts, with individual work-capacity constraints. The results demonstrate that our approach performs significantly better than the baselines in a wide array of scenarios, achieving an average $8.4\%$ reduction in the misclassification cost. The code used for the experiments is available at https://github.com/feedzai/deccaf</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-WzHuebRSgQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/WzHuebRSgQ.html">A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kiran Purohit &middot; Anurag Reddy Parvathgari &middot; Sourangshu Bhattacharya</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-WzHuebRSgQ"></div>

    <a href="paper_pages/WzHuebRSgQ.html">
        <img src="http://img.youtube.com/vi/egk0ZJb89Ao/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-WzHuebRSgQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-WzHuebRSgQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-WzHuebRSgQ">
                Abstract <i id="caret-WzHuebRSgQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-WzHuebRSgQ">
        <div class="abstract-display">
            <p>Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. Hence there is a need for a simple and efficient technique for whole network pruning. This paper proposes
a two-level hierarchical approach for whole-network filter pruning which is efficient and uses the classification loss as the final criterion. The lower-level algorithm (called filter-pruning) uses a sparse-approximation formulation based on linear approximation of filter weights. We explore two algorithms: orthogonal matching pursuit-based greedy selection and a greedy backward pruning approach. The backward pruning algorithm uses a novel closed-form error criterion for efficiently selecting the optimal filter at each stage, thus making the whole algorithm much faster. The higher-level algorithm (called layer-selection) greedily selects the best-pruned layer (pruning using the filter-selection algorithm) using a global pruning criterion. We propose algorithms for two different global-pruning criteria: (1) layerwise-relative error (HBGS), and (2) final classification error (HBGTS). Our suite of algorithms outperforms state-of-the-art pruning methods on ResNet18, ResNet32, ResNet56, VGG16, and ResNext101. Our method reduces the RAM requirement for ResNext101 from 7.6 GB to 1.5 GB and achieves a 94% reduction in FLOPS without losing accuracy on CIFAR-10.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DimPeeCxKO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DimPeeCxKO.html">Simple and Scalable Strategies to Continually Pre-train Large Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Adam Ibrahim &middot; Benjamin Thérien &middot; Kshitij Gupta &middot; Mats Leon Richter &middot; Quentin Gregory Anthony &middot; Eugene Belilovsky &middot; Timothée Lesort &middot; Irina Rish</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DimPeeCxKO"></div>

    <a href="paper_pages/DimPeeCxKO.html">
        <img src="http://img.youtube.com/vi/y4sUn3sYWFc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DimPeeCxKO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DimPeeCxKO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DimPeeCxKO">
                Abstract <i id="caret-DimPeeCxKO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DimPeeCxKO">
        <div class="abstract-display">
            <p>Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models—saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that autoregressive transformer-based LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tbOYJwXhcY">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tbOYJwXhcY.html">Misspecification-robust Sequential Neural Likelihood for Simulation-based Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ryan P. Kelly &middot; David J Nott &middot; David Tyler Frazier &middot; David J Warne &middot; Christopher Drovandi</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tbOYJwXhcY"></div>

    <a href="paper_pages/tbOYJwXhcY.html">
        <img src="http://img.youtube.com/vi/79u0rQTwUGY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tbOYJwXhcY" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tbOYJwXhcY" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tbOYJwXhcY">
                Abstract <i id="caret-tbOYJwXhcY" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tbOYJwXhcY">
        <div class="abstract-display">
            <p>Simulation-based inference techniques are indispensable for parameter estimation of mechanistic and simulable models with intractable likelihoods. While traditional statistical approaches like approximate Bayesian computation and Bayesian synthetic likelihood have been studied under well-specified and misspecified settings, they often suffer from inefficiencies due to wasted model simulations. Neural approaches, such as sequential neural likelihood (SNL) avoid this wastage by utilising all model simulations to train a neural surrogate for the likelihood function. However, the performance of SNL under model misspecification is unreliable and can result in overconfident posteriors centred around an inaccurate parameter estimate. In this paper, we propose a novel SNL method, which through the incorporation of additional adjustment parameters, is robust to model misspecification and capable of identifying features of the data that the model is not able to recover. We demonstrate the efficacy of our approach through several illustrative examples, where our method gives more accurate point estimates and uncertainty quantification than SNL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-5TaBxctwRZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/5TaBxctwRZ.html">Input Normalized Stochastic Gradient Descent Training for Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Salih Furkan Atici &middot; Hongyi Pan &middot; Ahmet Cetin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-5TaBxctwRZ"></div>

    <a href="paper_pages/5TaBxctwRZ.html">
        <img src="http://img.youtube.com/vi/QzTD0NgC3-A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-5TaBxctwRZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-5TaBxctwRZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-5TaBxctwRZ">
                Abstract <i id="caret-5TaBxctwRZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-5TaBxctwRZ">
        <div class="abstract-display">
            <p>In this paper, we propose a novel optimization algorithm for training machine learning models called Input Normalized Stochastic Gradient Descent (INSGD), inspired by the Normalized Least Mean Squares (NLMS) algorithm used in adaptive filtering. When training complex models on large datasets, choosing optimizer parameters, particularly the learning rate, is crucial to avoid divergence. Our algorithm updates the network weights using stochastic gradient descent with $\ell_1$ and $\ell_2$-based normalizations applied to the learning rate, similar to NLMS. However, unlike existing normalization methods, we exclude the error term from the normalization process and instead normalize the update term using the input vector to the neuron. Our experiments demonstrate that our optimization algorithm achieves higher accuracy levels compared to different initialization settings. We evaluate the efficiency of our training algorithm on benchmark datasets using a toy neural network and several mature modern deep networks including ResNet-20, ResNet-50, MobileNetV3, WResNet-18, and Vision Transformer. Our INSGD algorithm improves ResNet-20's CIFAR-10 test accuracy from 92.57\% to 92.67\%, MobileNetV3's CIFAR-10 test accuracy from 90.83\% to 91.13\%, WResNet-18 on CIFAR-100 from 78.24\% to 78.47\%, and ResNet-50's accuracy on ImageNet-1K validation dataset from 75.60\% to 75.92\%.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-c8WJ4Vozb2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/c8WJ4Vozb2.html">Correcting Flaws in Common Disentanglement Metrics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Louis Mahon &middot; Lei Sha &middot; Thomas Lukasiewicz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-c8WJ4Vozb2"></div>

    <a href="paper_pages/c8WJ4Vozb2.html">
        <img src="http://img.youtube.com/vi/d0kpCvTbz0U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-c8WJ4Vozb2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-c8WJ4Vozb2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-c8WJ4Vozb2">
                Abstract <i id="caret-c8WJ4Vozb2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-c8WJ4Vozb2">
        <div class="abstract-display">
            <p>Disentangled representations are those in which distinct features, such as size or shape, are represented by distinct neurons. Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed. In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems. First, we use hypothetical toy examples to demonstrate the failure modes we identify for existing metrics. Then, we show that similar situations occur in practice. Finally, we validate our metrics on the downstream task of compositional generalization. We measure the performance of six existing disentanglement models on this downstream compositional generalization task, and show that performance is (a) generally quite poor, (b) correlated, to varying degrees, with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics. Anonymous code to reproduce our results is available at https://github.com/anon296/anon.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-otTFPjziiK">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/otTFPjziiK.html">Directed Graph Transformers</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Qitong Wang &middot; Georgios Kollias &middot; Vasileios Kalantzis &middot; Naoki Abe &middot; Mohammed J Zaki</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-otTFPjziiK"></div>

    <a href="paper_pages/otTFPjziiK.html">
        <img src="http://img.youtube.com/vi/V7HGpuUPniw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-otTFPjziiK" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-otTFPjziiK" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-otTFPjziiK">
                Abstract <i id="caret-otTFPjziiK" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-otTFPjziiK">
        <div class="abstract-display">
            <p>In this paper, we address the problem of capturing graph directionality using transformers. Most existing graph transformers typically capture distances between graph nodes and do not take edge direction into account. This is a limiting assumption since many graph applications need to exploit sophisticated relationships in graph data, such as time, causality, or generic dependency constraints. We introduce a novel graph transformer architecture that explicitly takes into account the directionality between connected graph nodes. To achieve this, we make use of dual encodings to represent both potential roles, i.e., source or target, of each pair of vertices linked by a directed edge. These encodings are learned by leveraging the latent adjacency information extracted from a directional attention module, localized with $k$-hop neighborhood information. Extensive experiments on synthetic and real graph datasets show that our approach can have significant accuracy gains over previous graph transformer (GT) and graph neural network (GNN) approaches, providing state-of-the-art (SOTA) results on inherently directed graphs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aHtZuZfHcf">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aHtZuZfHcf.html">Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Timm Hess &middot; Eli Verwimp &middot; Gido M van de Ven &middot; Tinne Tuytelaars</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aHtZuZfHcf"></div>

    <a href="paper_pages/aHtZuZfHcf.html">
        <img src="http://img.youtube.com/vi/od0GNwd4-Cs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aHtZuZfHcf" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aHtZuZfHcf" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aHtZuZfHcf">
                Abstract <i id="caret-aHtZuZfHcf" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aHtZuZfHcf">
        <div class="abstract-display">
            <p>Continual learning research has shown that neural networks suffer from catastrophic forgetting "at the output level", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally in comparison with forgetting at the output level. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Taking both aspects into account, we show that, even though forgetting in the representation (i.e. feature forgetting) can be small in absolute terms, when measuring relative to how much was learned during a task, forgetting in the representation tends to be just as catastrophic as forgetting at the output level. Next we show that this feature forgetting is problematic as it substantially slows down the incremental learning of good general representations (i.e. knowledge accumulation). Finally, we study how feature forgetting and knowledge accumulation are affected by different types of continual learning methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-CuyJkNjIVd">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/CuyJkNjIVd.html">Homogenizing Non-IID Datasets via In-Distribution Knowledge Distillation for Decentralized Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Deepak Ravikumar &middot; Gobinda Saha &middot; Sai Aparna Aketi &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-CuyJkNjIVd"></div>

    <a href="paper_pages/CuyJkNjIVd.html">
        <img src="http://img.youtube.com/vi/I-den-2TNyk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-CuyJkNjIVd" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-CuyJkNjIVd" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-CuyJkNjIVd">
                Abstract <i id="caret-CuyJkNjIVd" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-CuyJkNjIVd">
        <div class="abstract-display">
            <p>Decentralized learning enables serverless training of deep neural networks (DNNs) in a distributed manner on multiple nodes. One of the key challenges with decentralized learning is heterogeneity in the data distribution across the nodes. Data heterogeneity results in slow and unstable global convergence and therefore poor generalization performance. In this paper, we propose In-Distribution Knowledge Distillation (IDKD) to address the challenge of heterogeneous data distribution. The goal of IDKD is to homogenize the data distribution across the nodes. While such data homogenization can be achieved by exchanging data among the nodes sacrificing privacy, IDKD achieves the same objective using a common public dataset across nodes without breaking the privacy constraint. This public dataset is different from the training dataset and is used to distill the knowledge from each node and communicate it to its neighbors through the generated labels. With traditional knowledge distillation, the generalization of the distilled model is reduced due to misalignment between the private and public data distribution. Thus, we introduce an Out-of-Distribution (OoD) detector at each node to label a subset of the public dataset that maps close to the local training data distribution. Our experiments on multiple image classification datasets and graph topologies show that the proposed IDKD scheme is more effective than traditional knowledge distillation and achieves state-of-the-art generalization performance on heterogeneously distributed data with minimal communication overhead.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9M2XqvH2SB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9M2XqvH2SB.html">[Re] Reproducibility Study of “Explaining Temporal Graph Models Through an Explorer-Navigator Framework"</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Helia Ghasemi &middot; Christina Isaicu &middot; Jesse Wonnink &middot; Andreas Berentzen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9M2XqvH2SB"></div>

    <a href="paper_pages/9M2XqvH2SB.html">
        <img src="http://img.youtube.com/vi/sOrRtldRd48/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9M2XqvH2SB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9M2XqvH2SB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9M2XqvH2SB">
                Abstract <i id="caret-9M2XqvH2SB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9M2XqvH2SB">
        <div class="abstract-display">
            <p>This paper seeks to reproduce and extend the results of the paper “Explaining Temporal Graph Models Through an Explorer-Navigator Framework” by (Xia et al., 2023). The main contribution of the original authors is a novel explainer for temporal graph networks, the Temporal GNN Explainer (T-GNNExplainer), which finds a subset of preceding events that “explain” a prediction made by a temporal graph model. The explorer is tested on two temporal graph models that are trained on two real-world and two synthetic datasets. The explorer is evaluated using a newly proposed metric for explanatory graph models. The authors compare the performance of their explorer to three baseline explainer methods, either adapted from a GNN explainer or developed by the authors. The authors claim that T-GNNExplainer achieves superior performance compared to the baselines when evaluated with their proposed metric. This work reproduces the original experiments by using the code (with minor adjustments), model specifications, and hyperparameters provided by the original authors. To evaluate the robustness of these claims, the method was extended to one new dataset (MOOC). Results show that the T-GNNexplainer performs best on some, but not all metrics as reported in the original findings. We conclude that the main lines of this paper hold up even though all results are less pronounced than claimed. Results show that the T-GNNExplainer does not perform similarly across different T-GNN models, precise dataset specifications are needed to obtain high performance, and there are simpler, less computationally costly explainer methods (like PBONE) that could offer competitive results.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zVDMh6JvWc">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zVDMh6JvWc.html">A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kim Youwang &middot; Lee Hyun &middot; Kim Sung-Bin &middot; Suekyeong Nam &middot; Janghoon Ju &middot; Tae-Hyun Oh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zVDMh6JvWc"></div>

    <a href="paper_pages/zVDMh6JvWc.html">
        <img src="http://img.youtube.com/vi/68e6t6Y2zJc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zVDMh6JvWc" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zVDMh6JvWc" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zVDMh6JvWc">
                Abstract <i id="caret-zVDMh6JvWc" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zVDMh6JvWc">
        <div class="abstract-display">
            <p>We propose NeuFace, a 3D face mesh pseudo annotation method on videos via neural re-parameterized optimization. Despite the huge progress in 3D face reconstruction methods, generating reliable 3D face labels for in-the-wild dynamic videos remains challenging. Using NeuFace optimization, we annotate the per-view/-frame accurate and consistent face meshes on large-scale face videos, called the NeuFace-dataset. We investigate how neural re-parameterization helps to reconstruct image-aligned facial details on 3D meshes via gradient analysis. By exploiting the naturalness and diversity of 3D faces in our dataset, we demonstrate the usefulness of our dataset for 3D face-related tasks: improving the reconstruction accuracy of an existing 3D face reconstruction model and learning 3D facial motion prior.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p1a6ruIZCT">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p1a6ruIZCT.html">IMEX-Reg: Implicit-Explicit Regularization in the Function Space for Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Prashant Shivaram Bhat &middot; Bharath Chennamkulam Renjith &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p1a6ruIZCT"></div>

    <a href="paper_pages/p1a6ruIZCT.html">
        <img src="http://img.youtube.com/vi/X1Qh_Czx-NM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p1a6ruIZCT" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p1a6ruIZCT" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p1a6ruIZCT">
                Abstract <i id="caret-p1a6ruIZCT" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p1a6ruIZCT">
        <div class="abstract-display">
            <p>Continual learning (CL) remains one of the long-standing challenges for deep neural networks due to catastrophic forgetting of previously acquired knowledge. Although rehearsal-based approaches have been fairly successful in mitigating catastrophic forgetting, they suffer from overfitting on buffered samples and prior information loss, hindering generalization under low-buffer regimes. Inspired by how humans learn using strong inductive biases, we propose \textbf{IMEX-Reg} to improve the generalization performance of experience rehearsal in CL under low buffer regimes. Specifically, we employ a two-pronged implicit-explicit regularization approach using contrastive representation learning (CRL) and consistency regularization. To further leverage the global relationship between representations learned using CRL, we propose a regularization strategy to guide the classifier toward the activation correlations in the unit hypersphere of the CRL. Our results show that IMEX-Reg significantly improves generalization performance and outperforms rehearsal-based approaches in several CL scenarios. It is also robust to natural and adversarial corruptions with less task-recency bias. Additionally, we provide theoretical insights to support our design decisions further.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-imGl7xItqQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/imGl7xItqQ.html">A Lennard-Jones Layer for Distribution Normalization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mulun Na &middot; Jonathan Klein &middot; Biao Zhang &middot; Wojtek Palubicki &middot; Soren Pirk &middot; Dominik Michels</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-imGl7xItqQ"></div>

    <a href="paper_pages/imGl7xItqQ.html">
        <img src="http://img.youtube.com/vi/XlLpASZ2QE4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-imGl7xItqQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-imGl7xItqQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-imGl7xItqQ">
                Abstract <i id="caret-imGl7xItqQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-imGl7xItqQ">
        <div class="abstract-display">
            <p>We introduce the Lennard-Jones layer (LJL) for the equalization of the density of 2D and 3D point clouds through systematically rearranging points without destroying their overall structure (distribution normalization). LJL simulates a dissipative process of repulsive and weakly attractive interactions between individual points by considering the nearest neighbor of each point at a given moment in time. This pushes the particles into a potential valley, reaching a well-defined stable configuration that approximates an equidistant sampling after the stabilization process. We apply LJLs to redistribute randomly generated point clouds into a randomized uniform distribution. Moreover, LJLs are embedded in the generation process of point cloud networks by adding them at later stages of the inference process. The improvements in 3D point cloud generation utilizing LJLs are evaluated qualitatively and quantitatively. Finally, we apply LJLs to improve the point distribution of a score-based 3D point cloud denoising network. In general, we demonstrate that LJLs are effective for distribution normalization which can be applied at negligible cost without retraining the given neural network.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-kfhoeZCeW7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/kfhoeZCeW7.html">Fine-tuning can cripple your foundation model; preserving features may be the solution</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jishnu Mukhoti &middot; Yarin Gal &middot; Philip Torr &middot; Puneet K. Dokania</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-kfhoeZCeW7"></div>

    <a href="paper_pages/kfhoeZCeW7.html">
        <img src="http://img.youtube.com/vi/VVG_KWi-BSM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-kfhoeZCeW7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-kfhoeZCeW7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-kfhoeZCeW7">
                Abstract <i id="caret-kfhoeZCeW7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-kfhoeZCeW7">
        <div class="abstract-display">
            <p>Pre-trained foundation models, due to their enormous capacity and exposure to vast amounts of data during pre-training, are known to have learned plenty of real-world concepts. An important step in making these pre-trained models effective on downstream tasks is to fine-tune them on related datasets. While various fine-tuning methods have been devised and have been shown to be highly effective, we observe that a fine-tuned model's ability to recognize concepts on tasks different from the downstream one is reduced significantly compared to its pre-trained counterpart. This is an undesirable effect of fine-tuning as a substantial amount of resources was used to learn these pre-trained concepts in the first place. We call this phenomenon "concept forgetting'' and via experiments show that most end-to-end fine-tuning approaches suffer heavily from this side effect. To this end, we propose a simple fix to this problem by designing a new fine-tuning method called LDIFS (short for $\ell_2$ distance in feature space) that, while learning new concepts related to the downstream task, allows a model to preserve its pre-trained knowledge as well. Through extensive experiments on 10 fine-tuning tasks we show that LDIFS significantly reduces concept forgetting. Additionally, we show that LDIFS is highly effective in performing continual fine-tuning on a sequence of tasks as well, in comparison with both fine-tuning as well as continual learning baselines.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-iulMde3dP1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/iulMde3dP1.html">What Has Been Overlooked in Contrastive Source-Free Domain Adaptation: Leveraging Source-Informed Latent Augmentation within Neighborhood Context</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wang &middot; Wonho Bae &middot; Jiahong Chen &middot; Kuangen Zhang &middot; Leonid Sigal &middot; Clarence W. de Silva</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-iulMde3dP1"></div>

    <a href="paper_pages/iulMde3dP1.html">
        <img src="http://img.youtube.com/vi/A0YLvomkOwU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-iulMde3dP1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-iulMde3dP1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-iulMde3dP1">
                Abstract <i id="caret-iulMde3dP1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-iulMde3dP1">
        <div class="abstract-display">
            <p>Source-free domain adaptation (SFDA) involves adapting a model originally trained using a labeled dataset (source domain) to perform effectively on an unlabeled dataset (target domain) without relying on any source data during adaptation. This adaptation is especially crucial when significant disparities in data distributions exist between the two domains and when there are privacy concerns regarding the source model's training data. The absence of access to source data during adaptation makes it challenging to analytically estimate the domain gap. To tackle this issue, various techniques have been proposed, such as unsupervised clustering, contrastive learning, and continual learning. In this paper, we first conduct an extensive theoretical analysis of SFDA based on contrastive learning, primarily because it has demonstrated superior performance compared to other techniques. Motivated by the obtained insights, we then introduce a straightforward yet highly effective latent augmentation method tailored for contrastive SFDA. This augmentation method leverages the dispersion of latent features within the neighborhood of the query sample, guided by the source pre-trained model, to enhance the informativeness of positive keys. Our approach, based on a single InfoNCE-based contrastive loss, outperforms state-of-the-art SFDA methods on widely recognized benchmark datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VzKXbCzNoU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VzKXbCzNoU.html">Efficient Parallelized Simulation of Cyber-Physical Systems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bas van der Heijden &middot; Laura Ferranti &middot; Jens Kober &middot; Robert Babuska</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VzKXbCzNoU"></div>

    <a href="paper_pages/VzKXbCzNoU.html">
        <img src="http://img.youtube.com/vi/I-1asHKBX6o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VzKXbCzNoU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VzKXbCzNoU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VzKXbCzNoU">
                Abstract <i id="caret-VzKXbCzNoU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VzKXbCzNoU">
        <div class="abstract-display">
            <p>Advancements in accelerated physics simulations have greatly reduced training times for reinforcement learning policies, yet the conventional step-by-step agent-simulator interaction undermines simulation accuracy. In the real-world, interactions are asynchronous, with sensing, acting and processing happening simultaneously. Failing to capture this widens the sim2real gap and results in suboptimal real-world performance. In this paper, we address the challenges of simulating realistic asynchronicity and delays within parallelized simulations, crucial to bridging the sim2real gap in complex cyber-physical systems. Our approach efficiently parallelizes cyber-physical system simulations on accelerator hardware, including physics, sensors, actuators, processing components and their asynchronous interactions. We extend existing accelerated physics simulations with latency simulation capabilities by constructing a `supergraph' that encodes all data dependencies across parallelized simulation steps, ensuring accurate simulation. By finding the smallest supergraph, we minimize redundant computation. We validate our approach on two real-world systems and perform an extensive ablation, demonstrating superior performance compared to baseline methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-RA4yRhjoXw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/RA4yRhjoXw.html">***FastDoc***: Domain-Specific Fast Continual Pre-training Technique using Document-Level Metadata and Taxonomy</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Abhilash Nandy &middot; Manav Nitin Kapadnis &middot; Sohan Patnaik &middot; Yash Parag Butala &middot; Pawan Goyal &middot; Niloy Ganguly</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-RA4yRhjoXw"></div>

    <a href="paper_pages/RA4yRhjoXw.html">
        <img src="https://drive.google.com/thumbnail?id=1ENnNnCpv_QCyUHmsAaDU0eteTOHIAwwg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-RA4yRhjoXw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-RA4yRhjoXw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-RA4yRhjoXw">
                Abstract <i id="caret-RA4yRhjoXw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-RA4yRhjoXw">
        <div class="abstract-display">
            <p>In this paper, we propose FastDoc (Fast Continual Pre-training Technique using Document Level Metadata and Taxonomy), a novel, compute-efficient framework that utilizes Document metadata and Domain-Specific Taxonomy as supervision signals to continually pre-train transformer encoder on a domain-specific corpus. The main innovation is that during domain-specific pretraining, an open-domain encoder is continually pre-trained using sentence-level embeddings as inputs (to accommodate long documents), however, fine-tuning is done with token-level embeddings as inputs to this encoder. We perform such domain-specific pre-training on three different domains namely customer support, scientific, and legal domains, and compare performance on 6 different downstream tasks and 9 different datasets. The novel use of document-level supervision along with sentence-level embedding input for pre-training reduces pre-training compute by around 1,000, 4,500, and 500 times compared to MLM and/or NSP in Customer Support, Scientific, and Legal Domains, respectively. The reduced training time does not lead to a deterioration in performance. In fact we show that FastDoc either outperforms or performs on par with several competitive transformer-based baselines in terms of character-level F1 scores and other automated metrics in the Customer Support, Scientific, and Legal Domains. Moreover, reduced training aids in mitigating the risk of catastrophic forgetting. Thus, unlike baselines, FastDoc shows a negligible drop in performance on open domain.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-CrpDwMFgxr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/CrpDwMFgxr.html">Linear Bandits with Memory</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Giulia Clerici &middot; Pierre Laforgue &middot; Nicolò Cesa-Bianchi</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-CrpDwMFgxr"></div>

    <a href="paper_pages/CrpDwMFgxr.html">
        <img src="http://img.youtube.com/vi/zJxDpa7dfYE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-CrpDwMFgxr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-CrpDwMFgxr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-CrpDwMFgxr">
                Abstract <i id="caret-CrpDwMFgxr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-CrpDwMFgxr">
        <div class="abstract-display">
            <p>Nonstationary phenomena, such as satiation effects in recommendations, have mostly been modeled using bandits with finitely many arms. However, the richer action space provided by linear bandits is often preferred in practice. In this work, we introduce a novel nonstationary linear bandit model, where current rewards are influenced by the learner's past actions in a fixed-size window. Our model, which recovers stationary linear bandits as a special case, leverages two parameters: the window size $m \ge 0$, and an exponent $\gamma$ that captures the rotting ($\gamma < 0)$ or rising ($\gamma > 0$) nature of the phenomenon. When both $m$ and $\gamma$ are known, we propose and analyze a variant of OFUL which minimizes regret against cyclic policies. By choosing the cycle length so as to trade-off approximation and estimation errors, we then prove a bound of order $\sqrt{d}\,(m+1)^{\frac{1}{2}+\max\{\gamma,0\}}\,T^{3/4}$ (ignoring log factors) on the regret against the optimal sequence of actions, where $T$ is the horizon and $d$ is the dimension of the linear action space. Through a bandit model selection approach, our results are then extended to the case where both $m$ and $\gamma$ are unknown. Finally, we complement our theoretical results with experiments comparing our approach to natural baselines.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-epcLNhkoEL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/epcLNhkoEL.html">Fixed Budget Best Arm Identification in Unimodal Bandits</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Debamita Ghosh &middot; Manjesh Kumar Hanawal &middot; Nikola Zlatanov</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-epcLNhkoEL"></div>

    <a href="paper_pages/epcLNhkoEL.html">
        <img src="https://drive.google.com/thumbnail?id=12DEUiyK-rFvhnR_sr5EE25x1Qs1p94UZ" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-epcLNhkoEL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-epcLNhkoEL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-epcLNhkoEL">
                Abstract <i id="caret-epcLNhkoEL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-epcLNhkoEL">
        <div class="abstract-display">
            <p>We consider the best arm identification problem in a fixed budget stochastic multi-armed bandit in which arm means exhibit unimodal structure, i.e., there is only one local maximum. We establish that the probability of misidentifying the optimal arm within a budget of $T$ is lower bounded as $\mathcal{O}\left(\exp\left\{-T/\bar{H}\right\}\right)$, where $\bar{H}$ depends on the sub-optimality gaps of arms in the neighborhood of the optimal arm. % where $\bar{H}\leq 2\Delta^{-2}$. In contrast to the lower bound for the unstructured case, the error exponent in this bound does not depend on the number of arms $K$ and is smaller by a factor $\log K$, which captures the gain achievable by exploiting the unimodal structure. We then develop an algorithm named {\it Fixed Budget Best Arm Unimodal Bandits ( FB-BAUB)} that exploits unimodality to achieve the gain. Specifically, we show that the error probability of \algo{} is upper bounded as $\mathcal{O}\left(\log_2 K\exp\left\{-T\Delta^2\right\}\right)$, where $\Delta$ is the gap between the neighboring arms and $\bar{H}\leq 2\Delta^{-2}$. We demonstrate that \algo{} outperforms the state-of-the-art algorithms through extensive simulations. Moreover, \algo{} is parameter-free and simple to implement.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-thfoUZugvS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/thfoUZugvS.html">Koopman Spectrum Nonlinear Regulators and Efficient Online Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Motoya Ohnishi &middot; Isao Ishikawa &middot; Kendall Lowrey &middot; Masahiro Ikeda &middot; Sham M. Kakade &middot; Yoshinobu Kawahara</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-thfoUZugvS"></div>

    <a href="paper_pages/thfoUZugvS.html">
        <img src="http://img.youtube.com/vi/uYLgQObi9P8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-thfoUZugvS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-thfoUZugvS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-thfoUZugvS">
                Abstract <i id="caret-thfoUZugvS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-thfoUZugvS">
        <div class="abstract-display">
            <p>Most modern reinforcement learning algorithms optimize a cumulative single-step cost along a trajectory.  The optimized motions are often ‘unnatural’, representing, for example, behaviors with sudden accelerations that waste energy and lack predictability.  In this work, we present a novel paradigm of controlling nonlinear systems via the minimization of the Koopman spectrum cost: a cost over the Koopman operator of the controlled dynamics.  This induces a broader class of dynamical behaviors that evolve over stable manifolds such as nonlinear oscillators, closed loops, and smooth movements.   We demonstrate that some dynamics characterizations that are not possible with a cumulative cost are feasible in this paradigm, which generalizes the classical eigenstructure and pole assignments to nonlinear decision making.   Moreover, we present a sample efficient online learning algorithm for our problem that enjoys a sub-linear regret bound under some structural assumptions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-wczqrpOrIc">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/wczqrpOrIc.html">LeanVec: Searching vectors faster by making them fit</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mariano Tepper &middot; Ishwar Singh Bhati &middot; Cecilia Aguerrebere &middot; Mark Hildebrand &middot; Theodore L. Willke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-wczqrpOrIc"></div>

    <a href="paper_pages/wczqrpOrIc.html">
        <img src="http://img.youtube.com/vi/-o1K3mwQE78/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-wczqrpOrIc" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-wczqrpOrIc" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-wczqrpOrIc">
                Abstract <i id="caret-wczqrpOrIc" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-wczqrpOrIc">
        <div class="abstract-display">
            <p>Modern deep learning models have the ability to generate high-dimensional vectors whose similarity reflects semantic resemblance.
Thus, similarity search, i.e., the operation of retrieving those vectors in a large collection that are similar to a given query, has become a critical component of a wide range of applications that demand highly accurate and timely answers. In this setting, the high vector dimensionality puts similarity search systems under compute and memory pressure, leading to subpar performance.
Additionally, cross-modal retrieval tasks have become increasingly common, e.g., where a user inputs a text query to find the most relevant images for that query. However, these queries often have different distributions than the database embeddings, making it challenging to achieve high accuracy. In this work, we present LeanVec, a framework that combines linear dimensionality reduction with vector quantization to accelerate similarity search on high-dimensional vectors while maintaining accuracy. We present LeanVec variants for in-distribution (ID) and out-of-distribution (OOD) queries. LeanVec-ID yields accuracies on par with those from recently introduced deep learning alternatives whose computational overhead precludes their usage in practice. LeanVec-OOD uses a novel technique for dimensionality reduction that considers the query and database distributions to simultaneously boost the accuracy and the performance of the framework even further (even presenting competitive results when the query and database distributions match). All in all, our extensive and varied experimental results show that LeanVec produces state-of-the-art results, with up to 3.7x improvement in search throughput and up to 4.9x faster index build time over the state of the art.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-KLojVqdj2y">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/KLojVqdj2y.html">Training Graph Neural Networks Subject to a Tight Lipschitz Constraint</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Simona Ioana Juvina &middot; Ana Antonia Neacșu &middot; Jérôme Rony &middot; Jean-Christophe Pesquet &middot; Corneliu Burileanu &middot; Ismail Ben Ayed</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-KLojVqdj2y"></div>

    <a href="paper_pages/KLojVqdj2y.html">
        <img src="http://img.youtube.com/vi/_4AI1BmUnLo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-KLojVqdj2y" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-KLojVqdj2y" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-KLojVqdj2y">
                Abstract <i id="caret-KLojVqdj2y" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-KLojVqdj2y">
        <div class="abstract-display">
            <p>We propose a strategy for training a wide range of graph neural networks (GNNs) under tight Lipschitz bound constraints. 
Specifically, by leveraging graph spectral theory, we derive computationally tractable expressions of a tight Lipschitz constant. This allows us to propose a constrained-optimization approach to control the constant, ensuring robustness to adversarial perturbations. Unlike the existing methods for controlling the Lipschitz constant, our approach reduces the size of the handled matrices by a factor equal to the square of the number of nodes in the graph. We employ a stochastic projected subgradient algorithm, which operates in a block-coordinate manner, with the projection step performed via an accelerated iterative proximal algorithm.
We focus on defending against attacks that perturb features while keeping the topology of the graph constant. This contrasts with most of the existing defenses, which tackle perturbations of the graph structure. We report experiments on various datasets in the context of node classification tasks, showing the effectiveness of our constrained GNN model.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-o5kYH7bNe3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/o5kYH7bNe3.html">VisionAD, a software package of performant anomaly detection algorithms, and Proportion Localised, an interpretable metric</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander D. J. Taylor &middot; Phillip Tregidgo &middot; Jonathan James Morrison &middot; Neill D. F. Campbell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-o5kYH7bNe3"></div>

    <a href="paper_pages/o5kYH7bNe3.html">
        <img src="http://img.youtube.com/vi/tUqyAjONy8s/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-o5kYH7bNe3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-o5kYH7bNe3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-o5kYH7bNe3">
                Abstract <i id="caret-o5kYH7bNe3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-o5kYH7bNe3">
        <div class="abstract-display">
            <p>We release VisionAD, an anomaly detection library in the domain of images. The library forms the largest and most performant collection of such algorithms to date. Each algorithm is written through a standardised API, for ease of use. The library has a focus on fair benchmarking intended to mitigate the issue of cherry-picked results. It enables rapid experimentation and straightforward integration of new algorithms. In addition, we propose a new metric, Proportion Localised (PL). This reports the proportion of anomalies that are sufficiently localised via classifying each discrete anomaly as localised or not. The metric is far more intuitive as it has a real physical relation, meaning it is attractive to industry-based professionals. We also release the VisionADIndustrial (VADI) benchmark, a thorough benchmarking of the top anomaly detection algorithms. This benchmark calculates the mean across the pooled classes of the MVTec and VisA datasets. We are committed to hosting an updated version of this leaderboard online, and encourage researchers to add, tweak and improve algorithms to climb this leaderboard. VisionAD code is found at https://github.com/alext1995/VisionAD, and Proportion Localised code is found at https://github.com/alext1995/proportion_localised.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xNkASJL0F6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xNkASJL0F6.html">Dynamic Structure Estimation from Bandit Feedback using Nonvanishing Exponential Sums</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Motoya Ohnishi &middot; Isao Ishikawa &middot; Yuko Kuroki &middot; Masahiro Ikeda</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xNkASJL0F6"></div>

    <a href="paper_pages/xNkASJL0F6.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xNkASJL0F6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xNkASJL0F6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xNkASJL0F6">
                Abstract <i id="caret-xNkASJL0F6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xNkASJL0F6">
        <div class="abstract-display">
            <p>This work tackles the dynamic structure estimation problems for periodically behaved discrete dynamical system in the Euclidean space.  We assume the observations become sequentially available in a form of bandit feedback contaminated by a sub-Gaussian noise.  Under such fairly general assumptions on the noise distribution, we carefully identify a set of recoverable information of periodic structures.  Our main results are the (computation and sample) efficient algorithms that exploit asymptotic behaviors of exponential sums to effectively average out the noise effect while preventing the information to be estimated from vanishing.  In particular, the novel use of the Weyl sum, a variant of exponential sums, allows us to extract spectrum information for linear systems.  We provide sample complexity bounds for our algorithms, and we experimentally validate our theoretical claims on simulations of toy examples, including Cellular Automata.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zn3fB4VVF0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zn3fB4VVF0.html">Navigating Noise: A Study of How Noise Influences Generalisation and Calibration of Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Martin Ferianc &middot; Ondrej Bohdal &middot; Timothy Hospedales &middot; Miguel R. D. Rodrigues</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zn3fB4VVF0"></div>

    <a href="paper_pages/zn3fB4VVF0.html">
        <img src="http://img.youtube.com/vi/fvKvDGZdGL0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zn3fB4VVF0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zn3fB4VVF0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zn3fB4VVF0">
                Abstract <i id="caret-zn3fB4VVF0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zn3fB4VVF0">
        <div class="abstract-display">
            <p>Enhancing the generalisation abilities of neural networks (NNs) through integrating noise such as MixUp or Dropout during training has emerged as a powerful and adaptable technique. Despite the proven efficacy of noise in NN training, there is no consensus regarding which noise sources, types and placements yield maximal benefits in generalisation and confidence calibration. This study thoroughly explores diverse noise modalities to evaluate their impacts on NN's generalisation and calibration under in-distribution or out-of-distribution settings, paired with experiments investigating the metric landscapes of the learnt representations, across a spectrum of NN architectures, tasks, and datasets. Our study shows that AugMix and weak augmentation exhibit cross-task effectiveness in computer vision, emphasising the need to tailor noise to specific domains. Our findings emphasise the efficacy of combining noises and successful hyperparameter transfer within a single domain but the difficulties in transferring the benefits to other domains. Furthermore, the study underscores the complexity of simultaneously optimising for both generalisation and calibration, emphasising the need for practitioners to carefully consider noise combinations and hyperparameter tuning for optimal performance in specific tasks and datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-N0Sc0KY0AH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/N0Sc0KY0AH.html">Improving Subgraph-GNNs via Edge-Level Ego-Network Encodings</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nurudin Alvarez-Gonzalez &middot; Andreas Kaltenbrunner &middot; Vicenç Gómez</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-N0Sc0KY0AH"></div>

    <a href="paper_pages/N0Sc0KY0AH.html">
        <img src="http://img.youtube.com/vi/nlYwZ8FF9vI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-N0Sc0KY0AH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-N0Sc0KY0AH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-N0Sc0KY0AH">
                Abstract <i id="caret-N0Sc0KY0AH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-N0Sc0KY0AH">
        <div class="abstract-display">
            <p>We present a novel edge-level ego-network encoding for learning on graphs that can boost Message Passing Graph Neural Networks (MP-GNNs) by providing additional node and edge features or extending message-passing formats. The proposed encoding is sufficient to distinguish Strongly Regular Graphs, a family of challenging 3-WL equivalent graphs. We show theoretically that such encoding is more expressive than node-based sub-graph MP-GNNs. In an empirical evaluation on four benchmarks with 10 graph datasets, our results match or improve previous baselines on expressivity, graph classification, graph regression, and proximity tasks---while reducing memory usage by 18.1x in certain real-world settings.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3nprbNR3HB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3nprbNR3HB.html">ASPEST: Bridging the Gap Between Active Learning and Selective Prediction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jiefeng Chen &middot; Jinsung Yoon &middot; Sayna Ebrahimi &middot; Sercan O Arik &middot; Somesh Jha &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3nprbNR3HB"></div>

    <a href="paper_pages/3nprbNR3HB.html">
        <img src="https://drive.google.com/thumbnail?id=1mEZ1O_b6PKGBR2Tw3VTOpzUCDN6IiiZH" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3nprbNR3HB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3nprbNR3HB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3nprbNR3HB">
                Abstract <i id="caret-3nprbNR3HB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3nprbNR3HB">
        <div class="abstract-display">
            <p>Selective prediction aims to learn a reliable model that abstains from making predictions when uncertain. These predictions can then be deferred to humans for further evaluation. As an everlasting challenge for machine learning, in many real-world scenarios, the distribution of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive. Active learning aims to lower the overall labeling effort, and hence human dependence, by querying the most informative examples. Selective prediction and active learning have been approached from different angles, with the connection between them missing. In this work, we introduce a new learning paradigm, active selective prediction, which aims to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new paradigm, we propose a simple yet effective approach, ASPEST, that utilizes ensembles of model snapshots with self-training with their aggregated outputs as pseudo labels. Extensive experiments on numerous image, text and structured datasets, which suffer from domain shifts, demonstrate that ASPEST can significantly outperform prior work on selective prediction and active learning (e.g. on the MNIST$\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUACC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HVxumpoWBm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HVxumpoWBm.html">One by One, Continual Coordinating with Humans via Hyper-Teammate Identification</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Cong Guan &middot; Feng Chen &middot; Ke Xue &middot; Chunpeng Fan &middot; Lichao Zhang &middot; Ziqian Zhang &middot; Pengyao Zhao &middot; Zongzhang Zhang &middot; Chao Qian &middot; Lei Yuan &middot; Yang Yu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HVxumpoWBm"></div>

    <a href="paper_pages/HVxumpoWBm.html">
        <img src="https://drive.google.com/thumbnail?id=1-E8NqrCbkbNNH4BMskn35m7saONWfIPZ" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HVxumpoWBm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HVxumpoWBm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HVxumpoWBm">
                Abstract <i id="caret-HVxumpoWBm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HVxumpoWBm">
        <div class="abstract-display">
            <p>One of the primary objectives in modern artificial intelligence researches is to empower  agents to effectively coordinate with diverse teammates, particularly human teammates. Previous studies focused on training agents either with a fixed population of pre-generated teammates or through the co-evolution of distinct populations of agents and teammates. However, it is challenging to enumerate all possible teammates in advance, and it is costly, or even impractical to maintain such a sufficiently diverse population and repeatedly interact with previously encountered teammates. Additional design considerations, such as prioritized sampling, are also required to ensure efficient training. To address these challenges and obtain an efficient human-AI coordination paradigm, we propose a novel approach called \textbf{Concord}. Considering that human participants tend to occur in a sequential manner, we model the training process with different teammates as a continual learning framework, akin to how humans learn and adapt in the real world.  We propose a mechanism based on hyper-teammate identification to prevent catastrophic forgetting while promoting forward knowledge transfer.  Concretely, we introduce a teammate recognition module that captures the identification of corresponding teammates. Leveraging the identification, a well-coordinated AI policy can be generated via the hyper-network. The entire framework is trained in a decomposed policy gradient manner,  allowing for effective credit assignment among agents. This approach enables us to train agents with each generated teammate or humans one by one, ensuring that agents can coordinate effectively with concurrent teammates without forgetting previous knowledge. Our approach outperforms multiple baselines in various multi-agent benchmarks, either with generated human proxies or real human participants.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YCgX7sJRF1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YCgX7sJRF1.html">Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nikolas Adaloglou &middot; Felix Michels &middot; Tim Kaiser &middot; Markus Kollmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YCgX7sJRF1"></div>

    <a href="paper_pages/YCgX7sJRF1.html">
        <img src="http://img.youtube.com/vi/eVUKVfxpx8A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YCgX7sJRF1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YCgX7sJRF1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YCgX7sJRF1">
                Abstract <i id="caret-YCgX7sJRF1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YCgX7sJRF1">
        <div class="abstract-display">
            <p>We present a comprehensive experimental study on pre-trained feature extractors for visual out-of-distribution (OOD) detection, focusing on leveraging contrastive language-image pre-trained (CLIP) models. Without fine-tuning on the training data, we are able to establish a positive correlation ($R^2\geq0.92$) between in-distribution classification and unsupervised OOD detection for CLIP models in $4$ benchmarks. We further propose a new simple and scalable method called \textit{pseudo-label probing} (PLP) that adapts vision-language models for OOD detection. Given a set of label names of the training set, PLP trains a linear layer using the pseudo-labels derived from the text encoder of CLIP. Intriguingly, we show that without modifying the weights of CLIP or training additional image/text encoders (i) PLP outperforms the previous state-of-the-art on all $5$ large-scale benchmarks based on ImageNet, specifically by an average AUROC gain of 3.4\% using the largest CLIP model (ViT-G), (ii) linear probing outperforms fine-tuning by large margins for CLIP architectures (i.e. CLIP ViT-H achieves a mean gain of 7.3\% AUROC on average on all ImageNet-based benchmarks), and (iii) billion-parameter CLIP models still fail at detecting feature-based adversarially manipulated OOD images. The code is available at https://github.com/HHU-MMBS/plp-official-tmlr2024.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-N05OnQG1BA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/N05OnQG1BA.html">CoDeC: Communication-Efficient Decentralized Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sakshi Choudhary &middot; Sai Aparna Aketi &middot; Gobinda Saha &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-N05OnQG1BA"></div>

    <a href="paper_pages/N05OnQG1BA.html">
        <img src="https://drive.google.com/thumbnail?id=1UPp5btj8j_JziRPeyWbEB6f7y_KBFsZY" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-N05OnQG1BA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-N05OnQG1BA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-N05OnQG1BA">
                Abstract <i id="caret-N05OnQG1BA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-N05OnQG1BA">
        <div class="abstract-display">
            <p>Training at the edge utilizes continuously evolving data generated at different locations. Privacy concerns prohibit the co-location of this spatially as well as temporally distributed data, deeming it crucial to design training algorithms that enable efficient continual learning
over decentralized private data. Decentralized learning allows serverless training with spatially distributed data. A fundamental barrier in such setups is the high bandwidth cost of communicating model updates between agents. Moreover, existing works under this training paradigm are not inherently suitable for learning a temporal sequence of tasks while retaining the previously acquired knowledge. In this work, we propose CoDeC, a novel communication-efficient decentralized continual learning algorithm that addresses these challenges. We mitigate catastrophic forgetting while learning a distributed task sequence by incorporating orthogonal gradient projection within a gossip-based decentralized learning algorithm. Further, CoDeC includes a novel lossless communication compression scheme based on the gradient subspaces. We theoretically analyze the convergence rate for our algorithm and demonstrate through an extensive set of experiments that CoDeC successfully learns distributed continual tasks with minimal forgetting. The proposed compression scheme results in up to 4.8× reduction in communication costs without any loss in performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-iwCBWULItx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/iwCBWULItx.html">DeepReShape: Redesigning  Neural Networks for Efficient Private Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nandan Kumar Jha &middot; Brandon Reagen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-iwCBWULItx"></div>

    <a href="paper_pages/iwCBWULItx.html">
        <img src="https://drive.google.com/thumbnail?id=17byDYNIuiAYvdTQJJDv29UnK7XdCdwHQ" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-iwCBWULItx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-iwCBWULItx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-iwCBWULItx">
                Abstract <i id="caret-iwCBWULItx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-iwCBWULItx">
        <div class="abstract-display">
            <p>Prior work on Private Inference (PI)---inferences performed directly on encrypted input---has focused on minimizing a network's ReLUs, which have been assumed to dominate PI latency rather than FLOPs. Recent work has shown that FLOPs for PI can no longer be ignored and incur high latency penalties. In this paper, we develop DeepReShape, a technique that optimizes neural network architectures under PI's constraints, optimizing for both ReLUs {\em and} FLOPs for the first time. The key insight is strategically allocating channels to position the network's ReLUs in order of their criticality to network accuracy, simultaneously optimizes ReLU and FLOPs efficiency. DeepReShape automates network development with an efficient process, and we call generated networks HybReNets. We evaluate DeepReShape using standard PI benchmarks and demonstrate a  2.1% accuracy gain with a 5.2$\times$ runtime improvement at iso-ReLU on CIFAR-100 and an 8.7$\times$ runtime improvement at iso-accuracy on TinyImageNet. Furthermore, we investigate the significance of network selection in prior ReLU optimizations and shed light on the key network attributes for superior PI performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-hFALpTb4fR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/hFALpTb4fR.html">LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Long Lian &middot; Boyi Li &middot; Adam Yala &middot; Trevor Darrell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-hFALpTb4fR"></div>

    <a href="paper_pages/hFALpTb4fR.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-hFALpTb4fR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-hFALpTb4fR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-hFALpTb4fR">
                Abstract <i id="caret-hFALpTb4fR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-hFALpTb4fR">
        <div class="abstract-display">
            <p>Recent advancements in text-to-image diffusion models have yielded impressive results in generating realistic and diverse images. However, these models still struggle with complex prompts, such as those that involve numeracy and spatial reasoning. This work proposes to enhance prompt understanding capabilities in diffusion models. Our method leverages a pretrained large language model (LLM) for grounded generation in a novel two-stage process. In the first stage, the LLM generates a scene layout that comprises captioned bounding boxes from a given prompt describing the desired image. In the second stage, a novel controller guides an off-the-shelf diffusion model for layout-grounded image generation. Both stages utilize existing pretrained models without additional model parameter optimization. Our method significantly outperforms the base diffusion model and several strong baselines in accurately generating images according to prompts that require various capabilities, doubling the generation accuracy across four tasks on average. Furthermore, our method enables instruction-based multi-round scene specification and can handle prompts in languages not supported by the underlying diffusion model. We anticipate that our method will unleash users' creativity by accurately following more complex prompts. Our code, demo, and benchmark are available at: https://llm-grounded-diffusion.github.io</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oYIjw37pTP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oYIjw37pTP.html">An optimal control perspective on diffusion-based generative modeling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Julius Berner &middot; Lorenz Richter &middot; Karen Ullrich</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oYIjw37pTP"></div>

    <a href="paper_pages/oYIjw37pTP.html">
        <img src="http://img.youtube.com/vi/wQpQg1xIlBA/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oYIjw37pTP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oYIjw37pTP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oYIjw37pTP">
                Abstract <i id="caret-oYIjw37pTP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oYIjw37pTP">
        <div class="abstract-display">
            <p>We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton--Jacobi--Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback--Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ux9BrxPCl8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ux9BrxPCl8.html">Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jack William Miller &middot; Charles O'Neill &middot; Thang D Bui</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ux9BrxPCl8"></div>

    <a href="paper_pages/ux9BrxPCl8.html">
        <img src="http://img.youtube.com/vi/--RAHz68f3c/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ux9BrxPCl8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ux9BrxPCl8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ux9BrxPCl8">
                Abstract <i id="caret-ux9BrxPCl8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ux9BrxPCl8">
        <div class="abstract-display">
            <p>In some settings neural networks exhibit a phenomenon known as \textit{grokking}, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression, linear regression and Bayesian neural networks. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures shows that grokking is not restricted to settings considered in current theoretical and empirical studies. Instead, grokking may be possible in any model where solution search is guided by complexity and error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Jy2IgzjoFH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Jy2IgzjoFH.html">Hierarchical Neural Simulation-Based Inference Over Event Ensembles</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lukas Heinrich &middot; Siddharth Mishra-Sharma &middot; Chris Pollard &middot; Philipp Windischhofer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Jy2IgzjoFH"></div>

    <a href="paper_pages/Jy2IgzjoFH.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Jy2IgzjoFH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Jy2IgzjoFH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Jy2IgzjoFH">
                Abstract <i id="caret-Jy2IgzjoFH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Jy2IgzjoFH">
        <div class="abstract-display">
            <p>When analyzing real-world data it is common to work with event ensembles, which comprise sets of observations that collectively constrain the parameters of an underlying model of interest. Such models often have a hierarchical structure, where ``local'' parameters impact individual events and ``global'' parameters influence the entire dataset. We introduce practical approaches for frequentist and Bayesian dataset-wide probabilistic inference in cases where the likelihood is intractable, but simulations can be realized via a hierarchical forward model. We construct neural estimators for the likelihood(-ratio) or posterior and show that explicitly accounting for the model's hierarchical structure can lead to significantly tighter parameter constraints. We ground our discussion using case studies from the physical sciences, focusing on examples from particle physics and cosmology.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-yUmJ483OB0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/yUmJ483OB0.html">Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Seongjun Yang &middot; Gibbeum Lee &middot; Jaewoong Cho &middot; Dimitris Papailiopoulos &middot; Kangwook Lee</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-yUmJ483OB0"></div>

    <a href="paper_pages/yUmJ483OB0.html">
        <img src="https://drive.google.com/thumbnail?id=1QHLv7n0iEdqyeyJz4Mh57WEH8cThZiaW" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-yUmJ483OB0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-yUmJ483OB0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-yUmJ483OB0">
                Abstract <i id="caret-yUmJ483OB0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-yUmJ483OB0">
        <div class="abstract-display">
            <p>This paper presents Predictive Pipelined Decoding (PPD), an approach that speeds up decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding. Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding. This method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies. We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency. Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as $p_\text{correct}$. The results demonstrate that the use of extra computational resources has the potential to accelerate LLM decoding. Additionally, we implement PPD and conduct preliminary experiments to empirically validate its efficacy, addressing potential practical overheads not covered by theoretical analysis.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Nzy0XmCPuZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Nzy0XmCPuZ.html">Rotate the ReLU to Sparsify Deep Networks Implicitly</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nancy Nayak &middot; Sheetal Kalyani</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Nzy0XmCPuZ"></div>

    <a href="paper_pages/Nzy0XmCPuZ.html">
        <img src="http://img.youtube.com/vi/tLxNTUXtfyI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Nzy0XmCPuZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Nzy0XmCPuZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Nzy0XmCPuZ">
                Abstract <i id="caret-Nzy0XmCPuZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Nzy0XmCPuZ">
        <div class="abstract-display">
            <p>Compact and energy-efficient models have become essential in this era when deep learning-based solutions are widely used for various real-life tasks. In this paper, we propose rotating the ReLU activation to give an additional degree of freedom in conjunction with the appropriate initialization of the rotation. This combination leads to implicit sparsification without the use of a regularizer. We show that this rotated ReLU (RReLU) activation improves the representation capability of the parameters/filters in the network and eliminates those parameters/filters that are not crucial for the task, giving rise to significant savings in memory and computation. While the state-of-the-art regularization-based Network-Slimming method achieves $32.33\%$ saving in memory and $26.38\%$ saving in computation with ResNet-$164$, RReLU achieves a saving of $35.92\%$ in memory and $25.97\%$ in the computation with a better accuracy. The savings in memory and computation further increase by $64.67\%$ and $52.96\%$, respectively, with the introduction of $L_1$ regularization to the RReLU slopes. We note that the slopes of the rotated ReLU activations act as coarse feature extractors and can eliminate unnecessary features before retraining. Our studies indicate that features always choose to pass through a lesser number of filters. We demonstrate the results with popular datasets such as MNIST, CIFAR-10, CIFAR-100, SVHN, and Imagenet with different architectures, including Vision Transformers and EfficientNet. We also briefly study the impact of adversarial attacks on RReLU-based ResNets and observe that we get better adversarial accuracy for the architectures with RReLU than ReLU. We also demonstrate how this concept of rotation can be applied to the GELU and SiLU activation functions, commonly utilized in Transformer and EfficientNet architectures, respectively. The proposed method can be utilized by combining with other structural pruning methods resulting in better sparsity. For the GELU-based multi-layer perceptron (MLP) part of the Transformer, we obtain $2.6\%$ improvement in accuracy with $6.32\%$ saving in both memory and computation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Wqn8zirthg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Wqn8zirthg.html">DDLP: Unsupervised Object-centric Video Prediction with Deep Dynamic Latent Particles</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tal Daniel &middot; Aviv Tamar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Wqn8zirthg"></div>

    <a href="paper_pages/Wqn8zirthg.html">
        <img src="http://img.youtube.com/vi/3S2pKhi_ewY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Wqn8zirthg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Wqn8zirthg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Wqn8zirthg">
                Abstract <i id="caret-Wqn8zirthg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Wqn8zirthg">
        <div class="abstract-display">
            <p>We propose a new object-centric video prediction algorithm based on the deep latent particle (DLP) representation of Daniel and Tamar (2022). In comparison to existing slot- or patch-based representations, DLPs model the scene using a set of keypoints with learned parameters for properties such as position and size, and are both efficient and interpretable. Our method, \textit{deep dynamic latent particles} (DDLP), yields state-of-the-art object-centric video prediction results on several challenging datasets. The interpretable nature of DDLP allows us to perform ``what-if'' generation -- predict the consequence of changing properties of objects in the initial frames, and DLP's compact structure enables efficient diffusion-based unconditional video generation. Videos, code and pre-trained models are available: https://taldatech.github.io/ddlp-web</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tP1PBrMUlX">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tP1PBrMUlX.html">Synthesizing Libraries of Programs with Auxiliary Functions</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Habibur Rahman &middot; Thirupathi Reddy Emireddy &middot; Kenneth Tjhia &middot; Elham Parhizkar &middot; Levi Lelis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tP1PBrMUlX"></div>

    <a href="paper_pages/tP1PBrMUlX.html">
        <img src="http://img.youtube.com/vi/SJAAMtyqqnE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tP1PBrMUlX" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tP1PBrMUlX" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tP1PBrMUlX">
                Abstract <i id="caret-tP1PBrMUlX" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tP1PBrMUlX">
        <div class="abstract-display">
            <p>A common approach to program synthesis is to use a learned function to guide the search for a program that satisfies the user's intent. In this paper, we propose a method that offers search guidance, through a domain-dependent auxiliary function, that can be orthogonal to the guidance previous functions provide. Our method, which we call Auxiliary-Based Library Learning (Aulile), searches for a solution in the program space using a base algorithm. If this search does not produce a solution, Aulile enhances the language with a library of programs discovered in the search that optimizes for the auxiliary function. Then, it repeats the search with this library-augmented language. This process is repeated until a solution is found or the system reaches a timeout. We evaluate Aulile in string manipulation tasks. Aulile improved, in some cases by a large margin, the performance of several base algorithms that use different search and learning strategies: Bus, Bustle, Crossbeam, and Bee Search. Our results suggest that Aulile offers an effective method of injecting domain knowledge into existing systems through a library learning scheme that optimizes for an auxiliary function.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-7yswRA8zzw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/7yswRA8zzw.html">Pull-back Geometry of Persistent Homology Encodings</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shuang Liang &middot; Renata Turkes &middot; Jiayi Li &middot; Nina Otter &middot; Guido Montufar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-7yswRA8zzw"></div>

    <a href="paper_pages/7yswRA8zzw.html">
        <img src="http://img.youtube.com/vi/q4DctLOZZTs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-7yswRA8zzw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-7yswRA8zzw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-7yswRA8zzw">
                Abstract <i id="caret-7yswRA8zzw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-7yswRA8zzw">
        <div class="abstract-display">
            <p>Persistent homology (PH) is a method for generating topology-inspired representations of data. Empirical studies that investigate the properties of PH, such as its sensitivity to perturbations or ability to detect a feature of interest, commonly rely on training and testing an additional model on the basis of the PH representation. To gain more intrinsic insights about PH, independently of the choice of such a model, we propose a novel methodology based on the pull-back geometry that a PH encoding induces on the data manifold. The spectrum and eigenvectors of the induced metric help to identify the most and least significant information captured by PH. Furthermore, the pull-back norm of tangent vectors provides insights about the sensitivity of PH to a given perturbation, or its potential to detect a given feature of interest, and in turn its ability to solve a given classification or regression problem. Experimentally, the insights gained through our methodology align well with the existing knowledge about PH. Moreover, we show that the pull-back norm correlates with the performance on downstream tasks, and can therefore guide the choice of a suitable PH encoding.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YY2iA0hfia">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YY2iA0hfia.html">Does Representation Similarity Capture Function Similarity?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lucas Hayne &middot; Heejung Jung &middot; R. Carter</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YY2iA0hfia"></div>

    <a href="paper_pages/YY2iA0hfia.html">
        <img src="http://img.youtube.com/vi/9m9f45_72B0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YY2iA0hfia" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YY2iA0hfia" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YY2iA0hfia">
                Abstract <i id="caret-YY2iA0hfia" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YY2iA0hfia">
        <div class="abstract-display">
            <p>Representation similarity metrics are widely used to compare learned representations in neural networks, as is evident in extensive literature investigating metrics that accurately capture information encoded in representations. However, aiming to capture all of the information available in representations may have little to do with what information is actually used by the downstream network. One solution is to experiment with interventions on network function. By ablating groups of units thought to carry information and observing whether those ablations affect network performance, we can focus on an outcome that mechanistically links representations to function. In this paper, we systematically test representation similarity metrics to evaluate their sensitivity to functional changes induced by ablation. We use network performance changes after ablation as a way to measure the influence of representation on function. These measures of function allow us to test how well similarity metrics capture changes in network performance versus changes to linear decodability. Network performance measures index the information used by the downstream network, while linear decoding methods index available information in the representation. We show that all of the tested metrics are more sensitive to decodable features than network performance. When comparing these metrics, Procrustes and CKA outperform regularized CCA-based methods on average. Although Procrustes and CKA outperform on average, these metrics have a diminished advantage when looking at network performance. We provide ablation tests of the utility of different representational similarity metrics. Our results suggest that interpretability methods will be more effective if they are based on representational similarity metrics that have been evaluated using ablation tests.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0T2OTVCCC1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0T2OTVCCC1.html">Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">William Andersson &middot; Jakob Heiss &middot; Florian Krach &middot; Josef Teichmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0T2OTVCCC1"></div>

    <a href="paper_pages/0T2OTVCCC1.html">
        <img src="http://img.youtube.com/vi/PSglx3a3bBI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0T2OTVCCC1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0T2OTVCCC1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0T2OTVCCC1">
                Abstract <i id="caret-0T2OTVCCC1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0T2OTVCCC1">
        <div class="abstract-display">
            <p>The \emph{Path-Dependent Neural Jump Ordinary Differential Equation (PD-NJ-ODE)} is a model for predicting continuous-time stochastic processes with irregular and incomplete observations. In particular, the method learns optimal forecasts given irregularly sampled time series of incomplete past observations. So far the process itself and the coordinate-wise observation times were assumed to be independent and observations were assumed to be noiseless. In this work we discuss two extensions to lift these restrictions and provide theoretical guarantees as well as empirical examples for them. In particular, we can lift the assumption of independence by extending the theory to much more realistic settings of conditional independence without any need to change the algorithm. Moreover, we introduce a new loss function, which allows us to deal with noisy observations and explain why the previously used loss function did not lead to a consistent estimator.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9TqAUYB6tC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9TqAUYB6tC.html">Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pulkit Gopalani &middot; Samyak Jha &middot; Anirbit Mukherjee</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9TqAUYB6tC"></div>

    <a href="paper_pages/9TqAUYB6tC.html">
        <img src="http://img.youtube.com/vi/aFZFph-k-EM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9TqAUYB6tC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9TqAUYB6tC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9TqAUYB6tC">
                Abstract <i id="caret-9TqAUYB6tC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9TqAUYB6tC">
        <div class="abstract-display">
            <p>In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data with any number of gates with adequately smooth and bounded activations, like sigmoid and tanh, and for a class of distributions from which the initial weight is sampled. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show that the logistic loss function on any size neural net can be Frobenius norm regularized by a width-independent parameter such that the regularized loss is a ``Villani function'' -- and thus be able to build on recent progress with analyzing SGD on such objectives.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-uxNfN2PU1W">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/uxNfN2PU1W.html">Effective Latent Differential Equation Models via Attention and Multiple Shooting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Germán Abrevaya &middot; Mahta Ramezanian-Panahi &middot; Jean-Christophe Gagnon-Audet &middot; Pablo Polosecki &middot; Irina Rish &middot; Silvina Ponce Dawson &middot; Guillermo Cecchi &middot; Guillaume Dumas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-uxNfN2PU1W"></div>

    <a href="paper_pages/uxNfN2PU1W.html">
        <img src="http://img.youtube.com/vi/XYv10fuumCQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-uxNfN2PU1W" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-uxNfN2PU1W" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-uxNfN2PU1W">
                Abstract <i id="caret-uxNfN2PU1W" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-uxNfN2PU1W">
        <div class="abstract-display">
            <p>Scientific Machine Learning (SciML) is a burgeoning field that synergistically combines domain-aware and interpretable models with agnostic machine learning techniques. In this work, we introduce GOKU-UI, an evolution of the SciML generative model GOKU-nets. GOKU-UI not only broadens the original model's spectrum to incorporate other classes of differential equations, such as Stochastic Differential Equations (SDEs), but also integrates attention mechanisms and a novel multiple shooting training strategy in the latent space. These modifications have led to a significant increase in its performance in both reconstruction and forecast tasks, as demonstrated by our evaluation on simulated and empirical data. Specifically, GOKU-UI outperformed all baseline models on synthetic datasets even with a training set 16-fold smaller, underscoring its remarkable data efficiency. Furthermore, when applied to empirical human brain data, while incorporating stochastic Stuart-Landau oscillators into its dynamical core, our proposed enhancements markedly increased the model's effectiveness in capturing complex brain dynamics. GOKU-UI demonstrated a reconstruction error five times lower than other baselines, and the multiple shooting method reduced the GOKU-nets prediction error for future brain activity up to 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded whole-brain dynamics into a latent representation, learning a low-dimensional dynamical system model that could offer insights into brain functionality and open avenues for practical applications such as the classification of mental states or psychiatric conditions. Ultimately, our research provides further impetus for the field of Scientific Machine Learning, showcasing the potential for advancements when established scientific insights are interwoven with modern machine learning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Uv3XVAEgG6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Uv3XVAEgG6.html">Kernel Normalized Convolutional Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reza Nasirigerdeh &middot; Reihaneh Torkzadehmahani &middot; Daniel Rueckert &middot; Georgios Kaissis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Uv3XVAEgG6"></div>

    <a href="paper_pages/Uv3XVAEgG6.html">
        <img src="http://img.youtube.com/vi/V7fQTc6MNSE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Uv3XVAEgG6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Uv3XVAEgG6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Uv3XVAEgG6">
                Abstract <i id="caret-Uv3XVAEgG6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Uv3XVAEgG6">
        <div class="abstract-display">
            <p>Existing convolutional neural network architectures frequently rely upon batch normalization (BatchNorm) to effectively train the model. BatchNorm, however, performs poorly with small batch sizes, and is inapplicable to differential privacy. To address these limitations, we propose the kernel normalization (KernelNorm) and kernel normalized convolutional layers, and incorporate them into kernel normalized convolutional networks (KNConvNets) as the main building blocks. We implement KNConvNets corresponding to the state-of-the-art ResNets while forgoing the BatchNorm layers. Through extensive experiments, we illustrate that KNConvNets achieve higher or competitive performance compared to the BatchNorm counterparts in image classification and semantic segmentation. They also significantly outperform their batch-independent competitors including those based on layer and group normalization in non-private and differentially private training. Given that, KernelNorm combines the batch-independence property of layer and group normalization with the performance advantage of BatchNorm.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-75OwvzZZBT">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/75OwvzZZBT.html">Bias Amplification Enhances Minority Group Performance</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gaotang Li &middot; Jiarui Liu &middot; Wei Hu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-75OwvzZZBT"></div>

    <a href="paper_pages/75OwvzZZBT.html">
        <img src="http://img.youtube.com/vi/SOze6QxCPgw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-75OwvzZZBT" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-75OwvzZZBT" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-75OwvzZZBT">
                Abstract <i id="caret-75OwvzZZBT" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-75OwvzZZBT">
        <div class="abstract-display">
            <p>Neural networks produced by standard training are known to suffer from poor accuracy on rare subgroups despite achieving high accuracy on average, due to the correlations between certain spurious features and labels. Previous approaches based on worst-group loss minimization (e.g. Group-DRO) are effective in improving worse-group accuracy but require expensive group annotations for all the training samples. In this paper, we focus on the more challenging and realistic setting where group annotations are only available on a small validation set or are not available at all. We propose BAM, a novel two-stage training algorithm: in the first stage, the model is trained using a bias amplification scheme via introducing a learnable auxiliary variable for each training sample; in the second stage, we upweight the samples that the bias-amplified model misclassifies, and then continue training the same model on the reweighted dataset. Empirically, BAM achieves competitive performance compared with existing methods evaluated on spurious correlation benchmarks in computer vision and natural language processing. Moreover, we find a simple stopping criterion based on minimum class accuracy difference that can remove the need for group annotations, with little or no loss in worst-group accuracy. We perform extensive analyses and ablations to verify the effectiveness and robustness of our algorithm in varying class and group imbalance ratios.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-eN9CjU3h1b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/eN9CjU3h1b.html">MMD-Regularized Unbalanced Optimal Transport</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Piyushi Manupriya &middot; SakethaNath Jagarlapudi &middot; Pratik Jawanpuria</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-eN9CjU3h1b"></div>

    <a href="paper_pages/eN9CjU3h1b.html">
        <img src="http://img.youtube.com/vi/FSJ4_GfLhHo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-eN9CjU3h1b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-eN9CjU3h1b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-eN9CjU3h1b">
                Abstract <i id="caret-eN9CjU3h1b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-eN9CjU3h1b">
        <div class="abstract-display">
            <p>We study the unbalanced optimal transport (UOT) problem, where the marginal constraints are enforced using Maximum Mean Discrepancy (MMD) regularization. Our work is motivated by the observation that the literature on UOT is focused on regularization based on $\phi$-divergence (e.g., KL divergence). Despite the popularity of MMD, its role as a regularizer in the context of UOT seems less understood. We begin by deriving a specific dual of MMD-regularized UOT (MMD-UOT), which helps us prove several useful properties. One interesting outcome of this duality result is that MMD-UOT induces novel metrics, which not only lift the ground metric like the Wasserstein but are also sample-wise efficient to estimate like the MMD. Further, for real-world applications involving non-discrete measures, we present an estimator for the transport plan that is supported only on the given ($m$) samples. Under certain conditions, we prove that the estimation error with this finitely-supported transport plan is also $\mathcal{O}(1/\sqrt{m})$. As far as we know, such error bounds that are free from the curse of dimensionality are not known for $\phi$-divergence regularized UOT. Finally, we discuss how the proposed estimator can be computed efficiently using accelerated gradient descent. Our experiments show that MMD-UOT consistently outperforms popular baselines, including KL-regularized UOT and MMD, in diverse machine learning applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-H2EeStRTQn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/H2EeStRTQn.html">Introducing "Forecast Utterance" for Conversational Data Science</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Md. Mahadi Hassan &middot; Alex Knipper &middot; Shubhra Kanti Karmaker Santu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-H2EeStRTQn"></div>

    <a href="paper_pages/H2EeStRTQn.html">
        <img src="http://img.youtube.com/vi/oAJwaVVJPI4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-H2EeStRTQn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-H2EeStRTQn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-H2EeStRTQn">
                Abstract <i id="caret-H2EeStRTQn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-H2EeStRTQn">
        <div class="abstract-display">
            <p>Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, evaluated with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dUVejidXO7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dUVejidXO7.html">Visual Prompt Based Personalized Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Guanghao Li &middot; Wansen Wu &middot; Yan Sun &middot; Li Shen &middot; Baoyuan Wu &middot; Dacheng Tao</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dUVejidXO7"></div>

    <a href="paper_pages/dUVejidXO7.html">
        <img src="http://img.youtube.com/vi/kzBMpZ7od1k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dUVejidXO7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dUVejidXO7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dUVejidXO7">
                Abstract <i id="caret-dUVejidXO7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dUVejidXO7">
        <div class="abstract-display">
            <p>As a popular paradigm of distributed learning, personalized federated learning (PFL) allows personalized models to improve generalization ability and robustness by utilizing knowledge from all distributed clients. Most existing PFL algorithms tackle personalization in a model-centric way, such as personalized layer partition, model regularization, and model interpolation, which all fail to take into account the data characteristics of distributed clients. In this paper, we propose a novel PFL framework for image classification tasks, dubbed pFedPT, that leverages personalized visual prompts to implicitly represent local data distribution information of clients and provides that information to the aggregation model to help with classification tasks. Specifically, in each round of pFedPT training, each client generates a local personalized prompt related to local data distribution. Then, the local model is trained on the input composed of raw data and a visual prompt to learn the distribution information contained in the prompt. During model testing, the aggregated model obtains client-specific knowledge of the data distributions based on the prompts, which can be seen as an adaptive fine-tuning of the aggregation model to improve model performances on different clients. Furthermore, the visual prompt can be added as an orthogonal method to implement personalization on the client for existing FL methods to boost their performance. Experiments on the CIFAR10 and CIFAR100 datasets show that pFedPT outperforms several state-of-the-art (SOTA) PFL algorithms by a large margin in various settings. The code is available at: https://github.com/hkgdifyu/pFedPT.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-n2YifD4Dxo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/n2YifD4Dxo.html">Are you using test log-likelihood correctly?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sameer Deshpande &middot; Soumya Ghosh &middot; Tin D. Nguyen &middot; Tamara Broderick</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-n2YifD4Dxo"></div>

    <a href="paper_pages/n2YifD4Dxo.html">
        <img src="https://drive.google.com/thumbnail?id=10Hg_OBUU52ARiWjDJK7q6fYHU74my8vX" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-n2YifD4Dxo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-n2YifD4Dxo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-n2YifD4Dxo">
                Abstract <i id="caret-n2YifD4Dxo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-n2YifD4Dxo">
        <div class="abstract-display">
            <p>Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JllRdycmLk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JllRdycmLk.html">The (Un)Scalability of Informed Heuristic Function Estimation in NP-Hard Search Problems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sumedh Pendurkar &middot; Taoan Huang &middot; Brendan Juba &middot; Jiapeng Zhang &middot; Sven Koenig &middot; Guni Sharon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JllRdycmLk"></div>

    <a href="paper_pages/JllRdycmLk.html">
        <img src="http://img.youtube.com/vi/jc4YN-Nt1RU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JllRdycmLk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JllRdycmLk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JllRdycmLk">
                Abstract <i id="caret-JllRdycmLk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JllRdycmLk">
        <div class="abstract-display">
            <p>The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with a completely informed heuristic function, A* can solve such problems in time complexity that is polynomial in the solution cost and branching factor. In light of this fact, we examine a line of recent publications that propose fitting deep neural networks to the completely informed heuristic function. We assert that these works suffer from inherent scalability limitations since --- under the assumption of NP $\not \subseteq$ P/poly --- such approaches result in either (a) network sizes that scale super-polynomially in the instance sizes or (b) the accuracy of the fitted deep neural networks scales inversely with the instance sizes. Complementing our theoretical claims, we provide experimental results for three representative NP-hard search problems. The results suggest that fitting deep neural networks to informed heuristic functions requires network sizes that grow quickly with the problem instance size. We conclude by suggesting that the research community should focus on scalable methods for integrating heuristic search with machine learning, as opposed to methods relying on informed heuristic estimation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jesKcQxQ7j">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jesKcQxQ7j.html">A Review of the Applications of Deep Learning-Based Emergent Communication</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Brendon Boldt &middot; David R Mortensen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jesKcQxQ7j"></div>

    <a href="paper_pages/jesKcQxQ7j.html">
        <img src="http://img.youtube.com/vi/vkL-hRSuWfk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jesKcQxQ7j" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jesKcQxQ7j" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jesKcQxQ7j">
                Abstract <i id="caret-jesKcQxQ7j" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jesKcQxQ7j">
        <div class="abstract-display">
            <p>Emergent communication, or emergent language, is the field of research which studies how human language-like communication systems emerge de novo in deep multi-agent reinforcement learning environments. The possibilities of replicating the emergence of a complex behavior like language have strong intuitive appeal, yet it is necessary to complement this with clear notions of how such research can be applicable to other fields of science, technology, and engineering. This paper comprehensively reviews the applications of emergent communication research across machine learning, natural language processing, linguistics, and cognitive science. Each application is illustrated with a description of its scope, an explication of emergent communication's unique role in addressing it, a summary of the extant literature working towards the application, and brief recommendations for near-term research directions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YVPb6tyRJu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YVPb6tyRJu.html">FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Telepov &middot; Artem Tsypin &middot; Kuzma Khrabrov &middot; Sergey Yakukhnov &middot; Pavel Strashnov &middot; Petr Zhilyaev &middot; Egor Rumiantsev &middot; Daniel Ezhov &middot; Manvel Avetisian &middot; Olga Popova &middot; Artur Kadurin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YVPb6tyRJu"></div>

    <a href="paper_pages/YVPb6tyRJu.html">
        <img src="http://img.youtube.com/vi/BctJymnJfJg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YVPb6tyRJu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YVPb6tyRJu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YVPb6tyRJu">
                Abstract <i id="caret-YVPb6tyRJu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YVPb6tyRJu">
        <div class="abstract-display">
            <p>A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it.
Molecular docking is a common technique for evaluating protein-molecule interactions.
Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward.
In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (Yang et al., 2021).
Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins.
Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation.
We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oyfRWeoUJY">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oyfRWeoUJY.html">Addressing caveats of neural persistence with deep graph persistence</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Leander Girrbach &middot; Anders Christensen &middot; Ole Winther &middot; Zeynep Akata &middot; A. Sophia Koepke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oyfRWeoUJY"></div>

    <a href="paper_pages/oyfRWeoUJY.html">
        <img src="http://img.youtube.com/vi/KfCpoPYK_CY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oyfRWeoUJY" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oyfRWeoUJY" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oyfRWeoUJY">
                Abstract <i id="caret-oyfRWeoUJY" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oyfRWeoUJY">
        <div class="abstract-display">
            <p>Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at  https://github.com/ExplainableML/Deep-Graph-Persistence.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4uflhObpcp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4uflhObpcp.html">UnIVAL: Unified Model for Image, Video, Audio and Language Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mustafa Shukor &middot; Corentin Dancette &middot; Alexandre Rame &middot; Matthieu Cord</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4uflhObpcp"></div>

    <a href="paper_pages/4uflhObpcp.html">
        <img src="http://img.youtube.com/vi/mYOun92st08/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4uflhObpcp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4uflhObpcp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4uflhObpcp">
                Abstract <i id="caret-4uflhObpcp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4uflhObpcp">
        <div class="abstract-display">
            <p>Large Language Models (LLMs) have made the ambitious quest for generalist agents significantly far from being a fantasy. A key hurdle for building such general models is the diversity and heterogeneity of tasks and modalities. A promising solution is unification, allowing the support of a myriad of tasks and modalities within one unified framework. While few large models (e.g., Flamingo (Alayrac et al. 2022)), trained on massive datasets, can support more than two modalities, current small to mid-scale unified models are still limited to 2 modalities, usually image-text or video-text. The question that we ask is: is it possible to build efficiently a unified model that can support all modalities? To answer this, we propose UnIVAL, a step further towards this ambitious goal. Without relying on fancy datasets sizes or models with billions of parameters, the ~ 0.25B parameter UnIVAL model goes beyond two modalities and unifies text, images, video, and audio into a single model. Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning. UnIVAL shows competitive performance to existing state-of-the-art approaches, across image and video-text tasks. The feature representations learned from image and video-text modalities,  allows the model to achieve competitive performance when finetuned on audio-text tasks, despite not being pretrained on audio. Thanks to the unified model, we propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-of-distribution generalization. Finally, we motivate unification by showing the synergy between tasks. The model weights and code are available at: https://github.com/mshukor/UnIVAL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lTOku838Zv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lTOku838Zv.html">Neural Implicit Manifold Learning for Topology-Aware Density Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Brendan Leigh Ross &middot; Gabriel Loaiza-Ganem &middot; Anthony L. Caterini &middot; Jesse C. Cresswell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lTOku838Zv"></div>

    <a href="paper_pages/lTOku838Zv.html">
        <img src="http://img.youtube.com/vi/f1a_8LoyZxw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lTOku838Zv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lTOku838Zv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lTOku838Zv">
                Abstract <i id="caret-lTOku838Zv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lTOku838Zv">
        <div class="abstract-display">
            <p>Natural data observed in $\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\mathcal{M}$, where $m < n$. This work focuses on the task of building theoretically principled generative models for such data. Current generative models learn $\mathcal{M}$ by mapping an $m$-dimensional latent variable through a neural network $f_\theta: \mathbb{R}^m \to \mathbb{R}^n$. These procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. We then learn the probability density within $\mathcal{M}$ with a constrained energy-based model, which employs a constrained variant of Langevin dynamics to train and sample from the learned manifold. In experiments on synthetic and natural data, we show that our model can learn manifold-supported distributions with complex topologies more accurately than pushforward models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-igDOV2KBwM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/igDOV2KBwM.html">On Perfect Clustering for Gaussian Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Juan Cuesta-Albertos &middot; Subhajit Dutta</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-igDOV2KBwM"></div>

    <a href="paper_pages/igDOV2KBwM.html">
        <img src="http://img.youtube.com/vi/NkV7sgdMioE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-igDOV2KBwM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-igDOV2KBwM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-igDOV2KBwM">
                Abstract <i id="caret-igDOV2KBwM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-igDOV2KBwM">
        <div class="abstract-display">
            <p>In this paper, we propose a data based transformation for infinite-dimensional Gaussian processes and derive its limit theorem. For a clustering problem using mixture models, an appropriate modification of this transformation asymptotically leads to perfect separation of the populations under rather general conditions, except the scenario in which differences between clusters depend only on the locations; in which case our procedure is useless. Theoretical properties related to label consistency are studied for the k-means clustering algorithm when used on this transformed data. Good empirical performance of the proposed methodology is demonstrated using simulated as well as benchmark data sets, when compared with some popular parametric and nonparametric methods for such functional data.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Q4aAITDgdP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Q4aAITDgdP.html">Learn the Time to Learn: Replay Scheduling in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Marcus Klasson &middot; Hedvig Kjellstrom &middot; Cheng Zhang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Q4aAITDgdP"></div>

    <a href="paper_pages/Q4aAITDgdP.html">
        <img src="http://img.youtube.com/vi/huCX46HqMl4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Q4aAITDgdP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Q4aAITDgdP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Q4aAITDgdP">
                Abstract <i id="caret-Q4aAITDgdP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Q4aAITDgdP">
        <div class="abstract-display">
            <p>Replay methods are known to be successful at mitigating catastrophic forgetting in continual learning scenarios despite having limited access to historical data. However, storing historical data is cheap in many real-world settings, yet replaying all historical data is often prohibited due to processing time constraints. In such settings, we propose that continual learning systems should learn the time to learn and schedule which tasks to replay at different time steps. We first demonstrate the benefits of our proposal by using Monte Carlo tree search to find a proper replay schedule, and show that the found replay schedules can outperform fixed scheduling policies when combined with various replay methods in different continual learning settings. Additionally, we propose a framework for learning replay scheduling policies with reinforcement learning. We show that the learned policies can generalize better in new continual learning scenarios compared to equally replaying all seen tasks, without added computational cost. Our study reveals the importance of learning the time to learn in continual learning, which brings current research closer to real-world needs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-RyZB4qXEgt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/RyZB4qXEgt.html">Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vincent Abbott</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-RyZB4qXEgt"></div>

    <a href="paper_pages/RyZB4qXEgt.html">
        <img src="http://img.youtube.com/vi/ghlIs8bVXU4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-RyZB4qXEgt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-RyZB4qXEgt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-RyZB4qXEgt">
                Abstract <i id="caret-RyZB4qXEgt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-RyZB4qXEgt">
        <div class="abstract-display">
            <p>Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation.

In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oud7Ny0KQy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oud7Ny0KQy.html">RIFLE: Imputation and Robust Inference from Low Order Marginals</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sina Baharlouei &middot; Sze-Chuan Suen &middot; Meisam Razaviyayn</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oud7Ny0KQy"></div>

    <a href="paper_pages/oud7Ny0KQy.html">
        <img src="http://img.youtube.com/vi/hS9d7RS7TBQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oud7Ny0KQy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oud7Ny0KQy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oud7Ny0KQy">
                Abstract <i id="caret-oud7Ny0KQy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oud7Ny0KQy">
        <div class="abstract-display">
            <p>The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for predicting the target variable in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. We compare RIFLE with state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) in numerical experiments. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-leqr0vQzeN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/leqr0vQzeN.html">A Robust Backpropagation-Free Framework for Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Timothy Zee &middot; Alex Ororbia &middot; Ankur Mali &middot; Ifeoma Nwogu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-leqr0vQzeN"></div>

    <a href="paper_pages/leqr0vQzeN.html">
        <img src="http://img.youtube.com/vi/bVOzZjMxGzo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-leqr0vQzeN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-leqr0vQzeN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-leqr0vQzeN">
                Abstract <i id="caret-leqr0vQzeN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-leqr0vQzeN">
        <div class="abstract-display">
            <p>While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients that are computed by backpropagation of errors (backprop). Gradients are required to obtain synaptic weight adjustments but require knowledge of feed forward activities in order to conduct backward propagation, a biologically implausible process. This is known as the "weight transport problem''. Therefore, in this work, we present a more biologically plausible approach towards solving the weight transport problem for image data. This approach, which we name the error-kernel driven activation alignment (EKDAA) algorithm, accomplishes through the introduction of locally derived error transmission kernels and error maps. Like standard deep learning networks, EKDAA performs the standard forward process via weights and activation functions; however, its backward error computation involves adaptive error kernels that propagate local error signals through the network. The efficacy of EKDAA is demonstrated by performing visual-recognition tasks on the Fashion MNIST, CIFAR-10 and SVHN benchmarks, along with demonstrating its ability to extract visual features from natural color images. Furthermore, in order to demonstrate its non-reliance on gradient computations, results are presented for an EKDAA-trained CNN that employs a non-differentiable activation function.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3taIQG4C7H">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3taIQG4C7H.html">Label Noise-Robust Learning using a Confidence-Based Sieving Strategy</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reihaneh Torkzadehmahani &middot; Reza Nasirigerdeh &middot; Daniel Rueckert &middot; Georgios Kaissis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3taIQG4C7H"></div>

    <a href="paper_pages/3taIQG4C7H.html">
        <img src="http://img.youtube.com/vi/LE9iD9hcAKc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3taIQG4C7H" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3taIQG4C7H" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3taIQG4C7H">
                Abstract <i id="caret-3taIQG4C7H" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3taIQG4C7H">
        <div class="abstract-display">
            <p>In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other state-of-the-art approaches, such as Co-teaching and DivideMix to further improve model performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4i1MXH8Sle">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4i1MXH8Sle.html">CAREER: A Foundation Model for Labor Sequence Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Keyon Vafa &middot; Emil Palikot &middot; Tianyu Du &middot; Ayush Kanodia &middot; Susan Athey &middot; David Blei</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4i1MXH8Sle"></div>

    <a href="paper_pages/4i1MXH8Sle.html">
        <img src="http://img.youtube.com/vi/BLgfbNeTLCI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4i1MXH8Sle" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4i1MXH8Sle" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4i1MXH8Sle">
                Abstract <i id="caret-4i1MXH8Sle" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4i1MXH8Sle">
        <div class="abstract-display">
            <p>Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-PEyVq0hlO3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/PEyVq0hlO3.html">Dual Cognitive Architecture: Incorporating Biases and Multi-Memory Systems for Lifelong Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shruthi Gowda &middot; Bahram Zonooz &middot; Elahe Arani</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-PEyVq0hlO3"></div>

    <a href="paper_pages/PEyVq0hlO3.html">
        <img src="http://img.youtube.com/vi/08tfpjvUGqs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-PEyVq0hlO3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-PEyVq0hlO3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-PEyVq0hlO3">
                Abstract <i id="caret-PEyVq0hlO3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-PEyVq0hlO3">
        <div class="abstract-display">
            <p>Artificial neural networks (ANNs) exhibit a narrow scope of expertise on stationary independent data. However, the data in the real world is continuous and dynamic, and ANNs must adapt to novel scenarios while also retaining the learned knowledge to become lifelong learners. The ability of humans to excel at these tasks can be attributed to multiple factors ranging from cognitive computational structures, cognitive biases, and the multi-memory systems in the brain. We incorporate key concepts from each of these to design a novel framework, Dual Cognitive Architecture (DUCA), which includes multiple sub-systems, implicit and explicit knowledge representation dichotomy, inductive bias, and a multi-memory system. DUCA shows improvement across different settings and datasets, and it also exhibits reduced task recency bias, without the need for extra information. To further test the versatility of lifelong learning methods on a challenging distribution shift, we introduce a novel domain-incremental dataset DN4IL. In addition to improving performance on existing benchmarks, DUCA also demonstrates superior performance on this complex dataset.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2uMnAwWnRy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2uMnAwWnRy.html">Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Lev Proleev &middot; Diana Mincu &middot; F Lee Hartsell &middot; Katherine A Heller &middot; Subhrajit Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2uMnAwWnRy"></div>

    <a href="paper_pages/2uMnAwWnRy.html">
        <img src="http://img.youtube.com/vi/sqDLDkbP2H0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2uMnAwWnRy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2uMnAwWnRy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2uMnAwWnRy">
                Abstract <i id="caret-2uMnAwWnRy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2uMnAwWnRy">
        <div class="abstract-display">
            <p>Multiple sclerosis is a disease that affects the brain and spinal cord, it can lead to severe disability and has no known cure. The majority of prior work in machine learning for multiple sclerosis has been centered around using Magnetic Resonance Imaging scans or laboratory tests; these modalities are both expensive to acquire and can be unreliable. In a recent paper it was shown that disease progression can be predicted effectively using performance outcome measures and demographic data. In our work we build on this to investigate the modeling side, using continuous time models to predict progression. We benchmark four continuous time models using a publicly available multiple sclerosis dataset. We find that the best continuous model is often able to outperform the best benchmarked discrete time model. We also carry out an extensive ablation to discover the sources of performance gains, we find that standardizing existing features leads to a larger performance increase than interpolating missing features.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-W0ehjkl9x7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/W0ehjkl9x7.html">DoCoM: Compressed Decentralized Optimization with Near-Optimal Sample Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chung-Yiu Yau &middot; Hoi To Wai</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-W0ehjkl9x7"></div>

    <a href="paper_pages/W0ehjkl9x7.html">
        <img src="http://img.youtube.com/vi/3ZNmkE9ryEs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-W0ehjkl9x7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-W0ehjkl9x7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-W0ehjkl9x7">
                Abstract <i id="caret-W0ehjkl9x7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-W0ehjkl9x7">
        <div class="abstract-display">
            <p>This paper proposes the Doubly Compressed Momentum-assisted stochastic gradient tracking algorithm (DoCoM) for communication-efficient decentralized optimization. The algorithm features two main ingredients to achieve a near-optimal sample complexity while allowing for communication compression. First, the algorithm tracks both the averaged iterate and stochastic gradient using compressed gossiping consensus. Second, a momentum step is incorporated for adaptive variance reduction with the local gradient estimates. We show that DoCoM finds a near-stationary solution at all participating agents satisfying $\mathbb{E}[ \| \nabla f( \theta ) \|^2 ] = {\cal O}( 1 / T^{2/3} )$ in $T$ iterations, where $f(\theta)$ is a smooth (possibly non-convex) objective function. Notice that the proof is achieved via analytically designing a new potential function that tightly tracks the one-iteration progress of DoCoM. As a corollary, our analysis also established the linear convergence of DoCoM to a global optimal solution for objective functions with the Polyak-Łojasiewicz condition. Numerical experiments demonstrate that our algorithm outperforms several state-of-the-art algorithms in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ySWQ6eXAKp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ySWQ6eXAKp.html">Not All Causal Inference is the Same</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej Zečević &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ySWQ6eXAKp"></div>

    <a href="paper_pages/ySWQ6eXAKp.html">
        <img src="http://img.youtube.com/vi/WSYtc-IUe3A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ySWQ6eXAKp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ySWQ6eXAKp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ySWQ6eXAKp">
                Abstract <i id="caret-ySWQ6eXAKp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ySWQ6eXAKp">
        <div class="abstract-display">
            <p>Neurally-parameterized Structural Causal Models in the Pearlian notion to causality, referred to as NCM, were recently introduced as a step towards next-generation learning systems. However, said NCM are only concerned with the learning aspect of causal inference
and totally miss out on the architecture aspect. That is, actual causal inference within NCM is intractable in that the NCM won’t return an answer to a query in polynomial time. This insight follows as corollary to the more general statement on the intractability of arbitrary structural causal model (SCM) parameterizations, which we prove in this work through classical 3-SAT reduction. Since future learning algorithms will be required to deal with both high dimensional data and highly complex mechanisms governing the data, we ultimately believe work on tractable inference for causality to be decisive. We also show that not all “causal” models are created equal. More specifically, there are models capable of answering causal queries that are not SCM, which we refer to as partially causal models
(PCM). We provide a tabular taxonomy in terms of tractability properties for all of the different model families, namely correlation-based, PCM and SCM. To conclude our work, we also provide some initial ideas on how to overcome parts of the intractability of causal inference
with SCM by showing an example of how parameterizing an SCM with SPN modules can at least allow for tractable mechanisms. With this work we hope that our insights can raise awareness for this novel research direction since achieving success with causality in real world downstream tasks will not only depend on learning correct models but also require having the practical ability to gain access to
model inferences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tv46tCzs83">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tv46tCzs83.html">Causal Parrots: Large Language Models May Talk Causality But Are Not Causal</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej Zečević &middot; Moritz Willig &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tv46tCzs83"></div>

    <a href="paper_pages/tv46tCzs83.html">
        <img src="http://img.youtube.com/vi/vbwrhbuvedE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tv46tCzs83" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tv46tCzs83" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tv46tCzs83">
                Abstract <i id="caret-tv46tCzs83" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tv46tCzs83">
        <div class="abstract-display">
            <p>Some argue scale is all what is needed to achieve AI, covering even causal models.
We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables.
We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained.
If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1irVjE7A3w">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1irVjE7A3w.html">Meta-Learning via Classifier(-free) Diffusion Guidance</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elvis Nava &middot; Seijin Kobayashi &middot; Yifei Yin &middot; Robert K. Katzschmann &middot; Benjamin F Grewe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1irVjE7A3w"></div>

    <a href="paper_pages/1irVjE7A3w.html">
        <img src="http://img.youtube.com/vi/O6lB2RaBh2k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1irVjE7A3w" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1irVjE7A3w" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1irVjE7A3w">
                Abstract <i id="caret-1irVjE7A3w" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1irVjE7A3w">
        <div class="abstract-display">
            <p>We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second "guidance" model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: "HyperCLIP"-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model ("HyperLDM"), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Tkvmt9nDmB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Tkvmt9nDmB.html">Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal Murali &middot; Aahlad Manas Puli &middot; Ke Yu &middot; Rajesh Ranganath &middot; kayhan Batmanghelich</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Tkvmt9nDmB"></div>

    <a href="paper_pages/Tkvmt9nDmB.html">
        <img src="http://img.youtube.com/vi/kkQ0IKukx5o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Tkvmt9nDmB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Tkvmt9nDmB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Tkvmt9nDmB">
                Abstract <i id="caret-Tkvmt9nDmB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Tkvmt9nDmB">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) are prone to learning spurious features that correlate with the label during training but are irrelevant to the learning problem. This hurts model generalization and poses problems when deploying them in safety-critical applications. This paper aims to better understand the effects of spurious features through the lens of the learning dynamics of the internal neurons during the training process. We make the following observations: (1) While previous works highlight the harmful effects of spurious features on the generalization ability of DNNs, we emphasize that not all spurious features are harmful. Spurious features can be "benign" or "harmful" depending on whether they are "harder" or "easier" to learn than the core features for a given model. This definition is model and dataset dependent. (2) We build upon this premise and use instance difficulty methods (like Prediction Depth) to quantify "easiness" for a given model and to identify this behavior during the training phase. (3) We empirically show that the harmful spurious features can be detected by observing the learning dynamics of the DNN's early layers. In other words, easy features learned by the initial layers of a DNN early during the training can (potentially) hurt model generalization. We verify our claims on medical and vision datasets, both simulated and real, and justify the empirical success of our hypothesis by showing the theoretical connections between Prediction Depth and information-theoretic concepts like $\mathcal{V}$-usable information. Lastly, our experiments show that monitoring only accuracy during training (as is common in machine learning pipelines) is insufficient to detect spurious features. We, therefore, highlight the need for monitoring early training dynamics using suitable instance difficulty metrics.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-pHCdMat0gI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/pHCdMat0gI.html">Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Antonio Longa &middot; Veronica Lachi &middot; Gabriele Santin &middot; Monica Bianchini &middot; Bruno Lepri &middot; Pietro Lio &middot; franco scarselli &middot; Andrea Passerini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-pHCdMat0gI"></div>

    <a href="paper_pages/pHCdMat0gI.html">
        <img src="http://img.youtube.com/vi/2ImatNxkKFY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-pHCdMat0gI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-pHCdMat0gI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-pHCdMat0gI">
                Abstract <i id="caret-pHCdMat0gI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-pHCdMat0gI">
        <div class="abstract-display">
            <p>Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y8RZoPjEUl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y8RZoPjEUl.html">Simulate Time-integrated Coarse-grained Molecular Dynamics with Multi-scale Graph Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xiang Fu &middot; Tian Xie &middot; Nathan J. Rebello &middot; Bradley Olsen &middot; Tommi S. Jaakkola</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y8RZoPjEUl"></div>

    <a href="paper_pages/y8RZoPjEUl.html">
        <img src="http://img.youtube.com/vi/l3aGVjQezsc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y8RZoPjEUl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y8RZoPjEUl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y8RZoPjEUl">
                Abstract <i id="caret-y8RZoPjEUl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y8RZoPjEUl">
        <div class="abstract-display">
            <p>Molecular dynamics (MD) simulation is essential for various scientific domains but computationally expensive. Learning-based force fields have made significant progress in accelerating ab-initio MD simulation but are not fast enough for many real-world applications due to slow inference for large systems and small time steps (femtosecond-level). We aim to address these challenges by learning a multi-scale graph neural network that directly simulates coarse-grained MD with a very large time step (nanosecond-level) and a novel refinement module based on diffusion models to mitigate simulation instability. The effectiveness of our method is demonstrated in two complex systems: single-chain coarse-grained polymers and multi-component Li-ion polymer electrolytes. For evaluation, we simulate trajectories much longer than the training trajectories for systems with different chemical compositions that the model is not trained on. Structural and dynamical properties can be accurately recovered at several orders of magnitude higher speed than classical force fields by getting out of the femtosecond regime. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-m8U9rSs6gU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/m8U9rSs6gU.html">Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Melika Behjati &middot; James Henderson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-m8U9rSs6gU"></div>

    <a href="paper_pages/m8U9rSs6gU.html">
        <img src="http://img.youtube.com/vi/KjAc20Co1Nk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-m8U9rSs6gU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-m8U9rSs6gU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-m8U9rSs6gU">
                Abstract <i id="caret-m8U9rSs6gU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-m8U9rSs6gU">
        <div class="abstract-display">
            <p>Characters do not convey meaning, but sequences of characters do.  We propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images.  We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers.  These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content, and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8L7Rh6FIXt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8L7Rh6FIXt.html">IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shivani Bathla &middot; Vinita Vasudevan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8L7Rh6FIXt"></div>

    <a href="paper_pages/8L7Rh6FIXt.html">
        <img src="http://img.youtube.com/vi/143xjwN-MSw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8L7Rh6FIXt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8L7Rh6FIXt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8L7Rh6FIXt">
                Abstract <i id="caret-8L7Rh6FIXt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8L7Rh6FIXt">
        <div class="abstract-display">
            <p>Exact computation of the partition function is known to be intractable, necessitating approximate inference techniques. Existing methods for approximate inference are slow to converge for many benchmarks. The control of accuracy-complexity trade-off is also non-trivial in many of these methods. We propose a novel  incremental build-infer-approximate (IBIA) framework for approximate inference that addresses these issues. In this framework, the probabilistic graphical model is converted into a  sequence of clique tree forests (SCTF) with bounded clique sizes.  We show that the SCTF can be used to efficiently compute the partition function. We propose two new algorithms which are used to construct the SCTF  and prove the correctness of both. The first is an algorithm for incremental construction of CTFs that is guaranteed to give a  valid CTF with bounded clique sizes and the second is an approximation algorithm that takes a calibrated CTF as input and yields a valid and calibrated CTF with reduced clique sizes as the output. We have evaluated our method using several benchmark sets from recent UAI competitions and our results show good accuracies with competitive runtimes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HqIuAzBxbh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HqIuAzBxbh.html">Consistent Collaborative Filtering via Tensor Decomposition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shiwen Zhao &middot; Guillermo Sapiro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HqIuAzBxbh"></div>

    <a href="paper_pages/HqIuAzBxbh.html">
        <img src="http://img.youtube.com/vi/MTHefLFLSZI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HqIuAzBxbh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HqIuAzBxbh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HqIuAzBxbh">
                Abstract <i id="caret-HqIuAzBxbh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HqIuAzBxbh">
        <div class="abstract-display">
            <p>Collaborative filtering is the de facto standard for analyzing users’ activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zshemTAa6U">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zshemTAa6U.html">Test-Time Adaptation for Visual Document Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sayna Ebrahimi &middot; Sercan O Arik &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zshemTAa6U"></div>

    <a href="paper_pages/zshemTAa6U.html">
        <img src="video_thumbnails/zshemTAa6U.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zshemTAa6U" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zshemTAa6U" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zshemTAa6U">
                Abstract <i id="caret-zshemTAa6U" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zshemTAa6U">
        <div class="abstract-display">
            <p>For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\%  (ANLS score), respectively.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-f0FSDAy1bU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/f0FSDAy1bU.html">Faster Training of Neural ODEs Using Gauß–Legendre Quadrature</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-f0FSDAy1bU"></div>

    <a href="paper_pages/f0FSDAy1bU.html">
        <img src="http://img.youtube.com/vi/pKbLwsqy8aM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-f0FSDAy1bU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-f0FSDAy1bU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-f0FSDAy1bU">
                Abstract <i id="caret-f0FSDAy1bU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-f0FSDAy1bU">
        <div class="abstract-display">
            <p>Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gauß-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VmyFF5lL3F">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VmyFF5lL3F.html">Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mauricio Delbracio &middot; Peyman Milanfar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VmyFF5lL3F"></div>

    <a href="paper_pages/VmyFF5lL3F.html">
        <img src="http://img.youtube.com/vi/_VfyR9ChOFk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VmyFF5lL3F" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VmyFF5lL3F" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VmyFF5lL3F">
                Abstract <i id="caret-VmyFF5lL3F" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VmyFF5lL3F">
        <div class="abstract-display">
            <p>Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.

Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically  an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality.

While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XNFo3dQiCJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XNFo3dQiCJ.html">Generalizability of Adversarial Robustness Under Distribution Shifts</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kumail Alhamoud &middot; Hasan Abed Al Kader Hammoud &middot; Motasem Alfarra &middot; Bernard Ghanem</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XNFo3dQiCJ"></div>

    <a href="paper_pages/XNFo3dQiCJ.html">
        <img src="http://img.youtube.com/vi/PL4PbCmjyno/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XNFo3dQiCJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XNFo3dQiCJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XNFo3dQiCJ">
                Abstract <i id="caret-XNFo3dQiCJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XNFo3dQiCJ">
        <div class="abstract-display">
            <p>Recent progress in empirical and certified robustness promises to deliver reliable and deployable Deep Neural Networks (DNNs). Despite that success, most existing evaluations of DNN robustness have been done on images sampled from the same distribution on which the model was trained on. However, in the real world, DNNs may be deployed in dynamic environments that exhibit significant distribution shifts. In this work, we take a first step towards thoroughly investigating the interplay between empirical and certified adversarial robustness on one hand and domain generalization on another. To do so, we train robust models on multiple domains and evaluate their accuracy and robustness on an unseen domain. We observe that: (1) both empirical and certified robustness generalize to unseen domains, and (2) the level of generalizability does not correlate well with input visual similarity, measured by the FID between source and target domains. We also extend our study to cover a real-world medical application, in which adversarial augmentation significantly boosts the generalization of robustness with minimal effect on clean data accuracy.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VV4zJwLwI7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VV4zJwLwI7.html">Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Junhyun Nam &middot; Sangwoo Mo &middot; Jaeho Lee &middot; Jinwoo Shin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VV4zJwLwI7"></div>

    <a href="paper_pages/VV4zJwLwI7.html">
        <img src="http://img.youtube.com/vi/RDhLKJnZTjE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VV4zJwLwI7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VV4zJwLwI7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VV4zJwLwI7">
                Abstract <i id="caret-VV4zJwLwI7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VV4zJwLwI7">
        <div class="abstract-display">
            <p>Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LKz5SqIXPJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LKz5SqIXPJ.html">On the Robustness of Dataset Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sebastian Szyller &middot; Rui Zhang &middot; Jian Liu &middot; N Asokan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LKz5SqIXPJ"></div>

    <a href="paper_pages/LKz5SqIXPJ.html">
        <img src="http://img.youtube.com/vi/jZ3Lw98gfv8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LKz5SqIXPJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LKz5SqIXPJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LKz5SqIXPJ">
                Abstract <i id="caret-LKz5SqIXPJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LKz5SqIXPJ">
        <div class="abstract-display">
            <p>Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification)  or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p28wv4G65d">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p28wv4G65d.html">SC2 Benchmark: Supervised Compression for Split Computing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yoshitomo Matsubara &middot; Ruihan Yang &middot; Marco Levorato &middot; Stephan Mandt</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p28wv4G65d"></div>

    <a href="paper_pages/p28wv4G65d.html">
        <img src="http://img.youtube.com/vi/uwwV_vAOvX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p28wv4G65d" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p28wv4G65d" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p28wv4G65d">
                Abstract <i id="caret-p28wv4G65d" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p28wv4G65d">
        <div class="abstract-display">
            <p>With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nfYwRIezvg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nfYwRIezvg.html">DORA: Exploring Outlier Representations in Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kirill Bykov &middot; Mayukh Deb &middot; Dennis Grinwald &middot; Klaus Robert Muller &middot; Marina MC Höhne</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nfYwRIezvg"></div>

    <a href="paper_pages/nfYwRIezvg.html">
        <img src="http://img.youtube.com/vi/k2tgN7YsjN8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nfYwRIezvg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nfYwRIezvg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nfYwRIezvg">
                Abstract <i id="caret-nfYwRIezvg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nfYwRIezvg">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vXSsTYs6ZB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vXSsTYs6ZB.html">LEAD: Min-Max Optimization from a Physical Perspective</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reyhane Askari Hemmat &middot; Amartya Mitra &middot; Guillaume Lajoie &middot; Ioannis Mitliagkas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vXSsTYs6ZB"></div>

    <a href="paper_pages/vXSsTYs6ZB.html">
        <img src="http://img.youtube.com/vi/EfwIc0GXb8E/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vXSsTYs6ZB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vXSsTYs6ZB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vXSsTYs6ZB">
                Abstract <i id="caret-vXSsTYs6ZB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vXSsTYs6ZB">
        <div class="abstract-display">
            <p>Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEAD’s convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-g97OHbQyk1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/g97OHbQyk1.html">The Vendi Score: A Diversity Evaluation Metric for Machine Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dan Friedman &middot; Adji Bousso Dieng</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-g97OHbQyk1"></div>

    <a href="paper_pages/g97OHbQyk1.html">
        <img src="http://img.youtube.com/vi/r12fod3WZ78/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-g97OHbQyk1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-g97OHbQyk1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-g97OHbQyk1">
                Abstract <i id="caret-g97OHbQyk1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-g97OHbQyk1">
        <div class="abstract-display">
            <p>Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dXnccpSSYF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dXnccpSSYF.html">Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xueying Zhan &middot; Zeyu Dai &middot; Qingzhong Wang &middot; Qing Li &middot; Haoyi Xiong &middot; Dejing Dou &middot; Antoni B. Chan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dXnccpSSYF"></div>

    <a href="paper_pages/dXnccpSSYF.html">
        <img src="http://img.youtube.com/vi/HUXedZB47zc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dXnccpSSYF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dXnccpSSYF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dXnccpSSYF">
                Abstract <i id="caret-dXnccpSSYF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dXnccpSSYF">
        <div class="abstract-display">
            <p>Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators.  However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HVAeM6sNo8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HVAeM6sNo8.html">Robust Alzheimer's Progression Modeling using Cross-Domain Self-Supervised Deep Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saba Dadsetan &middot; Mohsen Hejrati &middot; Shandong Wu &middot; Somaye Hashemifar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HVAeM6sNo8"></div>

    <a href="paper_pages/HVAeM6sNo8.html">
        <img src="https://drive.google.com/thumbnail?id=1AXjAHw2Ef3Ni_uqZpoih9r72Jq-nHc5F" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HVAeM6sNo8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HVAeM6sNo8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HVAeM6sNo8">
                Abstract <i id="caret-HVAeM6sNo8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HVAeM6sNo8">
        <div class="abstract-display">
            <p>Developing successful artificial intelligence systems in practice depends on both robust deep learning models and large, high-quality data. However, acquiring and labeling data can be prohibitively expensive and time-consuming in many real-world applications, such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using medical images as input. We demonstrate that self-supervised pretraining can improve the prediction of Alzheimer's Disease progression from brain MRI. We also show that pretraining on extended (but not labeled) brain MRI data outperforms pretraining on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pretraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YwNrPLjHSL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YwNrPLjHSL.html">Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tian Yun &middot; Usha Bhalla &middot; Ellie Pavlick &middot; Chen Sun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YwNrPLjHSL"></div>

    <a href="paper_pages/YwNrPLjHSL.html">
        <img src="http://img.youtube.com/vi/qerql58NeeE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YwNrPLjHSL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YwNrPLjHSL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YwNrPLjHSL">
                Abstract <i id="caret-YwNrPLjHSL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YwNrPLjHSL">
        <div class="abstract-display">
            <p>Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive concepts–such as colors, shapes, or the attributes of object parts–emerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap
first asks a VL model to generate concept activations with text prompts from a predefined list of primitive concepts, and then learns to construct an explicit composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to com-
posite concepts (e.g. a red-winged blackbird). We demonstrate that a composition model can be designed as a set operation, and show that a composition model is straightforward for machines to learn from ground truth primitive concepts (as a linear classifier). We thus
hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability of the VL models’ learned primitive concept representations. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However,
we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p7UTv2hWgM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p7UTv2hWgM.html">Stochastic gradient updates yield deep equilibrium kernels</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Russell Tsuchida &middot; Cheng Soon Ong</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p7UTv2hWgM"></div>

    <a href="paper_pages/p7UTv2hWgM.html">
        <img src="http://img.youtube.com/vi/Ab2KEE9OqEk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p7UTv2hWgM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p7UTv2hWgM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p7UTv2hWgM">
                Abstract <i id="caret-p7UTv2hWgM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p7UTv2hWgM">
        <div class="abstract-display">
            <p>Implicit deep learning allows one to compute with implicitly defined features, for example features that solve optimisation problems. We consider the problem of computing with implicitly defined features in a kernel regime. We call such a kernel a deep equilibrium kernel (DEKer). Specialising on a stochastic gradient descent (SGD) update rule applied to features (not weights) in a latent variable model, we find an exact deterministic update rule for the (DEKer) in a high dimensional limit. This derived update rule resembles previously introduced infinitely wide neural network kernels. To perform our analysis, we describe an alternative parameterisation of the link function of exponential families, a result that may be of independent interest. This new parameterisation allows us to draw new connections between a statistician's inverse link function and a machine learner's activation function. We describe an interesting property of SGD in this high dimensional limit: even though individual iterates are random vectors, inner products of any two iterates are deterministic, and can converge to a unique fixed point as the number of iterates increases. We find that the (DEKer) empirically outperforms related neural network kernels on a series of benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DJr6zorJM2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DJr6zorJM2.html">A Study of Biologically Plausible Neural Network: The Role and Interactions of Brain-Inspired Mechanisms in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fahad Sarfraz &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DJr6zorJM2"></div>

    <a href="paper_pages/DJr6zorJM2.html">
        <img src="http://img.youtube.com/vi/xh2iyEwLnSg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DJr6zorJM2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DJr6zorJM2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DJr6zorJM2">
                Abstract <i id="caret-DJr6zorJM2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DJr6zorJM2">
        <div class="abstract-display">
            <p>Humans excel at continually acquiring, consolidating, and retaining information from an ever-changing environment, whereas artificial neural networks (ANNs) exhibit catastrophic forgetting. There are considerable differences in the complexity of synapses, the processing of information, and the learning mechanisms in biological neural networks and their artificial counterparts, which may explain the mismatch in performance. We consider a biologically plausible framework that constitutes separate populations of exclusively excitatory and inhibitory neurons that adhere to Dale's principle, and the excitatory pyramidal neurons are augmented with dendritic-like structures for context-dependent processing of stimuli. We then conduct a comprehensive study on the role and interactions of different mechanisms inspired by the brain, including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations that accompanied the learning event. Our study suggests that the employing of multiple complementary mechanisms in a biologically plausible architecture, similar to the brain, may be effective in enabling continual learning in ANNs. \footnote{We will make the code available upon acceptance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2mZSlQscj3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2mZSlQscj3.html">Neural Monge Map estimation and its applications</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jiaojiao Fan &middot; Shu Liu &middot; Shaojun Ma &middot; Hao-Min Zhou &middot; Yongxin Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2mZSlQscj3"></div>

    <a href="paper_pages/2mZSlQscj3.html">
        <img src="http://img.youtube.com/vi/wIb2ZyieQPo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2mZSlQscj3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2mZSlQscj3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2mZSlQscj3">
                Abstract <i id="caret-2mZSlQscj3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2mZSlQscj3">
        <div class="abstract-display">
            <p>Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another.  Neural network-based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can be applied in large-scale settings. Furthermore, using the duality gap we prove rigorously \textit{a posteriori} error analysis for the method. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation, class-preserving map, and image inpainting tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-KxBQPz7HKh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/KxBQPz7HKh.html">Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Johanna Vielhaben &middot; Stefan Bluecher &middot; Nils Strodthoff</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-KxBQPz7HKh"></div>

    <a href="paper_pages/KxBQPz7HKh.html">
        <img src="http://img.youtube.com/vi/JZOzo-K05F0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-KxBQPz7HKh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-KxBQPz7HKh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-KxBQPz7HKh">
                Abstract <i id="caret-KxBQPz7HKh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-KxBQPz7HKh">
        <div class="abstract-display">
            <p>The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fvyh6mDWFr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fvyh6mDWFr.html">Understanding Noise-Augmented Training for Randomized Smoothing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ambar Pal &middot; Jeremias Sulam</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fvyh6mDWFr"></div>

    <a href="paper_pages/fvyh6mDWFr.html">
        <img src="http://img.youtube.com/vi/LzIoT5pX7pQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fvyh6mDWFr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fvyh6mDWFr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fvyh6mDWFr">
                Abstract <i id="caret-fvyh6mDWFr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fvyh6mDWFr">
        <div class="abstract-display">
            <p>Randomized smoothing is a technique for providing provable robustness guarantees against adversarial attacks while making minimal assumptions about a classifier. This method relies on taking a majority vote of any base classifier over multiple noise-perturbed inputs to obtain a smoothed classifier, and it remains the tool of choice to certify deep and complex neural network models. Nonetheless, non-trivial performance of such smoothed classifier crucially depends on the base model being trained on noise-augmented data, i.e., on a smoothed input distribution. While widely adopted in practice, it is still unclear how this noisy training of the base classifier precisely affects the risk of the robust smoothed classifier, leading to heuristics and tricks that are poorly understood. In this work we analyze these trade-offs theoretically in a binary classification setting, proving that these common observations are not universal. We show that, without making stronger distributional assumptions, no benefit can be expected from predictors trained with noise-augmentation, and we further characterize distributions where such benefit is obtained. Our analysis has direct implications to the practical deployment of randomized smoothing, and we illustrate some of these via experiments on CIFAR-10 and MNIST, as well as on synthetic datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VynY6Bk03b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VynY6Bk03b.html">How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jorge A Mendez &middot; ERIC EATON</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VynY6Bk03b"></div>

    <a href="paper_pages/VynY6Bk03b.html">
        <img src="http://img.youtube.com/vi/d6RSRnTvUfY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VynY6Bk03b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VynY6Bk03b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VynY6Bk03b">
                Abstract <i id="caret-VynY6Bk03b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VynY6Bk03b">
        <div class="abstract-display">
            <p>A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MRLHN4MSmA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MRLHN4MSmA.html">A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohamed Abdelhack &middot; Jiaming Zhang &middot; Sandhya Tripathi &middot; Bradley A Fritz &middot; Daniel Felsky &middot; Michael Avidan &middot; Yixin Chen &middot; Christopher Ryan King</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MRLHN4MSmA"></div>

    <a href="paper_pages/MRLHN4MSmA.html">
        <img src="http://img.youtube.com/vi/SI-5cuPJV9U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MRLHN4MSmA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MRLHN4MSmA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MRLHN4MSmA">
                Abstract <i id="caret-MRLHN4MSmA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MRLHN4MSmA">
        <div class="abstract-display">
            <p>Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high-quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low-quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of additional input. This is inspired by neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against data quality degradation, including additional missingness. These models are superior to imputation as they save on training time by entirely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. Our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gR9UVgH8PZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gR9UVgH8PZ.html">Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tiange Luo &middot; Honglak Lee &middot; Justin Johnson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gR9UVgH8PZ"></div>

    <a href="paper_pages/gR9UVgH8PZ.html">
        <img src="video_thumbnails/gR9UVgH8PZ.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gR9UVgH8PZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gR9UVgH8PZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gR9UVgH8PZ">
                Abstract <i id="caret-gR9UVgH8PZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gR9UVgH8PZ">
        <div class="abstract-display">
            <p>3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\textit{Text}$ $\Longleftrightarrow$ $\textit{Point Cloud}$ $\Longleftrightarrow$ $\textit{Program}$. We propose $\textbf{\textit{Neural Shape Compiler}}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\textit{Text}$ $\Longrightarrow$ $\textit{Point Cloud}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Text}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Program}$, and Point Cloud Completion tasks. Additionally, Neural Shape Compiler benefits from jointly training on all heterogeneous data and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-T1XtOqrVKn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/T1XtOqrVKn.html">Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Maurits Bleeker &middot; Andrew Yates &middot; Maarten de Rijke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-T1XtOqrVKn"></div>

    <a href="paper_pages/T1XtOqrVKn.html">
        <img src="http://img.youtube.com/vi/CrT7wlzY5K8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-T1XtOqrVKn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-T1XtOqrVKn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-T1XtOqrVKn">
                Abstract <i id="caret-T1XtOqrVKn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-T1XtOqrVKn">
        <div class="abstract-display">
            <p>To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. 
Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. 
Predictive features are features that correctly indicate the similarity between a query and a candidate item. 
However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and
negative pairs. 
We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose
sentence encoder, which prevents the image and caption encoder from suppressing
predictive features. 
We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a bound value while primarily optimizing for the contrastive loss. 
Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. 
Our experiments show that, unlike reconstructing the input caption in the input space, LTD reduces predictive feature suppression, measured by obtaining higher recall@k, r-precision, and nDCG scores than a contrastive ICR baseline.
Moreover, we show that LTD should be implemented as an optimization constraint instead
of a dual optimization objective. Finally, we show that LTD can be used with different
contrastive learning losses and a wide variety of resource-constrained ICR methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4eL6z9ziw7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4eL6z9ziw7.html">NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Patrick Feeney &middot; Sarah Schneider &middot; Panagiotis Lymperopoulos &middot; Liping Liu &middot; Matthias Scheutz &middot; Michael C Hughes</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4eL6z9ziw7"></div>

    <a href="paper_pages/4eL6z9ziw7.html">
        <img src="http://img.youtube.com/vi/d0AAH_eMPoQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4eL6z9ziw7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4eL6z9ziw7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4eL6z9ziw7">
                Abstract <i id="caret-4eL6z9ziw7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4eL6z9ziw7">
        <div class="abstract-display">
            <p>In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qdDmxzGuzu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qdDmxzGuzu.html">Reusable Options through Gradient-based Meta Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">David Kuric &middot; Herke van Hoof</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qdDmxzGuzu"></div>

    <a href="paper_pages/qdDmxzGuzu.html">
        <img src="http://img.youtube.com/vi/Dp5a20y9ohw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qdDmxzGuzu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qdDmxzGuzu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qdDmxzGuzu">
                Abstract <i id="caret-qdDmxzGuzu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qdDmxzGuzu">
        <div class="abstract-display">
            <p>Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding a reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior methods developed for this setting. Additionally, we perform ablations to quantify the impact of using gradient-based meta-learning as well as other proposed changes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MTFf1rDDEI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MTFf1rDDEI.html">Successor Feature Representations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chris Reinke &middot; Xavier Alameda-Pineda</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MTFf1rDDEI"></div>

    <a href="paper_pages/MTFf1rDDEI.html">
        <img src="http://img.youtube.com/vi/RYemlh2NSzQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MTFf1rDDEI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MTFf1rDDEI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MTFf1rDDEI">
                Abstract <i id="caret-MTFf1rDDEI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MTFf1rDDEI">
        <div class="abstract-display">
            <p>Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nHfPXl1ly7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nHfPXl1ly7.html">A Kernel Perspective on Behavioural Metrics for Markov Decision Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pablo Samuel Castro &middot; Tyler Kastner &middot; Prakash Panangaden &middot; Mark Rowland</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nHfPXl1ly7"></div>

    <a href="paper_pages/nHfPXl1ly7.html">
        <img src="http://img.youtube.com/vi/or5W73cn-WQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nHfPXl1ly7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nHfPXl1ly7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nHfPXl1ly7">
                Abstract <i id="caret-nHfPXl1ly7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nHfPXl1ly7">
        <div class="abstract-display">
            <p>We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We define a new metric under this lens that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective enables us to provide new theoretical results, including value-function bounds and low-distortion finite-dimensional Euclidean embeddings, which are crucial when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y4CGF1A8VG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y4CGF1A8VG.html">Machine Explanations and Human Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chacha Chen &middot; Shi Feng &middot; Amit Sharma &middot; Chenhao Tan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y4CGF1A8VG"></div>

    <a href="paper_pages/y4CGF1A8VG.html">
        <img src="http://img.youtube.com/vi/-hNKPaX7L4o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y4CGF1A8VG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y4CGF1A8VG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y4CGF1A8VG">
                Abstract <i id="caret-y4CGF1A8VG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y4CGF1A8VG">
        <div class="abstract-display">
            <p>Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-a0T3nOP9sB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/a0T3nOP9sB.html">Adaptive patch foraging in deep reinforcement learning agents</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nathan Wispinski &middot; Andrew Butcher &middot; Kory Wallace Mathewson &middot; Craig S Chapman &middot; Matthew Botvinick &middot; Patrick M. Pilarski</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-a0T3nOP9sB"></div>

    <a href="paper_pages/a0T3nOP9sB.html">
        <img src="http://img.youtube.com/vi/5PfxPj5Jzwo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-a0T3nOP9sB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-a0T3nOP9sB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-a0T3nOP9sB">
                Abstract <i id="caret-a0T3nOP9sB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-a0T3nOP9sB">
        <div class="abstract-display">
            <p>Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-onufdyHvqN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/onufdyHvqN.html">Private Multi-Task Learning: Formulation and Applications to Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shengyuan Hu &middot; Steven Wu &middot; Virginia Smith</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-onufdyHvqN"></div>

    <a href="paper_pages/onufdyHvqN.html">
        <img src="https://drive.google.com/thumbnail?id=1J35lwtPfLtEF3HpomNKYc3CzEW6nhgu6" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-onufdyHvqN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-onufdyHvqN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-onufdyHvqN">
                Abstract <i id="caret-onufdyHvqN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-onufdyHvqN">
        <div class="abstract-display">
            <p>Many problems in machine learning rely on multi-task learning (MTL), in which the goal is to solve multiple related machine learning tasks simultaneously. MTL is particularly relevant for privacy-sensitive applications in areas such as healthcare, finance, and IoT computing,
where sensitive data from multiple, varied sources are shared for the purpose of learning. In this work, we formalize notions of client-level privacy for MTL via billboard privacy (BP), a relaxation of differential privacy for mechanism design and distributed optimization. We then propose an algorithm for mean-regularized MTL, an objective commonly used for applications in personalized federated learning, subject to BP. We analyze our objective and solver, providing certifiable guarantees on both privacy and utility. Empirically, we find that our method provides improved privacy/utility trade-offs relative to global baselines across common federated learning benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9aXKUJEKwV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9aXKUJEKwV.html">Learning to Look by Self-Prediction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Koichi Grimes &middot; Joseph Varughese Modayil &middot; Piotr W Mirowski &middot; Dushyant Rao &middot; Raia Hadsell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9aXKUJEKwV"></div>

    <a href="paper_pages/9aXKUJEKwV.html">
        <img src="https://drive.google.com/thumbnail?id=1iOFC1IWk0Jx-poBZW0lh5FcTmT55BdDw" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9aXKUJEKwV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9aXKUJEKwV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9aXKUJEKwV">
                Abstract <i id="caret-9aXKUJEKwV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9aXKUJEKwV">
        <div class="abstract-display">
            <p>We present a method for learning active vision skills, to move the camera to observe a robot's sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies' precision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TNocbXm5MZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TNocbXm5MZ.html">Guaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alex Lamb &middot; Riashat Islam &middot; Yonathan Efroni &middot; Aniket Rajiv Didolkar &middot; Dipendra Misra &middot; Dylan J Foster &middot; Lekan P Molu &middot; Rajan Chari &middot; Akshay Krishnamurthy &middot; John Langford</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TNocbXm5MZ"></div>

    <a href="paper_pages/TNocbXm5MZ.html">
        <img src="http://img.youtube.com/vi/prS5EG9dLVg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TNocbXm5MZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TNocbXm5MZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TNocbXm5MZ">
                Abstract <i id="caret-TNocbXm5MZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TNocbXm5MZ">
        <div class="abstract-display">
            <p>In many sequential decision-making tasks, the agent is not able to model the full complexity of the world, which consists of multitudes of relevant and irrelevant information. For example, a person walking along a city street who tries to model all aspects of the world would quickly be overwhelmed by a multitude of shops, cars, and people moving in and out of view, each following their own complex and inscrutable dynamics.  Is it possible to turn the agent's firehose of sensory information into a minimal latent state that is both necessary and sufficient for an agent to successfully act in the world? We formulate this question concretely, and propose the Agent Control-Endogenous State Discovery algorithm (AC-State), which has theoretical guarantees and is practically demonstrated to discover the minimal control-endogenous latent state which contains all of the information necessary for controlling the agent, while fully discarding all irrelevant information.    This algorithm consists of a multi-step inverse model (predicting actions from distant observations) with an information bottleneck.  AC-State enables localization, exploration, and navigation without reward or demonstrations.  We demonstrate the discovery of the control-endogenous latent state in three domains: localizing a robot arm with distractions (e.g., changing lighting conditions and background), exploring a maze alongside other agents, and navigating in the Matterport house simulator.  </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-5aYGXxByI6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/5aYGXxByI6.html">MASIF: Meta-learned Algorithm Selection using Implicit Fidelity Information</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tim Ruhkopf &middot; Aditya Mohan &middot; Difan Deng &middot; Alexander Tornede &middot; Frank Hutter &middot; Marius Lindauer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-5aYGXxByI6"></div>

    <a href="paper_pages/5aYGXxByI6.html">
        <img src="http://img.youtube.com/vi/4qXRyRjJPIY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-5aYGXxByI6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-5aYGXxByI6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-5aYGXxByI6">
                Abstract <i id="caret-5aYGXxByI6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-5aYGXxByI6">
        <div class="abstract-display">
            <p>Selecting a well-performing algorithm for a given task or dataset can be time-consuming and
tedious, but is crucial for the successful day-to-day business of developing new AI & ML
applications. Algorithm Selection (AS) mitigates this through a meta-model leveraging
meta-information about previous tasks. However, most of the available AS methods are
error-prone because they characterize a task by either cheap-to-compute properties of the
dataset or evaluations of cheap proxy algorithms, called landmarks. In this work, we extend
the classical AS data setup to include multi-fidelity information and empirically demonstrate
how meta-learning on algorithms’ learning behaviour allows us to exploit cheap test-time
evidence effectively and combat myopia significantly. We further postulate a budget-regret
trade-off w.r.t. the selection process. Our new selector MASIF is able to jointly interpret
online evidence on a task in form of varying-length learning curves without any parametric
assumption by leveraging a transformer-based encoder. This opens up new possibilities for
guided rapid prototyping in data science on cheaply observed partial learning curves.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-NrfSRtTpN5">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/NrfSRtTpN5.html">Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hong-Xing Yu &middot; Michelle Guo &middot; Alireza Fathi &middot; Yen-Yu Chang &middot; Eric Ryan Chan &middot; Ruohan Gao &middot; Thomas Funkhouser &middot; Jiajun Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-NrfSRtTpN5"></div>

    <a href="paper_pages/NrfSRtTpN5.html">
        <img src="http://img.youtube.com/vi/BqKiO5GDtH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-NrfSRtTpN5" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-NrfSRtTpN5" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-NrfSRtTpN5">
                Abstract <i id="caret-NrfSRtTpN5" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-NrfSRtTpN5">
        <div class="abstract-display">
            <p>Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Oq5XKRVYpQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Oq5XKRVYpQ.html">Graph-based Multi-ODE Neural Networks for Spatio-Temporal Traffic Forecasting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zibo Liu &middot; Parshin Shojaee &middot; Chandan K. Reddy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Oq5XKRVYpQ"></div>

    <a href="paper_pages/Oq5XKRVYpQ.html">
        <img src="http://img.youtube.com/vi/00SItN8IP-M/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Oq5XKRVYpQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Oq5XKRVYpQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Oq5XKRVYpQ">
                Abstract <i id="caret-Oq5XKRVYpQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Oq5XKRVYpQ">
        <div class="abstract-display">
            <p>There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however,  remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. 
Current works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-WN1O2MJDST">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/WN1O2MJDST.html">Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vijaya Raghavan T Ramkumar &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-WN1O2MJDST"></div>

    <a href="paper_pages/WN1O2MJDST.html">
        <img src="http://img.youtube.com/vi/efulZvJBZ04/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-WN1O2MJDST" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-WN1O2MJDST" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-WN1O2MJDST">
                Abstract <i id="caret-WN1O2MJDST" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-WN1O2MJDST">
        <div class="abstract-display">
            <p>Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce "Learn, Unlearn, and Relearn (LURE)" an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-v5jwDLqfQo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/v5jwDLqfQo.html">Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wu &middot; David Pichler &middot; Daniel Marley &middot; Naira Hovakimyan &middot; David A Wilson &middot; Jennifer Hobbs</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-v5jwDLqfQo"></div>

    <a href="paper_pages/v5jwDLqfQo.html">
        <img src="http://img.youtube.com/vi/2xaKxUpY4iQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-v5jwDLqfQo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-v5jwDLqfQo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-v5jwDLqfQo">
                Abstract <i id="caret-v5jwDLqfQo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-v5jwDLqfQo">
        <div class="abstract-display">
            <p>A key challenge for much of the machine learning work on remote sensing and earth observation data is the difficulty in acquiring large amounts of accurately labeled data. This is particularly true for semantic segmentation tasks, which are much less common in the remote sensing domain because of the incredible difficulty in collecting precise, accurate, pixel-level annotations at scale. Recent efforts have addressed these challenges both through the creation of supervised datasets as well as the application of self-supervised methods. We continue these efforts on both fronts. First, we generate and release an improved version of the Agriculture-Vision dataset  (Chiu et al., 2020b) to include raw, full-field imagery for greater experimental flexibility. Second, we extend this dataset with the release of 3600 large, high-resolution (10cm/pixel), full-field, red-green-blue and near-infrared images for pre-training. Third, we incorporate the Pixel-to-Propagation Module Xie et al. (2021b) originally built on the SimCLR framework into the framework of MoCo-V2 Chen et al.(2020b). Finally, we demonstrate the usefulness of this data by benchmarking different contrastive learning approaches on both downstream classification and semantic segmentation tasks. We explore both CNN and Swin Transformer Liu et al. (2021a) architectures within different frameworks based on MoCo-V2. Together, these approaches enable us to better detect key agricultural patterns of interest across a field from aerial imagery so that farmers may be alerted to problematic areas in a timely fashion to inform their management decisions. Furthermore, the release of these datasets will support numerous avenues of research for computer vision in remote sensing for agriculture.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EiX2L4sDPG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EiX2L4sDPG.html">VN-Transformer: Rotation-Equivariant Attention for Vector Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Serge Assaad &middot; Carlton Downey &middot; Rami Al-Rfou' &middot; Nigamaa Nayakanti &middot; Benjamin Sapp</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EiX2L4sDPG"></div>

    <a href="paper_pages/EiX2L4sDPG.html">
        <img src="http://img.youtube.com/vi/1KrPzUKwSL8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EiX2L4sDPG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EiX2L4sDPG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EiX2L4sDPG">
                Abstract <i id="caret-EiX2L4sDPG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EiX2L4sDPG">
        <div class="abstract-display">
            <p>Rotation equivariance is a desirable property in many practical applications such as motion forecasting and 3D perception, where it can offer benefits like sample efficiency, better generalization, and robustness to input perturbations.
Vector Neurons (VN) is a recently developed framework offering a simple yet effective approach for deriving rotation-equivariant analogs of standard machine learning operations by extending one-dimensional scalar neurons to three-dimensional "vector neurons."
We introduce a novel "VN-Transformer" architecture to address several shortcomings of the current VN models. Our contributions are:
(i) we derive a rotation-equivariant attention mechanism which eliminates the need for the heavy feature preprocessing required by the original Vector Neurons models; (ii) we extend the VN framework to support non-spatial attributes, expanding the applicability of these models to real-world datasets; (iii) we derive a rotation-equivariant mechanism for multi-scale reduction of point-cloud resolution, greatly speeding up inference and training; (iv) we show that small tradeoffs in equivariance ($\epsilon$-approximate equivariance) can be used to obtain large improvements in numerical stability and training robustness on accelerated hardware, and we bound the propagation of equivariance violations in our models.
Finally, we apply our VN-Transformer to 3D shape classification and motion forecasting with compelling results.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jdGMBgYvfX">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jdGMBgYvfX.html">UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Francisca Vasconcelos &middot; Bobby He &middot; Nalini M Singh &middot; Yee Whye Teh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jdGMBgYvfX"></div>

    <a href="paper_pages/jdGMBgYvfX.html">
        <img src="http://img.youtube.com/vi/cD7Wx4F_EjQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jdGMBgYvfX" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jdGMBgYvfX" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jdGMBgYvfX">
                Abstract <i id="caret-jdGMBgYvfX" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jdGMBgYvfX">
        <div class="abstract-display">
            <p>Implicit neural representations (INRs) have achieved impressive results for scene reconstruction and computer graphics, where their performance has primarily been assessed on reconstruction accuracy. As INRs make their way into other domains, where model predictions inform high-stakes decision-making, uncertainty quantification of INR inference is becoming critical. To that end, we study a Bayesian reformulation of INRs, UncertaINR, in the context of computed tomography, and evaluate several Bayesian deep learning implementations in terms of accuracy and calibration.  We find that they achieve well-calibrated uncertainty, while retaining accuracy competitive with other classical, INR-based, and CNN-based reconstruction techniques. Contrary to common intuition in the Bayesian deep learning literature, we find that INRs obtain the best calibration with computationally efficient Monte Carlo dropout, outperforming Hamiltonian Monte Carlo and deep ensembles. Moreover, in contrast to the best-performing prior approaches, UncertaINR does not require a large training dataset, but only a handful of validation images.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-SM1BkjGePI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/SM1BkjGePI.html">Bridging performance gap between minimal and maximal SVM models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ondrej Such &middot; René Fabricius</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-SM1BkjGePI"></div>

    <a href="paper_pages/SM1BkjGePI.html">
        <img src="http://img.youtube.com/vi/jWAfN4deoC8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-SM1BkjGePI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-SM1BkjGePI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-SM1BkjGePI">
                Abstract <i id="caret-SM1BkjGePI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-SM1BkjGePI">
        <div class="abstract-display">
            <p>Multi-class support vector machine (SVM) models are typically built using all possible pairs of binary SVM in a one-against-one fashion. This requires too much computation for datasets with hundreds or thousands of classes,  which motivates the search for multi-class models that do not use all pairwise SVM.  Our models correspond to the choice of the model graph, whose vertices correspond to classes and edges represent which pairwise SVMs are trained. We conduct experiments to uncover metrical and topological properties that impact the accuracy of a multi-class SVM model. Based on their results we propose a way to construct intermediate multi-class SVM models. The key insight is that for model graphs of diameter two, we can estimate missing pairwise probabilities from the known ones thus transforming the computation of posteriors to the usual complete (maximal) case. Our proposed algorithm allows one to reduce computational effort by 50-80% while keeping accuracy near, or even above that of a softmax classifier. In our work we use convolutional data sets, which have multiple advantages for benchmarking multi-class SVM models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mySiFHCeAl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mySiFHCeAl.html">Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Amirali Aghazadeh &middot; Nived Rajaraman &middot; Tony Tu &middot; Kannan Ramchandran</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mySiFHCeAl"></div>

    <a href="paper_pages/mySiFHCeAl.html">
        <img src="http://img.youtube.com/vi/ER12pwvxTSU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mySiFHCeAl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mySiFHCeAl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mySiFHCeAl">
                Abstract <i id="caret-mySiFHCeAl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mySiFHCeAl">
        <div class="abstract-display">
            <p>Data-driven machine learning models are being increasingly employed in several important inference problems in biology, chemistry, and physics, which require learning over combinatorial spaces. Recent empirical evidence (see, e.g., ~\cite{tseng2020fourier,aghazadeh2021epistatic,ha2021adaptive}) suggests that regularizing the spectral representation of such models improves their generalization power when labeled data is scarce. However, despite these empirical studies, the theoretical underpinning of when and how spectral regularization enables improved generalization is poorly understood. In this paper, we focus on learning pseudo-Boolean functions and demonstrate that regularizing the empirical mean squared error by the $L_1$ norm of the spectral transform of the learned function reshapes the loss landscape and allows for data-frugal learning under a restricted secant condition on the learner's empirical error measured against the ground truth function. Under a weaker quadratic growth condition, we show that stationary points, which also approximately interpolate the training data points achieve statistically optimal generalization performance. Complementing our theory, we empirically demonstrate that running gradient descent on the regularized loss results in a better generalization performance compared to baseline algorithms in several data-scarce real-world problems.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3gfpBR1ncr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3gfpBR1ncr.html">On Characterizing the Trade-off in Invariant Representation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bashir Sadeghi &middot; Sepehr Dehdashtian &middot; Vishnu Boddeti</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3gfpBR1ncr"></div>

    <a href="paper_pages/3gfpBR1ncr.html">
        <img src="http://img.youtube.com/vi/bjeLIWoiTT8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3gfpBR1ncr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3gfpBR1ncr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3gfpBR1ncr">
                Abstract <i id="caret-3gfpBR1ncr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3gfpBR1ncr">
        <div class="abstract-display">
            <p>Many applications of representation learning, such as privacy preservation, algorithmic fairness, and domain adaptation, desire explicit control over semantic information being discarded. This goal is formulated as satisfying two objectives: maximizing utility for predicting a target attribute while simultaneously being invariant (independent) to a known semantic attribute. Solutions to invariant representation learning (IRepL) problems lead to a trade-off between utility and invariance when they are competing. While existing works study bounds on this trade-off, two questions remain outstanding: 1) What is the exact trade-off between utility and invariance? and 2) What are the encoders (mapping the data to a representation) that achieve the trade-off, and how can we estimate it from training data? This paper addresses these questions for IRepLs in reproducing kernel Hilbert spaces (RKHS)s. Under the assumption that the distribution of a low-dimensional projection of high-dimensional data is approximately normal, we derive a closed-form solution for the global optima of the underlying optimization problem for encoders in RKHSs. This yields closed formulae for a near-optimal trade-off, corresponding optimal representation dimensionality, and the corresponding encoder(s). We also numerically quantify the trade-off on representative problems and compare them to those achieved by baseline IRepL algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-d3rHk4VAf0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/d3rHk4VAf0.html">A Ranking Game for Imitation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Harshit Sikchi &middot; Akanksha Saran &middot; Wonjoon Goo &middot; Scott Niekum</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-d3rHk4VAf0"></div>

    <a href="paper_pages/d3rHk4VAf0.html">
        <img src="http://img.youtube.com/vi/gTf8WoYUOH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-d3rHk4VAf0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-d3rHk4VAf0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-d3rHk4VAf0">
                Abstract <i id="caret-d3rHk4VAf0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-d3rHk4VAf0">
        <div class="abstract-display">
            <p>We propose a new framework for imitation learning---treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-P9Cj6RJmN2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/P9Cj6RJmN2.html">A Stochastic Optimization Framework for Fair Risk Minimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Andrew Lowy &middot; Sina Baharlouei &middot; Rakesh Pavan &middot; Meisam Razaviyayn &middot; Ahmad Beirami</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-P9Cj6RJmN2"></div>

    <a href="paper_pages/P9Cj6RJmN2.html">
        <img src="video_thumbnails/P9Cj6RJmN2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-P9Cj6RJmN2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-P9Cj6RJmN2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-P9Cj6RJmN2">
                Abstract <i id="caret-P9Cj6RJmN2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-P9Cj6RJmN2">
        <div class="abstract-display">
            <p>Despite the success of large-scale empirical risk minimization (ERM) at achieving high accuracy across a variety of machine learning tasks, fair ERM is hindered by the incompatibility of fairness constraints with stochastic optimization. We consider the problem of fair classification with discrete sensitive attributes and potentially large models and data sets, requiring stochastic solvers. Existing in-processing fairness algorithms are either impractical in the large-scale setting because they require large batches of data at each iteration or they are not guaranteed to converge. In this paper, we develop the first stochastic in-processing fairness algorithm with guaranteed convergence. For demographic parity, equalized odds, and equal opportunity notions of fairness, we provide slight variations of our algorithm–called FERMI–and prove that each of these variations converges in stochastic optimization with any batch size. Empirically, we show that FERMI is amenable to stochastic solvers with multiple (non-binary) sensitive attributes and non-binary targets, performing well even with minibatch size as small as one. Extensive experiments show that FERMI achieves the most favorable tradeoffs between fairness violation and test accuracy across all tested setups compared with state-of-the-art baselines for demographic parity, equalized odds, equal opportunity. These benefits are especially significant with small batch sizes and for non-binary classification with large number of sensitive attributes, making FERMI a practical, scalable fairness algorithm. The code for all of the experiments in this paper is available at:
https://github.com/optimization-for-data-driven-science/FERMI</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VW4IrC0n0M">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VW4IrC0n0M.html">An approximate sampler for energy-based models with divergence diagnostics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bryan Eikema &middot; Germán Kruszewski &middot; Christopher R Dance &middot; Hady Elsahar &middot; Marc Dymetman</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VW4IrC0n0M"></div>

    <a href="paper_pages/VW4IrC0n0M.html">
        <img src="video_thumbnails/VW4IrC0n0M.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VW4IrC0n0M" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VW4IrC0n0M" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VW4IrC0n0M">
                Abstract <i id="caret-VW4IrC0n0M" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VW4IrC0n0M">
        <div class="abstract-display">
            <p>Energy-based models (EBMs) allow flexible specifications of probability distributions. However, sampling from EBMs is non-trivial, usually requiring approximate techniques such as Markov chain Monte Carlo (MCMC). A major downside of MCMC sampling is that it is often impossible to compute the divergence of the sampling distribution from the target distribution: therefore, the quality of the samples cannot be guaranteed. Here, we introduce quasi-rejection sampling (QRS), a simple extension of rejection sampling that performs approximate sampling, but, crucially, does provide divergence diagnostics (in terms of f-divergences, such as KL divergence and total variation distance). We apply QRS to sampling from discrete EBMs over text for controlled generation. We show that we can sample from such EBMs with arbitrary precision in exchange for sampling efficiency and quantify the trade-off between the two by means of the aforementioned diagnostics. 
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LHAbHkt6Aq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LHAbHkt6Aq.html">A Crisis In Simulation-Based Inference? Beware, Your Posterior Approximations Can Be Unfaithful</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joeri Hermans &middot; Arnaud Delaunoy &middot; François Rozet &middot; Antoine Wehenkel &middot; Volodimir Begy &middot; Gilles Louppe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LHAbHkt6Aq"></div>

    <a href="paper_pages/LHAbHkt6Aq.html">
        <img src="http://img.youtube.com/vi/sLM0JBbSjLw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LHAbHkt6Aq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LHAbHkt6Aq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LHAbHkt6Aq">
                Abstract <i id="caret-LHAbHkt6Aq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LHAbHkt6Aq">
        <div class="abstract-display">
            <p>We present extensive empirical evidence showing that current Bayesian simulation-based inference algorithms can produce computationally unfaithful posterior approximations. Our results show that all benchmarked algorithms -- (S)NPE, (S)NRE, SNL and variants of ABC -- can yield overconfident posterior approximations, which makes them unreliable for scientific use cases and falsificationist inquiry. Failing to address this issue may reduce the range of applicability of simulation-based inference. For this reason, we argue that research efforts should be made towards theoretical and methodological developments of conservative approximate inference algorithms and present research directions towards this objective. In this regard, we show empirical evidence that ensembling posterior surrogates provides more reliable approximations and mitigates the issue.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-myjAVQrRxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/myjAVQrRxS.html">Dropped Scheduled Task: Mitigating Negative Transfer in Multi-task Learning using Dynamic Task Dropping</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Aakarsh Malhotra &middot; Mayank Vatsa &middot; Richa Singh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-myjAVQrRxS"></div>

    <a href="paper_pages/myjAVQrRxS.html">
        <img src="http://img.youtube.com/vi/NZrnPHDFNTM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-myjAVQrRxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-myjAVQrRxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-myjAVQrRxS">
                Abstract <i id="caret-myjAVQrRxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-myjAVQrRxS">
        <div class="abstract-display">
            <p>In Multi-Task Learning (MTL), K distinct tasks are jointly optimized. With the varying nature and complexities of tasks, few tasks might dominate learning. For other tasks, their respective performances may get compromised due to a negative transfer from dominant tasks. We propose a Dropped-Scheduled Task (DST) algorithm, which probabilistically “drops” specific tasks during joint optimization while scheduling others to reduce negative transfer. For each task, a scheduling probability is decided based on four different metrics: (i) task depth, (ii) number of ground-truth samples per task, (iii) amount of training completed, and (iv) task stagnancy. Based on the scheduling probability, specific tasks get joint computation cycles while others are “dropped”. To demonstrate the effectiveness of the proposed DST algorithm, we perform multi-task learning on three applications and two architectures. Across unilateral (single input) and bilateral (multiple input) multi-task net- works, the chosen applications are (a) face (AFLW), (b) fingerprint (IIITD MOLF, MUST, and NIST SD27), and (c) character recognition (Omniglot) applications. Experimental results show that the proposed DST algorithm has the minimum negative transfer and overall least errors across different state-of-the-art algorithms and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-K6g4MbAC1r">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/K6g4MbAC1r.html">Investigating Action Encodings in Recurrent Neural Networks in Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Kyle Schlegel &middot; Volodymyr Tkachuk &middot; Adam M White &middot; Martha White</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-K6g4MbAC1r"></div>

    <a href="paper_pages/K6g4MbAC1r.html">
        <img src="http://img.youtube.com/vi/83vBK8DIdEY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-K6g4MbAC1r" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-K6g4MbAC1r" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-K6g4MbAC1r">
                Abstract <i id="caret-K6g4MbAC1r" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-K6g4MbAC1r">
        <div class="abstract-display">
            <p>Building and maintaining state to learn policies and value functions is critical for deploying reinforcement learning (RL) agents in the real world. Recurrent neural networks (RNNs) have become a key point of interest for the state-building problem, and several large-scale reinforcement learning agents incorporate recurrent networks. While RNNs have become a mainstay in many RL applications, many key design choices and implementation details responsible for performance improvements are often not reported. In this work, we discuss one axis on which RNN architectures can be (and have been) modified for use in RL. Specifically, we look at how action information can be incorporated into the state update function of a recurrent cell. We discuss several choices in using action information and empirically evaluate the resulting architectures on a set of illustrative domains. Finally, we discuss future work in developing recurrent cells and discuss challenges specific to the RL setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QaDevCcmcg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QaDevCcmcg.html">Uncertainty-Based Active Learning for Reading Comprehension</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wang &middot; Jie Shen &middot; Xiaofei Ma &middot; Andrew Arnold</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QaDevCcmcg"></div>

    <a href="paper_pages/QaDevCcmcg.html">
        <img src="http://img.youtube.com/vi/oRrMip1MWbY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QaDevCcmcg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QaDevCcmcg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QaDevCcmcg">
                Abstract <i id="caret-QaDevCcmcg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QaDevCcmcg">
        <div class="abstract-display">
            <p>Recent years have witnessed a surge of successful applications of machine reading comprehension. Of central importance to these tasks is the availability of massive amount of labeled data, which facilitates training of large-scale neural networks. However, in many real-world problems, annotated data are expensive to gather not only because of time cost and budget, but also  of certain domain-specific restrictions such as privacy for healthcare data. In this regard, we propose an uncertainty-based active learning algorithm for reading comprehension, which interleaves data annotation and model updating to mitigate the demand of labeling. Our key techniques are two-fold: 1) an unsupervised uncertainty-based sampling scheme that queries the labels of the most informative instances with respect to the currently learned model; and 2) an adaptive loss minimization paradigm that simultaneously fits the data and controls the degree of model updating. We demonstrate on  benchmark datasets that 25% less labeled samples suffice to guarantee similar, or even improved performance. Our results show strong evidence that for label-demanding scenarios, the proposed approach offers a practical guide on data collection and model training. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EYrRzKPinA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EYrRzKPinA.html">On a continuous time model of gradient descent dynamics and instability in deep learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mihaela Rosca &middot; Yan Wu &middot; Chongli Qin &middot; Benoit Dherin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EYrRzKPinA"></div>

    <a href="paper_pages/EYrRzKPinA.html">
        <img src="http://img.youtube.com/vi/UKHCH8ZdH1Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EYrRzKPinA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EYrRzKPinA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EYrRzKPinA">
                Abstract <i id="caret-EYrRzKPinA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EYrRzKPinA">
        <div class="abstract-display">
            <p>The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oq3tx5kinu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oq3tx5kinu.html">Active Learning of Ordinal Embeddings: A User Study on Football Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Christoffer Löffler &middot; Kion Fallah &middot; Stefano Fenu &middot; Dario Zanca &middot; Bjoern Eskofier &middot; Christopher John Rozell &middot; Christopher Mutschler</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oq3tx5kinu"></div>

    <a href="paper_pages/oq3tx5kinu.html">
        <img src="http://img.youtube.com/vi/xqOJAtjxjKE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oq3tx5kinu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oq3tx5kinu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oq3tx5kinu">
                Abstract <i id="caret-oq3tx5kinu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oq3tx5kinu">
        <div class="abstract-display">
            <p>Humans innately measure distance between instances in an unlabeled dataset using an unknown similarity function. Distance metrics can only serve as proxy for similarity in information retrieval of similar instances. Learning a good similarity function from human annotations improves the quality of retrievals. This work uses deep metric learning to learn these user-defined similarity functions from few annotations for a large football trajectory dataset.
We adapt an entropy-based active learning method with recent work from triplet mining to collect easy-to-answer but still informative annotations from human participants and use them to train a deep convolutional network that generalizes to unseen samples. 
Our user study shows that our approach improves the quality of the information retrieval compared to a previous deep metric learning approach that relies on a Siamese network. Specifically, we shed light on the strengths and weaknesses of passive sampling heuristics and active learners alike by analyzing the participants' response efficacy. To this end, we collect accuracy, algorithmic time complexity, the participants' fatigue and time-to-response, qualitative self-assessment and statements, as well as the effects of mixed-expertise annotators and their consistency on model performance and transfer-learning.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Lgs5pQ1v30">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Lgs5pQ1v30.html">FedShuffle:  Recipes for Better Use of Local Work in Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Samuel Horváth &middot; Maziar Sanjabi &middot; Lin Xiao &middot; Peter Richtárik &middot; Michael Rabbat</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Lgs5pQ1v30"></div>

    <a href="paper_pages/Lgs5pQ1v30.html">
        <img src="http://img.youtube.com/vi/jGVbs3Jl1K0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Lgs5pQ1v30" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Lgs5pQ1v30" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Lgs5pQ1v30">
                Abstract <i id="caret-Lgs5pQ1v30" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Lgs5pQ1v30">
        <div class="abstract-display">
            <p>The practice of applying several local updates before aggregation across clients has been empirically shown to be a successful approach to overcoming the communication bottleneck in Federated Learning (FL). Such methods are usually implemented by having clients perform one or more epochs of local training per round while randomly reshuffling their finite dataset in each epoch. Data imbalance, where clients have different numbers of local training samples, is ubiquitous in FL applications, resulting in different clients performing different numbers of local updates in each round. In this work, we propose a general recipe, FedShuffle, that better utilizes the local updates in FL, especially in this regime encompassing random reshuffling and heterogeneity. FedShuffle is the first local update method with theoretical convergence guarantees that incorporates random reshuffling, data imbalance, and client sampling — features that are essential in large-scale cross-device FL. We present a comprehensive theoretical analysis of FedShuffle and show, both theoretically and empirically, that it does not suffer from the objective function mismatch that is present in FL methods that assume homogeneous updates in heterogeneous FL setups, such as FedAvg (McMahan et al., 2017). In addition, by combining the ingredients above, FedShuffle improves upon FedNova (Wang et al., 2020), which was previously proposed to solve this mismatch. Similar to Mime (Karimireddy et al., 2020), we show that FedShuffle with momentum variance reduction (Cutkosky & Orabona, 2019) improves upon non-local methods under a Hessian similarity assumption.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MHOAEiTlen">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MHOAEiTlen.html">DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">kaichen zhou &middot; Lanqing HONG &middot; Shoukang Hu &middot; Fengwei Zhou &middot; Binxin Ru &middot; Jiashi Feng &middot; Zhenguo Li</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MHOAEiTlen"></div>

    <a href="paper_pages/MHOAEiTlen.html">
        <img src="https://drive.google.com/thumbnail?id=1LYpQU2zJkzK6BBQPV1JZXNUU4mkcMtMr" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MHOAEiTlen" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MHOAEiTlen" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MHOAEiTlen">
                Abstract <i id="caret-MHOAEiTlen" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MHOAEiTlen">
        <div class="abstract-display">
            <p>Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). Although many strategies have been developed for automating these components in separation, joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often suffers from the low-performance correlation between the searching and retraining stages. An end-to-end solution that integrates the AutoML components and returns a ready-to-use model at the end of the search is desirable. In view of these, we propose DHA, which achieves joint optimization of Data augmentation policy, Hyper-parameter, and Architecture. Specifically, end-to-end NAS is achieved in a differentiable manner by optimizing a compressed lower-dimensional feature space, while DA policy and HPO are regarded as dynamic schedulers, which adapt themselves to the update of network parameters and network architecture at the same time. Experiments show that DHA achieves state-of-the-art (SOTA) results on various datasets and search spaces. To the best of our knowledge, we are the first to efficiently and jointly optimize DA policy, NAS, and HPO in an end-to-end manner without retraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vUuHPRrWs2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vUuHPRrWs2.html">Practicality of generalization guarantees for unsupervised domain adaptation with neural networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Adam Breitholtz &middot; Fredrik Daniel Johansson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vUuHPRrWs2"></div>

    <a href="paper_pages/vUuHPRrWs2.html">
        <img src="video_thumbnails/vUuHPRrWs2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vUuHPRrWs2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vUuHPRrWs2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vUuHPRrWs2">
                Abstract <i id="caret-vUuHPRrWs2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vUuHPRrWs2">
        <div class="abstract-display">
            <p>Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. 
For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment.
However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions.
In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain shift. To overcome this and arrive at the tightest possible results, we combine each bound with recent data-dependent PAC-Bayes analysis, greatly improving the guarantees. We find that, when domain overlap can be assumed, a simple importance weighting extension of previous work provides the tightest estimable bound. Finally, we study which terms dominate the bounds and identify possible directions for further improvement. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Sh3RF9JowK">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Sh3RF9JowK.html">Learning Algorithms for Markovian Bandits:\\Is Posterior Sampling more Scalable than Optimism?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nicolas Gast &middot; Bruno Gaujal &middot; Kimang Khun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Sh3RF9JowK"></div>

    <a href="paper_pages/Sh3RF9JowK.html">
        <img src="http://img.youtube.com/vi/Ii2773_g3po/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Sh3RF9JowK" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Sh3RF9JowK" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Sh3RF9JowK">
                Abstract <i id="caret-Sh3RF9JowK" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Sh3RF9JowK">
        <div class="abstract-display">
            <p>In this paper, we study the scalability of model-based algorithms learning the optimal policy of a discounted \blue{rested} Markovian bandit  problem with $n$ arms. There are two categories of model-based reinforcement learning algorithms: Bayesian algorithms (like PSRL), and optimistic algorithms (like UCRL2 or UCBVI).  A naive application of these  algorithms is not scalable because  the state-space is exponential in $n$. In this paper, we construct variants of these algorithms specially tailored to Markovian bandits (MB) that we call MB-PSRL, MB-UCRL2, and MB-UCBVI. \blue{We consider an episodic setting with geometrically distributed episode length, and measure the performance of the algorithm in terms of regret (Bayesian regret for MB-PSRL and expected regret for MB-UCRL2 and MB-UCBVI)}. We prove that, for this setting, all algorithms have a low regret in $\tilde{O}(S\sqrt{nK})$ -- where $K$ is the number of episodes, $n$ is the number of arms and $S$ is the number of states of each arm. Up to a factor $\sqrt{S}$, these regrets match the \blue{Bayesian minimax regret} lower bound of $\Omega(\sqrt{SnK})$ that we also derive.

Even if their theoretical regrets are comparable, the {\it time complexities} of these  algorithms vary greatly: We show that MB-UCRL2, as well as all  algorithms that use bonuses on transition matrices have a { time} complexity  that grows  exponentially in $n$.  In contrast, MB-UCBVI does not use bonuses on transition matrices and we show that  it can be implemented efficiently, with a time complexity linear in $n$. Our numerical experiments show, however, that its empirical regret is large. Our Bayesian algorithm, MB-PSRL, enjoys the best of both worlds: its running time is linear in the number of arms and its empirical regret is the smallest of all algorithms.
This is a new addition in the understanding of the power of Bayesian algorithms, that can often be  tailored to the structure of the problems to learn.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mbwm7NdkpO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mbwm7NdkpO.html">Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohammad Ali Alomrani &middot; Reza Moravej &middot; Elias Boutros Khalil</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mbwm7NdkpO"></div>

    <a href="paper_pages/mbwm7NdkpO.html">
        <img src="http://img.youtube.com/vi/PoMrl5rjQ3U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mbwm7NdkpO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mbwm7NdkpO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mbwm7NdkpO">
                Abstract <i id="caret-mbwm7NdkpO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mbwm7NdkpO">
        <div class="abstract-display">
            <p>The challenge in the widely applicable online matching problem lies in making irrevocable assignments while there is uncertainty about future inputs. Most theoretically-grounded policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform consistently better than classical baseline algorithms on four synthetic and real-world datasets. On average, our proposed models improve the matching quality by 3-10% on a variety of synthetic and real-world datasets.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aIoEkwc2oB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aIoEkwc2oB.html">INR-V: A Continuous Representation Space for Video-based Generative Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bipasha Sen &middot; Aditya Agarwal &middot; Vinay P Namboodiri &middot; C.V. Jawahar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aIoEkwc2oB"></div>

    <a href="paper_pages/aIoEkwc2oB.html">
        <img src="http://img.youtube.com/vi/ViIwnu5vcck/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aIoEkwc2oB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aIoEkwc2oB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aIoEkwc2oB">
                Abstract <i id="caret-aIoEkwc2oB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aIoEkwc2oB">
        <div class="abstract-display">
            <p>Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lCPOHiztuw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lCPOHiztuw.html">Direct Molecular Conformation Generation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jinhua Zhu &middot; Yingce Xia &middot; Chang Liu &middot; Lijun Wu &middot; Shufang Xie &middot; Yusong Wang &middot; Tong Wang &middot; Tao Qin &middot; Wengang Zhou &middot; Houqiang Li &middot; Haiguang Liu &middot; Tie-Yan Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lCPOHiztuw"></div>

    <a href="paper_pages/lCPOHiztuw.html">
        <img src="https://drive.google.com/thumbnail?id=1p_-NHOWBH3oiPFuaJiskXYWGdmRmwtLK" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lCPOHiztuw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lCPOHiztuw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lCPOHiztuw">
                Abstract <i id="caret-lCPOHiztuw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lCPOHiztuw">
        <div class="abstract-display">
            <p>Molecular conformation generation aims to generate three-dimensional coordinates of all the atoms in a molecule and is an important task in bioinformatics and pharmacology. Previous methods usually first predict the interatomic distances, the gradients of interatomic distances or the local structures (e.g., torsion angles) of a molecule, and then reconstruct its 3D conformation. How to directly generate the conformation without the above intermediate values is not fully explored. In this work, we propose a method that directly predicts the coordinates of atoms: (1) the loss function is invariant to roto-translation of coordinates and permutation of symmetric atoms; (2) the newly proposed model adaptively aggregates the bond and atom information and iteratively refines the coordinates of the generated conformation. Our method achieves the best results on GEOM-QM9 and GEOM-Drugs datasets. Further analysis shows that our generated conformations have closer properties (e.g., HOMO-LUMO gap) with the groundtruth conformations. In addition, our method improves molecular docking by providing better initial conformations. All the results demonstrate the effectiveness of our method and the great potential of the direct approach. The code is released at  \url{https://github.com/DirectMolecularConfGen/DMCG}.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oRjk5V9eDp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oRjk5V9eDp.html">Bayesian Methods for Constraint Inference in Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dimitris Papadimitriou &middot; Usman Anwar &middot; Daniel S. Brown</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oRjk5V9eDp"></div>

    <a href="paper_pages/oRjk5V9eDp.html">
        <img src="https://drive.google.com/thumbnail?id=1_DMCjrmn5FygavUND1e71qJeNEK_Utch" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oRjk5V9eDp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oRjk5V9eDp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oRjk5V9eDp">
                Abstract <i id="caret-oRjk5V9eDp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oRjk5V9eDp">
        <div class="abstract-display">
            <p>Learning constraints from demonstrations provides a natural and efficient way to improve the safety of AI systems; however, prior work only considers learning a single, point-estimate of the constraints. By contrast, we consider the problem of inferring constraints from demonstrations using a Bayesian perspective. We propose Bayesian Inverse Constraint Reinforcement Learning (BICRL), a novel approach that infers a posterior probability distribution over constraints from demonstrated trajectories. The main advantages of BICRL, compared to prior constraint inference algorithms, are (1) the freedom to infer constraints from partial trajectories and even from disjoint state-action pairs,  (2) the ability to infer constraints from suboptimal demonstrations and in stochastic environments, and (3) the opportunity to use the posterior distribution over constraints in order to implement active learning and robust policy optimization techniques. We show that BICRL outperforms pre-existing constraint learning approaches, leading to more accurate constraint inference and consequently safer policies. We further propose Hierarchical BICRL that infers constraints locally in sub-spaces of the entire domain and then composes global constraint estimates leading to accurate and computationally efficient constraint estimation.  </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6qMKztPn0n">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6qMKztPn0n.html">Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fan Wang &middot; Hao Tian &middot; Haoyi Xiong &middot; Hua Wu &middot; Jie Fu &middot; Yang Cao &middot; Yu Kang &middot; Haifeng Wang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6qMKztPn0n"></div>

    <a href="paper_pages/6qMKztPn0n.html">
        <img src="http://img.youtube.com/vi/8EA8KqlCRzY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6qMKztPn0n" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6qMKztPn0n" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6qMKztPn0n">
                Abstract <i id="caret-6qMKztPn0n" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6qMKztPn0n">
        <div class="abstract-display">
            <p>Artificial neural networks (ANNs) are typically confined to accomplishing pre-defined tasks by learning a set of static parameters. In contrast, biological neural networks (BNNs) can adapt to various new tasks by continually updating the neural connections based on the inputs, which is aligned with the paradigm of learning effective learning rules in addition to static parameters, \textit{e.g.}, meta-learning. Among various biologically inspired learning rules, Hebbian plasticity updates the neural network weights using local signals without the guide of an explicit target function, thus enabling an agent to learn automatically without human efforts. However, typical plastic ANNs using a large amount of meta-parameters violate the nature of the genomics bottleneck and potentially deteriorate the generalization capacity. This work proposes a new learning paradigm decomposing those connection-dependent plasticity rules into neuron-dependent rules thus accommodating $\Theta(n^2)$ learnable parameters with only $\Theta(n)$ meta-parameters. We also thoroughly study the effect of different neural modulation on plasticity. Our algorithms are tested in challenging random 2D maze environments, where the agents have to use their past experiences to shape the neural connections and improve their performances for the future. The results of our experiment validate the following: 1. Plasticity can be adopted to continually update a randomly initialized RNN to surpass pre-trained, more sophisticated recurrent models, especially when coming to long-term memorization. 2. Following the genomics bottleneck, the proposed decomposed plasticity can be comparable to or even more effective than canonical plasticity rules in some instances.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-M8D5iZsnrO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/M8D5iZsnrO.html">TITRATED: Learned Human Driving Behavior without Infractions via Amortized Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vasileios Lioutas &middot; Adam Scibior &middot; Frank Wood</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-M8D5iZsnrO"></div>

    <a href="paper_pages/M8D5iZsnrO.html">
        <img src="http://img.youtube.com/vi/AMeZtzQxhX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-M8D5iZsnrO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-M8D5iZsnrO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-M8D5iZsnrO">
                Abstract <i id="caret-M8D5iZsnrO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-M8D5iZsnrO">
        <div class="abstract-display">
            <p>Models of human driving behavior have long been used for prediction in autonomous vehicles, but recently have also started being used to create non-playable characters for driving simulations. While such models are in many respects realistic, they tend to suffer from unacceptably high rates of driving infractions, such as collisions or off-road driving, particularly when deployed in map locations with road geometries dissimilar to the training dataset. In this paper we present a novel method for fine-tuning a foundation model of human driving behavior to novel locations where human demonstrations are not available which reduces the incidence of such infractions. The method relies on inference in the foundation model to generate infraction-free trajectories as well as additional penalties applied when fine-tuning the amortized inference behavioral model. We demonstrate this "titration" technique using the ITRA foundation behavior model trained on the INTERACTION dataset when transferring to CARLA map locations. We demonstrate a 76-86% reduction in infraction rate and provide evidence that further gains are possible with more computation or better inference algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lE7K4n1Esk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lE7K4n1Esk.html">On the Adversarial Robustness of Vision Transformers</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Rulin Shao &middot; Zhouxing Shi &middot; Jinfeng Yi &middot; Pin-Yu Chen &middot; Cho-Jui Hsieh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lE7K4n1Esk"></div>

    <a href="paper_pages/lE7K4n1Esk.html">
        <img src="http://img.youtube.com/vi/paMjHR5ufRs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lE7K4n1Esk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lE7K4n1Esk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lE7K4n1Esk">
                Abstract <i id="caret-lE7K4n1Esk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lE7K4n1Esk">
        <div class="abstract-display">
            <p>Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides a comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various white-box and transfer attack settings, we find that ViTs possess better adversarial robustness when compared with MLP-Mixer and convolutional neural networks (CNNs) including ConvNeXt, and this observation also holds for certified robustness. Through frequency analysis and feature visualization, we summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less high-frequency patterns that have spurious correlation,  which helps explain why ViTs are less sensitive to high-frequency perturbations than CNNs and MLP-Mixer, and there is a high correlation between how much the model learns high-frequency features and its robustness against different frequency-based perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning high-frequency features in ViTs can improve classification accuracy but at the cost of adversarial robustness. 3) Modern CNN designs that borrow techniques from ViTs including activation function, layer norm, larger kernel size to imitate the global attention, and patchify the images as inputs, etc., could help bridge the performance gap between ViTs and CNNs not only in terms of performance, but also certified and empirical adversarial robustness. Moreover, we show adversarial training is also applicable to ViT for training robust models, and sharpness-aware minimization can also help improve robustness, while pre-training with clean images on larger datasets does not significantly improve adversarial robustness. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XsPopigZXV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XsPopigZXV.html">FLEA: Provably Robust Fair Multisource Learning from Unreliable Training Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Eugenia Iofinova &middot; Nikola Konstantinov &middot; Christoph H Lampert</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XsPopigZXV"></div>

    <a href="paper_pages/XsPopigZXV.html">
        <img src="video_thumbnails/XsPopigZXV.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XsPopigZXV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XsPopigZXV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XsPopigZXV">
                Abstract <i id="caret-XsPopigZXV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XsPopigZXV">
        <div class="abstract-display">
            <p>Fairness-aware learning aims at constructing classifiers that not only make accurate predictions, but also do not discriminate against specific groups. It is a fast-growing area of machine learning with far-reaching societal impact. However, existing fair learning methods are vulnerable to accidental or malicious artifacts in the training data, which can cause them to unknowingly produce unfair classifiers. In this work we address the problem of fair learning from unreliable training data in the robust multisource setting, where the available training data comes from multiple sources, a fraction of which might not be representative of the true data distribution. We introduce FLEA, a filtering-based algorithm that identifies and suppresses those data sources that would have a negative impact on fairness or accuracy if they were used for training. As such, FLEA is not a replacement of prior fairness-aware learning methods but rather an augmentation that makes any of them robust against unreliable training data. We show the effectiveness of our approach by a diverse range of experiments on multiple datasets. Additionally, we prove formally that –given enough data– FLEA protects the learner against corruptions as long as the fraction of affected data sources is less than half. Our source code and documentation are available at https://github.com/ISTAustria-CVML/FLEA.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gCmQK6McbR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gCmQK6McbR.html">HEAT: Hyperedge Attention Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dobrik Georgiev Georgiev &middot; Marc Brockschmidt &middot; Miltiadis Allamanis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gCmQK6McbR"></div>

    <a href="paper_pages/gCmQK6McbR.html">
        <img src="http://img.youtube.com/vi/q0oFjmxz_60/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gCmQK6McbR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gCmQK6McbR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gCmQK6McbR">
                Abstract <i id="caret-gCmQK6McbR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gCmQK6McbR">
        <div class="abstract-display">
            <p>Learning from structured data is a core machine learning task. Commonly, such data is represented as graphs, which normally only consider (typed) binary relationships between pairs of nodes. This is a substantial limitation for many domains with highly-structured data. One important such domain is source code, where hypergraph-based representations can better capture the semantically rich and structured nature of code.
In this work, we present HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes contribute. It can be viewed as a generalization of both message passing neural networks and Transformers. We evaluate HEAT on knowledge base completion and on bug detection and repair using a novel hypergraph representation of programs. In both settings, it outperforms strong baselines, indicating its power and generality.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-e7mYYMSyZH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/e7mYYMSyZH.html">On the Convergence of Shallow Neural Network Training with Randomly Masked Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fangshuo Liao &middot; Anastasios Kyrillidis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-e7mYYMSyZH"></div>

    <a href="paper_pages/e7mYYMSyZH.html">
        <img src="http://img.youtube.com/vi/8dR4tcfOTkE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-e7mYYMSyZH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-e7mYYMSyZH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-e7mYYMSyZH">
                Abstract <i id="caret-e7mYYMSyZH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-e7mYYMSyZH">
        <div class="abstract-display">
            <p>With the motive of training all the parameters of a neural network, we study why and when one can achieve this by iteratively creating, training, and combining randomly selected subnetworks. Such scenarios have either implicitly or explicitly emerged in the recent literature: see e.g., the Dropout family of regularization techniques, or some distributed ML training protocols that reduce communication/computation complexities, such as the Independent Subnet Training protocol. While these methods are studied empirically and utilized in practice, they often enjoy partial or no theoretical support, especially when applied on neural network-based objectives.

In this manuscript, our focus is on overparameterized single hidden layer neural networks with ReLU activations in the lazy training regime. By carefully analyzing $i)$ the subnetworks' neural tangent kernel, $ii)$ the surrogate functions' gradient, and $iii)$ how we sample and combine the surrogate functions, we prove linear convergence rate of the training error --up to a neighborhood around the optimal point-- for an overparameterized single-hidden layer perceptron with a regression loss. Our analysis reveals a dependency of the size of the neighborhood around the optimal point on the number of surrogate models and the number of local training steps for each selected subnetwork. Moreover, the considered framework generalizes and provides new insights on dropout training, multi-sample dropout training, as well as Independent Subnet Training; for each case, we provide convergence results as corollaries of our main theorem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qzM1Tw5i7N">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qzM1Tw5i7N.html">SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">ZHUOWEI WANG &middot; Jing Jiang &middot; Bo Han &middot; Lei Feng &middot; Bo An &middot; Gang Niu &middot; Guodong Long</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qzM1Tw5i7N"></div>

    <a href="paper_pages/qzM1Tw5i7N.html">
        <img src="http://img.youtube.com/vi/sKDRt9GNLTs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qzM1Tw5i7N" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qzM1Tw5i7N" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qzM1Tw5i7N">
                Abstract <i id="caret-qzM1Tw5i7N" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qzM1Tw5i7N">
        <div class="abstract-display">
            <p>Deep learning with noisy labels is a challenging task, which has received much attention from the machine learning and computer vision communities. Recent prominent methods that build on a specific sample selection (SS) strategy and a specific semi-supervised learning (SSL) model achieved state-of-the-art performance. Intuitively, better performance could be achieved if stronger SS strategies and SSL models are employed. Following this intuition, one might easily derive various effective noisy-label learning methods using different combinations of SS strategies and SSL models, which is, however, simply reinventing the wheel in essence. To prevent this problem, we propose SemiNLL, a versatile framework that investigates how to naturally combine different SS and SSL components based on their effects and efficiencies. We conduct a systematic and detailed analysis of the combinations of possible components based on our framework. Our framework can absorb various SS strategies and SSL backbones, utilizing their power to achieve promising performance. The instantiations of our framework demonstrate substantial improvements over state-of-the-art methods on benchmark-simulated and real-world datasets with noisy labels.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ywr5sWqQt4">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ywr5sWqQt4.html">A Comprehensive Study of Real-Time Object Detection Networks Across Multiple Domains: A Survey</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elahe Arani &middot; Shruthi Gowda &middot; Ratnajit Mukherjee &middot; Omar Magdy &middot; Senthilkumar Sockalingam Kathiresan &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ywr5sWqQt4"></div>

    <a href="paper_pages/ywr5sWqQt4.html">
        <img src="http://img.youtube.com/vi/-Z_DEE96VM0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ywr5sWqQt4" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ywr5sWqQt4" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ywr5sWqQt4">
                Abstract <i id="caret-ywr5sWqQt4" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ywr5sWqQt4">
        <div class="abstract-display">
            <p>Deep neural network based object detectors are continuously evolving and are used in a multitude of applications, each having its own set of requirements. While safety-critical applications need high accuracy and reliability, low-latency tasks need resource and energy-efficient networks. Real-time detection networks, which are a necessity in high-impact real-world applications, are continuously proposed but they overemphasize the improvements in accuracy and speed while other capabilities such as versatility, robustness, resource, and energy efficiency are omitted. A reference benchmark for existing networks does not exist nor does a standard evaluation guideline for designing new networks, which results in ambiguous and inconsistent comparisons. We, therefore, conduct a comprehensive study on multiple real-time detection networks (anchor-based, keypoint-based, and transformer-based) on a wide range of datasets and report results on an extensive set of metrics. We also study the impact of variables such as image size, anchor dimensions, confidence thresholds, and architecture layers on the overall performance. We analyze the robustness of detection networks against distribution shift, natural corruptions, and adversarial attacks. Also, we provide the calibration analysis to gauge the reliability of the predictions. Finally, to highlight the real-world impact, we conduct two unique case studies, on autonomous driving and healthcare application. To further gauge the capability of networks in critical real-time applications, we report the performance after deploying the detection networks on edge devices. Our extensive empirical study can act as a guideline for the industrial community to make an informed choice on the existing networks. We also hope to inspire the research community towards a new direction of design and evaluation of networks that focuses on the bigger and holistic overview for a far-reaching impact.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0nEZCVshxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0nEZCVshxS.html">Diagnosing and Fixing Manifold Overfitting in Deep Generative Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gabriel Loaiza-Ganem &middot; Brendan Leigh Ross &middot; Jesse C Cresswell &middot; Anthony L. Caterini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0nEZCVshxS"></div>

    <a href="paper_pages/0nEZCVshxS.html">
        <img src="http://img.youtube.com/vi/-2YaUfMlwrU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0nEZCVshxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0nEZCVshxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0nEZCVshxS">
                Abstract <i id="caret-0nEZCVshxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0nEZCVshxS">
        <div class="abstract-display">
            <p>Likelihood-based, or explicit, deep generative models use neural networks to construct flexible high-dimensional densities. This formulation directly contradicts the manifold hypothesis, which states that observed data lies on a low-dimensional manifold embedded in high-dimensional ambient space. In this paper we investigate the pathologies of maximum-likelihood training in the presence of this dimensionality mismatch. We formally prove that degenerate optima are achieved wherein the manifold itself is learned but not the distribution on it, a phenomenon we call manifold overfitting. We propose a class of two-step procedures consisting of a dimensionality reduction step followed by maximum-likelihood density estimation, and prove that they recover the data-generating distribution in the nonparametric regime, thus avoiding manifold overfitting. We also show that these procedures enable density estimation on the manifolds learned by implicit models, such as generative adversarial networks, hence addressing a major shortcoming of these models. Several recently proposed methods are instances of our two-step procedures; we thus unify, extend, and theoretically justify a large class of models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8GvRCWKHIL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8GvRCWKHIL.html">Optimal Client Sampling for Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Wenlin Chen &middot; Samuel Horváth &middot; Peter Richtárik</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8GvRCWKHIL"></div>

    <a href="paper_pages/8GvRCWKHIL.html">
        <img src="http://img.youtube.com/vi/lhLJL1FJ_OE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8GvRCWKHIL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8GvRCWKHIL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8GvRCWKHIL">
                Abstract <i id="caret-8GvRCWKHIL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8GvRCWKHIL">
        <div class="abstract-display">
            <p>It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with "important" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2EOVIvRXlv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2EOVIvRXlv.html">Ranking Recovery under Privacy Considerations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Minoh Jeong &middot; Alex Dytso &middot; Martina Cardone</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2EOVIvRXlv"></div>

    <a href="paper_pages/2EOVIvRXlv.html">
        <img src="video_thumbnails/2EOVIvRXlv.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2EOVIvRXlv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2EOVIvRXlv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2EOVIvRXlv">
                Abstract <i id="caret-2EOVIvRXlv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2EOVIvRXlv">
        <div class="abstract-display">
            <p>We consider the private ranking recovery problem, where a data collector seeks to estimate the permutation/ranking of a data vector given a randomized (privatized) version of it. We aim to establish fundamental trade-offs between the performance of the estimation task, measured in terms of probability of error, and the level of privacy that can be guaranteed when the noise mechanism consists of adding artificial noise. Towards this end, we show the optimality of a low-complexity decision rule (referred to as linear decoder) for the estimation task, under several noise distributions widely used in the privacy literature (e.g., Gaussian, Laplace, and generalized normal model). We derive the Taylor series of the probability of error, which yields its first and second-order approximations when such a linear decoder is employed.  We quantify the guaranteed level of privacy using differential privacy (DP) types of metrics, such as $\epsilon$-DP and $(\alpha,\epsilon)$-Rényi DP. Finally, we put together the results to characterize trade-offs between privacy and probability of error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aRsLetumx1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aRsLetumx1.html">How Expressive are Transformers in Spectral Domain for Graphs?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Anson Bastos &middot; Abhishek Nadgeri &middot; Kuldeep Singh &middot; Hiroki Kanezashi &middot; Toyotaro Suzumura &middot; Isaiah Onando Mulang'</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aRsLetumx1"></div>

    <a href="paper_pages/aRsLetumx1.html">
        <img src="http://img.youtube.com/vi/7JNDYQuRSas/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aRsLetumx1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aRsLetumx1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aRsLetumx1">
                Abstract <i id="caret-aRsLetumx1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aRsLetumx1">
        <div class="abstract-display">
            <p>The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to investigate if spectral analysis of the transformer will reveal insights into its expressive power. Similar studies already established that spectral analysis of Graph neural networks (GNNs) provides extra perspectives on their expressiveness. 
In this work, we systematically study and establish the link between the spatial and spectral domain in the realm of the transformer. We further provide a theoretical analysis that the spatial attention mechanism in the transformer cannot effectively capture the desired frequency response, thus, inherently limiting its expressiveness in spectral space. Therefore, we propose FeTA, a framework that aims to perform attention over the entire graph spectrum (i.e. actual frequency components of the graph) analogous to the attention in spatial space. 
Empirical results suggest that FeTA provides homogeneous performance gain against vanilla transformer across all tasks on standard benchmarks and can easily be extended to GNN-based models with low-pass characteristics (e.g., GAT). </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-h1zuM6cXpH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/h1zuM6cXpH.html">Zero-Shot Learning with Common Sense Knowledge Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal V. Nayak &middot; Stephen Bach</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-h1zuM6cXpH"></div>

    <a href="paper_pages/h1zuM6cXpH.html">
        <img src="http://img.youtube.com/vi/VXt3MucMWvY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-h1zuM6cXpH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-h1zuM6cXpH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-h1zuM6cXpH">
                Abstract <i id="caret-h1zuM6cXpH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-h1zuM6cXpH">
        <div class="abstract-display">
            <p>Zero-shot learning relies on semantic class representations such as hand-engineered attributes or learned embeddings to predict classes without any labeled examples. We propose to learn class representations by embedding nodes from common sense knowledge graphs in a vector space. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a general-purpose framework with a novel transformer graph convolutional network (TrGCN) for generating class representations. Our proposed TrGCN architecture computes non-linear combinations of node neighbourhoods. Our results show that ZSL-KG improves over existing WordNet-based methods on five out of six zero-shot benchmark datasets in language and vision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xyt4wfdo4J">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xyt4wfdo4J.html">Iterative State Estimation in Non-linear Dynamical Systems Using Approximate Expectation Propagation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sanket Kamthe &middot; So Takao &middot; Shakir Mohamed &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xyt4wfdo4J"></div>

    <a href="paper_pages/xyt4wfdo4J.html">
        <img src="http://img.youtube.com/vi/FrTY04gXErY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xyt4wfdo4J" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xyt4wfdo4J" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xyt4wfdo4J">
                Abstract <i id="caret-xyt4wfdo4J" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xyt4wfdo4J">
        <div class="abstract-display">
            <p>Bayesian inference in non-linear dynamical systems seeks to find good posterior approximations of a latent state given a sequence of observations. Gaussian filters and smoothers, including the (extended/unscented) Kalman filter/smoother, which are commonly used in engineering applications, yield Gaussian posteriors on the latent state. While they are computationally efficient, they are often criticised for their crude approximation of the posterior state distribution. In this paper, we address this criticism by proposing a message passing scheme for iterative state estimation in non-linear dynamical systems, which yields more informative (Gaussian) posteriors on the latent states.  Our message passing scheme is based on expectation propagation (EP). We prove that classical Rauch--Tung--Striebel (RTS) smoothers, such as the extended Kalman smoother (EKS) or the unscented Kalman smoother (UKS), are special cases of our message passing scheme. Running the message passing scheme more than once can lead to significant improvements of the classical RTS smoothers, so that more informative state estimates can be obtained. We address potential convergence issues of EP by generalising our state estimation framework to damped updates and the consideration of general $\alpha$-divergences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ggPhsYCsm9">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ggPhsYCsm9.html">NeSF: Neural Semantic Fields for Generalizable Semantic Segmentation of 3D Scenes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Suhani Vora &middot; Noha Radwan &middot; Klaus Greff &middot; Henning Meyer &middot; Kyle Genova &middot; Mehdi S. M. Sajjadi &middot; Etienne Pot &middot; Andrea Tagliasacchi &middot; Daniel Duckworth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ggPhsYCsm9"></div>

    <a href="paper_pages/ggPhsYCsm9.html">
        <img src="http://img.youtube.com/vi/odg-L-fG7Wo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ggPhsYCsm9" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ggPhsYCsm9" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ggPhsYCsm9">
                Abstract <i id="caret-ggPhsYCsm9" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ggPhsYCsm9">
        <div class="abstract-display">
            <p>We present NeSF, a method for producing 3D semantic fields from posed RGB images alone. In place of classical 3D representations, our method builds on recent work in neural fields wherein 3D structure is captured by point-wise functions. We leverage this methodology to recover 3D density fields upon which we then train a 3D semantic segmentation model supervised by posed 2D semantic maps. Despite being trained on 2D signals alone, our method is able to generate 3D-consistent semantic maps from novel camera poses and can be queried at arbitrary 3D points. Notably, NeSF is compatible with any method producing a density field. Our empirical analysis demonstrates comparable quality to competitive 2D and 3D semantic segmentation baselines on complex, realistically-rendered scenes and significantly outperforms a comparable neural radiance field-based method on a series of tasks requiring 3D reasoning. Our method is the first to learn semantics by recognizing patterns in the geometry stored within a 3D neural field representation. NeSF is trained using purely 2D signals and requires as few as one labeled image per-scene at train time. No semantic input is required for inference on novel scenes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tnPjQpYk7D">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tnPjQpYk7D.html">Multi-Agent Off-Policy TDC with Near-Optimal Sample and Communication Complexities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ziyi Chen &middot; Yi Zhou &middot; Rong-Rong Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tnPjQpYk7D"></div>

    <a href="paper_pages/tnPjQpYk7D.html">
        <img src="http://img.youtube.com/vi/BCYEaLGtTNE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tnPjQpYk7D" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tnPjQpYk7D" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tnPjQpYk7D">
                Abstract <i id="caret-tnPjQpYk7D" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tnPjQpYk7D">
        <div class="abstract-display">
            <p>The finite-time convergence of off-policy temporal difference (TD) learning has been comprehensively studied recently. However, such a type of convergence has not been established for off-policy TD learning in the multi-agent setting, which covers broader reinforcement learning applications and is fundamentally more challenging. This work develops a decentralized TD with correction (TDC) algorithm for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithm avoids sharing the actions, policies and rewards of the agents, and adopts mini-batch sampling to reduce the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-time sample complexity of our algorithm for achieving an $\epsilon$-accurate solution is in the order of $\mathcal{O}\big(\frac{M\ln\epsilon^{-1}}{\epsilon(1-\sigma_2)^2}\big)$, where $M$ denotes the total number of agents and $\sigma_2$ is a network parameter. This matches the sample complexity of the centralized TDC. Moreover, our algorithm achieves the optimal communication complexity $\mathcal{O}\big(\frac{\sqrt{M}\ln\epsilon^{-1}}{1-\sigma_2}\big)$ for synchronizing the value function parameters, which is order-wise lower than the communication complexity of the existing decentralized TD(0). Numerical simulations corroborate our theoretical findings. </p>
        </div>
    </div>
</div>
                    </div>
                </div>
            </div>

        <script>
            function listmode(){
                $(".cards_img").hide();
                $(".pp-card").addClass("pp-mode-list").removeClass("pp-mode-compact");
            }
            function compactmode(){
                $(".cards_img").show();
                $(".pp-card").removeClass("pp-mode-list").addClass("pp-mode-compact");
            }
        </script>


<script>
    $(document).ready(function() {
        $(".abstract-link").on('click', function(e){
            var target = $(e.target).find("i")
            target.toggleClass("fa-caret-right");
            target.toggleClass("fa-caret-up");
        })
        touchup();
        /* touchup events currently adds dates to cached virtualcards for events */
    })

</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
  "tex2jax": {
    "inlineMath": [["$","$"], ["\(","\)"]],
    "displayMath": [["\[","\]"]],
    "processEscapes": true
  }
}
);
var jq2 = $;
</script>

<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>