<!DOCTYPE html>
<html lang="en" style="scroll-padding-top: 70px;">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>TMLR Infinite Conference</title>
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">
    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="/static/expo/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
    <link rel="stylesheet" href="cards.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">

    <script src="https://code.jquery.com/jquery-3.6.1.min.js"
            integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>
    </script>

    <script>
        if (typeof jQuery === 'undefined') {
            var script = document.createElement('script');
            script.type = 'text/javascript';
            script.src = "/static/core/js/jquery-3.6.1.min.js";
            document.head.appendChild(script);
        }
    </script>

    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/corejs-typeahead/1.3.1/typeahead.bundle.min.js" integrity="sha512-lEb9Vp/rkl9g2E/LdHIMFTqz21+LA79f84gqP75fbimHqVTu6483JG1AwJlWLLQ8ezTehty78fObKupq3HSHPQ==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>
    <script src="/static/virtual/js/virtual.js"></script>

    <link rel="stylesheet" href="virtual.css">

    <style>
    body {
        background: #f6f6f6;
    }
    </style>

</head>

<body>
<!-- NAV -->

<!--
<nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="/">
            <img src="/static/core/img/ICML-logo.svg" height="40px">
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item ">
                    <a class="nav-link" href="/virtual/2022/events/tutorial">Tutorials</a>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Main Conference
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <a class="dropdown-item" href="/virtual/2022/events/oral">Orals</a>
                        <div class="dropdown-divider"></div>
                        <a class="dropdown-item" href="/virtual/2022/papers.html">Papers</a>
                    </div>
                </li>
            </ul>
    </div>
    </div>
</nav>
-->

    <!-- NAV -->

    <nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="">
            <img src="tmlr_logo.jpeg" height="40px">
            Transactions on Machine Learning Research
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">

            <!--
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Main Conference
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/oral">Orals</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/spotlight">Spotlights</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/papers.html">Papers</a>
                </div>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../">All Papers</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="">Papers with Videos</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../featured_papers.html">Featured Papers</a>
            </li>
            -->

    <!--
    <li class="nav-item ">
        <a class="nav-link" href="/virtual/2023/search"><i class="fas fa-search"></i> &nbsp;</a>
    </li>
    -->
        </ul>
    </div>
</div>
</nav>



    <div class="container">
        <br />
        <div class="row">
            <div class="col-md-12"></div>
            <div class="title-centered" style="text-align:center">TMLR Infinite Conference</div>
        </div>
        <div class="row">
            <div class="col-md-12"></div>
            <div class="desc-centered" style="text-align:center">Papers with Videos</div>
        </div>
    </div>

        <div class="row">
            <div class="col-sm-12">
                <div style="max-width: 1500px; margin:auto; border">
                    <div class="grid-displaycards">
                        <div class="displaycards touchup-date" id="event-jIAPLDdGVx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jIAPLDdGVx.html">Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lukas Gosch &middot; Mahalakshmi Sabanayagam &middot; Debarghya Ghoshdastidar &middot; Stephan GÃ¼nnemann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jIAPLDdGVx"></div>

    <a href="paper_pages/jIAPLDdGVx.html">
        <img src="http://img.youtube.com/vi/joXb-uKsj2w/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jIAPLDdGVx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jIAPLDdGVx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jIAPLDdGVx">
                Abstract <i id="caret-jIAPLDdGVx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jIAPLDdGVx">
        <div class="abstract-display">
            <p>Generalization of machine learning models can be severely compromised by data poisoning, where adversarial changes are applied to the training data. This vulnerability has led to interest in certifying (i.e., proving) that such changes up to a certain magnitude do not affect test predictions. We, for the first time, certify Graph Neural Networks (GNNs) against poisoning attacks, including backdoors, targeting the node features of a given graph. Our certificates are white-box and based upon $(i)$ the neural tangent kernel, which characterizes the training dynamics of sufficiently wide networks; and $(ii)$ a novel reformulation of the bilevel optimization problem describing poisoning as a mixed-integer linear program. Consequently, we leverage our framework to provide fundamental insights into the role of graph structure and its connectivity on the worst-case robustness behavior of convolution-based and PageRank-based GNNs. We note that our framework is more general and constitutes the first approach to derive white-box poisoning certificates for NNs, which can be of independent interest beyond graph-related tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XBL7xi5rt0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XBL7xi5rt0.html">GaussianFlow: Splatting Gaussian Dynamics for 4D Content Creation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Quankai Gao &middot; Qiangeng Xu &middot; Zhe Cao &middot; Ben Mildenhall &middot; Wenchao Ma &middot; Le Chen &middot; Danhang Tang &middot; Ulrich Neumann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XBL7xi5rt0"></div>

    <a href="paper_pages/XBL7xi5rt0.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XBL7xi5rt0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XBL7xi5rt0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XBL7xi5rt0">
                Abstract <i id="caret-XBL7xi5rt0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XBL7xi5rt0">
        <div class="abstract-display">
            <p>Creating 4D fields of Gaussian Splatting from images or videos is a challenging task due to its under-constrained nature. While the optimization can draw photometric reference from the input videos or be regulated by generative models, directly supervising Gaussian motions remains underexplored. In this paper, we introduce a novel concept, Gaussian flow, which connects the dynamics of 3D Gaussians and pixel velocities between consecutive frames. The Gaussian flow can be obtained efficiently by splatting Gaussian dynamics into the image space. This differentiable process enables direct dynamic supervision from optical flow. Our method significantly benefits 4D dynamic content generation and 4D novel view synthesis with Gaussian Splatting, especially for contents with rich motions that are hard to handle by existing methods. The common color drifting issue that occurs in 4D generation is also resolved with improved Guassian dynamics. Superior visual quality in extensive experiments demonstrates the effectiveness of our method. As shown in our evaluation, GaussianFlow can drastically improve both quantitative and qualitative results for 4D generation and 4D novel view synthesis.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aFAMPSmNHR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aFAMPSmNHR.html">Do Think Tags Really Help LLMs Plan?  A Critical Evaluation of ReAct-Style Prompting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Siddhant Bhambri &middot; Mudit Verma &middot; Subbarao Kambhampati</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aFAMPSmNHR"></div>

    <a href="paper_pages/aFAMPSmNHR.html">
        <img src="http://img.youtube.com/vi/F8XNJ7tAcBE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aFAMPSmNHR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aFAMPSmNHR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aFAMPSmNHR">
                Abstract <i id="caret-aFAMPSmNHR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aFAMPSmNHR">
        <div class="abstract-display">
            <p>The reasoning abilities of Large Language Models (LLMs) remain a topic of considerable interest and debate. Among the original papers arguing for emergent reasoning abilities of LLMs, ReAct became particularly popular by claiming to tease out LLM reasoning abilities with special prompting involving âinterleaving reasoning trace with action execution". In this paper, we critically examine the claims of ReAct style prompting for planning and sequential decision-making problems. By introducing systematic variations to the input prompt, we perform a sensitivity analysis along the original claims of ReAct. Our experiments in AlfWorld and WebShop, domains that were used in the original ReAct work, show that the performance is minimally influenced by the interleaved reasoning trace or by the content of these generated reasoning traces. Instead, the performance of LLMs is primarily driven by the unreasonably high degree of similarity between input example tasks and queries, with shockingly little ability to generalize. In addition to raising questions on claims about reasoning abilities, this lack of generalization also implicitly forces the prompt designer to provide instance-specific examples, significantly increasing the cognitive burden on the human. Our empirical results show that the perceived reasoning abilities of LLMs stem from the exemplar-query similarity and approximate retrieval rather than any inherent reasoning abilities, thereby leading to severe lack of generalization beyond the few-shot examples given in the prompts. Our code and prompt settings can be found here on GitHub.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Q1Cf07flwD">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Q1Cf07flwD.html">Variance Dichotomy in Feature Spaces of Facial Recognition Systems is a Weak Defense against Simple Weight Manipulation Attacks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Bowditch &middot; Mike Paterson &middot; Matthias Englert &middot; Ranko Lazic</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Q1Cf07flwD"></div>

    <a href="paper_pages/Q1Cf07flwD.html">
        <img src="http://img.youtube.com/vi/DF_RjKacRms/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Q1Cf07flwD" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Q1Cf07flwD" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Q1Cf07flwD">
                Abstract <i id="caret-Q1Cf07flwD" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Q1Cf07flwD">
        <div class="abstract-display">
            <p>We show that several leading pretrained facial recognition systems exhibit a variance dichotomy in their feature space. In other words, the feature vectors approximately lie in a lower dimensional linear subspace. We demonstrate that this variance dichotomy degrades the performance of an otherwise powerful scheme for anonymity/unlinkability and confusion attacks on facial recognition system devised by Zehavi et al. (2024), which is based on simple weight manipulations in only the last hidden layer. Lastly, we propose a method for the attacker to overcome this intrinsic defense of these pretrained facial recognition systems.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LNoFjcLywb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LNoFjcLywb.html">Communication-Efficient Heterogeneous Federated Learning with Generalized Heavy-Ball Momentum</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Riccardo Zaccone &middot; Sai Praneeth Karimireddy &middot; Carlo Masone &middot; Marco Ciccone</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LNoFjcLywb"></div>

    <a href="paper_pages/LNoFjcLywb.html">
        <img src="http://img.youtube.com/vi/-2oO_QnB5yY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LNoFjcLywb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LNoFjcLywb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LNoFjcLywb">
                Abstract <i id="caret-LNoFjcLywb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LNoFjcLywb">
        <div class="abstract-display">
            <p>Federated Learning (FL) has emerged as the state-of-the-art approach for learning from decentralized data in privacy-constrained scenarios. However, system and statistical challenges hinder its real-world applicability, requiring efficient learning from edge devices and robustness to data heterogeneity. Despite significant research efforts, existing approaches often degrade severely due to the joint effect of heterogeneity and partial client participation. In particular, while momentum appears as a promising approach for overcoming statistical heterogeneity, in current approaches its update is biased towards the most recently sampled clients. As we show in this work, this is the reason why it fails to outperform FedAvg, preventing its effective use in real-world large-scale scenarios.
In this work, we propose a novel Generalized Heavy-Ball Momentum (GHBM) and theoretically prove it enables convergence under unbounded data heterogeneity in cyclic partial participation, thereby advancing the understanding of momentum's effectiveness in FL.
We then introduce adaptive and communication-efficient variants of GHBM that match the communication complexity of FedAvg in settings where clients can be stateful.
Extensive experiments on vision and language tasks confirm our theoretical findings, demonstrating that GHBM substantially improves state-of-the-art performance under random uniform client sampling, particularly in large-scale settings with high data heterogeneity and low client participation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TJRyDi7mwH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TJRyDi7mwH.html">NeoBERT: A Next Generation BERT</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lola Le Breton &middot; Quentin Fournier &middot; John Xavier Morris &middot; Mariam El Mezouar &middot; Sarath Chandar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TJRyDi7mwH"></div>

    <a href="paper_pages/TJRyDi7mwH.html">
        <img src="http://img.youtube.com/vi/WF3man-zo3o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TJRyDi7mwH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TJRyDi7mwH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TJRyDi7mwH">
                Abstract <i id="caret-TJRyDi7mwH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TJRyDi7mwH">
        <div class="abstract-display">
            <p>Recent innovations in architecture, pre-training, and fine-tuning have led to the remarkable in-context learning and reasoning abilities of large auto-regressive language models such as LLaMA and DeepSeek. In contrast, encoders like BERT and RoBERTa have not seen the same level of progress despite being foundational for many downstream NLP applications. To bridge this gap, we introduce NeoBERT, a next-generation encoder that redefines the capabilities of bidirectional models by integrating state-of-the-art advancements in architecture, modern data, and optimized pre-training methodologies. NeoBERT is designed for seamless adoption: it serves as a plug-and-play replacement for existing base models, relies on an optimal depth-to-width ratio, and leverages an extended context length of 4,096 tokens. Despite its compact 250M parameter footprint, it achieves state-of-the-art results on the massive MTEB benchmark, outperforming BERT$_{large}$, RoBERTa$_{large}$, NomicBERT, and ModernBERT under identical fine-tuning conditions. In addition, we rigorously evaluate the impact of each modification on GLUE and design a uniform fine-tuning and evaluation framework for MTEB. We release all code, data, checkpoints, and training scripts to accelerate research and real-world adoption.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-15keyzQj9h">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/15keyzQj9h.html">On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Asen Dotsinski &middot; Udit Thakur &middot; Marko Ivanov &middot; Mohammad Hafeez Khan &middot; Maria Heuss</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-15keyzQj9h"></div>

    <a href="paper_pages/15keyzQj9h.html">
        <img src="http://img.youtube.com/vi/GSY_q2cgWs0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-15keyzQj9h" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-15keyzQj9h" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-15keyzQj9h">
                Abstract <i id="caret-15keyzQj9h" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-15keyzQj9h">
        <div class="abstract-display">
            <p>We present a reproduction study of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which investigates competition of mechanisms in language models between factual recall and counterfactual in-context repetition. Our study successfully reproduces their primary findings regarding the localization of factual and counterfactual information, the dominance of attention blocks in mechanism competition, and the specialization of attention heads in handling competing information. We reproduce their results on both GPT-2 (Radford et al., 2019) and Pythia 6.9B (Biderman et al., 2023). We extend their work in three significant directions. First, we explore the generalizability of these findings to even larger models by replicating the experiments on Llama 3.1 8B (Grattafiori et al., 2024), discovering greatly reduced attention head specialization. Second, we investigate the impact of prompt structure by introducing variations where we avoid repeating the counterfactual statement verbatim or we change the premise word, observing a marked decrease in the logit for the counterfactual token. Finally, we test the validity of the authorsâ claims for prompts of specific domains, discovering that certain categories of prompts skew the results by providing the factual prediction token
as part of the subject of the sentence. Overall, we find that the attention head ablation proposed in Ortu et al. (2024) is ineffective for domains that are underrepresented in their dataset, and that the effectiveness varies based on model architecture, prompt structure,
domain and task.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vltzxxhzLU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vltzxxhzLU.html">A reproducibility study of âUser-item fairness tradeoffs in recommendationsâ</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sander Honig &middot; Elyanne Oey &middot; Lisanne Wallaard &middot; Sharanda Suttorp &middot; Clara Rus</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vltzxxhzLU"></div>

    <a href="paper_pages/vltzxxhzLU.html">
        <img src="http://img.youtube.com/vi/I5NTCq3oqDs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vltzxxhzLU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vltzxxhzLU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vltzxxhzLU">
                Abstract <i id="caret-vltzxxhzLU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vltzxxhzLU">
        <div class="abstract-display">
            <p>Recommendation systems are necessary to filter the abundance of information presented in our everyday lives. A recommendation system could exclusively recommend items that users prefer the most, potentially resulting in certain items never getting recommended. Conversely, an exclusive focus on including all items could hurt overall recommendation quality. This gives rise to the challenge of balancing user and item fairness. The paper âUser-item fairness tradeoffs in recommendationsâ by Greenwood et al. (2024) explores this tradeoff by developing a theoretical framework that optimizes for user-item fairness constraints. Their theoretical framework suggests that the cost of item fairness is low when users have varying preferences compared to each other, and may be high for users whose preferences are misestimated. They empirically measured these phenomena by creating their own recommendation system on arXiv preprints, and confirmed that the cost of item fairness is low when users have preferences that differ from one another. However, contrary to their theoretical expectations, misestimated users do not encounter a higher cost of item fairness. This study investigates the reproducibility of their research by replicating the empirical study. Additionally, we extend their research in two ways: (i) verifying the generalizability of their findings on a different dataset (Amazon books reviews), and (ii) analyzing the tradeoffs when recommending multiple items to a user instead of a single item. Our results further validate the claims made in the original paper. We concluded the claims hold true when recommending multiple items, with the cost of item fairness decreasing as more items are recommended.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zo5b60AuAH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zo5b60AuAH.html">Local Differential Privacy-Preserving Spectral Clustering for General Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sayan Mukherjee &middot; Vorapong Suppakitpaisarn</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zo5b60AuAH"></div>

    <a href="paper_pages/zo5b60AuAH.html">
        <img src="http://img.youtube.com/vi/8qQFrPtAnnU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zo5b60AuAH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zo5b60AuAH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zo5b60AuAH">
                Abstract <i id="caret-zo5b60AuAH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zo5b60AuAH">
        <div class="abstract-display">
            <p>Spectral clustering is a widely used algorithm to find clusters in networks. Several researchers have studied the stability of spectral clustering under local differential privacy with the additional assumption that the underlying networks are generated from the stochastic block model (SBM). However, we argue that this assumption is too restrictive since social networks do not originate from the SBM. Thus, we delve into an analysis for general graphs in this work. Our primary focus is the edge flipping method -- a common technique for protecting local differential privacy. We show that, when the edges of an $n$-vertex graph satisfying some reasonable well-clustering assumptions are flipped with a probability of $O(\log n/n)$, the clustering outcomes are largely consistent. Empirical tests further corroborate these theoretical findings. Conversely, although clustering outcomes have been stable for non-sparse and well-clustered graphs produced from the SBM, we show that in general, spectral clustering may yield highly erratic results on certain graphs when the flipping probability is $\omega(\log n/n)$. This indicates that the best privacy budget obtainable for general graphs is $\Theta(\log n)$.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fuOHI59rUW">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fuOHI59rUW.html">MarDini: Masked Auto-regressive Diffusion for Video Generation at Scale</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Haozhe Liu &middot; Shikun Liu &middot; Zijian Zhou &middot; Mengmeng Xu &middot; Yanping Xie &middot; Xiao Han &middot; Juan Camilo Perez &middot; Ding Liu &middot; Kumara Kahatapitiya &middot; Menglin Jia &middot; Jui-Chieh Wu &middot; Sen He &middot; Tao Xiang &middot; JÃ¼rgen Schmidhuber &middot; Juan-Manuel Perez-Rua</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fuOHI59rUW"></div>

    <a href="paper_pages/fuOHI59rUW.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fuOHI59rUW" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fuOHI59rUW" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fuOHI59rUW">
                Abstract <i id="caret-fuOHI59rUW" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fuOHI59rUW">
        <div class="abstract-display">
            <p>We introduce MarDini, a new family of video diffusion models that integrate the advantages of masked auto-regression (MAR) into a unified diffusion model (DM) framework. Here, MAR handles temporal planning, while DM focuses on spatial generation in an asymmetric network design: i) a MAR-based planning model containing most of the parameters generates planning signals for each masked frame using low-resolution input; ii) a lightweight generation model uses these signals to produce high-resolution frames via diffusion de-noising. MarDiniâs MAR enables video generation conditioned on any number of masked frames at any frame positions: a single model can handle video interpolation (e.g., masking middle frames), image-to-video generation (e.g., masking from the second frame onward), and video expansion (e.g., masking half the frames). The efficient design allocates most of the computational resources to the low-resolution planning model, making computationally expensive but important spatio-temporal attention feasible at scale. MarDini sets a new state-of-the-art for video interpolation; meanwhile, within few inference steps, it efficiently generates videos on par with those of much more expensive advanced image-to-video models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-kY2fKLOGkI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/kY2fKLOGkI.html">On the Utility of Existing Fine-Tuned Models on Data-Scarce Domains</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Md Ibrahim Ibne Alam &middot; Parikshit Ram &middot; Soham Dan &middot; Horst Samulowitz &middot; Koushik Kar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-kY2fKLOGkI"></div>

    <a href="paper_pages/kY2fKLOGkI.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-kY2fKLOGkI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-kY2fKLOGkI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-kY2fKLOGkI">
                Abstract <i id="caret-kY2fKLOGkI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-kY2fKLOGkI">
        <div class="abstract-display">
            <p>Large Language Models (LLMs) have been observed to perform well on a wide range of downstream tasks when fine-tuned on domain-specific data. However, such data may not be readily available in many applications, motivating zero-shot or few-shot approaches using existing domain or task adjacent (fine-tuned) models, which we call DAFT. While several fine-tuned models for various tasks are available, finding one appropriate DAFT model for a given task is often not straight forward. In this paper, we explore different utilization techniques of these existing DAFT models for data-scarce problems, i.e., tasks for which data is not available or limited. We observe that for zero-shot problems, ensembling of DAFT models provides an accuracy performance close to that of the single best model. With few-shot problems (few data from target domain available), this performance can be improved further by picking or putting more weights to the DAFT models that are expected to perform better on the target task.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-bzk1sV1svm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/bzk1sV1svm.html">SR-Reward: Taking The Path More Traveled</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Seyed Mahdi B. Azad &middot; Zahra Padar &middot; Gabriel Kalweit &middot; Joschka Boedecker</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-bzk1sV1svm"></div>

    <a href="paper_pages/bzk1sV1svm.html">
        <img src="http://img.youtube.com/vi/vYLgpXd5Lew/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-bzk1sV1svm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-bzk1sV1svm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-bzk1sV1svm">
                Abstract <i id="caret-bzk1sV1svm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-bzk1sV1svm">
        <div class="abstract-display">
            <p>In this paper, we propose a novel method for learning reward functions directly from offline demonstrations. 
Unlike traditional inverse reinforcement learning (IRL), our approach decouples the reward function from the learner's policy, eliminating the adversarial interaction typically required between the two. 
This results in a more stable and efficient training process. 
Our reward module, \textit{SR-Reward}, leverages successor representation (SR) to encode a state based on expected future states' visitation under the demonstration policy and transition dynamics. 
By utilizing the Bellman equation, SR-Reward can be learned concurrently with most reinforcement learning (RL) algorithms without altering the existing training pipeline.
We also introduce a negative sampling strategy to mitigate overestimation errors by reducing rewards for out-of-distribution data, thereby enhancing robustness. 
This strategy introduces an inherent conservative bias into RL algorithms that employ the learned reward, encouraging them to stay close to the demonstrations where the consequences of the actions are better understood. 
We evaluate our method on D4RL as well as Maniskill Robot Manipulation environments, achieving competitive results compared to offline RL algorithms with access to true rewards and imitation learning (IL) techniques like behavioral cloning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-pdC092Nn8N">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/pdC092Nn8N.html">Studying Exploration in RL: An Optimal Transport Analysis of Occupancy Measure Trajectories</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reabetswe M. Nkhumise &middot; Debabrota Basu &middot; Tony J. Prescott &middot; Aditya Gilra</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-pdC092Nn8N"></div>

    <a href="paper_pages/pdC092Nn8N.html">
        <img src="http://img.youtube.com/vi/fIYBGZcB0yQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-pdC092Nn8N" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-pdC092Nn8N" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-pdC092Nn8N">
                Abstract <i id="caret-pdC092Nn8N" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-pdC092Nn8N">
        <div class="abstract-display">
            <p>The rising successes of RL are propelled by combining smart algorithmic strategies and deep architectures to optimize the distribution of returns and visitations over the state-action space. A quantitative framework to compare the learning processes of these eclectic RL algorithms is currently absent but desired in practice. We address this gap by representing the learning process of an RL algorithm as a sequence of policies generated during training, and then studying the policy trajectory induced in the manifold of state-action occupancy measures. Using an optimal transport-based metric, we measure the length of the paths induced by the policy sequence yielded by an RL algorithm between an initial policy and a final optimal policy. Hence, we first define the Effort of Sequential Learning (ESL). ESL quantifies the relative distance that an RL algorithm travels compared to the shortest path from the initial to the optimal policy. Furthermore, we connect the dynamics of policies in the occupancy measure space and regret (another metric to understand the suboptimality of an RL algorithm), by defining the Optimal Movement Ratio (OMR). OMR assesses the fraction of movements in the occupancy measure space that effectively reduce an analogue of regret. Finally, we derive approximation guarantees to estimate ESL and OMR with a finite number of samples and without access to an optimal policy. Through empirical analyses across various environments and algorithms, we demonstrate that ESL and OMR provide insights into the exploration processes of RL algorithms and the hardness of different tasks in discrete and continuous MDPs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qmHlTkLdbL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qmHlTkLdbL.html">Online Bandit Nonlinear Control with Dynamic Batch Length and Adaptive Learning Rate</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jihun Kim &middot; Javad Lavaei</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qmHlTkLdbL"></div>

    <a href="paper_pages/qmHlTkLdbL.html">
        <img src="https://drive.google.com/thumbnail?id=1XOKOosCDSERB7LTm-d2YR1XXJTETUba3" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qmHlTkLdbL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qmHlTkLdbL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qmHlTkLdbL">
                Abstract <i id="caret-qmHlTkLdbL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qmHlTkLdbL">
        <div class="abstract-display">
            <p>This paper is concerned with the online bandit nonlinear control, which aims to learn the best stabilizing controller from a pool of stabilizing and destabilizing controllers of unknown types for a given nonlinear dynamical system. We develop an algorithm, named Dynamic Batch length and Adaptive learning Rate (DBAR), and study its stability and regret. Unlike the existing Exp3 algorithm requiring an exponentially stabilizing controller, DBAR only needs a significantly weaker notion of controller stability, in which case substantial time may be required to certify the system stability. Dynamic batch length in DBAR effectively addresses this issue and enables the system to attain asymptotic stability, where the algorithm behaves as if there were no destabilizing controllers. Moreover, adaptive learning rate in DBAR only uses the state norm information to achieve a tight regret bound even when none of the stabilizing controllers in the pool are exponentially stabilizing.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-BaRD2Nfj41">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/BaRD2Nfj41.html">Overcoming Knowledge Barriers: Online Imitation Learning from Visual Observation with Pretrained World Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xingyuan Zhang &middot; Philip Becker-Ehmck &middot; Patrick van der Smagt &middot; Maximilian Karl</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-BaRD2Nfj41"></div>

    <a href="paper_pages/BaRD2Nfj41.html">
        <img src="http://img.youtube.com/vi/4yO3Q2AM-7o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-BaRD2Nfj41" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-BaRD2Nfj41" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-BaRD2Nfj41">
                Abstract <i id="caret-BaRD2Nfj41" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-BaRD2Nfj41">
        <div class="abstract-display">
            <p>Pretraining and finetuning models has become increasingly popular in decision-making. But there are still serious impediments in Imitation Learning from Observation (ILfO) with pretrained models. This study identifies two primary obstacles: the Embodiment Knowledge Barrier (EKB) and the Demonstration Knowledge Barrier (DKB). The EKB emerges due to the pretrained models' limitations in handling novel observations, which leads to inaccurate action inference. Conversely, the DKB stems from the reliance on limited demonstration datasets, restricting the model's adaptability across diverse scenarios. We propose separate solutions to overcome each barrier and apply them to Action Inference by Maximising Evidence (AIME), a state-of-the-art algorithm. This new algorithm, AIME-NoB, integrates online interactions and a data-driven regulariser to mitigate the EKB. Additionally, it uses a surrogate reward function to broaden the policy's supported states, addressing the DKB. Our experiments on vision-based control tasks from the DeepMind Control Suite and MetaWorld benchmarks show that AIME-NoB significantly improves sample efficiency and converged performance, presenting a robust framework for overcoming the challenges in ILfO with pretrained models. Code available at https://github.com/IcarusWizard/AIME-NoB.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6Aj0aNXfRy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6Aj0aNXfRy.html">Exploring and Improving Initialization for Deep Graph Neural Networks: A Signal Propagation Perspective</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Senmiao Wang &middot; Yupeng Chen &middot; Yushun Zhang &middot; Ruoyu Sun &middot; Tian Ding</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6Aj0aNXfRy"></div>

    <a href="paper_pages/6Aj0aNXfRy.html">
        <img src="https://drive.google.com/thumbnail?id=1Pi7ACLUdqZG_h1oEjX3TXvMX11E0WqiV" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6Aj0aNXfRy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6Aj0aNXfRy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6Aj0aNXfRy">
                Abstract <i id="caret-6Aj0aNXfRy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6Aj0aNXfRy">
        <div class="abstract-display">
            <p>Graph Neural Networks (GNNs) often suffer from performance degradation as the network depth increases. This paper addresses this issue by introducing initialization methods that enhance signal propagation (SP) within GNNs. We propose three key metrics for effective SP in GNNs: forward propagation, backward propagation, and graph embedding variation (GEV). While the first two metrics derive from classical SP theory, the third is specifically designed for GNNs. We theoretically demonstrate that a broad range of commonly used initialization methods for GNNs, which exhibit performance degradation with increasing depth, fail to control these three metrics simultaneously. To deal with this limitation, a direct exploitation of the SP analysis--searching for weight initialization variances that optimize the three metrics--is shown to significantly enhance the SP in deep GCNs. This approach is called \textit{\textbf{S}ignal \textbf{P}ropagation \textbf{o}n \textbf{G}raph-guided \textbf{Init}ialization (\textbf{SPoGInit})}. Our experiments demonstrate that SPoGInit outperforms commonly used initialization methods on various tasks and architectures. Notably, SPoGInit enables performance improvements as GNNs deepen, which represents a significant advancement in addressing depth-related challenges and highlights the validity and effectiveness of the SP analysis framework.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DVeFqV56Iz">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DVeFqV56Iz.html">Change Point Detection in Dynamic Graphs with Decoder-only Latent Space Model</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yik Lun Kei &middot; Jialiang Li &middot; Hangjian Li &middot; Yanzhen Chen &middot; OSCAR HERNAN MADRID PADILLA</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DVeFqV56Iz"></div>

    <a href="paper_pages/DVeFqV56Iz.html">
        <img src="http://img.youtube.com/vi/s4IFIuK-B5k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DVeFqV56Iz" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DVeFqV56Iz" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DVeFqV56Iz">
                Abstract <i id="caret-DVeFqV56Iz" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DVeFqV56Iz">
        <div class="abstract-display">
            <p>This manuscript studies the unsupervised change point detection problem in time series of graphs using a decoder-only latent space model. The proposed framework consists of learnable prior distributions for low-dimensional graph representations and of a decoder that bridges the observed graphs and latent representations. The prior distributions of the latent spaces are learned from the observed data as empirical Bayes to assist change point detection. Specifically, the model parameters are estimated via maximum approximate likelihood, with a Group Fused Lasso regularization imposed on the prior parameters. The augmented Lagrangian is solved via Alternating Direction Method of Multipliers, and Langevin Dynamics are recruited for posterior inference. Simulation studies show good performance of the latent space model in supporting change point detection and real data experiments yield change points that align with significant events.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-PMO30TLI4l">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/PMO30TLI4l.html">Selective Concept Bottleneck Models Without Predefined Concepts</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Simon Schrodi &middot; Julian Schur &middot; Max Argus &middot; Thomas Brox</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-PMO30TLI4l"></div>

    <a href="paper_pages/PMO30TLI4l.html">
        <img src="http://img.youtube.com/vi/sdqfkwNge-I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-PMO30TLI4l" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-PMO30TLI4l" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-PMO30TLI4l">
                Abstract <i id="caret-PMO30TLI4l" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-PMO30TLI4l">
        <div class="abstract-display">
            <p>Concept-based models like Concept Bottleneck Models (CBMs) have garnered significant interest for improving model interpretability by first predicting human-understandable concepts before mapping them to the output classes. Early approaches required costly concept annotations. To alleviate this, recent methods utilized large language models to automatically generate class-specific concept descriptions and learned mappings from a pretrained black-box modelâs raw features to these concepts using vision-language models. However, these approaches assume prior knowledge of which concepts the black-box model has learned. In this work, we discover the concepts encoded by the model through unsupervised concept discovery techniques instead. We further leverage a simple input-dependent concept selection mechanism that dynamically retains a sparse set of relevant concepts of each input, enhancing both sparsity and interpretability. Our approach not only improves downstream performance, but also needs significantly fewer concepts for accurate classification. Lastly, we show how large vision-language models can guide the editing of our models' weights to correct model errors.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jXcx2oAIbw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jXcx2oAIbw.html">LLM-Guided Self-Supervised Tabular Learning With Task-Specific Pre-text Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sungwon Han &middot; Seungeon Lee &middot; Meeyoung Cha &middot; Sercan O Arik &middot; Jinsung Yoon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jXcx2oAIbw"></div>

    <a href="paper_pages/jXcx2oAIbw.html">
        <img src="https://drive.google.com/thumbnail?id=1pnBWRbs4lOjT_4nGlo2KD4lU_9XCzWm8" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jXcx2oAIbw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jXcx2oAIbw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jXcx2oAIbw">
                Abstract <i id="caret-jXcx2oAIbw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jXcx2oAIbw">
        <div class="abstract-display">
            <p>One of the most common approaches for self-supervised representation learning is defining pre-text tasks to learn data representations. 
Existing works determine pre-text tasks in a "task-agnostic'' way, without considering the forthcoming downstream tasks. This offers an advantage of broad applicability across tasks, but can also lead to a mismatch between task objectives, potentially degrading performance on downstream tasks. In this paper, we introduce TST-LLM, a framework that effectively reduces this mismatch when the natural language-based description of the downstream task is given without any ground-truth labels. TST-LLM instructs the LLM to use the downstream task's description and meta-information of data to discover features relevant to the target task. These discovered features are then treated as ground-truth labels to define "target-specific'' pre-text tasks. TST-LLM consistently outperforms contemporary baselines, such as STUNT and LFR, with win ratios of 95% and 81%, when applied to 22 benchmark tabular datasets, including binary and multi-class classification, and regression tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Tnwci2kLna">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Tnwci2kLna.html">CXAD: Contrastive Explanations for Anomaly Detection: Algorithms, Complexity Results and Experiments</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ian Davidson &middot; NicolÃ¡s Kennedy &middot; S. S. Ravi</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Tnwci2kLna"></div>

    <a href="paper_pages/Tnwci2kLna.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Tnwci2kLna" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Tnwci2kLna" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Tnwci2kLna">
                Abstract <i id="caret-Tnwci2kLna" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Tnwci2kLna">
        <div class="abstract-display">
            <p>Anomaly/Outlier detection (AD/OD) is often used in controversial applications to detect unusual behavior which is then further investigated or policed. This means an explanation of why something was predicted as an anomaly is desirable not only for individuals but also for the general population and policy-makers. However, existing explainable AI (XAI) methods are not well suited for Explainable Anomaly detection (XAD). In particular, most XAI methods provide instance-level explanations, whereas a model/global-level explanation is desirable for a complete understanding of the definition of normality or abnormality used by an AD algorithm. Further, existing XAI methods try to explain an algorithmâs behavior by finding an explanation of why an instance belongs to a category. However, by definition, anomalies/outliers are chosen because they are different from the normal instances. We propose a new style of model agnostic explanation, called contrastive explanation, that is designed specifically for AD algorithms. It addresses the novel challenge of providing a model-agnostic and global-level explanation by finding contrasts between the outlier group of instances and the normal group. We propose three formulations: (i) Contrastive Explanation, (ii) Strongly Contrastive Explanation, and (iii) Multiple Strong Contrastive Explanations. The last formulation is specifically for the case where a given dataset is believed to have many types of anomalies. For the first two formulations, we show the underlying problem is in the computational class P by presenting linear and polynomial time exact algorithms. We show that the last formulation is computationally intractable, and we use an integer linear program for that version to generate experimental results. We demonstrate our work on several data sets such as the CelebA image data set, the HateXplain language data set, and the COMPAS dataset on fairness. These data sets are chosen as their ground truth explanations are clear or well-known.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-BMGikHBjlx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/BMGikHBjlx.html">Ctrl-V: Higher Fidelity Autonomous Vehicle Video Generation with Bounding-Box Controlled Object Motion</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ge Ya Luo &middot; ZhiHao Luo &middot; Anthony Gosselin &middot; Alexia Jolicoeur-Martineau &middot; Christopher Pal</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-BMGikHBjlx"></div>

    <a href="paper_pages/BMGikHBjlx.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-BMGikHBjlx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-BMGikHBjlx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-BMGikHBjlx">
                Abstract <i id="caret-BMGikHBjlx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-BMGikHBjlx">
        <div class="abstract-display">
            <p>Controllable video generation has attracted significant attention, largely due to advances in video diffusion models. In domains such as autonomous driving, developing highly accurate predictions for object motions is essential. This paper addresses the key challenge of enabling fine-grained control over object motion in the context of driving video synthesis. To accomplish this, we 1) employ a distinct, specialized model to forecast the trajectories of object bounding boxes, 2) adapt and enhance a separate video diffusion network to create video content conditioned on these high-quality trajectory forecasts, and 3) we are able to exert precise control over object position/movements using bounding boxes in both 2D and 3D spaces. Our method, Ctrl-V, leverages modified and fine-tuned Stable Video Diffusion (SVD) models to solve both trajectory and video generation. Extensive experiments conducted on the KITTI, Virtual-KITTI 2, BDD100k, and nuScenes datasets validate the effectiveness of our approach in producing realistic and controllable video generation. Project page: \url{https://oooolga.github.io/ctrl-v.github.io/}</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-yGGoOVpBVP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/yGGoOVpBVP.html">Connecting Parameter Magnitudes and Hessian Eigenspaces at Scale using Sketched Methods</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Andres Fernandez &middot; Frank Schneider &middot; Maren Mahsereci &middot; Philipp Hennig</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-yGGoOVpBVP"></div>

    <a href="paper_pages/yGGoOVpBVP.html">
        <img src="http://img.youtube.com/vi/tV7hC65vQp4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-yGGoOVpBVP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-yGGoOVpBVP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-yGGoOVpBVP">
                Abstract <i id="caret-yGGoOVpBVP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-yGGoOVpBVP">
        <div class="abstract-display">
            <p>Recently, it has been observed that when training a deep neural net with SGD, the majority of the loss landscape's curvature quickly concentrates in a tiny *top* eigenspace of the loss Hessian, which remains largely stable thereafter.
Independently, it has been shown that successful magnitude pruning masks for deep neural nets emerge early in training and remain stable thereafter.
In this work, we study these two phenomena jointly and show that they are connected:
We develop a methodology to measure the similarity between arbitrary parameter masks and Hessian eigenspaces via Grassmannian metrics. We identify *overlap* as the most useful such metric due to its interpretability and stability.
To compute *overlap*, we develop a matrix-free algorithm based on sketched SVDs that allows us to compute over 1000 Hessian eigenpairs for nets with over 10M parameters --an unprecedented scale by several orders of magnitude.
Our experiments reveal an *overlap* between magnitude parameter masks and top Hessian eigenspaces consistently higher than chance-level, and that this effect gets accentuated for larger network sizes.
This result indicates that *top Hessian eigenvectors tend to be concentrated around larger parameters*, or equivalently, that *larger parameters tend to align with directions of larger loss curvature*.
Our work provides a methodology to approximate and analyze deep learning Hessians at scale, as well as a novel insight on the structure of their eigenspace</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JyjTJAG9yZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JyjTJAG9yZ.html">Personalized Layer Selection for Graph Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kartik Sharma &middot; Vineeth Rakesh &middot; Yingtong Dou &middot; Srijan Kumar &middot; Mahashweta Das</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JyjTJAG9yZ"></div>

    <a href="paper_pages/JyjTJAG9yZ.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JyjTJAG9yZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JyjTJAG9yZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JyjTJAG9yZ">
                Abstract <i id="caret-JyjTJAG9yZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JyjTJAG9yZ">
        <div class="abstract-display">
            <p>Graph Neural Networks (GNNs) combine node attributes over a fixed granularity of the local graph structure around a node to predict its label. However, different nodes may relate to a node-level property with a different granularity of its local neighborhood, and using the same level of smoothing for all nodes can be detrimental to their classification. In this work, we challenge the common fact that a single GNN layer can classify all nodes of a graph by training GNNs with a distinct personalized layer for each node. Inspired by metric learning, we propose a novel algorithm, MetSelect, to select the optimal representation layer to classify each node. In particular, we identify a prototype representation of each class in a transformed GNN layer and then, classify using the layer where the distance is smallest to a class prototype after normalizing with that layerâs variance. Results on 10 datasets and 3 different GNNs show that we significantly improve the node classification accuracy of GNNs in a plug-and-play manner. We also find that using variable layers for prediction enables GNNs to be deeper and more robust to poisoning attacks. We hope this work can inspire future works to learn more adaptive and personalized graph representations.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-FPJKZDzdsW">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/FPJKZDzdsW.html">Fairness with respect to Stereotype Predictors: Impossibilities and Best Practices</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Inbal Rachel Livni Navon &middot; Omer Reingold &middot; Judy Hanwen Shen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-FPJKZDzdsW"></div>

    <a href="paper_pages/FPJKZDzdsW.html">
        <img src="https://drive.google.com/thumbnail?id=109Ud2KIQY0IW8pHAxMI4XRDRv7lfy_dP" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-FPJKZDzdsW" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-FPJKZDzdsW" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-FPJKZDzdsW">
                Abstract <i id="caret-FPJKZDzdsW" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-FPJKZDzdsW">
        <div class="abstract-display">
            <p>As AI systems increasingly influence decision-making from consumer recommendations to educational opportunities, their accountability becomes paramount. This need for oversight has driven extensive research into algorithmic fairness, a body of work that has examined both allocative and representational harms. However, numerous works examining representational harms such as stereotypes encompass many different concepts measured by different criteria, yielding many, potentially conflicting, characterizations of harm. The abundance of measurement approaches makes the mitigation of stereotypes in downstream machine learning models highly challenging. Our work introduces and unifies a broad class of auditors through the framework of \textit{stereotype predictors}. We map notions of fairness with respect to these predictors to existing notions of group fairness. We give guidance, with theoretical foundations, for selecting one or a set of stereotype predictors and provide algorithms for achieving fairness with respect to stereotype predictors under various fairness notions. We demonstrate the effectiveness of our algorithms with different stereotype predictors in two empirical case studies.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TR6iUG8i6Z">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TR6iUG8i6Z.html">Federated Spectral Graph Transformers Meet Neural Ordinary Differential Equations for Non-IID Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kishan Gurumurthy &middot; Himanshu Pal &middot; Charu Sharma</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TR6iUG8i6Z"></div>

    <a href="paper_pages/TR6iUG8i6Z.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TR6iUG8i6Z" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TR6iUG8i6Z" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TR6iUG8i6Z">
                Abstract <i id="caret-TR6iUG8i6Z" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TR6iUG8i6Z">
        <div class="abstract-display">
            <p>Graph Neural Network (GNN) research is rapidly advancing due to GNNsâ capacity to learn distributed representations from graph-structured data. However, centralizing large volumes of real-world graph data for GNN training is often impractical due to privacy concerns, regulatory restrictions, and commercial competition. Federated learning (FL), a distributed learning paradigm, offers a solution by preserving data privacy with collaborative model training. Despite progress in training huge vision and language models, federated learning for GNNs remains underexplored. To address this challenge, we present a novel method for federated learning on GNNs based on spectral GNNs equipped with neural ordinary differential equations (ODE) for better information capture, showing promising results across both homophilic and heterophilic graphs. Our approach effectively handles non-Independent and Identically Distributed (non-IID) data, while also achieving performance comparable to existing methods that only operate on IID data. It is designed to be privacy-preserving and bandwidth-optimized, making it suitable for real-world applications such as social network analysis, recommendation systems, and fraud detection, which often involve complex, non-IID, and heterophilic graph structures. Our results in the area of federated learning on non-IID heterophilic graphs demonstrate significant improvements, while also achieving better performance on homophilic graphs. This work highlights the potential of federated learning in diverse and challenging graph settings.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6RCs2tLsHq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6RCs2tLsHq.html">Metamorphic Forward Adaptation Network: Dynamically Adaptive and Modular Multi-layer Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yu Sun &middot; Vijja Wichitwechkarn &middot; Ronald Clark &middot; Mirko Kovac &middot; Basaran Bahadir Kocer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6RCs2tLsHq"></div>

    <a href="paper_pages/6RCs2tLsHq.html">
        <img src="http://img.youtube.com/vi/nGv8Nno2hsw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6RCs2tLsHq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6RCs2tLsHq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6RCs2tLsHq">
                Abstract <i id="caret-6RCs2tLsHq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6RCs2tLsHq">
        <div class="abstract-display">
            <p>Back-propagation is a widely used algorithm for training neural networks by adjusting weights based on error gradients. However, back-propagation is biologically implausible with global derivative computation and lacks robustness in long-term dynamic learning. A previously proposed alternative to back-propagation is the Forward-Forward algorithm, which bypasses global gradient dependency and localises computations, making it a more biologically plausible approach. However, Forward-Forward has been evaluated in limited environments, does not yet match back-propagation's performance, and only supports classification, not regression. This research introduces the Metamorphic Forward Adaptation Network (MFAN), using a contrastive learning property as its core, and retaining the layer-wise architecture of the Forward-Forward algorithm. Compared to the Forward-Forward model being limited to discrete classification, MFAN can process discrete and continuous data, showing stability, adaptability, and the ability to handle evolving data. MFAN performs well in continuous data stream scenarios, demonstrating superior adaptability and robustness compared to back-propagation, particularly in tasks requiring dynamic, long-term learning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-heeJqQXKg7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/heeJqQXKg7.html">LitLLMs, LLMs for Literature Review: Are we there yet?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shubham Agarwal &middot; Gaurav Sahu &middot; Abhay Puri &middot; Issam H. Laradji &middot; Krishnamurthy Dj Dvijotham &middot; Jason Stanley &middot; Laurent Charlin &middot; Christopher Pal</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-heeJqQXKg7"></div>

    <a href="paper_pages/heeJqQXKg7.html">
        <img src="http://img.youtube.com/vi/wvYXJ832Qhc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-heeJqQXKg7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-heeJqQXKg7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-heeJqQXKg7">
                Abstract <i id="caret-heeJqQXKg7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-heeJqQXKg7">
        <div class="abstract-display">
            <p>Literature reviews are an essential component of scientific research, but they remain time-intensive and challenging to write, especially due to the recent influx of research papers. This paper explores the zero-shot abilities of recent Large Language Models (LLMs) in assisting with the writing of literature reviews based on an abstract. We decompose the task into two components: (1) Retrieving related works given a query abstract and (2) Writing a literature review based on the retrieved results. We analyze how effective LLMs are for both components. For retrieval, we introduce a novel two-step search strategy that first uses an LLM to extract meaningful keywords from the abstract of a paper and then retrieves potentially relevant papers by querying an external knowledge base. Additionally, we study a prompting-based re-ranking mechanism with attribution and show that re-ranking doubles the normalized recall compared to naive search methods while providing insights into the LLMâs decision-making process. In the generation phase, we propose a two-step approach that first outlines a plan for the review and then executes steps in the plan to generate the actual review. To evaluate different LLM-based literature review methods, we create test sets from arXiv papers using a protocol designed for rolling use with newly released LLMs to avoid test set contamination in zero-shot evaluations. We release this evaluation protocol to promote additional research and development in this regard. Our empirical results suggest that LLMs show promising potential for writing literature reviews when the task is decomposed into smaller components of retrieval and planning. Particularly, we find that combining keyword-based and document-embedding-based search improves precision and recall during retrieval by 10% and 30%, respectively, compared to using either of the methods in isolation. Further, we demonstrate that our planning-based approach achieves higher-quality reviews by minimizing hallucinated references in the generated review by 18-26% compared to existing simpler LLM-based generation methods. Our project page including a demonstration system and toolkit can be accessed here: https://litllm.github.io.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-k3Ab6RuJE9">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/k3Ab6RuJE9.html">Verbalized Machine Learning: Revisiting Machine Learning with Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tim Z. Xiao &middot; Robert Bamler &middot; Bernhard SchÃ¶lkopf &middot; Weiyang Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-k3Ab6RuJE9"></div>

    <a href="paper_pages/k3Ab6RuJE9.html">
        <img src="http://img.youtube.com/vi/LCl_np5oPWA/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-k3Ab6RuJE9" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-k3Ab6RuJE9" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-k3Ab6RuJE9">
                Abstract <i id="caret-k3Ab6RuJE9" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-k3Ab6RuJE9">
        <div class="abstract-display">
            <p>Motivated by the progress of large language models (LLMs), we introduce the framework of verbalized machine learning (VML). In contrast to conventional machine learning (ML) models that are typically optimized over a continuous parameter space, VML constrains the parameter space to be human-interpretable natural language. Such a constraint leads to a new perspective of function approximation, where an LLM with a text prompt can be viewed as a function parameterized by the text prompt. Guided by this perspective, we revisit classical ML problems, such as regression and classification, and find that these problems can be solved by an LLM-parameterized learner and optimizer. The major advantages of VML include (1) easy encoding of inductive bias: prior knowledge about the problem and hypothesis class can be encoded in natural language and fed into the LLM-parameterized learner; (2) automatic model class selection: the optimizer can automatically select a model class based on data and verbalized prior knowledge, and it can update the model class during training; and (3) interpretable learner updates: the LLM-parameterized optimizer can provide explanations for why an update is performed. We empirically verify the effectiveness of VML, and hope that VML can serve as a stepping stone to stronger interpretability.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-sSOxuUjE2o">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/sSOxuUjE2o.html">Controlled Training Data Generation with Diffusion Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Teresa Yeo &middot; Andrei Atanov &middot; Harold Luc Benoit &middot; Aleksandr Alekseev &middot; Ruchira Ray &middot; Pooya Esmaeil Akhoondi &middot; Amir Zamir</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-sSOxuUjE2o"></div>

    <a href="paper_pages/sSOxuUjE2o.html">
        <img src="http://img.youtube.com/vi/PDLYk7gekYo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-sSOxuUjE2o" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-sSOxuUjE2o" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-sSOxuUjE2o">
                Abstract <i id="caret-sSOxuUjE2o" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-sSOxuUjE2o">
        <div class="abstract-display">
            <p>We present a method to control a text-to-image generative model to produce training data useful for supervised learning. Unlike previous works that employ an open-loop approach via pre-defined prompts to generate new data using either a language model or human expertise, we develop an automated closed-loop system that involves two feedback mechanisms. The first mechanism uses feedback from a given supervised model to find adversarial prompts that result in generated images that maximize the model's loss and, consequently, expose its vulnerabilities. While these adversarial prompts generate training examples curated for improving the given model, they are not curated for a specific target distribution of interest, which can be inefficient. Therefore, we introduce the second feedback mechanism that can optionally guide the generation process towards a desirable target distribution. We call the method combining these two mechanisms Guided Adversarial Prompts. The proposed closed-loop system allows us to control the training data generation for a given model and target image distribution. We evaluate on different tasks, datasets, and architectures, with different types of distribution shifts (corruptions, spurious correlations, unseen domains) and illustrate the advantages of the proposed feedback mechanisms compared to open-loop approaches.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0AOUWC4ss8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0AOUWC4ss8.html">Illustrated Landmark Graphs for Long-horizon Policy Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Christopher Watson &middot; Arjun Krishna &middot; Rajeev Alur &middot; Dinesh Jayaraman</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0AOUWC4ss8"></div>

    <a href="paper_pages/0AOUWC4ss8.html">
        <img src="video_thumbnails/0AOUWC4ss8.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0AOUWC4ss8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0AOUWC4ss8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0AOUWC4ss8">
                Abstract <i id="caret-0AOUWC4ss8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0AOUWC4ss8">
        <div class="abstract-display">
            <p>Applying learning-based approaches to long-horizon sequential decision-making tasks requires a human teacher to carefully craft reward functions or curate demonstrations to elicit desired behaviors. To simplify this, we first introduce an alternative form of task-specification, Illustrated Landmark Graph (ILG), that represents the task as a directed graph where each vertex corresponds to a region of the state space (a landmark), and each edge represents an easier to achieve sub-task. A landmark in the ILG is conveyed to the agent through a few illustrative examples grounded in the agentâs observation space. Second, we propose ILG-Learn, a human in the loop algorithm that interleaves planning over the ILG and sub-task policy learning. ILG-Learn adaptively plans through the ILG by relying on the human teacherâs feedback to estimate the success rates of learned policies. We conduct experiments on long-horizon block stacking and point maze navigation tasks, and find that our approach achieves considerably higher success rates (~ 50% improvement) compared to hierarchical reinforcement learning and imitation learning baselines. Additionally, we highlight how the flexibility of the ILG specification allows the agent to learn a sequence of sub-tasks that is better suited to its limited capabilities.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EoiuRII7MQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EoiuRII7MQ.html">Lower Ricci Curvature for Efficient Community Detection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yun Jin Park &middot; Didong Li</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EoiuRII7MQ"></div>

    <a href="paper_pages/EoiuRII7MQ.html">
        <img src="http://img.youtube.com/vi/AQab_K7ccM4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EoiuRII7MQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EoiuRII7MQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EoiuRII7MQ">
                Abstract <i id="caret-EoiuRII7MQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EoiuRII7MQ">
        <div class="abstract-display">
            <p>This study introduces the Lower Ricci Curvature (LRC), a novel, scalable, and scale-free discrete curvature designed to enhance community detection in networks. Addressing the computational challenges posed by existing curvature-based methods, LRC offers a streamlined approach with linear computational complexity, which makes it well suited for large-scale network analysis. We further develop an LRC-based preprocessing method that effectively augments popular community detection algorithms. Through applications on multiple real-world datasets, including the NCAA football league network, the DBLP collaboration network, the Amazon product co-purchasing network, and the YouTube social network, we demonstrate the efficacy of our method in significantly improving the performance of various community detection algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-s1zfBJysbI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/s1zfBJysbI.html">Enhancing Temporal Consistency in Video Editing by Reconstructing Videos with 3D Gaussian Splatting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Inkyu Shin &middot; Qihang Yu &middot; Xiaohui Shen &middot; In So Kweon &middot; Kuk-Jin Yoon &middot; Liang-Chieh Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-s1zfBJysbI"></div>

    <a href="paper_pages/s1zfBJysbI.html">
        <img src="http://img.youtube.com/vi/xy5HYOaGVbk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-s1zfBJysbI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-s1zfBJysbI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-s1zfBJysbI">
                Abstract <i id="caret-s1zfBJysbI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-s1zfBJysbI">
        <div class="abstract-display">
            <p>Recent advancements in zero-shot video diffusion models have shown promise for text-driven video editing, but challenges remain in achieving high temporal consistency. To address this, we introduce Video-3DGS, a 3D Gaussian Splatting (3DGS)-based video refiner designed to enhance temporal consistency in zero-shot video editors. Our approach utilizes a two-stage 3D Gaussian optimizing process tailored for editing dynamic monocular videos. In the first stage, Video-3DGS employs an improved version of COLMAP, referred to as MC-COLMAP, which processes original videos using a Masked and Clipped approach. For each video clip, MC-COLMAP generates the point clouds for dynamic foreground objects and complex backgrounds. These point clouds are utilized to initialize two sets of 3D Gaussians (Frg-3DGS and Bkg-3DGS) aiming to represent foreground and background views. Both foreground and background views are then merged with a 2D learnable parameter map to reconstruct full views. In the second stage, we leverage the reconstruction ability developed in the first stage to impose the temporal constraints on the video diffusion model. This approach ensures the temporal consistency in the edited videos while maintaining high fidelity to the editing text prompt. We further propose a recursive and ensembled refinement by revisiting the denoising step and guidance scale used in video diffusion process with Video-3DGS. To demonstrate the efficacy of Video-3DGS on both stages, we conduct extensive experiments across two related tasks: Video Reconstruction and Video Editing. Video-3DGS trained with 3k iterations significantly improves video reconstruction quality (+3 PSNR, +7 PSNR increase) and training efficiency (Ã1.9, Ã4.5 times faster) over NeRF-based and 3DGS-based state-of-art methods on DAVIS dataset, respectively. Moreover, it enhances video editing by ensuring temporal consistency across 58 dynamic monocular videos.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-OGifiton47">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/OGifiton47.html">Active Diffusion Subsampling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">OisÃ­n Nolan &middot; Tristan Stevens &middot; Wessel L. van Nierop &middot; Ruud Van Sloun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-OGifiton47"></div>

    <a href="paper_pages/OGifiton47.html">
        <img src="http://img.youtube.com/vi/kFTfiwRKwlw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-OGifiton47" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-OGifiton47" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-OGifiton47">
                Abstract <i id="caret-OGifiton47" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-OGifiton47">
        <div class="abstract-display">
            <p>Subsampling is commonly used to mitigate costs associated with data acquisition, such as
time or energy requirements, motivating the development of algorithms for estimating the
fully-sampled signal of interest $x$ from partially observed measurements $y$. In maximum-
entropy sampling, one selects measurement locations that are expected to have the highest
entropy, so as to minimize uncertainty about $x$. This approach relies on an accurate model
of the posterior distribution over future measurements, given the measurements observed so
far. Recently, diffusion models have been shown to produce high-quality posterior samples
of high-dimensional signals using guided diffusion. In this work, we propose Active Diffusion
Subsampling (ADS), a method for designing intelligent subsampling masks using guided dif-
fusion in which the model tracks a distribution of beliefs over the true state of $x$ throughout
the reverse diffusion process, progressively decreasing its uncertainty by actively choosing
to acquire measurements with maximum expected entropy, ultimately producing the pos-
terior distribution $p(x | y)$. ADS can be applied using pre-trained diffusion models for any
subsampling rate, and does not require task-specific retraining â just the specification of
a measurement model. Furthermore, the maximum entropy sampling policy employed by
ADS is interpretable, enhancing transparency relative to existing methods using black-box
policies. Experimentally, we show that through designing informative subsampling masks,
ADS significantly improves reconstruction quality compared to fixed sampling strategies on
the MNIST and CelebA datasets, as measured by standard image quality metrics, includ-
ing PSNR, SSIM, and LPIPS. Furthermore, on the task of Magnetic Resonance Imaging
acceleration, we find that ADS performs competitively with existing supervised methods in
reconstruction quality while using a more interpretable acquisition scheme design procedure.
Code is available at https://active-diffusion-subsampling.github.io/.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jJOVpnNrEp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jJOVpnNrEp.html">Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Minttu Alakuijala &middot; Reginald McLean &middot; Isaac Woungang &middot; Nariman Farsad &middot; Samuel Kaski &middot; Pekka Marttinen &middot; Kai Yuan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jJOVpnNrEp"></div>

    <a href="paper_pages/jJOVpnNrEp.html">
        <img src="http://img.youtube.com/vi/2oac-IKSs6k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jJOVpnNrEp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jJOVpnNrEp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jJOVpnNrEp">
                Abstract <i id="caret-jJOVpnNrEp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jJOVpnNrEp">
        <div class="abstract-display">
            <p>Natural language is often the easiest and most convenient modality for humans to specify tasks for robots. However, learning to ground language to behavior typically requires impractical amounts of diverse, language-annotated demonstrations collected on each target robot. In this work, we aim to separate the problem of what to accomplish from how to accomplish it, as the former can benefit from substantial amounts of external observation-only data, and only the latter depends on a specific robot embodiment. To this end, we propose Video-Language Critic, a reward model that can be trained on readily available cross-embodiment data using contrastive learning and a temporal ranking objective, and use it to score behavior traces from a separate actor. When trained on Open X-Embodiment data, our reward model enables 2x more sample-efficient policy training on Meta-World tasks than a sparse reward only, despite a significant domain gap. Using in-domain data but in a challenging task generalization setting on Meta-World, we further demonstrate more sample-efficient training than is possible with prior language-conditioned reward models that are either trained with binary classification, use static images, or do not leverage the temporal information present in video data.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HkmymFPODz">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HkmymFPODz.html">Deep Active Learning in the Open World</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tian Xie &middot; Jifan Zhang &middot; Haoyue Bai &middot; Robert D Nowak</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HkmymFPODz"></div>

    <a href="paper_pages/HkmymFPODz.html">
        <img src="http://img.youtube.com/vi/MrKra6ZfVKo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HkmymFPODz" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HkmymFPODz" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HkmymFPODz">
                Abstract <i id="caret-HkmymFPODz" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HkmymFPODz">
        <div class="abstract-display">
            <p>Machine learning models deployed in open-world scenarios often encounter unfamiliar conditions and perform poorly in unanticipated situations. As AI systems advance and find application in safety-critical domains, effectively handling out-of-distribution (OOD) data is crucial to building open-world learning systems. In this work, we introduce ALOE, a novel active learning algorithm for open-world environments designed to enhance model adaptation by incorporating new OOD classes via a two-stage approach. First, diversity sampling selects a representative set of examples, followed by energy-based OOD detection to prioritize likely unknown classes for annotation. This strategy accelerates class discovery and learning, even under constrained annotation budgets. Evaluations on three long-tailed image classification benchmarks demonstrate that ALOE outperforms traditional active learning baselines, effectively expanding known categories while balancing annotation cost. Our findings reveal a crucial tradeoff between enhancing known-class performance and discovering new classes, setting the stage for future advancements in open-world machine learning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-J5IRyTKZ9s">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/J5IRyTKZ9s.html">An Adversarial Perspective on Machine Unlearning for AI Safety</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jakub Åucki &middot; Boyi Wei &middot; Yangsibo Huang &middot; Peter Henderson &middot; Florian TramÃ¨r &middot; Javier Rando</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-J5IRyTKZ9s"></div>

    <a href="paper_pages/J5IRyTKZ9s.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-J5IRyTKZ9s" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-J5IRyTKZ9s" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-J5IRyTKZ9s">
                Abstract <i id="caret-J5IRyTKZ9s" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-J5IRyTKZ9s">
        <div class="abstract-display">
            <p>Large language models are finetuned to refuse questions about hazardous knowledge, but these protections can often be bypassed. Unlearning methods aim at completely removing hazardous capabilities from models and make them inaccessible to adversaries. This work challenges the fundamental differences between unlearning and traditional safety post-training from an adversarial perspective. We demonstrate that existing jailbreak methods, previously reported as ineffective against unlearning, can be successful when applied carefully. Furthermore, we develop a variety of adaptive methods that recover most supposedly unlearned capabilities. For instance, we show that finetuning on 10 unrelated examples or removing specific directions in the activation space can recover most hazardous capabilities for models edited with RMU, a state-of-the-art unlearning method. Our findings challenge the robustness of current unlearning approaches and question their advantages over safety training.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-IrBYuh9W3T">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/IrBYuh9W3T.html">What Makes ImageNet Look Unlike LAION</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ali Shirali &middot; Moritz Hardt</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-IrBYuh9W3T"></div>

    <a href="paper_pages/IrBYuh9W3T.html">
        <img src="http://img.youtube.com/vi/ioUdKJgRrJ0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-IrBYuh9W3T" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-IrBYuh9W3T" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-IrBYuh9W3T">
                Abstract <i id="caret-IrBYuh9W3T" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-IrBYuh9W3T">
        <div class="abstract-display">
            <p>ImageNet was famously created by querying several image search engines such as Flickr. What if we recreated ImageNet instead by searching the massive LAION dataset based on image captions alone? In this work, we carry out this counterfactual investigation. We find that the resulting ImageNet recreation, which we call LAIONet, looks distinctly unlike the original. Specifically, the intra-class similarity of images in the original ImageNet is dramatically higher than it is for LAIONet. Consequently, models trained on ImageNet perform significantly worse on LAIONet. We propose a rigorous explanation for the discrepancy in terms of a subtle, yet important, difference in two plausible causal data-generating processes for the respective datasets, that we support with systematic experimentation. In a nutshell, searching based on an image caption alone creates an information bottleneck that mitigates the selection bias otherwise present in image-based filtering. Our explanation formalizes a long-held intuition in the community that ImageNet images are stereotypical, unnatural, and overly simple representations of the class category. At the same time, it provides a simple and actionable takeaway for future dataset creation efforts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Okxp1W8If0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Okxp1W8If0.html">(Accelerated) Noise-adaptive Stochastic Heavy-Ball Momentum</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Anh Quang Dang &middot; Reza Babanezhad Harikandeh &middot; Sharan Vaswani</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Okxp1W8If0"></div>

    <a href="paper_pages/Okxp1W8If0.html">
        <img src="http://img.youtube.com/vi/jtRojA5aMfE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Okxp1W8If0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Okxp1W8If0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Okxp1W8If0">
                Abstract <i id="caret-Okxp1W8If0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Okxp1W8If0">
        <div class="abstract-display">
            <p>Stochastic heavy ball momentum (SHB) is commonly used to train machine learning models, and often provides empirical improvements over stochastic gradient descent. By primarily focusing on strongly-convex quadratics, we aim to better understand the theoretical advantage of SHB and subsequently improve the method. For strongly-convex quadratics, Kidambi et al. (2018) show that SHB (with a mini-batch of size $1$) cannot attain accelerated convergence, and hence has no theoretical benefit over SGD. They conjecture that the practical gain of SHB is a by-product of using larger mini-batches. We first substantiate this claim by showing that SHB can attain an accelerated rate when the mini-batch size is larger than a threshold $b^*$ that depends on the condition number $\kappa$. Specifically, we prove that with the same step-size and momentum parameters as in the deterministic setting, SHB with a sufficiently large mini-batch size results in an $O\left(\exp(-\frac{T}{\sqrt{\kappa}}) + \sigma \right)$ convergence when measuring the distance to the optimal solution in the $\ell_2$ norm, where $T$ is the number of iterations and $\sigma^2$ is the variance in the stochastic gradients. We prove a lower-bound which demonstrates that a $\kappa$ dependence in $b^*$ is necessary. To ensure convergence to the minimizer, we design a noise-adaptive multi-stage algorithm that results in an $O\left(\exp\left(-\frac{T}{\sqrt{\kappa}}\right) + \frac{\sigma}{\sqrt{T}}\right)$ rate when measuring the distance to the optimal solution in the $\ell_2$ norm. We also consider the general smooth, strongly-convex setting and propose the first noise-adaptive SHB variant that converges to the minimizer at an $O(\exp(-\frac{T}{\kappa}) + \frac{\sigma^2}{T})$ rate when measuring the distance to the optimal solution in the squared $\ell_2$ norm. We empirically demonstrate the effectiveness of the proposed algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-FecsgPCOHk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/FecsgPCOHk.html">Causal Discovery over High-Dimensional Structured Hypothesis Spaces with  Causal Graph Partitioning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ashka Shah &middot; Adela Frances DePavia &middot; Nathaniel C Hudson &middot; Ian Foster &middot; Rick Stevens</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-FecsgPCOHk"></div>

    <a href="paper_pages/FecsgPCOHk.html">
        <img src="video_thumbnails/FecsgPCOHk.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-FecsgPCOHk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-FecsgPCOHk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-FecsgPCOHk">
                Abstract <i id="caret-FecsgPCOHk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-FecsgPCOHk">
        <div class="abstract-display">
            <p>The aim in many sciences is to understand the mechanisms that underlie the observed distribution of variables, starting from a set of initial hypotheses. Causal discovery allows us to infer mechanisms as sets of cause and effect relationships in a generalized way---without necessarily tailoring to a specific domain. Causal discovery algorithms search over a structured hypothesis space, defined by the set of Directed Acyclic Graphs (DAG), to find the graph that best explains the data. For high-dimensional problems, however, this search becomes intractable and scalable algorithms for causal discovery are needed to bridge the gap. 
    In this paper, we define a novel causal graph partition that allows for divide-and-conquer causal discovery with theoretical guarantees under the Maximal Ancestral Graph (MAG) class. We leverage the idea of a superstructure---a set of learned or existing candidate hypotheses---to partition the search space. We prove under certain assumptions that learning with a causal graph partition always yields the Markov Equivalence Class of the true causal graph. We show our algorithm achieves comparable accuracy and a faster time to solution for biologically-tuned synthetic networks and networks up to ${10^4}$ variables. This makes our method applicable to gene regulatory network inference and other domains with high-dimensional structured hypothesis spaces.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8otbGorZK2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8otbGorZK2.html">Semantic-Syntactic Discrepancy in Images (SSDI): Learning Meaning and Order of Features from Natural Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chun Tao &middot; Timur Ibrayev &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8otbGorZK2"></div>

    <a href="paper_pages/8otbGorZK2.html">
        <img src="http://img.youtube.com/vi/ACANh_TPsPE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8otbGorZK2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8otbGorZK2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8otbGorZK2">
                Abstract <i id="caret-8otbGorZK2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8otbGorZK2">
        <div class="abstract-display">
            <p>Despite considerable progress in image classification tasks, classification models seem unaffected by the images that significantly deviate from those that appear natural to human eyes. Specifically, while human perception can easily identify abnormal appearances or compositions in images, classification models overlook any alterations in the arrangement of object parts as long as they are present in any order, even if unnatural. Hence, this work exposes the vulnerability of having semantic and syntactic discrepancy in images (SSDI) in the form of corruptions that remove or shuffle image patches or present images in the form of puzzles. To address this vulnerability, we propose the concept of "image grammar", comprising "image semantics" and "image syntax". Image semantics pertains to the interpretation of parts or patches within an image, whereas image syntax refers to the arrangement of these parts to form a coherent object. We present a semi-supervised two-stage method for learning the image grammar of visual elements and environments solely from natural images. While the first stage learns the semantic meaning of individual object parts, the second stage learns how their relative arrangement constitutes an entire object. The efficacy of the proposed approach is then demonstrated by achieving SSDI detection rates ranging from 70% to 90% on corruptions generated from CelebA and SUN-RGBD datasets. Code is publicly available at: https://github.com/ChunTao1999/SSDI/.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1QeI99nH9k">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1QeI99nH9k.html">Robust High-Dimensional Mean Estimation With Low Data Size, an Empirical Study</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Cullen Anderson &middot; Jeff M. Phillips</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1QeI99nH9k"></div>

    <a href="paper_pages/1QeI99nH9k.html">
        <img src="http://img.youtube.com/vi/Tp_1rFTRMBI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1QeI99nH9k" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1QeI99nH9k" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1QeI99nH9k">
                Abstract <i id="caret-1QeI99nH9k" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1QeI99nH9k">
        <div class="abstract-display">
            <p>Robust statistics aims to compute quantities to represent data where a fraction of it may be arbitrarily corrupted.   The most essential statistic is the mean, and in recent years, there has been a flurry of theoretical advancement for efficiently estimating the mean in high dimensions on corrupted data.  While several algorithms have been proposed that achieve near-optimal error, they all rely on large data size requirements as a function of dimension. In this paper, we perform an extensive experimentation over various mean estimation techniques where data size might not meet this requirement due to the high-dimensional setting.  

For data with inliers generated from a Gaussian with known covariance, we find experimentally that several robust mean estimation techniques can practically improve upon the sample mean, with the quantum entropy scaling approach from Dong \etal (NeurIPS 2019) performing consistently the best.  However, this consistent improvement is conditioned on a couple of simple modifications to how the steps to prune outliers work in the high-dimension low-data setting, and when the inliers deviate significantly from Gaussianity. In fact, with these modifications, they are typically able to achieve roughly the same error as taking the sample mean of the uncorrupted inlier data, even with very low data size. In addition to controlled experiments on synthetic data, we also explore these methods on large language models, deep pretrained image models, and non-contextual word embedding models that do not necessarily have an inherent Gaussian distribution.  Yet, in these settings, a mean point of a set of embedded objects is a desirable quantity to learn, and the data exhibits the high-dimension low-data setting studied in this paper.  We show both the challenges of achieving this goal, and that our updated robust mean estimation methods can provide significant improvement over using just the sample mean. We additionally publish a library of Python implementations of robust mean estimation algorithms, allowing practitioners and researchers to apply these techniques and to perform further experimentation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aPyJilTiIb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aPyJilTiIb.html">A Unified View of Double-Weighting for Marginal Distribution Shift</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">JosÃ© I. Segovia-MartÃ­n &middot; Santiago Mazuelas &middot; Anqi Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aPyJilTiIb"></div>

    <a href="paper_pages/aPyJilTiIb.html">
        <img src="http://img.youtube.com/vi/DzfWVgjfH5s/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aPyJilTiIb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aPyJilTiIb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aPyJilTiIb">
                Abstract <i id="caret-aPyJilTiIb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aPyJilTiIb">
        <div class="abstract-display">
            <p>Supervised classification traditionally assumes that training and testing samples are drawn from the same underlying distribution. However, practical scenarios are often affected by distribution shifts, such as covariate and label shifts. Most existing techniques for correcting distribution shifts are based on a reweighted approach that weights training samples, assigning lower relevance to the samples that are unlikely at testing. However, these methods may achieve poor performance when the weights obtained take large values at certain training samples. In addition, in multi-source cases, existing methods do not exploit complementary information among sources, and equally combine sources for all instances. In this paper, we establish a unified learning framework for distribution shift adaptation. We present a double-weighting approach to deal with distribution shifts, considering weight functions associated with both training and testing samples. For the multi-source case, the presented methods assign source-dependent weights for training and testing samples, where weights are obtained jointly using information from all sources. We also present generalization bounds for the proposed methods that show a significant increase in the effective sample size compared with existing approaches. Empirically, the proposed methods achieve enhanced classification performance in both synthetic and empirical experiments.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-H4S4ETc8c9">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/H4S4ETc8c9.html">Evaluation of Best-of-N Sampling Strategies for Language Model Alignment</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yuki Ichihara &middot; Yuu Jinnai &middot; Tetsuro Morimura &middot; Kenshi Abe &middot; Kaito Ariu &middot; Mitsuki Sakamoto &middot; Eiji Uchibe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-H4S4ETc8c9"></div>

    <a href="paper_pages/H4S4ETc8c9.html">
        <img src="http://img.youtube.com/vi/2HC6Bqvrdk4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-H4S4ETc8c9" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-H4S4ETc8c9" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-H4S4ETc8c9">
                Abstract <i id="caret-H4S4ETc8c9" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-H4S4ETc8c9">
        <div class="abstract-display">
            <p>Best-of-N (BoN) sampling with a reward model has been shown to be an effective strategy for aligning Large Language Models (LLMs) with human preferences at the time of decoding. BoN sampling is susceptible to a problem known as reward hacking. Since the reward model is an imperfect proxy for the true objective, an excessive focus on optimizing its value can lead to a compromise of its performance on the true objective. Previous work proposes Regularized BoN sampling (RBoN), a BoN sampling with regularization to the objective, and shows that it outperforms BoN sampling so that it mitigates reward hacking and empirically (Jinnai et al., 2024). However, Jinnai et al. (2024) introduce RBoN based on a heuristic and they lack the analysis of why such regularization strategy improves the performance of BoN sampling. The aim of this study is to analyze the effect of BoN sampling on regularization strategies. Using the regularization strategies corresponds to robust optimization, which maximizes the worst case over a set of possible perturbations in the proxy reward. Although the theoretical guarantees are not directly applicable to RBoN, RBoN corresponds to a practical implementation. This paper proposes an extension of the RBoN framework, called Stochastic RBoN sampling (SRBoN), which is a theoretically guaranteed approach to worst-case RBoN in proxy reward. We then perform an empirical evaluation using the AlpacaFarm and Anthropicâs hh-rlhf datasets to evaluate which factors of the regularization strategies contribute to the improvement of the true proxy reward. In addition, we also propose another simple RBoN method, the Sentence Length Regularized BoN, which has a better performance in the experiment as compared to the previous methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-O4CQ5AM5yP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/O4CQ5AM5yP.html">REX: GPU-Accelerated Sim2Real Framework with Delay and Dynamics Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bas van der Heijden &middot; Jens Kober &middot; Robert Babuska &middot; Laura Ferranti</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-O4CQ5AM5yP"></div>

    <a href="paper_pages/O4CQ5AM5yP.html">
        <img src="http://img.youtube.com/vi/7j30LUjTx_I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-O4CQ5AM5yP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-O4CQ5AM5yP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-O4CQ5AM5yP">
                Abstract <i id="caret-O4CQ5AM5yP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-O4CQ5AM5yP">
        <div class="abstract-display">
            <p>Sim2real, the transfer of control policies from simulation to the real world, is crucial for efficiently solving robotic tasks without the risks associated with real-world learning. However, discrepancies between simulated and real environments, especially due to unmodeled dynamics and latencies, significantly impact the performance of these transferred policies. In this paper, we address the challenges of sim2real transfer caused by latency and asynchronous dynamics in real-world robotic systems. Our approach involves developing a novel framework, REX (Robotic Environments with jaX), that uses a graph-based simulation model to incorporate latency effects while optimizing for parallelization on accelerator hardware. Our framework simulates the asynchronous, hierarchical nature of real-world systems, while simultaneously estimating system dynamics and delays from real-world data and implementing delay compensation strategies to minimize the sim2real gap. We validate our approach on two real-world systems, demonstrating its effectiveness in improving sim2real performance by accurately modeling both system dynamics and delays. Our results show that the proposed framework supports both accelerated simulation and real-time processing, making it valuable for robot learning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HOnL5hjaIt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HOnL5hjaIt.html">Generalized Tangent Kernel: A Unified Geometric Foundation for Natural Gradient and Standard Gradient</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Qinxun Bai &middot; Steven Rosenberg &middot; Wei Xu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HOnL5hjaIt"></div>

    <a href="paper_pages/HOnL5hjaIt.html">
        <img src="http://img.youtube.com/vi/cp7QuHKvI8E/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HOnL5hjaIt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HOnL5hjaIt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HOnL5hjaIt">
                Abstract <i id="caret-HOnL5hjaIt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HOnL5hjaIt">
        <div class="abstract-display">
            <p>Natural gradients have been widely studied from both theoretical and empirical perspectives, and it is commonly believed that natural gradients have advantages over standard (Euclidean) gradients in capturing the intrinsic geometric structure of the underlying function space and being invariant under reparameterization. However, for function optimization, a fundamental theoretical issue regarding the existence of natural gradients on the function space remains underexplored. We address this issue by providing a geometric perspective and mathematical framework for studying both natural gradient and standard gradient that is more complete than existing studies. The key tool that unifies natural gradient and standard gradient is a generalized form of the Neural Tangent Kernel (NTK), which we name the Generalized Tangent Kernel (GTK). Using a novel orthonormality property of GTK, we show that for a fixed parameterization, GTK determines a Riemannian metric on the entire function space which makes the standard gradient as ânatural" as the natural gradient in capturing the intrinsic structure of the parameterized function space. Many aspects of this approach relate to RKHS theory. For the practical side of this theory paper, we showcase that our framework motivates new solutions to the non-immersion/degenerate case of natural gradient and leads to new families of natural/standard gradient descent methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ZRXwHRXm8i">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ZRXwHRXm8i.html">CREW: Facilitating Human-AI Teaming Research</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lingyu Zhang &middot; Zhengran Ji &middot; Boyuan Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ZRXwHRXm8i"></div>

    <a href="paper_pages/ZRXwHRXm8i.html">
        <img src="http://img.youtube.com/vi/RINSo3uI0dI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ZRXwHRXm8i" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ZRXwHRXm8i" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ZRXwHRXm8i">
                Abstract <i id="caret-ZRXwHRXm8i" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ZRXwHRXm8i">
        <div class="abstract-display">
            <p>With the increasing deployment of artificial intelligence (AI) technologies, the potential of humans working with AI agents has been growing at a great speed. Human-AI teaming is an important paradigm for studying various aspects when humans and AI agents work together. The unique aspect of Human-AI teaming research is the need to jointly study humans and AI agents, demanding multidisciplinary research efforts from machine learning to human-computer interaction, robotics, cognitive science, neuroscience, psychology, social science, and complex systems. However, existing platforms for Human-AI teaming research are limited, often supporting oversimplified scenarios and a single task, or specifically focusing on either human-teaming research or multi-agent AI algorithms. We introduce \textbf{CREW}, a platform to facilitate Human-AI teaming research in real-time decision-making scenarios and engage collaborations from multiple scientific disciplines, with a strong emphasis on human involvement. It includes pre-built tasks for cognitive studies and Human-AI teaming with expandable potentials from our modular design. Following conventional cognitive neuroscience research, CREW also supports multimodal human physiological signal recording for behavior analysis. Moreover, CREW benchmarks real-time human-guided reinforcement learning agents using state-of-the-art algorithms and well-tuned baselines. With CREW, we were able to conduct 50 human subject studies within a week to verify the effectiveness of our benchmark.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Utjw2z1ale">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Utjw2z1ale.html">Identifying Spurious Correlations using Counterfactual Alignment</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joseph Paul Cohen &middot; Louis Blankemeier &middot; Akshay S Chaudhari</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Utjw2z1ale"></div>

    <a href="paper_pages/Utjw2z1ale.html">
        <img src="http://img.youtube.com/vi/Qdz3woTLCF4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Utjw2z1ale" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Utjw2z1ale" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Utjw2z1ale">
                Abstract <i id="caret-Utjw2z1ale" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Utjw2z1ale">
        <div class="abstract-display">
            <p>Models driven by spurious correlations often yield poor generalization performance. We propose the counterfactual (CF) alignment method to detect and quantify spurious correlations of black box classifiers. Our methodology is based on counterfactual images generated with respect to one classifier being input into other classifiers to see if they also induce changes in the outputs of these classifiers. The relationship between these responses can be quantified and used to identify specific instances where a spurious correlation exists. This is validated by observing intuitive trends in face-attribute and waterbird classifiers, as well as by fabricating spurious correlations and detecting their presence, both visually and quantitatively. Furthermore, utilizing the CF alignment method, we demonstrate that we can evaluate robust optimization methods (GroupDRO, JTT, and FLAC) by detecting a reduction in spurious correlations.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QezxDgd5hf">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QezxDgd5hf.html">Mind the truncation gap: challenges of learning on dynamic graphs with recurrent architectures</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">JoÃ£o Bravo &middot; Jacopo Bono &middot; Hugo Ferreira &middot; Pedro Saleiro &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QezxDgd5hf"></div>

    <a href="paper_pages/QezxDgd5hf.html">
        <img src="http://img.youtube.com/vi/IdteTB8IzP8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QezxDgd5hf" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QezxDgd5hf" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QezxDgd5hf">
                Abstract <i id="caret-QezxDgd5hf" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QezxDgd5hf">
        <div class="abstract-display">
            <p>Systems characterized by evolving interactions, prevalent in social, financial, and biological domains, are effectively modeled as continuous-time dynamic graphs (CTDGs). To manage the scale and complexity of these graph datasets, machine learning (ML) approaches have become essential. However, CTDGs pose challenges for ML because traditional static graph methods fail to account for event timings naturally. Newer approaches, such as graph recurrent neural networks (GRNNs), are inherently time-aware and offer advantages over static methods for CTDGs. Yet, GRNNs face another issue: the short truncation of backpropagation-through-time (BPTT) whose impact has never been properly examined until now. In this work, we demonstrate that this truncation can limit the learning of dependencies more than a hop away, resulting in reduced performance. Through experiments on a novel synthetic task as well as real-world datasets, we reveal that there exists a performance gap between full backpropagation-through-time (F-BPTT) and the truncated backpropagation-through-time (T-BPTT) commonly used to train GRNN models. We term this gap the "truncation gap" and argue that understanding and addressing it is essential as the importance of CTDGs grows, discussing potential future directions of research for this type of models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-7CUluLpLxV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/7CUluLpLxV.html">Explaining Explainability: Recommendations for Effective Use of Concept Activation Vectors</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Angus Nicolson &middot; Lisa Schut &middot; Alison Noble &middot; Yarin Gal</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-7CUluLpLxV"></div>

    <a href="paper_pages/7CUluLpLxV.html">
        <img src="http://img.youtube.com/vi/7LYfz5pKZdU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-7CUluLpLxV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-7CUluLpLxV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-7CUluLpLxV">
                Abstract <i id="caret-7CUluLpLxV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-7CUluLpLxV">
        <div class="abstract-display">
            <p>Concept-based explanations translate the internal representations of deep learning models into a language that humans are familiar with: concepts. One popular method for finding concepts is Concept Activation Vectors (CAVs), which are learnt using a probe dataset of concept exemplars. In this work, we investigate three properties of CAVs: (1) inconsistency across layers, (2) entanglement with other concepts, and (3) spatial dependency. Each property provides both challenges and opportunities in interpreting models. We introduce tools designed to detect the presence of these properties, provide insight into how each property can lead to misleading explanations, and provide recommendations to mitigate their impact. To demonstrate practical applications, we apply our recommendations to a melanoma classification task, showing how entanglement can lead to uninterpretable results and that the choice of negative probe set can have a substantial impact on the meaning of a CAV. Further, we show that understanding these properties can be used to our advantage. For example, we introduce spatially dependent CAVs to test if a model is translation invariant with respect to a specific concept and class. Our experiments are performed on natural images (ImageNet), skin lesions (ISIC 2019), and a new synthetic dataset, Elements. Elements is designed to capture a known ground truth relationship between concepts and classes. We release this dataset to facilitate further research in understanding and evaluating interpretability methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-BsMMc4MEGS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/BsMMc4MEGS.html">CORE-Bench: Fostering the Credibility of Published Research Through a Computational Reproducibility Agent Benchmark</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zachary S Siegel &middot; Sayash Kapoor &middot; Nitya Nadgir &middot; Benedikt Stroebl &middot; Arvind Narayanan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-BsMMc4MEGS"></div>

    <a href="paper_pages/BsMMc4MEGS.html">
        <img src="http://img.youtube.com/vi/Nrml8ta3PFc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-BsMMc4MEGS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-BsMMc4MEGS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-BsMMc4MEGS">
                Abstract <i id="caret-BsMMc4MEGS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-BsMMc4MEGS">
        <div class="abstract-display">
            <p>AI agents have the potential to aid users on a variety of consequential tasks, including conducting scientific research. To spur the development of useful agents, we need benchmarks that are challenging, but more crucially, directly correspond to real-world tasks of interest. This paper introduces such a benchmark, designed to measure the accuracy of AI agents in tackling a crucial yet surprisingly challenging aspect of scientific research: computational reproducibility. This task, fundamental to the scientific process, involves reproducing the results of a study using the provided code and data. We introduce CORE-Bench (Computational Reproducibility Agent Benchmark), a benchmark consisting of 270 tasks based on 90 scientific papers across three disciplines (computer science, social science, and medicine). Tasks in CORE-Bench consist of three difficulty levels and include both language-only and vision-language tasks. We provide an evaluation system to measure the accuracy of agents in a fast and parallelizable way, saving days of evaluation time for each run compared to a sequential implementation. We evaluated two baseline agents: the general-purpose AutoGPT and a task-specific agent called CORE-Agent. We tested both variants using two underlying language models: GPT-4o and GPT-4o-mini. The best agent achieved an accuracy of 19% on the hardest level of tasks, showing the vast scope for improvement in automating routine scientific tasks. Having agents that can reproduce existing work is a necessary step toward building agents that can conduct novel research and could verify and improve the performance of other research agents. We hope that CORE-Bench can improve the state of reproducibility and spur the development of future research agents.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-OE4P1tW8iQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/OE4P1tW8iQ.html">Noise-free Loss Gradients: A Surprisingly Effective Baseline for Coreset Selection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saumyaranjan Mohanty &middot; Chimata Anudeep &middot; Konda Reddy Mopuri</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-OE4P1tW8iQ"></div>

    <a href="paper_pages/OE4P1tW8iQ.html">
        <img src="https://drive.google.com/thumbnail?id=1h8XuoCw1BtndH2Tu8lGdmsQ3dkgK9l1q" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-OE4P1tW8iQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-OE4P1tW8iQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-OE4P1tW8iQ">
                Abstract <i id="caret-OE4P1tW8iQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-OE4P1tW8iQ">
        <div class="abstract-display">
            <p>The exponential rise in size and complexity of deep learning models and datasets have resulted
in a considerable demand for computational resources. Coreset selection is one of the
methods to alleviate this rising demand. The goal is to select a subset from a large dataset
to train a model that performs almost at par with the one trained on the large dataset
while reducing computational time and resource requirements. Existing approaches either
attempt to identify remarkable samples (e.g., Forgetting, Adversarial Deepfool, EL2N, etc.)
that stand out from the rest or solve complex optimization (e.g., submodular maximization,
OMP) problems to compose the coresets. This paper proposes a novel and intuitive approach
to efficiently select a coreset based on the similarity of loss gradients. Our method
works on the hypothesis that gradients of samples belonging to a given class will point
in similar directions during the early training phase. Samples with most neighbours that
produce similar gradient directions, in other words, that produce noise-free gradients, will
represent that class. Through extensive experimentation, we have demonstrated the effectiveness
of our approach in out-performing state-of-the-art coreset selection algorithms
on a range of benchmark datasets from CIFAR-10 to ImageNet with architectures of varied
complexity (ResNet-18, ResNet-50, VGG-16, ViT).We have also demonstrated the effectiveness
of our approach in Generative Modelling by implementing coreset selection to reduce
training time for various GAN models (DCGAN, MSGAN, SAGAN, SNGAN) for different
datasets (CIFAR-10, CIFAR-100, Tiny ImageNet) while not impacting the performance
metrics significantly. Source code is provided at URL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aWRMvXTvPf">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aWRMvXTvPf.html">Shapley Values of Structured Additive Regression Models and Application to RKHS Weightings of Functions</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gabriel DubÃ© &middot; Mario Marchand</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aWRMvXTvPf"></div>

    <a href="paper_pages/aWRMvXTvPf.html">
        <img src="http://img.youtube.com/vi/hQM7fJ_aBrQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aWRMvXTvPf" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aWRMvXTvPf" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aWRMvXTvPf">
                Abstract <i id="caret-aWRMvXTvPf" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aWRMvXTvPf">
        <div class="abstract-display">
            <p>Shapley values are widely used in machine learning to interpret model predictions. However, they have an important drawback in their computational time, which is exponential in the number of variables in the data. Recent work has yielded algorithms that can efficiently and exactly calculate the Shapley values of specific model families, such as Decision Trees and Generalized Additive Models (GAMs). Unfortunately, these model families are fairly restricted.
Consequently, we present STAR-SHAP, an algorithm for efficiently calculating the Shapley values of Structured Additive Regression (STAR) models, a generalization of GAMs which allow any number of variable interactions. While the computational cost of STAR-SHAP scales exponentially in the size of these interactions, it is independent of the total number of variables. This allows the interpretation of more complex and flexible models. As long as the variable interactions are moderately-sized, the computation of the Shapley values will be fast, even on high-dimensional datasets.
Since STAR models with more than pairwise interactions (e.g. GA2Ms) are seldom used in practice, we also present a new class of STAR models built on the RKHS Weightings of Functions paradigm. More precisely, we introduce a new RKHS Weighting instantiation, and show how to transform it and other RKHS Weightings into STAR models. We therefore introduce a new family of STAR models, as well as the means to interpret their outputs in a timely manner.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MHJlFCqXdA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MHJlFCqXdA.html">Is Value Functions Estimation with Classification Plug-and- play for Offline Reinforcement Learning?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Denis Tarasov &middot; Kirill Brilliantov &middot; Dmitrii Kharlapenko</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MHJlFCqXdA"></div>

    <a href="paper_pages/MHJlFCqXdA.html">
        <img src="http://img.youtube.com/vi/xwfQ2Oa6ycs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MHJlFCqXdA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MHJlFCqXdA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MHJlFCqXdA">
                Abstract <i id="caret-MHJlFCqXdA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MHJlFCqXdA">
        <div class="abstract-display">
            <p>In deep Reinforcement Learning (RL), value functions are typically approximated using deep neural networks and trained via mean squared error regression objectives to fit the true value functions. Recent research has proposed an alternative approach, utilizing the cross-entropy classification objective, which has demonstrated improved performance and scalability of RL algorithms. However, existing study have not extensively benchmarked the effects of this replacement across various domains, as the primary objective was to demonstrate the efficacy of the concept across a broad spectrum of tasks, without delving into in-depth analysis. Our work seeks to empirically investigate the impact of such a replacement in an offline RL setup and analyze the effects of different aspects on performance. Through large-scale experiments conducted across a diverse range of tasks using different algorithms, we aim to gain deeper insights into the implications of this approach. Our results reveal that incorporating this change can lead to superior performance over state-of-the-art solutions for some algorithms in certain tasks, while maintaining comparable performance levels in other tasks, however for other algorithms this modification might lead to the dramatic performance drop. This findings are crucial for further application of classification approach in research and practical tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-iVV7IzI55V">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/iVV7IzI55V.html">On Inherent Adversarial Robustness of Active Vision Systems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Amitangshu Mukherjee &middot; Timur Ibrayev &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-iVV7IzI55V"></div>

    <a href="paper_pages/iVV7IzI55V.html">
        <img src="http://img.youtube.com/vi/_o7cw6MI5o0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-iVV7IzI55V" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-iVV7IzI55V" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-iVV7IzI55V">
                Abstract <i id="caret-iVV7IzI55V" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-iVV7IzI55V">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) are susceptible to adversarial inputs, such as imperceptible noise and naturally occurring challenging samples. This vulnerability likely arises from their passive, one-shot processing approach. In contrast, neuroscience suggests that human vision robustly identifies salient object features by actively switching between multiple fixation points (saccades) and processing surroundings with non-uniform resolution (foveation). This information is processed via two pathways: the dorsal (where) and ventral (what) streams, which identify relevant input portions and discard irrelevant details. Building on this perspective, we outline a deep learning-based active dorsal-ventral vision system and adapt two prior methods, FALcon and GFNet, within this framework to evaluate their robustness. We conduct a comprehensive robustness analysis across three categories: adversarially crafted inputs evaluated under transfer attack scenarios, natural adversarial images, and foreground-distorted images. By learning from focused, downsampled glimpses at multiple distinct fixation points, these active methods significantly enhance the robustness of passive networks, achieving a 2-21 % increase in accuracy. This improvement is demonstrated against state-of-the-art transferable black-box attack. On ImageNet-A, a benchmark for naturally occurring hard samples, we show how distinct predictions from multiple fixation points yield performance gains of 1.5-2 times for both CNN and Transformer based networks. Lastly, we qualitatively demonstrate how an active vision system aligns more closely with human perception for structurally distorted images. This alignment leads to more stable and resilient predictions, with lesser catastrophic mispredictions. In contrast, passive methods, which rely on single-shot learning and inference, often lack the necessary structural understanding.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QlTLkH6xRC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QlTLkH6xRC.html">TOTEM: TOkenized Time Series EMbeddings for General Time Series Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sabera J Talukder &middot; Yisong Yue &middot; Georgia Gkioxari</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QlTLkH6xRC"></div>

    <a href="paper_pages/QlTLkH6xRC.html">
        <img src="http://img.youtube.com/vi/OqrCpdb6MJk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QlTLkH6xRC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QlTLkH6xRC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QlTLkH6xRC">
                Abstract <i id="caret-QlTLkH6xRC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QlTLkH6xRC">
        <div class="abstract-display">
            <p>This work studies the problem of time series analysis with generalist (or foundation) models, which are models trained across many data domains. Drawing inspiration from the widespread success of large language models, we consider the simple strategy of discretely tokenizing time series data drawn from a myriad of datasets via self-supervision, then using the fixed tokenization to solve a variety of tasks across many data domains. Canonically, time series models are either trained on a single dataset or built in a task-specific manner (e.g., a forecasting-only model), where many use patches of time as inputs to the model. As such, performant generalist, discrete representation time series models explored across many tasks are of value. Our method, TOkenized Time Series EMbeddings (TOTEM), produces such generalist time series models with minimal or no fine-tuning while exhibiting strong zero-shot performance. We evaluate TOTEM extensively over nearly 500 experiments on three commonly-studied time series tasks with real-world data: imputation (17 baselines, 12 datasets), anomaly detection (19 baselines, 25 datasets), and forecasting (14 baselines, 12 datasets). We conclude that TOTEM matches or outperforms existing state-of-the-art models in both the canonical specialist setting (i.e., training one model on one domain) as well as the generalist setting (i.e., training a single model on many domains), which demonstrates the efficacy of tokenization for general time series analysis. The open-source implementation is available here: https://github.com/SaberaTalukder/TOTEM; a video summary is available here: https://www.youtube.com/watch?v=OqrCpdb6MJk.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lIy0TEUou7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lIy0TEUou7.html">Modular Quantization-Aware Training for 6D Object Pose Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saqib Javed &middot; Chengkun Li &middot; Andrew Lawrence Price &middot; Yinlin Hu &middot; Mathieu Salzmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lIy0TEUou7"></div>

    <a href="paper_pages/lIy0TEUou7.html">
        <img src="http://img.youtube.com/vi/EBNr0qNem8U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lIy0TEUou7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lIy0TEUou7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lIy0TEUou7">
                Abstract <i id="caret-lIy0TEUou7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lIy0TEUou7">
        <div class="abstract-display">
            <p>Edge applications, such as collaborative robotics and spacecraft rendezvous, demand efficient 6D object pose estimation on resource-constrained embedded platforms. Existing 6D object pose estimation networks are often too large for such deployments, necessitating compression while maintaining reliable performance. To address this challenge, we introduce Modular Quantization-Aware Training (MQAT), an adaptive and mixed-precision quantization-aware training strategy that exploits the modular structure of modern 6D object pose estimation architectures. MQAT guides a systematic gradated modular quantization sequence and determines module-specific bit precisions, leading to quantized models that outperform those produced by state-of-the-art uniform and mixed-precision quantization techniques. Our experiments showcase the generality of MQAT across datasets, architectures, and quantization algorithms. Additionally, we observe that MQAT quantized models can achieve an accuracy boost (>7% ADI-0.1d) over the baseline full-precision network while reducing model size by a factor of 4x or more.
Project Page: https://saqibjaved1.github.io/MQAT_</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-D1PPuk8ZBI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/D1PPuk8ZBI.html">When Should Reinforcement Learning Use Causal Reasoning?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Oliver Schulte &middot; Pascal Poupart</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-D1PPuk8ZBI"></div>

    <a href="paper_pages/D1PPuk8ZBI.html">
        <img src="https://drive.google.com/thumbnail?id=1Jbfh5lf7SLREttEAXj_GuhCBd2btm49j" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-D1PPuk8ZBI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-D1PPuk8ZBI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-D1PPuk8ZBI">
                Abstract <i id="caret-D1PPuk8ZBI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-D1PPuk8ZBI">
        <div class="abstract-display">
            <p>Reinforcement learning (RL) and causal reasoning naturally complement each other. The goal of causal reasoning is to predict the effects of interventions in an environment, while the goal of reinforcement learning is to select interventions that maximize the rewards the agent receives from the environment. Reinforcement learning includes the two most powerful sources of information for estimating causal relationships: temporal ordering and the ability to act on an environment. This paper provides a theoretical study examining which reinforcement learning settings  we can expect to benefit from causal reasoning, and how. According to our analysis, the key factor is {\em whether the behavioral policy---which generates the data---can be executed by the learning agent}, meaning that the observation signal available to the learning agent comprises all observations used by the behavioral policy. Common RL settings with behavioral policies that are executable by the learning agent include on-policy learning 
 and online exploration, where the learning agent uses a behavioral policy to explore the environment. 
 Common RL settings with behavioral policies that are not executable by the learning agent include offline learning with a partially observable state space and asymmetric imitation learning where the demonstrator has access to more observations than the imitator. Using the theory of causal graphs, we show formally that when the behavioral policy is executable by the learning agent, conditional probabilities are causal, and can therefore be used to estimate expected rewards as done in traditional RL. However, when the behavioral policy is not executable by the learning agent, conditional probabilities may be confounded and provide misleading estimates of expected rewards. For confounded settings, we describe previous and new methods for leveraging causal reasoning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-q7YXEbFOAt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/q7YXEbFOAt.html">$\clubsuit$ CLOVER $\clubsuit$: Probabilistic Forecasting with Coherent Learning Objective Reparameterization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kin G. Olivares &middot; Geoffrey NÃ©giar &middot; Ruijun Ma &middot; Oinam Nganba Meetei &middot; Mengfei Cao &middot; Michael W. Mahoney</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-q7YXEbFOAt"></div>

    <a href="paper_pages/q7YXEbFOAt.html">
        <img src="https://drive.google.com/thumbnail?id=1-xkmuYSB7YQDXOEaBKeFa-pAa1Gq1-i8" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-q7YXEbFOAt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-q7YXEbFOAt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-q7YXEbFOAt">
                Abstract <i id="caret-q7YXEbFOAt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-q7YXEbFOAt">
        <div class="abstract-display">
            <p>Obtaining accurate probabilistic forecasts is an operational challenge in many applications, such as energy management, climate forecasting, supply chain planning, and resource allocation.
Many of these applications present a natural hierarchical structure over the forecasted quantities; and forecasting systems that adhere to this hierarchical structure are said to be coherent. 
Furthermore, operational planning benefits from the accuracy at all levels of the aggregation hierarchy. However, building accurate and coherent forecasting systems is challenging: classic multivariate time series tools and neural network methods are still being adapted for this purpose. In this paper, we augment an MQForecaster neural network architecture with a modified multivariate Gaussian factor model that achieves coherence by construction. The factor model samples can be differentiated with respect to the model parameters, allowing optimization on arbitrary differentiable learning objectives that align with the forecasting system's goals, including quantile loss and the scaled Continuous Ranked Probability Score (CRPS). We call our method the Coherent Learning Objective Reparametrization Neural Network (CLOVER). In comparison to state-of-the-art coherent forecasting methods, 
CLOVER achieves significant improvements in scaled CRPS forecast accuracy, with average gains of 15%, as measured on six publicly-available datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tYxRyNT0TC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tYxRyNT0TC.html">Perception Stitching: Zero-Shot Perception Encoder Transfer for Visuomotor Robot Policies</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pingcheng Jian &middot; Easop Lee &middot; Zachary I. Bell &middot; Michael M. Zavlanos &middot; Boyuan Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tYxRyNT0TC"></div>

    <a href="paper_pages/tYxRyNT0TC.html">
        <img src="http://img.youtube.com/vi/H6SD9Tcvhrg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tYxRyNT0TC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tYxRyNT0TC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tYxRyNT0TC">
                Abstract <i id="caret-tYxRyNT0TC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tYxRyNT0TC">
        <div class="abstract-display">
            <p>Vision-based imitation learning has shown promising capabilities of endowing robots with various motion skills given visual observation. However, current visuomotor policies fail to adapt to drastic changes in their visual observations. We present Perception Stitching that enables strong zero-shot adaptation to large visual changes by directly stitching novel combinations of visual encoders. Our key idea is to enforce modularity of visual encoders by aligning the latent visual features among different visuomotor policies. Our method disentangles the perceptual knowledge with the downstream motion skills and allows the reuse of the visual encoders by directly stitching them to a policy network trained with partially different visual conditions. We evaluate our method in various simulated and real-world manipulation tasks. While baseline methods failed at all attempts, our method could achieve zero-shot success in real-world visuomotor tasks. Our quantitative and qualitative analysis of the learned features of the policy network provides more insights into the high performance of our proposed method.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-V2SD2uVKEE">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/V2SD2uVKEE.html">Zero-shot CLIP Class Forgetting via Text-image Space Adaptation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexey Kravets &middot; Vinay P. Namboodiri</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-V2SD2uVKEE"></div>

    <a href="paper_pages/V2SD2uVKEE.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-V2SD2uVKEE" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-V2SD2uVKEE" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-V2SD2uVKEE">
                Abstract <i id="caret-V2SD2uVKEE" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-V2SD2uVKEE">
        <div class="abstract-display">
            <p>Efficient class forgetting has attracted significant interest due to the high computational cost of retraining models from scratch whenever classes need to be forgotten. This need arises from data privacy regulations, the necessity to remove outdated information, and the possibility to enhance model robustness and security. 
In this paper we address class forgetting in vision-language CLIP model. Modern class forgetting methods for CLIP have demonstrated that zero-shot forgetting is achievable by generating synthetic data and fine-tuning both visual and textual encoders with a regularization loss. Our approach shows that class forgetting in CLIP can be accomplished in a zero-shot manner without any visual data by adapting the shared vision-text space of CLIP, thereby making the class forgetting process more efficient. Our method delivers superior results, demonstrating strong performance and complete class removal, regardless of the visual encoder used in CLIP. Furthermore, we explore what exactly is being targeted by the class forgetting algorithm discovering some interesting properties of CLIP features.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4c9UzDhg49">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4c9UzDhg49.html">On the theoretical limit of gradient descent for Simple Recurrent Neural Networks with finite precision</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Volodimir Mitarchuk &middot; RÃ©mi Emonet &middot; Remi Eyraud &middot; Amaury Habrard</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4c9UzDhg49"></div>

    <a href="paper_pages/4c9UzDhg49.html">
        <img src="http://img.youtube.com/vi/ap6LOok_Vtk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4c9UzDhg49" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4c9UzDhg49" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4c9UzDhg49">
                Abstract <i id="caret-4c9UzDhg49" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4c9UzDhg49">
        <div class="abstract-display">
            <p>Despite their great practical successes, the understanding of neural network behavior is still
a topical research issue. In particular, the class of functions learnable in the context of a
finite precision configuration is an open question. In this paper, we propose to study the
limits of gradient descent when such a configuration is set for the class of Simple Recurrent
Networks (SRN). We exhibit conditions under which the gradient descend will provably fail.
We also design a class of SRN based on Deterministic finite State Automata (DFA) that
fulfills the failure requirements. The definition of this class is constructive: we propose an
algorithm that, from any DFA, constructs a SRN that computes exactly the same function,
a result of interest by its own.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-SP8DLl6jgb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/SP8DLl6jgb.html">Feature Distillation Improves Zero-Shot Transfer from Synthetic Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Niclas Popp &middot; Jan Hendrik Metzen &middot; Matthias Hein</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-SP8DLl6jgb"></div>

    <a href="paper_pages/SP8DLl6jgb.html">
        <img src="http://img.youtube.com/vi/KbdacNWGiAM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-SP8DLl6jgb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-SP8DLl6jgb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-SP8DLl6jgb">
                Abstract <i id="caret-SP8DLl6jgb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-SP8DLl6jgb">
        <div class="abstract-display">
            <p>Vision-language foundation models such as CLIP have showcased impressive zero-shot capabilities. However, their applicability in resource-constrained environments is limited due to their size and the resulting latency. Knowledge distillation allows to mitigate these challenges by distilling small image encoders that can replace the large CLIP image encoder. In a zero-shot setting, where only the class names are known, no real domain images can be used for this process. Instead, we investigate the use of synthetic images for this purpose. Unlike existing works that focus on improving the quality of synthetic images to bridge the performance gap compared to training on natural images, we find the choice of loss to be a crucial factor. Specifically, minimizing only the distance between the student and teacher image features, without incorporating image captions in the loss function, increases the robustness to spurious features and data corruptions. As a result, this feature distillation approach greatly improves the transfer performance from synthetic to real images. Leveraging these insights, we are able to train domain-specific students that achieve zero-shot performance comparable to a ViT-B/32 teacher on six fine-grained classification datasets while using up to 92% fewer parameters.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QdGtwjDgub">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QdGtwjDgub.html">Contaminated Online Convex Optimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tomoya Kamijima &middot; Shinji Ito</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QdGtwjDgub"></div>

    <a href="paper_pages/QdGtwjDgub.html">
        <img src="https://drive.google.com/thumbnail?id=1EwrCZxiGUj_iw5_i787d88x3Nqy-Kcij" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QdGtwjDgub" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QdGtwjDgub" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QdGtwjDgub">
                Abstract <i id="caret-QdGtwjDgub" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QdGtwjDgub">
        <div class="abstract-display">
            <p>In online convex optimization, some efficient algorithms have been designed for each of the individual classes of objective functions, e.g., convex, strongly convex, and exp-concave. However, existing regret analyses, including those of universal algorithms, are limited to cases in which the objective functions in all rounds belong to the same class and cannot be applied to cases in which the property of objective functions may change in each time step. This paper introduces a novel approach to address such cases, proposing a new regime we term as \textit{contaminated} online convex optimization. For the contaminated case, we demonstrate that the regret is lower bounded by $\Omega(\log T + \sqrt{k})$. Here, $k$ signifies the level of contamination in the objective functions. We also demonstrate that the regret is bounded by $O(\log T+\sqrt{k\log T})$ when universal algorithms are used. When our proposed algorithms with additional information are employed, the regret is bounded by $O(\log T+\sqrt{k})$, which matches the lower bound. These are intermediate bounds between a convex case and a strongly convex or exp-concave case.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-t9c3pfrR1X">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/t9c3pfrR1X.html">OmniPred: Language Models as Universal Regressors</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xingyou Song &middot; Oscar Li &middot; Chansoo Lee &middot; Bangding Yang &middot; Daiyi Peng &middot; Sagi Perel &middot; Yutian Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-t9c3pfrR1X"></div>

    <a href="paper_pages/t9c3pfrR1X.html">
        <img src="http://img.youtube.com/vi/fv-cK9LgQmk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-t9c3pfrR1X" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-t9c3pfrR1X" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-t9c3pfrR1X">
                Abstract <i id="caret-t9c3pfrR1X" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-t9c3pfrR1X">
        <div class="abstract-display">
            <p>Regression is a powerful tool to accurately predict the outcome metric of a system given a set of parameters, but has traditionally been restricted to methods which are only applicable to a specific task. In this paper, we propose OmniPred, a framework for training language models as universal end-to-end regressors over (x,y) data from arbitrary formats. Using data sourced from Google Vizier, one of the largest proprietary blackbox optimization databases in the world, our extensive experiments demonstrate that language models are capable of very precise numerical regression using only textual representations of mathematical parameters and values, and if given the opportunity to train at scale over multiple tasks, can significantly outperform traditional regression models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XxbQAsxrRC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XxbQAsxrRC.html">Maximally Expressive GNNs for Outerplanar Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Franka Bause &middot; Fabian Jogl &middot; Patrick Indri &middot; Tamara Drucks &middot; David Penz &middot; Nils Morten Kriege &middot; Thomas GÃ¤rtner &middot; Pascal Welke &middot; Maximilian Thiessen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XxbQAsxrRC"></div>

    <a href="paper_pages/XxbQAsxrRC.html">
        <img src="http://img.youtube.com/vi/AW6Cy6pcc1Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XxbQAsxrRC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XxbQAsxrRC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XxbQAsxrRC">
                Abstract <i id="caret-XxbQAsxrRC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XxbQAsxrRC">
        <div class="abstract-display">
            <p>We propose a linear time graph transformation that enables the Weisfeiler-Leman (WL) algorithm and message passing graph neural networks (MPNNs) to be maximally expressive on outerplanar graphs. Our approach is motivated by the fact that most pharmaceutical molecules correspond to outerplanar graphs. Existing research predominantly enhances the expressivity of graph neural networks without specific graph families in mind. This often leads to methods that are impractical due to their computational complexity. In contrast, the restriction to outerplanar graphs enables us to encode the Hamiltonian cycle of each biconnected component in linear time. As the main contribution of the paper we prove that our method achieves maximum expressivity on outerplanar graphs. Experiments confirm that our graph transformation improves the predictive performance of MPNNs on molecular benchmark datasets at negligible computational overhead.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lh6vOAHuvo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lh6vOAHuvo.html">AGaLiTe: Approximate Gated Linear Transformers for Online Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Subhojeet Pramanik &middot; Esraa Elelimy &middot; Marlos C. Machado &middot; Adam White</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lh6vOAHuvo"></div>

    <a href="paper_pages/lh6vOAHuvo.html">
        <img src="http://img.youtube.com/vi/-bTe48JIUds/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lh6vOAHuvo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lh6vOAHuvo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lh6vOAHuvo">
                Abstract <i id="caret-lh6vOAHuvo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lh6vOAHuvo">
        <div class="abstract-display">
            <p>In this paper we investigate transformer architectures designed for partially observable online reinforcement learning. The self-attention mechanism in the transformer architecture is capable of capturing long-range dependencies and it is the main reason behind its effectiveness in processing sequential data. Nevertheless, despite their success, transformers have two significant drawbacks that still limit their applicability in online reinforcement learning: (1) in order to remember all past information, the self-attention mechanism requires access to the whole history to be provided as context. (2) The inference cost in transformers is expensive. In this paper, we introduce recurrent alternatives to the transformer self-attention mechanism that offer context-independent inference cost, leverage long-range dependencies effectively, and performs well in online reinforcement learning task. We quantify the impact of the different components of our architecture in a diagnostic environment and assess performance gains in 2D and 3D pixel-based partially-observable environments (e.g. T-Maze, Mystery Path, Craftax, and Memory Maze). Compared with a state-of-the-art architecture, GTrXL, inference in our approach is at least 40% cheaper while reducing memory use more than 50%. Our approach either performs similarly or better than GTrXL, improving more than 37% upon GTrXL performance in harder tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-M3SkSMfWcP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/M3SkSMfWcP.html">Adaptive Multi-step Refinement Network for Robust Point Cloud Registration</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zhi Chen &middot; Yufan Ren &middot; Tong Zhang &middot; Zheng Dang &middot; Wenbing Tao &middot; Sabine Susstrunk &middot; Mathieu Salzmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-M3SkSMfWcP"></div>

    <a href="paper_pages/M3SkSMfWcP.html">
        <img src="http://img.youtube.com/vi/74q3y2GZAwg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-M3SkSMfWcP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-M3SkSMfWcP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-M3SkSMfWcP">
                Abstract <i id="caret-M3SkSMfWcP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-M3SkSMfWcP">
        <div class="abstract-display">
            <p>Point Cloud Registration (PCR) estimates the relative rigid transformation between two point clouds of the same scene. Despite significant progress with learning-based approaches, existing methods still face challenges when the overlapping region between the two point clouds is small. In this paper, we propose an adaptive multi-step refinement network that refines the registration quality at each step by leveraging the information from the preceding step. To achieve this, we introduce a training procedure and a refinement network. Firstly, to adapt the network to the current step, we utilize a generalized one-way attention mechanism, which prioritizes the last step's estimated overlapping region, and we condition the network on step indices. Secondly, instead of training the network to map either random transformations or a fixed pre-trained model's estimations to the ground truth, we train it on transformations with varying registration qualities, ranging from accurate to inaccurate, thereby enhancing the network's adaptiveness and robustness. Despite its conceptual simplicity, our method achieves state-of-the-art performance on both the 3DMatch/3DLoMatch and KITTI benchmarks. Notably, on 3DLoMatch, our method reaches 80.4% recall rate, with an absolute improvement of 1.2%.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VmfWywWuYQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VmfWywWuYQ.html">Interactive Task Planning with Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Boyi Li &middot; Philipp Wu &middot; Pieter Abbeel &middot; Jitendra Malik</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VmfWywWuYQ"></div>

    <a href="paper_pages/VmfWywWuYQ.html">
        <img src="http://img.youtube.com/vi/TrKLuyv26_g/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VmfWywWuYQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VmfWywWuYQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VmfWywWuYQ">
                Abstract <i id="caret-VmfWywWuYQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VmfWywWuYQ">
        <div class="abstract-display">
            <p>An interactive robot framework accomplishes long-horizon task planning and can easily generalize to new goals or distinct tasks, even during execution. However, most traditional methods require predefined module design, which makes it hard to generalize to different goals. Recent large language model based approaches can allow for more open-ended planning but often require heavy prompt engineering or domain specific pretrained models. To tackle this, we propose a simple framework that achieves interactive task planning with language models by incorporating both high-level planning and low-level skill execution through function calling, leveraging pretrained vision models to ground the scene in language. We verify the robustness of our system on the real world task of making milk tea drinks. Our system is able to generate novel high-level instructions for unseen objectives and successfully accomplishes user tasks. Furthermore, when the user sends a new request, our system is able to replan accordingly with precision based on the new request, task guidelines and previously executed steps. Our approach is easy to adapt to different tasks by merely substituting the task guidelines, without the need for additional complex prompt engineering.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0uwe0z2Hqm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0uwe0z2Hqm.html">Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ahmad Naser Eddin &middot; Jacopo Bono &middot; David Oliveira Aparicio &middot; Hugo Ferreira &middot; Pedro Manuel Pinto Ribeiro &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0uwe0z2Hqm"></div>

    <a href="paper_pages/0uwe0z2Hqm.html">
        <img src="http://img.youtube.com/vi/LU0324z6mHo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0uwe0z2Hqm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0uwe0z2Hqm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0uwe0z2Hqm">
                Abstract <i id="caret-0uwe0z2Hqm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0uwe0z2Hqm">
        <div class="abstract-display">
            <p>Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems. Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning. Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications. This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements. We benchmark DGS against state-of-the-art (SOTA) feature engineering and graph neural network methods using five diverse datasets. The results indicate that DGS achieves competitive performance while inference speed improves between 4x and 12x compared to other deep learning approaches on our benchmark datasets. Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-15tjpSHI15">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/15tjpSHI15.html">Teacher-Guided Graph Contrastive Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jay Nandy &middot; Arnab Kumar Mondal &middot; Manohar Kaul &middot; Prathosh AP</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-15tjpSHI15"></div>

    <a href="paper_pages/15tjpSHI15.html">
        <img src="http://img.youtube.com/vi/WAG3W63m8g8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-15tjpSHI15" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-15tjpSHI15" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-15tjpSHI15">
                Abstract <i id="caret-15tjpSHI15" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-15tjpSHI15">
        <div class="abstract-display">
            <p>State-of-the-art self-supervised representation learning methods for Graphs are typically based on contrastive learning (CL) principles. 
These CL objective functions can be posed as a supervised discriminative task using *'hard'* labels that consider any minor augmented pairs of graphs as 'equally positive'. However, such a notion of 'equal' pairs is incorrect for graphs as even a smaller 'discrete' perturbation may lead to large semantic changes that should be carefully encapsulated within the learned representations. This paper proposes a novel CL framework for GNNs, called *Teacher-guided Graph Contrastive Learning (TGCL)*, that incorporates 'soft' pseudo-labels to facilitate a more regularized discrimination. In particular, we propose a teacher-student framework where the student learns the representation by distilling the teacher's perception. Our TGCL framework can be adapted to existing CL methods to enhance their performance. Our empirical findings validate these claims on both inductive and transductive settings across diverse downstream tasks, including molecular graphs and social networks. Our experiments on benchmark datasets demonstrate that our framework consistently improves the average AUROC scores for molecules' property prediction and social network link prediction. Our code is available at: https://github.com/jayjaynandy/TGCL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fJEsas1z8J">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fJEsas1z8J.html">MoCaE: Mixture of Calibrated Experts Significantly Improves Object Detection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kemal Oksuz &middot; Selim Kuzucu &middot; Tom Joy &middot; Puneet K. Dokania</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fJEsas1z8J"></div>

    <a href="paper_pages/fJEsas1z8J.html">
        <img src="http://img.youtube.com/vi/PzyXl5VBrqE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fJEsas1z8J" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fJEsas1z8J" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fJEsas1z8J">
                Abstract <i id="caret-fJEsas1z8J" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fJEsas1z8J">
        <div class="abstract-display">
            <p>Combining the strengths of many existing predictors to obtain a Mixture of Experts which is superior to its individual components is an effective way to improve the performance without having to develop new architectures or train a model from scratch. However, surprisingly, we find that naively combining off-the-shelf object detectors in a similar way to Deep Ensembles, can often lead to degraded performance. We identify that the primary cause of this issue is that the predictions of the experts do not match their performance, a term referred to as miscalibration. Consequently, the most confident detector dominates the final predictions, preventing the mixture from leveraging all the predictions from the experts appropriately. To address this, when constructing the Mixture of Experts for object detection, we propose to combine their predictions in a manner which reflects the individual performance of the experts; an objective we achieve by first calibrating the predictions before filtering and refining them. We term this approach the Mixture of Calibrated Experts (MoCaE) and demonstrate its effectiveness through extensive experiments on 5 different detection tasks, showing that it: (i) improves object detectors on COCO and instance segmentation methods on LVIS by up to $\sim 2.5$ AP; (ii) reaches state-of-the-art on COCO test-dev with $65.1$ AP and on DOTA with $82.62$ $\mathrm{AP_{50}}$; (iii) outperforms single models consistently on recent detection tasks such as Open Vocabulary Object Detection. Code is available at: https://github.com/fiveai/MoCaE</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6j5M75iK3a">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6j5M75iK3a.html">Continual Learning in Open-vocabulary Classification with Complementary Memory Systems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zhen Zhu &middot; Weijie Lyu &middot; Yao Xiao &middot; Derek Hoiem</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6j5M75iK3a"></div>

    <a href="paper_pages/6j5M75iK3a.html">
        <img src="http://img.youtube.com/vi/RkmeJupwNkY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6j5M75iK3a" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6j5M75iK3a" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6j5M75iK3a">
                Abstract <i id="caret-6j5M75iK3a" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6j5M75iK3a">
        <div class="abstract-display">
            <p>We introduce a method for flexible and efficient continual learning in open-vocabulary image classification, drawing inspiration from the complementary learning systems observed in human cognition. Specifically, we propose to combine predictions from a CLIP zero-shot model and the exemplar-based model, using the zero-shot estimated probability that a sample's class is within the exemplar classes. We also propose a ``tree probe'' method, an adaption of lazy learning principles, which enables fast learning from new examples with competitive accuracy to batch-trained linear models. We test in data incremental, class incremental, and task incremental settings, as well as ability to perform flexible inference on varying subsets of zero-shot and learned categories. Our proposed method achieves a good balance of learning speed, target task effectiveness, and zero-shot effectiveness. Code is available at https://github.com/jessemelpolio/TreeProbe.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YcnjgKbZQS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YcnjgKbZQS.html">Unlearning Sensitive Information in Multimodal LLMs: Benchmark and Attack-Defense Evaluation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vaidehi Patil &middot; Yi-Lin Sung &middot; Peter Hase &middot; Jie Peng &middot; Tianlong Chen &middot; Mohit Bansal</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YcnjgKbZQS"></div>

    <a href="paper_pages/YcnjgKbZQS.html">
        <img src="https://drive.google.com/thumbnail?id=13SWGsoj_rGGLawFD9zYzQUBUfuGIvTc3" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YcnjgKbZQS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YcnjgKbZQS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YcnjgKbZQS">
                Abstract <i id="caret-YcnjgKbZQS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YcnjgKbZQS">
        <div class="abstract-display">
            <p>Large Language Models (LLMs) trained on massive datasets may inadvertently acquire sensitive information such as personal details and potentially harmful content. This risk is further heightened in multimodal LLMs (aka MLLMs) as they integrate information from multiple modalities (image and text). Adversaries can exploit this stored knowledge by crafting inputs across modalities to extract sensitive details. Evaluating how effectively MLLMs can forget such information (targeted unlearning) necessitates the creation of high-quality, well-annotated image-text pairs. While significant research has addressed the creation of datasets for unlearning within LLMs, it has primarily concentrated on text modality. Creation of analogous datasets for multimodal data and models remain an understudied area. To address this gap, we first introduce a multimodal unlearning benchmark, UnLOK-VQA (Unlearning Outside Knowledge VQA), as well as an âattack and-defenseâ framework to evaluate methods for deleting specific multimodal knowledge from MLLMs. Our dataset generation process involves an automated pipeline to create samples of varied proximity levels to the target data point for evaluation of generalization and specificity, followed by manual filtering to retain only the high-quality data points. We use this process to extend a visual question-answering dataset for evaluating multimodal information deletion. Next, we present a comprehensive unlearning evaluation involving an attack-and-defense framework consisting of four white box and three blackbox attacks against six unlearning defense objectives. We also design a whitebox attack based on the interpretability of hidden states in LLMs motivated by past work. Our experimental results demonstrate that multimodal extraction attacks (with an attack success rate of 45.5%) are more successful than either image-only (32%) or text-only attacks (39%). The best overall defense mechanism, which removes answer information from internal model hidden states, reduces the success rate of multimodal attack to 15.7%. Furthermore, our findings suggest that larger models exhibit greater resilience to attacks, implying that model scaling could be a valuable strategy for enhancing robustness and developing safer models. UnLOK-VQA thus facilitates a comprehensive evaluation of unlearning in MLLMs and serves as a challenging benchmark for future research in unlearning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mDGvrH7lju">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mDGvrH7lju.html">CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in Variational AutoEncoder</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hee-Jun Jung &middot; Jaehyoung Jeong &middot; Kangil Kim</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mDGvrH7lju"></div>

    <a href="paper_pages/mDGvrH7lju.html">
        <img src="http://img.youtube.com/vi/R03AoD3SRZ8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mDGvrH7lju" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mDGvrH7lju" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mDGvrH7lju">
                Abstract <i id="caret-mDGvrH7lju" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mDGvrH7lju">
        <div class="abstract-display">
            <p>Symmetries of input and latent vectors have provided valuable insights for disentanglement learning in VAEs. However, only a few works were proposed as an unsupervised method, and even these works require known factor information in training data. We propose a
novel method, Composite Factor-Aligned Symmetry Learning (CFASL), which is integrated into VAEs for learning symmetry-based disentanglement in unsupervised learning without any knowledge of the dataset factor information. CFASL incorporates three novel features for learning symmetry-based disentanglement: 1) Injecting inductive bias to align latent vector dimensions to factor-aligned symmetries within an explicit learnable symmetry code-book 2) Learning a composite symmetry to express unknown factors change between two random samples by learning factor-aligned symmetries within the codebook 3) Inducing group equivariant encoder and decoder in training VAEs with the two conditions. In addition, we propose an extended evaluation metric for multi-factor changes in comparison to disentanglement evaluation in VAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a significant improvement of disentanglement in single-factor change, and multi-factor change conditions compared to state-of-the-art methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-IJlbuSrXmk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/IJlbuSrXmk.html">Audio-Visual Dataset Distillation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saksham Singh Kushwaha &middot; Siva Sai Nagender Vasireddy &middot; Kai Wang &middot; Yapeng Tian</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-IJlbuSrXmk"></div>

    <a href="paper_pages/IJlbuSrXmk.html">
        <img src="http://img.youtube.com/vi/SfXLu8D_K6o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-IJlbuSrXmk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-IJlbuSrXmk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-IJlbuSrXmk">
                Abstract <i id="caret-IJlbuSrXmk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-IJlbuSrXmk">
        <div class="abstract-display">
            <p>In this article, we introduce \textit{audio-visual dataset distillation}, a task to construct a smaller yet representative synthetic audio-visual dataset that maintains the cross-modal semantic association between audio and visual modalities. Dataset distillation techniques have primarily focused on image classification. However, with the growing capabilities of audio-visual models and the vast datasets required for their training, it is necessary to explore distillation methods beyond the visual modality. Our approach builds upon the foundation of Distribution Matching (DM), extending it to handle the unique challenges of audio-visual data. A key challenge is to jointly learn synthetic data that distills both the modality-wise information and natural alignment from real audio-visual data. We introduce a vanilla audio-visual distribution matching framework that separately trains visual-only and audio-only DM components, enabling us to investigate the effectiveness of audio-visual integration and various multimodal fusion methods. To address the limitations of unimodal distillation, we propose two novel matching losses: implicit cross-matching and cross-modal gap matching. These losses work in conjunction with the vanilla unimodal distribution matching loss to enforce cross-modal alignment and enhance the audio-visual dataset distillation process. Extensive audio-visual classification and retrieval experiments on four audio-visual datasets, AVE, MUSIC-21, VGGSound, and VGGSound-10K, demonstrate the effectiveness of our proposed matching approaches and validate the benefits of audio-visual integration with condensed data. This work establishes a new frontier in audio-visual dataset distillation, paving the way for further advancements in this exciting field. \textit{Our source code and pre-trained models will be released}.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-hbtG6s6e7r">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/hbtG6s6e7r.html">Growing Tiny Networks: Spotting Expressivity Bottlenecks and Fixing Them Optimally</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Manon Verbockhaven &middot; ThÃ©o Rudkiewicz &middot; Sylvain Chevallier &middot; Guillaume Charpiat</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-hbtG6s6e7r"></div>

    <a href="paper_pages/hbtG6s6e7r.html">
        <img src="http://img.youtube.com/vi/VJ8Ik5OsKOE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-hbtG6s6e7r" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-hbtG6s6e7r" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-hbtG6s6e7r">
                Abstract <i id="caret-hbtG6s6e7r" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-hbtG6s6e7r">
        <div class="abstract-display">
            <p>Machine learning tasks are generally formulated as optimization problems, where one searches for an optimal function within a certain functional space. In practice, parameterized functional spaces are considered, in order to be able to perform gradient descent. Typically, a neural network architecture is chosen and fixed, and its parameters (connection weights) are optimized, yielding an architecture-dependent result. This way of proceeding however forces the evolution of the function during training to lie within the realm of what is expressible with the chosen architecture, and prevents any optimization across architectures. Costly architectural hyper-parameter optimization is often performed to compensate for this. Instead, we propose to adapt the architecture on the fly during training. We show that the information about desirable architectural changes, due to expressivity bottlenecks when attempting to follow the functional gradient, can be extracted from backpropagation. To do this, we propose a mathematical definition of expressivity bottlenecks, which enables us to detect, quantify and solve them while training, by adding suitable neurons. Thus, while the standard approach requires large networks, in terms of number of neurons per layer, for expressivity and optimization reasons, we provid tools and properties to develop an architecture starting with a very small number of neurons. As a proof of concept, we show results~on the CIFAR dataset, matching large neural network accuracy, with competitive training time, while removing the need for standard architectural hyper-parameter search.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3YlOr7BHkx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3YlOr7BHkx.html">Mislabeled examples detection viewed as probing machine learning models: concepts, survey and extensive benchmark</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Thomas George &middot; Pierre Nodet &middot; Alexis Bondu &middot; Vincent Lemaire</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3YlOr7BHkx"></div>

    <a href="paper_pages/3YlOr7BHkx.html">
        <img src="http://img.youtube.com/vi/fT9VZXs0nh8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3YlOr7BHkx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3YlOr7BHkx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3YlOr7BHkx">
                Abstract <i id="caret-3YlOr7BHkx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3YlOr7BHkx">
        <div class="abstract-display">
            <p>Mislabeled examples are ubiquitous in real-world machine learning datasets, advocating the development of techniques for automatic detection. We show that most mislabeled detection methods can be viewed as probing trained machine learning models using a few core principles. We formalize a modular framework that encompasses these methods, parameterized by only 4 building blocks, as well as a Python library that demonstrates that these principles can actually be implemented. The focus is on classifier-agnostic concepts, with an emphasis on adapting methods developed for deep learning models to non-deep classifiers for tabular data. We benchmark existing methods on (artificial) Completely At Random (NCAR) as well as (realistic) Not At Random (NNAR) labeling noise from a variety of tasks with imperfect labeling rules. This benchmark provides new insights as well as limitations of existing methods in this setup.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-k4AxEwTaHq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/k4AxEwTaHq.html">FaAlGrad: Fairness through Alignment of Gradients across Different Subpopulations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nikita Malik &middot; Konda Reddy Mopuri</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-k4AxEwTaHq"></div>

    <a href="paper_pages/k4AxEwTaHq.html">
        <img src="http://img.youtube.com/vi/YFx0svBR4Lw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-k4AxEwTaHq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-k4AxEwTaHq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-k4AxEwTaHq">
                Abstract <i id="caret-k4AxEwTaHq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-k4AxEwTaHq">
        <div class="abstract-display">
            <p>The growing deployment of Machine Learning systems has increased interest in systems optimized for other important criteria along with the expected task performance. For instance, machine learning models often exhibit biases that lead to unfair outcomes for certain protected subpopulations. This work aims to handle the bias in machine learning models and enhance their fairness by aligning the loss gradients. Specifically, leveraging the meta-learning technique, we propose a novel training framework that aligns the gradients computed across different subpopulations for learning fair classifiers. Aligning the gradients enables our framework to regularize the training process, thereby prioritizing fairness over predictive accuracy. Our experiments on multiple benchmark datasets demonstrate significant improvements in fairness metrics without having any exclusive regularizers for fairness. Thus our work contributes to developing fairer machine learning models with broader societal benefits.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6R3fRqFfhn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6R3fRqFfhn.html">GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Arto Maranjyan &middot; Mher Safaryan &middot; Peter RichtÃ¡rik</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6R3fRqFfhn"></div>

    <a href="paper_pages/6R3fRqFfhn.html">
        <img src="http://img.youtube.com/vi/WWhY5tO-FiM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6R3fRqFfhn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6R3fRqFfhn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6R3fRqFfhn">
                Abstract <i id="caret-6R3fRqFfhn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6R3fRqFfhn">
        <div class="abstract-display">
            <p>We study a class of distributed optimization algorithms that aim to alleviate high communication costs by allowing clients to perform multiple local gradient-type training steps before communication. In a recent breakthrough, Mishchenko et al. (2022) proved that local training, when properly executed, leads to provable communication acceleration, and this holds in the strongly convex regime without relying on any data similarity assumptions. However, their ProxSkip method requires all clients to take the same number of local training steps in each communication round. We propose a redesign of the ProxSkip method, allowing clients with ``less important'' data to get away with fewer local training steps without impacting the overall communication complexity of the method. In particular, we prove that our modified method, GradSkip, converges linearly under the same assumptions and has the same accelerated communication complexity, while the number of local gradient steps can be reduced relative to a local condition number. We further generalize our method by extending the randomness of probabilistic alternations to arbitrary unbiased compression operators and by considering a generic proximable regularizer. This generalization, which we call GradSkip+, recovers several related methods in the literature as special cases. Finally, we present an empirical study on carefully designed toy problems that confirm our theoretical claims.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2noXK5KBbx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2noXK5KBbx.html">Graph Structure Learning with Interpretable Bayesian Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Max Wasserman &middot; Gonzalo Mateos</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2noXK5KBbx"></div>

    <a href="paper_pages/2noXK5KBbx.html">
        <img src="http://img.youtube.com/vi/zcYD-r8DlUI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2noXK5KBbx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2noXK5KBbx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2noXK5KBbx">
                Abstract <i id="caret-2noXK5KBbx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2noXK5KBbx">
        <div class="abstract-display">
            <p>Graphs serve as generic tools to encode the underlying relational structure of data. Often this graph is not given, and so the task of inferring it from nodal observations becomes important. Traditional approaches formulate a convex inverse problem with a smoothness promoting objective and rely on iterative methods to obtain a solution. In supervised settings where graph labels are available, one can unroll and truncate these iterations into a deep network that is trained end-to-end. Such a network is parameter efficient and inherits inductive bias from the optimization formulation, an appealing aspect for data constrained settings in, e.g., medicine, finance, and the natural sciences. But typically such settings care equally about \textit{uncertainty} over edge predictions, not just point estimates. Here we introduce novel iterations with \textit{independently interpretable parameters}, i.e., parameters whose values - independent of other parameters' settings - proportionally influence characteristics of the estimated graph, such as edge sparsity. After unrolling these iterations, prior knowledge over such graph characteristics shape \textit{prior distributions} over these independently interpretable network parameters to yield a Bayesian neural network (BNN) capable of graph structure learning (GSL) from smooth signal observations. Fast execution and parameter efficiency allow for high-fidelity posterior approximation via Markov Chain Monte Carlo (MCMC) and thus uncertainty quantification on edge predictions. Informative priors unlock modeling tools from Bayesian statistics like prior predictive checks. Synthetic and real data experiments corroborate this model's ability to provide well-calibrated estimates of uncertainty, in test cases that include unveiling economic sector modular structure from S$\&$P$500$ data and recovering pairwise digit similarities from MNIST images. Overall, this framework enables GSL in modest-scale applications where uncertainty on the data structure is paramount.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-hrKHkmLUFk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/hrKHkmLUFk.html">Multi-intention Inverse Q-learning for Interpretable Behavior Representation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hao Zhu &middot; Brice De La Crompe &middot; Gabriel Kalweit &middot; Artur Schneider &middot; Maria Kalweit &middot; Ilka Diester &middot; Joschka Boedecker</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-hrKHkmLUFk"></div>

    <a href="paper_pages/hrKHkmLUFk.html">
        <img src="http://img.youtube.com/vi/0u-fboAO6-I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-hrKHkmLUFk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-hrKHkmLUFk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-hrKHkmLUFk">
                Abstract <i id="caret-hrKHkmLUFk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-hrKHkmLUFk">
        <div class="abstract-display">
            <p>In advancing the understanding of natural decision-making processes, inverse reinforcement learning (IRL) methods have proven instrumental in reconstructing animal's intentions underlying complex behaviors. Given the recent development of a continuous-time multi-intention IRL framework, there has been persistent inquiry into inferring discrete time-varying rewards with IRL. To address this challenge, we introduce the class of hierarchical inverse Q-learning (HIQL) algorithms. Through an unsupervised learning process, HIQL divides expert trajectories into multiple intention segments, and solves the IRL problem independently for each. Applying HIQL to simulated experiments and several real animal behavior datasets, our approach outperforms current benchmarks in behavior prediction and produces interpretable reward functions. Our results suggest that the intention transition dynamics underlying complex decision-making behavior is better modeled by a step function instead of a smoothly varying function. This advancement holds promise for neuroscience and cognitive science, contributing to a deeper understanding of decision-making and uncovering underlying brain mechanisms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QQZ8uPxFb3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QQZ8uPxFb3.html">Explaining Node Embeddings</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zohair Shafi &middot; Ayan Chatterjee &middot; Tina Eliassi-Rad</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QQZ8uPxFb3"></div>

    <a href="paper_pages/QQZ8uPxFb3.html">
        <img src="https://drive.google.com/thumbnail?id=1l9lGFAlSFjLYLe_3mxnO08mEs_8nFUqw" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QQZ8uPxFb3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QQZ8uPxFb3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QQZ8uPxFb3">
                Abstract <i id="caret-QQZ8uPxFb3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QQZ8uPxFb3">
        <div class="abstract-display">
            <p>Node embedding algorithms produce low-dimensional latent representations of nodes in a graph. These embeddings are often used for downstream tasks, such as node classification and link prediction. In this paper, we investigate the following two questions: (Q1) Can we explain each embedding dimension with human-understandable graph features (e.g. degree, clustering coefficient and PageRank). (Q2) How can we modify existing node embedding algorithms to produce embeddings that can be easily explained by human-understandable graph features? We find that the answer to Q1 is yes and introduce a new framework called XM (short for eXplain eMbedding) to answer Q2. A key aspect of XM involves minimizing the nuclear norm of the generated explanations. We show that by minimizing the nuclear norm, we minimize the lower bound on the entropy of the generated explanations. We test XM on a variety of real-world graphs and show that XM not only preserves the performance of existing node embedding methods, but also enhances their explainability.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-kUuPUIPvJ6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/kUuPUIPvJ6.html">Support-Set Context Matters for Bongard Problems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nikhil Raghuraman &middot; Adam W Harley &middot; Leonidas Guibas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-kUuPUIPvJ6"></div>

    <a href="paper_pages/kUuPUIPvJ6.html">
        <img src="http://img.youtube.com/vi/JO00GQHp0mQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-kUuPUIPvJ6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-kUuPUIPvJ6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-kUuPUIPvJ6">
                Abstract <i id="caret-kUuPUIPvJ6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-kUuPUIPvJ6">
        <div class="abstract-display">
            <p>Current machine learning methods struggle to solve Bongard problems, which are a type of IQ test that requires deriving an abstract âconceptâ from a set of positive and negative âsupportâ images, and then classifying whether or not a new query image depicts the key concept. On Bongard-HOI, a benchmark for natural-image Bongard problems, most existing methods have reached at best 69% accuracy (where chance is 50%). Low accuracy is often attributed to neural netsâ lack of ability to find human-like symbolic rules. In this work, we point out that many existing methods are forfeiting accuracy due to a much simpler problem: they do not adapt image features given information contained in the support set as a whole, and rely instead on information extracted from individual supports. This is a critical issue, because the âkey conceptâ in a typical Bongard problem can often only be distinguished using multiple positives and multiple negatives. We explore simple methods to incorporate this context and show substantial gains over prior works, leading to new state-of-the-art accuracy on Bongard-LOGO (75.3%) and Bongard-HOI (76.4%) compared to methods with equivalent vision backbone architectures and strong performance on the original Bongard problem set (60.8%).  Code is available at https://github.com/nraghuraman/bongard-context.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-FNBv2vweBI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/FNBv2vweBI.html">Constraining Generative Models for Engineering Design with Negative Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lyle Regenwetter &middot; Giorgio Giannone &middot; Akash Srivastava &middot; Dan Gutfreund &middot; Faez Ahmed</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-FNBv2vweBI"></div>

    <a href="paper_pages/FNBv2vweBI.html">
        <img src="http://img.youtube.com/vi/dFwRUL2qB3o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-FNBv2vweBI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-FNBv2vweBI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-FNBv2vweBI">
                Abstract <i id="caret-FNBv2vweBI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-FNBv2vweBI">
        <div class="abstract-display">
            <p>Generative models have recently achieved remarkable success and widespread adoption in society, yet they still often struggle to generate realistic and accurate outputs. This challenge extends beyond language and vision into fields like engineering design, where safety-critical engineering standards and non-negotiable physical laws tightly constrain what outputs are considered acceptable. 
In this work, we introduce two approaches to guide models toward constraint-satisfying outputs using `negative data' -- examples of what to avoid. Our negative data generative models (NDGMs) outperform state-of-the-art NDGMs by 4x in constraint satisfaction and easily outperform classic generative models using 8x less data in certain problems. To demonstrate this, we rigorously benchmark our NDGMs against 14 baseline models across numerous synthetic and real engineering problems, such as ship hulls with hydrodynamic constraints and vehicle design with impact safety constraints. Our benchmarks showcase both the best-in-class performance of our new NDGM models and the widespread dominance of NDGMs over classic generative models in general. In doing so, we advocate for the more widespread use of NDGMs in engineering design tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-llQXLfbGOq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/llQXLfbGOq.html">Attention Normalization Impacts Cardinality Generalization in Slot Attention</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Markus Krimmel &middot; Jan Achterhold &middot; Joerg Stueckler</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-llQXLfbGOq"></div>

    <a href="paper_pages/llQXLfbGOq.html">
        <img src="http://img.youtube.com/vi/dnTrHyZgyCY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-llQXLfbGOq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-llQXLfbGOq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-llQXLfbGOq">
                Abstract <i id="caret-llQXLfbGOq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-llQXLfbGOq">
        <div class="abstract-display">
            <p>Object-centric scene decompositions are important representations for downstream tasks in fields such as computer vision and robotics. The recently proposed Slot Attention module, already leveraged by several derivative works for image segmentation and object tracking in videos, is a deep learning component which performs unsupervised object-centric scene decomposition on input images. It is based on an attention architecture, in which latent slot vectors, which hold compressed information on objects, attend to localized perceptual features from the input image. In this paper, we demonstrate that design decisions on normalizing the aggregated values in the attention architecture have considerable impact on the capabilities of Slot Attention to generalize to a higher number of slots and objects as seen during training. We propose and investigate alternatives to the original normalization scheme which increase the generalization capabilities of Slot Attention to varying slot and object counts, resulting in performance gains on the task of unsupervised image segmentation. The newly proposed normalizations represent minimal and easy to implement modifications of the usual Slot Attention module, changing the value aggregation mechanism from a weighted mean operation to a scaled weighted sum operation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2D36otXvBE">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2D36otXvBE.html">Identifying and Clustering Counter Relationships of Team Compositions in PvP Games for Efficient Balance Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chiu-Chou Lin &middot; Yu-Wei Shih &middot; Kuei-Ting Kuo &middot; Yu-Cheng Chen &middot; Chien-Hua Chen &middot; Wei-Chen Chiu &middot; I-Chen Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2D36otXvBE"></div>

    <a href="paper_pages/2D36otXvBE.html">
        <img src="http://img.youtube.com/vi/CmgoUtRqmI8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2D36otXvBE" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2D36otXvBE" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2D36otXvBE">
                Abstract <i id="caret-2D36otXvBE" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2D36otXvBE">
        <div class="abstract-display">
            <p>\textbf{How can balance be quantified in game settings?} This question is crucial for game designers, especially in player-versus-player (PvP) games, where analyzing the strength relations among predefined team compositionsâsuch as hero combinations in multiplayer online battle arena (MOBA) games or decks in card gamesâis essential for enhancing gameplay and achieving balance. We have developed two advanced measures that extend beyond the simplistic win rate to quantify balance in zero-sum competitive scenarios. These measures are derived from win value estimations, which employ strength rating approximations via the Bradley-Terry model and counter relationship approximations via vector quantization, significantly reducing the computational complexity associated with traditional win value estimations. Throughout the learning process of these models, we identify useful categories of compositions and pinpoint their counter relationships, aligning with the experiences of human players without requiring specific game knowledge. Our methodology hinges on a simple technique to enhance codebook utilization in discrete representation with a deterministic vector quantization process for an extremely small state space. Our framework has been validated in popular online games, including \textit{Age of Empires II}, \textit{Hearthstone}, \textit{Brawl Stars}, and \textit{League of Legends}. The accuracy of the observed strength relations in these games is comparable to traditional pairwise win value predictions, while also offering a more manageable complexity for analysis. Ultimately, our findings contribute to a deeper understanding of PvP game dynamics and present a methodology that significantly improves game balance evaluation and design.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-IEKtMMSblm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/IEKtMMSblm.html">PLUM: Improving Inference Efficiency By Leveraging Repetition-Sparsity Trade-Off</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sachit Kuhar &middot; Yash Jain &middot; Alexey Tumanov</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-IEKtMMSblm"></div>

    <a href="paper_pages/IEKtMMSblm.html">
        <img src="http://img.youtube.com/vi/nE_CYDWqQ_I/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-IEKtMMSblm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-IEKtMMSblm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-IEKtMMSblm">
                Abstract <i id="caret-IEKtMMSblm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-IEKtMMSblm">
        <div class="abstract-display">
            <p>Efficient inference of Deep Neural Networks (DNNs) on resource-constrained edge devices is essential. Quantization and sparsity are key techniques that translate to repetition and sparsity within tensors at the hardware-software interface. This paper introduces the concept of repetition-sparsity trade-off that helps explain computational efficiency during inference. We propose PLUM, a unified co-design framework that integrates DNN inference systems and quantization (forward and backward pass) to leverage the repetition-sparsity trade-off to improve inference efficiency. Our results demonstrate that PLUMâs quantization method is more accurate than binary quantization with the same number of non-zero weights. Detailed analysis indicates that signed binarization generates a smaller distribution of effectual (non-zero) parameters nested within a larger distribution of total parameters of latent full-precision weights for a DNN block. Finally, the proposed PLUM framework achieves a 26% speedup on real hardware, doubles energy efficiency, and reduces density by 2.8Ã compared to binary methods while retaining top-1 accuracy when compared to prior-art methods for ResNets on ImageNet (by achieving 66.2% top-1 accuracy), presenting an alternative solution for deploying efficient models in resource-limited environments</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-x8wscCAJ2m">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/x8wscCAJ2m.html">Sparse Neural Architectures via Deterministic Ramanujan Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Suryam Arnav Kalra &middot; Arindam Biswas &middot; Pabitra Mitra &middot; BISWAJIT BASU</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-x8wscCAJ2m"></div>

    <a href="paper_pages/x8wscCAJ2m.html">
        <img src="https://drive.google.com/thumbnail?id=1Sc0-PZNCc5WcOHJnXcV9Gek53FyZgQ4M" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-x8wscCAJ2m" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-x8wscCAJ2m" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-x8wscCAJ2m">
                Abstract <i id="caret-x8wscCAJ2m" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-x8wscCAJ2m">
        <div class="abstract-display">
            <p>We present a method to construct sparse neural networks using the theory of expander graphs. Expanders are sparse but well connected graph structures that are used for designing resilient networks. A Ramanujan graph is an extremal expander in terms of the spectral gap of its eigenvalues. In this work, bipartite Ramanujan expanders are deterministically constructed and used as connection structures of the convolutional and fully connected layers of a neural network. The Ramanujan graphs occur either as Cayley graphs of certain algebraic groups or as Ramanujan $r$-coverings of the full $(k,l)$ bi-regular bipartite graph on $k + l$ vertices. The proposed sparse networks are found to provide comparable performance to a fully dense network on benchmark datasets achieving an extremely low network density.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1WqLLYgBNt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1WqLLYgBNt.html">Do not trust what you trust: Miscalibration in Semisupervised Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shambhavi Mishra &middot; Balamurali Murugesan &middot; Ismail Ben Ayed &middot; Marco Pedersoli &middot; Jose Dolz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1WqLLYgBNt"></div>

    <a href="paper_pages/1WqLLYgBNt.html">
        <img src="http://img.youtube.com/vi/Gj3-NgXo9Wk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1WqLLYgBNt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1WqLLYgBNt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1WqLLYgBNt">
                Abstract <i id="caret-1WqLLYgBNt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1WqLLYgBNt">
        <div class="abstract-display">
            <p>State-of-the-art semi-supervised learning (SSL) approaches rely on highly confident predictions to serve as pseudo-labels that guide the training on unlabeled samples. An inherent drawback of this strategy stems from the quality of the uncertainty estimates, as pseudo-labels are filtered only based on their degree of uncertainty, regardless of the correctness of their predictions.  Thus, assessing and enhancing the uncertainty of network predictions is of paramount importance in the pseudo-labeling process. In this work, we empirically demonstrate that SSL methods based on pseudo-labels are significantly miscalibrated, and formally demonstrate the minimization of the min-entropy, a lower bound of the Shannon entropy, as a potential cause for miscalibration. To alleviate this issue, we integrate a simple penalty term, which enforces the logit distances of the predictions on unlabeled samples to remain low, preventing the network predictions to become overconfident. Comprehensive experiments on a variety of SSL image classification benchmarks demonstrate that the proposed solution systematically improves the calibration performance of relevant SSL models, while also enhancing their discriminative power, being an appealing addition to tackle SSL tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TB18G0w6Ld">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TB18G0w6Ld.html">Fairness Under Demographic Scarce Regime</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Patrik Joslin Kenfack &middot; Samira Ebrahimi Kahou &middot; Ulrich AÃ¯vodji</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TB18G0w6Ld"></div>

    <a href="paper_pages/TB18G0w6Ld.html">
        <img src="http://img.youtube.com/vi/dLMC1IbR4LA/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TB18G0w6Ld" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TB18G0w6Ld" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TB18G0w6Ld">
                Abstract <i id="caret-TB18G0w6Ld" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TB18G0w6Ld">
        <div class="abstract-display">
            <p>Most existing works on fairness assume the model has full access to demographic information. However, there exist scenarios where demographic information is partially available because a record was not maintained throughout data collection or for privacy reasons. This setting is known as demographic scarce regime. Prior research has shown that training an attribute classifier to replace the missing sensitive attributes (proxy) can still improve fairness. However, using proxy-sensitive attributes worsens fairness-accuracy tradeoffs compared to true sensitive attributes. To address this limitation, we propose a framework to build attribute classifiers that achieve better fairness-accuracy tradeoffs. Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty.  We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes can negatively impact the fairness-accuracy tradeoff. Our experiments on five datasets showed that the proposed framework yields models with significantly better fairness-accuracy tradeoffs than classic attribute classifiers.  Surprisingly, our framework can outperform models trained with fairness constraints on the true sensitive attributes in most benchmarks. We also show that these findings are consistent with other uncertainty measures such as conformal prediction.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JxxkKt9yrx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JxxkKt9yrx.html">Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Raphael Lafargue &middot; Luke A Smith &middot; Franck VERMET &middot; Matthias LÃ¶we &middot; Ian Reid &middot; Jack Valmadre &middot; Vincent Gripon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JxxkKt9yrx"></div>

    <a href="paper_pages/JxxkKt9yrx.html">
        <img src="http://img.youtube.com/vi/OB95-BLxE0s/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JxxkKt9yrx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JxxkKt9yrx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JxxkKt9yrx">
                Abstract <i id="caret-JxxkKt9yrx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JxxkKt9yrx">
        <div class="abstract-display">
            <p>The predominant method for computing confidence intervals (CI) in few-shot learning (FSL) is based on sampling the tasks with replacement, i.e. allowing the same samples to appear in multiple tasks. This makes the CI misleading in that it takes into account the randomness of the sampler but not the data itself. To quantify the extent of this problem, we conduct a comparative analysis between CIs computed with and without replacement. These reveal a notable underestimation by the predominant method. This observation calls for a reevaluation of how we interpret confidence intervals and the resulting conclusions in FSL comparative studies. Our research demonstrates that the use of paired tests can partially address this issue. Additionally, we explore methods to further reduce the (size of the) CI by strategically sampling tasks of a specific size. We also introduce a new optimized benchmark, which can be accessed at https://github.com/RafLaf/FSL-benchmark-again</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-K58n87DE4s">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/K58n87DE4s.html">Adaptive Self-Distillation for Minimizing Client Drift in Heterogeneous Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">M Yashwanth &middot; Gaurav Kumar Nayak &middot; Arya Singh &middot; Yogesh Simmhan &middot; Anirban Chakraborty</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-K58n87DE4s"></div>

    <a href="paper_pages/K58n87DE4s.html">
        <img src="http://img.youtube.com/vi/6ld6AKLsmY0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-K58n87DE4s" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-K58n87DE4s" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-K58n87DE4s">
                Abstract <i id="caret-K58n87DE4s" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-K58n87DE4s">
        <div class="abstract-display">
            <p>Federated Learning (FL) is a machine learning paradigm that enables clients to jointly train a global model by aggregating the locally trained models without sharing any local training data. In practice, there can often be substantial heterogeneity (e.g., class imbalance) across the local data distributions observed by each of these clients. Under such non-iid label distributions across clients, FL suffers from the `client-driftâ problem where every client drifts to its own local optimum. This results in slower convergence and poor performance of the aggregated model. To address this limitation, we propose a novel regularization technique based on adaptive self-distillation (ASD) for training models on the client side. Our regularization scheme adaptively adjusts to each client's training data based on the global model's prediction entropy and the client-data label distribution. We show in this paper that our proposed regularization (ASD) can be easily integrated atop existing, state-of-the-art FL algorithms, leading to a further boost in the performance of these off-the-shelf methods. We theoretically explain how incorporation of ASD regularizer leads to reduction in client-drift and empirically justify the generalization ability of the trained model. We demonstrate the efficacy of our approach through extensive experiments on multiple real-world benchmarks and show substantial gains in performance when the proposed regularizer is combined with popular FL methods. The code is provided as supplementary material.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-A6D3PYSyqJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/A6D3PYSyqJ.html">LINOCS: Lookahead Inference of Networked Operators for Continuous Stability</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Noga Mudrik &middot; Eva Yezerets &middot; Yenho Chen &middot; Christopher John Rozell &middot; Adam Shabti Charles</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-A6D3PYSyqJ"></div>

    <a href="paper_pages/A6D3PYSyqJ.html">
        <img src="http://img.youtube.com/vi/5XVYRHd5wGs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-A6D3PYSyqJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-A6D3PYSyqJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-A6D3PYSyqJ">
                Abstract <i id="caret-A6D3PYSyqJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-A6D3PYSyqJ">
        <div class="abstract-display">
            <p>Identifying latent interactions within complex systems is key to unlocking deeper insights into their operational dynamics, including how their elements affect each other and contribute to the overall system behavior. For instance, in neuroscience, discovering neuron-to-neuron interactions is essential for understanding brain function; in ecology, recognizing the interactions among populations is key for understanding complex ecosystems. Such systems, often modeled as dynamical systems, typically exhibit noisy high-dimensional and non-stationary temporal behavior that renders their identification challenging. Existing dynamical system identification methods often yield operators that accurately capture short-term behavior  but  fail to predict long-term trends, suggesting an incomplete capture of the underlying process. Methods that consider extended forecasts (e.g., recurrent neural networks) lack explicit representations of element-wise interactions and require substantial training data, thereby failing to capture interpretable network operators. Here we introduce Lookahead-driven Inference of Networked Operators for Continuous Stability (LINOCS), a robust learning procedure for identifying hidden dynamical interactions in noisy time-series data. LINOCS integrates several multi-step predictions with adaptive weights during training to recover dynamical operators that can yield accurate long-term predictions. We demonstrate LINOCS' ability to recover the ground truth dynamical operators underlying synthetic time-series data for multiple dynamical systems models (including  linear, piece-wise linear, time-changing linear systems' decomposition, and regularized linear time-varying systems) as well as its capability to produce meaningful operators with robust reconstructions through various real-world examples.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xI6cPQObp0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xI6cPQObp0.html">Incremental Spatial and Spectral Learning of Neural Operators for Solving Large-Scale PDEs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Robert Joseph George &middot; Jiawei Zhao &middot; Jean Kossaifi &middot; Zongyi Li &middot; Anima Anandkumar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xI6cPQObp0"></div>

    <a href="paper_pages/xI6cPQObp0.html">
        <img src="video_thumbnails/xI6cPQObp0.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xI6cPQObp0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xI6cPQObp0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xI6cPQObp0">
                Abstract <i id="caret-xI6cPQObp0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xI6cPQObp0">
        <div class="abstract-display">
            <p>Fourier Neural Operators (FNO) offer a principled approach to solving challenging partial differential equations (PDE) such as turbulent flows. At the core of FNO is a spectral layer that leverages a discretization-convergent representation in the Fourier domain, and learns
weights over a fixed set of frequencies. However, training FNO presents two significant challenges, particularly in large-scale, high-resolution applications: (i) Computing Fourier transform on high-resolution inputs is computationally intensive but necessary since fine-scale details are needed for solving many PDEs, such as fluid flows, (ii) selecting the relevant set of frequencies in the spectral layers is challenging, and too many modes can lead to overfitting, while too few can lead to underfitting. To address these issues, we introduce
the Incremental Fourier Neural Operator (iFNO), which progressively increases both the number of frequency modes used by the model as well as the resolution of the training data. We empirically show that iFNO reduces total training time while maintaining or improving
generalization performance across various datasets. Our method demonstrates a 38% lower testing error, using 20% fewer frequency modes compared to the existing FNO, while also achieving up to 46% faster training and a 2.8x reduction in model size.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-38P40gJPrI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/38P40gJPrI.html">Simple Drop-in LoRA Conditioning on Attention Layers Will Improve Your Diffusion Model</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joo Young Choi &middot; Jaesung R. Park &middot; Inkyu Park &middot; Jaewoong Cho &middot; Albert No &middot; Ernest K. Ryu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-38P40gJPrI"></div>

    <a href="paper_pages/38P40gJPrI.html">
        <img src="http://img.youtube.com/vi/z-1LE2aNHak/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-38P40gJPrI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-38P40gJPrI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-38P40gJPrI">
                Abstract <i id="caret-38P40gJPrI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-38P40gJPrI">
        <div class="abstract-display">
            <p>Current state-of-the-art diffusion models employ U-Net architectures containing convolutional and (qkv) self-attention layers. The U-Net processes images while being conditioned on the time embedding input for each sampling step and the class or caption embedding input corresponding to the desired conditional generation. Such conditioning involves scale-and-shift operations to the convolutional layers but does not directly affect the attention layers. While these standard architectural choices are certainly effective, not conditioning the attention layers feels arbitrary and potentially suboptimal. In this work, we show that simply adding LoRA conditioning to the attention layers without changing or tuning the other parts of the U-Net architecture improves the image generation quality. For example, a drop-in addition of LoRA conditioning to EDM diffusion model yields FID scores of 1.91/1.75 for unconditional and class-conditional CIFAR-10 generation, improving upon the baseline of 1.97/1.79.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-30C9AWBW49">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/30C9AWBW49.html">Perceptual Similarity for Measuring Decision-Making Style and Policy Diversity in Games</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chiu-Chou Lin &middot; Wei-Chen Chiu &middot; I-Chen Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-30C9AWBW49"></div>

    <a href="paper_pages/30C9AWBW49.html">
        <img src="http://img.youtube.com/vi/eR0Kx6xnH6Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-30C9AWBW49" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-30C9AWBW49" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-30C9AWBW49">
                Abstract <i id="caret-30C9AWBW49" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-30C9AWBW49">
        <div class="abstract-display">
            <p>Defining and measuring decision-making styles, also known as playstyles, is crucial in gaming, where these styles reflect a broad spectrum of individuality and diversity. However, finding a universally applicable measure for these styles poses a challenge. Building on $\textit{Playstyle Distance}$, the first unsupervised metric to measure playstyle similarity based on game screens and raw actions by identifying comparable states with discrete representations for computing policy distance, we introduce three enhancements to increase accuracy: multiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, and the utilization of the intersection-over-union method for efficient evaluation. These innovations not only advance measurement precision but also offer insights into human cognition of similarity. Across two racing games and seven Atari games, our techniques significantly improve the precision of zero-shot playstyle classification, achieving an accuracy exceeding 90\% with fewer than 512 observation-action pairsâless than half an episode of these games. Furthermore, our experiments with $\textit{2048}$ and $\textit{Go}$ demonstrate the potential of discrete playstyle measures in puzzle and board games. We also develop an algorithm for assessing decision-making diversity using these measures. Our findings improve the measurement of end-to-end game analysis and the evolution of artificial intelligence for diverse playstyles.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y8DSGN5nuN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y8DSGN5nuN.html">FlexEControl: Flexible and Efficient Multimodal Control for Text-to-Image Generation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xuehai He &middot; Jian Zheng &middot; Jacob Zhiyuan Fang &middot; Robinson Piramuthu &middot; Mohit Bansal &middot; Vicente Ordonez &middot; Gunnar A Sigurdsson &middot; Nanyun Peng &middot; Xin Eric Wang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y8DSGN5nuN"></div>

    <a href="paper_pages/y8DSGN5nuN.html">
        <img src="https://drive.google.com/thumbnail?id=1eIOZuOvNTSAww5t780LtxribUB5J9DgR" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y8DSGN5nuN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y8DSGN5nuN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y8DSGN5nuN">
                Abstract <i id="caret-y8DSGN5nuN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y8DSGN5nuN">
        <div class="abstract-display">
            <p>Controllable text-to-image (T2I) diffusion models generate images conditioned on both text
prompts and semantic inputs of other modalities like edge maps. Nevertheless, current
controllable T2I methods commonly face challenges related to efficiency and faithfulness,
especially when conditioning on multiple inputs from either the same or diverse modalities. In
this paper, we propose a novel Flexible and Efficient method, FlexEControl, for controllable
T2I generation. At the core of FlexEControl is a unique weight decomposition strategy, which
allows for streamlined integration of various input types. This approach not only enhances
the faithfulness of the generated image to the control, but also significantly reduces the
computational overhead typically associated with multimodal conditioning. Our approach
achieves a reduction of 41% in trainable parameters and 30% in memory usage compared
with Uni-ControlNet. Moreover, it doubles data efficiency and can flexibly generate images
under the guidance of multiple input conditions of various modalities.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-cD209UgOX7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/cD209UgOX7.html">Scaling Up Bayesian Neural Networks with Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zahra Moslemi &middot; Yang Meng &middot; Shiwei Lan &middot; Babak Shahbaba</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-cD209UgOX7"></div>

    <a href="paper_pages/cD209UgOX7.html">
        <img src="https://drive.google.com/thumbnail?id=10cIAASi5ZN1O5MCm8ojIuTGZhEmygwE4" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-cD209UgOX7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-cD209UgOX7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-cD209UgOX7">
                Abstract <i id="caret-cD209UgOX7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-cD209UgOX7">
        <div class="abstract-display">
            <p>Bayesian Neural Networks (BNNs) offer a principled and natural framework for proper uncertainty quantification in the context of deep learning. They address the typical challenges associated with conventional deep learning methods, such as data insatiability, ad-hoc nature, and susceptibility to overfitting. However, their implementation typically either relies on Markov chain Monte Carlo (MCMC) methods, which are characterized by their computational intensity and inefficiency in a high-dimensional space, or variational inference methods, which tend to underestimate uncertainty. To address this issue, we propose a novel Calibration-Emulation-Sampling (CES) strategy to significantly enhance the computational efficiency of BNN. In this framework, during the initial calibration stage, we collect a small set of samples from the parameter space. These samples serve as training data for the emulator, which approximates the map between parameters and posterior probability. The trained emulator is then used for sampling from the posterior distribution at substantially higher speed compared to the standard BNN. Using simulated and real data, we demonstrate that our proposed method improves computational efficiency of BNN, while maintaining similar performance in terms of prediction accuracy and uncertainty quantification.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-cT8oOJ6Q6F">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/cT8oOJ6Q6F.html">Grid Cell-Inspired Fragmentation and Recall for Efficient Map Building</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jaedong Hwang &middot; Zhang-Wei Hong &middot; Eric R Chen &middot; Akhilan Boopathy &middot; Pulkit Agrawal &middot; Ila R Fiete</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-cT8oOJ6Q6F"></div>

    <a href="paper_pages/cT8oOJ6Q6F.html">
        <img src="http://img.youtube.com/vi/lV0clkUssvs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-cT8oOJ6Q6F" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-cT8oOJ6Q6F" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-cT8oOJ6Q6F">
                Abstract <i id="caret-cT8oOJ6Q6F" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-cT8oOJ6Q6F">
        <div class="abstract-display">
            <p>Animals and robots navigate through environments by building and refining maps of space. These maps enable functions including navigation back to home, planning, search and foraging. Here, we use observations from neuroscience, specifically the observed fragmentation of grid cell map in compartmentalized spaces, to propose and apply the concept of Fragmentation-and-Recall (FARMap) in the mapping of large spaces. Agents solve the mapping problem by building local maps via a surprisal-based clustering of space, which they use to set subgoals for spatial exploration. Agents build and use a local map to predict their observations; high surprisal leads to a "fragmentation event" that truncates the local map. At these events, the recent local map is placed into long-term memory (LTM) and a different local map is initialized. If observations at a fracture point match observations in one of the stored local maps, that map is recalled (and thus reused) from LTM. The fragmentation points induce a natural online clustering of the larger space, forming a set of intrinsic potential subgoals that are stored in LTM as a topological graph. Agents choose their next subgoal from the set of near and far potential subgoals from within the current local map or LTM, respectively. Thus, local maps guide exploration locally, while LTM promotes global exploration. We demonstrate that FARMap replicates the fragmentation points observed in animal studies. We evaluate FARMap on complex procedurally-generated spatial environments and realistic simulations to demonstrate that this mapping strategy much more rapidly covers the environment (number of agent steps and wall clock time) and is more efficient in active memory usage, without loss of performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dLaazW9zuF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dLaazW9zuF.html">Multi-Fidelity Active Learning with GFlowNets</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alex HernÃ¡ndez-GarcÃ­a &middot; Nikita Saxena &middot; Moksh Jain &middot; Cheng-Hao Liu &middot; Yoshua Bengio</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dLaazW9zuF"></div>

    <a href="paper_pages/dLaazW9zuF.html">
        <img src="https://www.dailymotion.com/thumbnail/video/k1k8KKYS67DgFCB516w" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dLaazW9zuF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dLaazW9zuF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dLaazW9zuF">
                Abstract <i id="caret-dLaazW9zuF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dLaazW9zuF">
        <div class="abstract-display">
            <p>In the last decades, the capacity to generate large amounts of data in science and engineering applications has been growing steadily. Meanwhile, machine learning has progressed to become a suitable tool to process and utilise the available data. Nonetheless, many relevant scientific and engineering problems present challenges where current machine learning methods cannot yet efficiently leverage the available data and resources. For example, in scientific discovery, we are often faced with the problem of exploring very large, structured and high-dimensional spaces. Moreover, the high fidelity, black-box objective function is often very expensive to evaluate. Progress in machine learning methods that can efficiently tackle such challenges would help accelerate currently crucial areas such as drug and materials discovery. In this paper, we propose a multi-fidelity active learning algorithm with GFlowNets as a sampler, to efficiently discover diverse, high-scoring candidates where multiple approximations of the black-box function are available at lower fidelity and cost. Our evaluation on molecular discovery tasks shows that multi-fidelity active learning with GFlowNets can discover high-scoring candidates at a fraction of the budget of its single-fidelity counterpart while maintaining diversity, unlike RL-based alternatives. These results open new avenues for multi-fidelity active learning to accelerate scientific discovery and engineering design.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TAvGZm2Rqb">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TAvGZm2Rqb.html">Cost-Sensitive Learning to Defer to Multiple Experts with Workload Constraints</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jean Vieira Alves &middot; Diogo LeitÃ£o &middot; SÃ©rgio Jesus &middot; Marco O. P. Sampaio &middot; Javier LiÃ©bana &middot; Pedro Saleiro &middot; Mario A. T. Figueiredo &middot; Pedro Bizarro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TAvGZm2Rqb"></div>

    <a href="paper_pages/TAvGZm2Rqb.html">
        <img src="http://img.youtube.com/vi/R51SBj02RuU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TAvGZm2Rqb" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TAvGZm2Rqb" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TAvGZm2Rqb">
                Abstract <i id="caret-TAvGZm2Rqb" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TAvGZm2Rqb">
        <div class="abstract-display">
            <p>Learning to defer (L2D) aims to improve human-AI collaboration systems by learning how to defer decisions to humans when they are more likely to be correct than an ML classifier. Existing research in L2D overlooks key real-world aspects that impede its practical adoption, namely: i) neglecting cost-sensitive scenarios, where type I and type II errors have different costs; ii) requiring concurrent human predictions for every instance of the training dataset; and iii) not dealing with human work-capacity constraints. To address these issues, we propose the \textit{deferral under cost and capacity constraints framework} (DeCCaF). DeCCaF is a novel L2D approach, employing supervised learning to model the probability of human error under less restrictive data requirements (only one expert prediction per instance) and using constraint programming to globally minimize the error cost, subject to workload limitations. We test DeCCaF in a series of cost-sensitive fraud detection scenarios with different teams of 9 synthetic fraud analysts, with individual work-capacity constraints. The results demonstrate that our approach performs significantly better than the baselines in a wide array of scenarios, achieving an average $8.4\%$ reduction in the misclassification cost. The code used for the experiments is available at https://github.com/feedzai/deccaf</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-WzHuebRSgQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/WzHuebRSgQ.html">A Greedy Hierarchical Approach to Whole-Network Filter-Pruning in CNNs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kiran Purohit &middot; Anurag Reddy Parvathgari &middot; Sourangshu Bhattacharya</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-WzHuebRSgQ"></div>

    <a href="paper_pages/WzHuebRSgQ.html">
        <img src="http://img.youtube.com/vi/egk0ZJb89Ao/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-WzHuebRSgQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-WzHuebRSgQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-WzHuebRSgQ">
                Abstract <i id="caret-WzHuebRSgQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-WzHuebRSgQ">
        <div class="abstract-display">
            <p>Deep convolutional neural networks (CNNs) have achieved impressive performance in many computer vision tasks. However, their large model sizes require heavy computational resources, making pruning redundant filters from existing pre-trained CNNs an essential task in developing efficient models for resource-constrained devices. Whole-network filter pruning algorithms prune varying fractions of filters from each layer, hence providing greater flexibility. State-of-the-art whole-network pruning methods are either computationally expensive due to the need to calculate the loss for each pruned filter using a training dataset, or use various heuristic / learned criteria for determining the pruning fractions for each layer. Hence there is a need for a simple and efficient technique for whole network pruning. This paper proposes
a two-level hierarchical approach for whole-network filter pruning which is efficient and uses the classification loss as the final criterion. The lower-level algorithm (called filter-pruning) uses a sparse-approximation formulation based on linear approximation of filter weights. We explore two algorithms: orthogonal matching pursuit-based greedy selection and a greedy backward pruning approach. The backward pruning algorithm uses a novel closed-form error criterion for efficiently selecting the optimal filter at each stage, thus making the whole algorithm much faster. The higher-level algorithm (called layer-selection) greedily selects the best-pruned layer (pruning using the filter-selection algorithm) using a global pruning criterion. We propose algorithms for two different global-pruning criteria: (1) layerwise-relative error (HBGS), and (2) final classification error (HBGTS). Our suite of algorithms outperforms state-of-the-art pruning methods on ResNet18, ResNet32, ResNet56, VGG16, and ResNext101. Our method reduces the RAM requirement for ResNext101 from 7.6 GB to 1.5 GB and achieves a 94% reduction in FLOPS without losing accuracy on CIFAR-10.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DimPeeCxKO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DimPeeCxKO.html">Simple and Scalable Strategies to Continually Pre-train Large Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Adam Ibrahim &middot; Benjamin ThÃ©rien &middot; Kshitij Gupta &middot; Mats Leon Richter &middot; Quentin Gregory Anthony &middot; Eugene Belilovsky &middot; TimothÃ©e Lesort &middot; Irina Rish</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DimPeeCxKO"></div>

    <a href="paper_pages/DimPeeCxKO.html">
        <img src="http://img.youtube.com/vi/y4sUn3sYWFc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DimPeeCxKO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DimPeeCxKO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DimPeeCxKO">
                Abstract <i id="caret-DimPeeCxKO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DimPeeCxKO">
        <div class="abstract-display">
            <p>Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these modelsâsaving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English$\rightarrow$English) and a stronger distribution shift (English$\rightarrow$German) at the $405$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that autoregressive transformer-based LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tbOYJwXhcY">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tbOYJwXhcY.html">Misspecification-robust Sequential Neural Likelihood for Simulation-based Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ryan P. Kelly &middot; David J Nott &middot; David Tyler Frazier &middot; David J Warne &middot; Christopher Drovandi</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tbOYJwXhcY"></div>

    <a href="paper_pages/tbOYJwXhcY.html">
        <img src="http://img.youtube.com/vi/79u0rQTwUGY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tbOYJwXhcY" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tbOYJwXhcY" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tbOYJwXhcY">
                Abstract <i id="caret-tbOYJwXhcY" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tbOYJwXhcY">
        <div class="abstract-display">
            <p>Simulation-based inference techniques are indispensable for parameter estimation of mechanistic and simulable models with intractable likelihoods. While traditional statistical approaches like approximate Bayesian computation and Bayesian synthetic likelihood have been studied under well-specified and misspecified settings, they often suffer from inefficiencies due to wasted model simulations. Neural approaches, such as sequential neural likelihood (SNL) avoid this wastage by utilising all model simulations to train a neural surrogate for the likelihood function. However, the performance of SNL under model misspecification is unreliable and can result in overconfident posteriors centred around an inaccurate parameter estimate. In this paper, we propose a novel SNL method, which through the incorporation of additional adjustment parameters, is robust to model misspecification and capable of identifying features of the data that the model is not able to recover. We demonstrate the efficacy of our approach through several illustrative examples, where our method gives more accurate point estimates and uncertainty quantification than SNL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-5TaBxctwRZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/5TaBxctwRZ.html">Input Normalized Stochastic Gradient Descent Training for Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Salih Furkan Atici &middot; Hongyi Pan &middot; Ahmet Cetin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-5TaBxctwRZ"></div>

    <a href="paper_pages/5TaBxctwRZ.html">
        <img src="http://img.youtube.com/vi/QzTD0NgC3-A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-5TaBxctwRZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-5TaBxctwRZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-5TaBxctwRZ">
                Abstract <i id="caret-5TaBxctwRZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-5TaBxctwRZ">
        <div class="abstract-display">
            <p>In this paper, we propose a novel optimization algorithm for training machine learning models called Input Normalized Stochastic Gradient Descent (INSGD), inspired by the Normalized Least Mean Squares (NLMS) algorithm used in adaptive filtering. When training complex models on large datasets, choosing optimizer parameters, particularly the learning rate, is crucial to avoid divergence. Our algorithm updates the network weights using stochastic gradient descent with $\ell_1$ and $\ell_2$-based normalizations applied to the learning rate, similar to NLMS. However, unlike existing normalization methods, we exclude the error term from the normalization process and instead normalize the update term using the input vector to the neuron. Our experiments demonstrate that our optimization algorithm achieves higher accuracy levels compared to different initialization settings. We evaluate the efficiency of our training algorithm on benchmark datasets using a toy neural network and several mature modern deep networks including ResNet-20, ResNet-50, MobileNetV3, WResNet-18, and Vision Transformer. Our INSGD algorithm improves ResNet-20's CIFAR-10 test accuracy from 92.57\% to 92.67\%, MobileNetV3's CIFAR-10 test accuracy from 90.83\% to 91.13\%, WResNet-18 on CIFAR-100 from 78.24\% to 78.47\%, and ResNet-50's accuracy on ImageNet-1K validation dataset from 75.60\% to 75.92\%.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-b68QOenPWy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/b68QOenPWy.html">Active Learning via Classifier Impact and Greedy Selection for Interactive Image Retrieval</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Leah Bar &middot; Boaz Lerner &middot; Nir Darshan &middot; Rami Ben-Ari</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-b68QOenPWy"></div>

    <a href="paper_pages/b68QOenPWy.html">
        <img src="http://img.youtube.com/vi/bHDARDpu8Fg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-b68QOenPWy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-b68QOenPWy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-b68QOenPWy">
                Abstract <i id="caret-b68QOenPWy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-b68QOenPWy">
        <div class="abstract-display">
            <p>Active Learning (AL) is a user-interactive approach aimed at reducing annotation costs by selecting the most crucial examples to label. Although AL has been extensively studied for image classification tasks, the specific scenario of interactive image retrieval has received relatively little attention. This scenario presents unique characteristics, including an open-set and class-imbalanced binary classification, starting with very few labeled samples. We introduce a novel batch-mode Active Learning framework named GAL (Greedy Active Learning) that better copes with this application. It incorporates new acquisition functions for sample selection that measure the impact of each unlabeled sample on the classifier. We further embed this strategy in a greedy selection approach, better exploiting the samples within each batch. We evaluate our framework with both linear (SVM) and non-linear MLP/Gaussian Process classifiers. For the Gaussian Process case, we show a theoretical guarantee on the greedy approximation. Finally, we assess our performance for the interactive content-based image retrieval task on several benchmarks and demonstrate its superiority over existing approaches and common baselines. Code is available at
https://github.com/barleah/GreedyAL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-c8WJ4Vozb2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/c8WJ4Vozb2.html">Correcting Flaws in Common Disentanglement Metrics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Louis Mahon &middot; Lei Sha &middot; Thomas Lukasiewicz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-c8WJ4Vozb2"></div>

    <a href="paper_pages/c8WJ4Vozb2.html">
        <img src="http://img.youtube.com/vi/d0kpCvTbz0U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-c8WJ4Vozb2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-c8WJ4Vozb2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-c8WJ4Vozb2">
                Abstract <i id="caret-c8WJ4Vozb2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-c8WJ4Vozb2">
        <div class="abstract-display">
            <p>Disentangled representations are those in which distinct features, such as size or shape, are represented by distinct neurons. Quantifying the extent to which a given representation is disentangled is not straightforward; multiple metrics have been proposed. In this paper, we identify two failings of existing metrics, which mean they can assign a high score to a model which is still entangled, and we propose two new metrics, which redress these problems. First, we use hypothetical toy examples to demonstrate the failure modes we identify for existing metrics. Then, we show that similar situations occur in practice. Finally, we validate our metrics on the downstream task of compositional generalization. We measure the performance of six existing disentanglement models on this downstream compositional generalization task, and show that performance is (a) generally quite poor, (b) correlated, to varying degrees, with most disentanglement metrics, and (c) most strongly correlated with our newly proposed metrics. Anonymous code to reproduce our results is available at https://github.com/anon296/anon.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-otTFPjziiK">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/otTFPjziiK.html">Directed Graph Transformers</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Qitong Wang &middot; Georgios Kollias &middot; Vasileios Kalantzis &middot; Naoki Abe &middot; Mohammed J Zaki</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-otTFPjziiK"></div>

    <a href="paper_pages/otTFPjziiK.html">
        <img src="http://img.youtube.com/vi/V7HGpuUPniw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-otTFPjziiK" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-otTFPjziiK" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-otTFPjziiK">
                Abstract <i id="caret-otTFPjziiK" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-otTFPjziiK">
        <div class="abstract-display">
            <p>In this paper, we address the problem of capturing graph directionality using transformers. Most existing graph transformers typically capture distances between graph nodes and do not take edge direction into account. This is a limiting assumption since many graph applications need to exploit sophisticated relationships in graph data, such as time, causality, or generic dependency constraints. We introduce a novel graph transformer architecture that explicitly takes into account the directionality between connected graph nodes. To achieve this, we make use of dual encodings to represent both potential roles, i.e., source or target, of each pair of vertices linked by a directed edge. These encodings are learned by leveraging the latent adjacency information extracted from a directional attention module, localized with $k$-hop neighborhood information. Extensive experiments on synthetic and real graph datasets show that our approach can have significant accuracy gains over previous graph transformer (GT) and graph neural network (GNN) approaches, providing state-of-the-art (SOTA) results on inherently directed graphs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aHtZuZfHcf">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aHtZuZfHcf.html">Knowledge Accumulation in Continually Learned Representations and the Issue of Feature Forgetting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Timm Hess &middot; Eli Verwimp &middot; Gido M van de Ven &middot; Tinne Tuytelaars</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aHtZuZfHcf"></div>

    <a href="paper_pages/aHtZuZfHcf.html">
        <img src="http://img.youtube.com/vi/od0GNwd4-Cs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aHtZuZfHcf" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aHtZuZfHcf" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aHtZuZfHcf">
                Abstract <i id="caret-aHtZuZfHcf" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aHtZuZfHcf">
        <div class="abstract-display">
            <p>Continual learning research has shown that neural networks suffer from catastrophic forgetting "at the output level", but it is debated whether this is also the case at the level of learned representations. Multiple recent studies ascribe representations a certain level of innate robustness against forgetting - that they only forget minimally in comparison with forgetting at the output level. We revisit and expand upon the experiments that revealed this difference in forgetting and illustrate the coexistence of two phenomena that affect the quality of continually learned representations: knowledge accumulation and feature forgetting. Taking both aspects into account, we show that, even though forgetting in the representation (i.e. feature forgetting) can be small in absolute terms, when measuring relative to how much was learned during a task, forgetting in the representation tends to be just as catastrophic as forgetting at the output level. Next we show that this feature forgetting is problematic as it substantially slows down the incremental learning of good general representations (i.e. knowledge accumulation). Finally, we study how feature forgetting and knowledge accumulation are affected by different types of continual learning methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-CuyJkNjIVd">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/CuyJkNjIVd.html">Homogenizing Non-IID Datasets via In-Distribution Knowledge Distillation for Decentralized Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Deepak Ravikumar &middot; Gobinda Saha &middot; Sai Aparna Aketi &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-CuyJkNjIVd"></div>

    <a href="paper_pages/CuyJkNjIVd.html">
        <img src="http://img.youtube.com/vi/I-den-2TNyk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-CuyJkNjIVd" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-CuyJkNjIVd" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-CuyJkNjIVd">
                Abstract <i id="caret-CuyJkNjIVd" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-CuyJkNjIVd">
        <div class="abstract-display">
            <p>Decentralized learning enables serverless training of deep neural networks (DNNs) in a distributed manner on multiple nodes. One of the key challenges with decentralized learning is heterogeneity in the data distribution across the nodes. Data heterogeneity results in slow and unstable global convergence and therefore poor generalization performance. In this paper, we propose In-Distribution Knowledge Distillation (IDKD) to address the challenge of heterogeneous data distribution. The goal of IDKD is to homogenize the data distribution across the nodes. While such data homogenization can be achieved by exchanging data among the nodes sacrificing privacy, IDKD achieves the same objective using a common public dataset across nodes without breaking the privacy constraint. This public dataset is different from the training dataset and is used to distill the knowledge from each node and communicate it to its neighbors through the generated labels. With traditional knowledge distillation, the generalization of the distilled model is reduced due to misalignment between the private and public data distribution. Thus, we introduce an Out-of-Distribution (OoD) detector at each node to label a subset of the public dataset that maps close to the local training data distribution. Our experiments on multiple image classification datasets and graph topologies show that the proposed IDKD scheme is more effective than traditional knowledge distillation and achieves state-of-the-art generalization performance on heterogeneously distributed data with minimal communication overhead.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-PzmaWLqK0e">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/PzmaWLqK0e.html">Reward-based Autonomous Online Learning Framework for Resilient Cooperative Target Monitoring using a Swarm of Robots</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shubhankar Gupta &middot; Saksham Sharma &middot; Suresh Sundaram</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-PzmaWLqK0e"></div>

    <a href="paper_pages/PzmaWLqK0e.html">
        <img src="http://img.youtube.com/vi/FOMs3Rk6PM4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-PzmaWLqK0e" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-PzmaWLqK0e" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-PzmaWLqK0e">
                Abstract <i id="caret-PzmaWLqK0e" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-PzmaWLqK0e">
        <div class="abstract-display">
            <p>This paper addresses the problem of decentralized cooperative monitoring of an agile target using a swarm of robots undergoing dynamic sensor failures. Each robot is equipped with a proprioceptive sensor suite for the estimation of its own pose and an exteroceptive sensor suite for target detection and position estimation with a limited field of view. Further, the robots use broadcast-based communication modules with a limited communication radius and bandwidth. The uncertainty in the system and the environment can lead to intermittent communication link drops, target visual loss, and large biases in the sensorsâ estimation output due to temporary or permanent failures. Robotic swarms often operate without leaders, supervisors, or landmarks, i.e., without the availability of ground truth regarding pose information. In such scenarios, each robot is required to exhibit autonomous learning by taking charge of its own learning process while making the most out of available information. In this regard, a novel Autonomous Online Learning (AOL) framework has been proposed, in which a decentralized online learning mechanism driven by reward-like signals, is intertwined with an implicit adaptive consensus-based, two-layered, weighted information fusion process that utilizes the robotsâ observations and their shared information, thereby ensuring resilience in the robotic swarm. In order to study the effect of loss or reward design in the local and social learning layers, three AOL variants are presented. A novel perturbation-greedy reward design is introduced in the learning layers of two variants, leading to exploration-exploitation in their information fusion's weights' space. Convergence analysis of the weights is carried out, showing that the weights converge under reasonable assumptions. Simulation results show that the AOL variant using the perturbation-greedy reward in its local learning layer performs the best, doing $182.2\%$ to $652\%$ and $94.7\%$ to $150.4\%$ better than the baselines in terms of detection score and closeness score per robot, respectively, as the total number of robots is increased from $5$ to $30$. Further, AOL's Sim2Real implementation has been validated using a ROS-Gazebo setup.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9M2XqvH2SB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9M2XqvH2SB.html">[Re] Reproducibility Study of âExplaining Temporal Graph Models Through an Explorer-Navigator Framework"</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Helia Ghasemi &middot; Christina Isaicu &middot; Jesse Wonnink &middot; Andreas Berentzen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9M2XqvH2SB"></div>

    <a href="paper_pages/9M2XqvH2SB.html">
        <img src="http://img.youtube.com/vi/sOrRtldRd48/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9M2XqvH2SB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9M2XqvH2SB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9M2XqvH2SB">
                Abstract <i id="caret-9M2XqvH2SB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9M2XqvH2SB">
        <div class="abstract-display">
            <p>This paper seeks to reproduce and extend the results of the paper âExplaining Temporal Graph Models Through an Explorer-Navigator Frameworkâ by (Xia et al., 2023). The main contribution of the original authors is a novel explainer for temporal graph networks, the Temporal GNN Explainer (T-GNNExplainer), which finds a subset of preceding events that âexplainâ a prediction made by a temporal graph model. The explorer is tested on two temporal graph models that are trained on two real-world and two synthetic datasets. The explorer is evaluated using a newly proposed metric for explanatory graph models. The authors compare the performance of their explorer to three baseline explainer methods, either adapted from a GNN explainer or developed by the authors. The authors claim that T-GNNExplainer achieves superior performance compared to the baselines when evaluated with their proposed metric. This work reproduces the original experiments by using the code (with minor adjustments), model specifications, and hyperparameters provided by the original authors. To evaluate the robustness of these claims, the method was extended to one new dataset (MOOC). Results show that the T-GNNexplainer performs best on some, but not all metrics as reported in the original findings. We conclude that the main lines of this paper hold up even though all results are less pronounced than claimed. Results show that the T-GNNExplainer does not perform similarly across different T-GNN models, precise dataset specifications are needed to obtain high performance, and there are simpler, less computationally costly explainer methods (like PBONE) that could offer competitive results.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zVDMh6JvWc">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zVDMh6JvWc.html">A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kim Youwang &middot; Lee Hyun &middot; Kim Sung-Bin &middot; Suekyeong Nam &middot; Janghoon Ju &middot; Tae-Hyun Oh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zVDMh6JvWc"></div>

    <a href="paper_pages/zVDMh6JvWc.html">
        <img src="http://img.youtube.com/vi/68e6t6Y2zJc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zVDMh6JvWc" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zVDMh6JvWc" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zVDMh6JvWc">
                Abstract <i id="caret-zVDMh6JvWc" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zVDMh6JvWc">
        <div class="abstract-display">
            <p>We propose NeuFace, a 3D face mesh pseudo annotation method on videos via neural re-parameterized optimization. Despite the huge progress in 3D face reconstruction methods, generating reliable 3D face labels for in-the-wild dynamic videos remains challenging. Using NeuFace optimization, we annotate the per-view/-frame accurate and consistent face meshes on large-scale face videos, called the NeuFace-dataset. We investigate how neural re-parameterization helps to reconstruct image-aligned facial details on 3D meshes via gradient analysis. By exploiting the naturalness and diversity of 3D faces in our dataset, we demonstrate the usefulness of our dataset for 3D face-related tasks: improving the reconstruction accuracy of an existing 3D face reconstruction model and learning 3D facial motion prior.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p1a6ruIZCT">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p1a6ruIZCT.html">IMEX-Reg: Implicit-Explicit Regularization in the Function Space for Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Prashant Shivaram Bhat &middot; Bharath Chennamkulam Renjith &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p1a6ruIZCT"></div>

    <a href="paper_pages/p1a6ruIZCT.html">
        <img src="http://img.youtube.com/vi/X1Qh_Czx-NM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p1a6ruIZCT" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p1a6ruIZCT" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p1a6ruIZCT">
                Abstract <i id="caret-p1a6ruIZCT" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p1a6ruIZCT">
        <div class="abstract-display">
            <p>Continual learning (CL) remains one of the long-standing challenges for deep neural networks due to catastrophic forgetting of previously acquired knowledge. Although rehearsal-based approaches have been fairly successful in mitigating catastrophic forgetting, they suffer from overfitting on buffered samples and prior information loss, hindering generalization under low-buffer regimes. Inspired by how humans learn using strong inductive biases, we propose \textbf{IMEX-Reg} to improve the generalization performance of experience rehearsal in CL under low buffer regimes. Specifically, we employ a two-pronged implicit-explicit regularization approach using contrastive representation learning (CRL) and consistency regularization. To further leverage the global relationship between representations learned using CRL, we propose a regularization strategy to guide the classifier toward the activation correlations in the unit hypersphere of the CRL. Our results show that IMEX-Reg significantly improves generalization performance and outperforms rehearsal-based approaches in several CL scenarios. It is also robust to natural and adversarial corruptions with less task-recency bias. Additionally, we provide theoretical insights to support our design decisions further.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-imGl7xItqQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/imGl7xItqQ.html">A Lennard-Jones Layer for Distribution Normalization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mulun Na &middot; Jonathan Klein &middot; Biao Zhang &middot; Wojtek Palubicki &middot; Soren Pirk &middot; Dominik Michels</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-imGl7xItqQ"></div>

    <a href="paper_pages/imGl7xItqQ.html">
        <img src="http://img.youtube.com/vi/XlLpASZ2QE4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-imGl7xItqQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-imGl7xItqQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-imGl7xItqQ">
                Abstract <i id="caret-imGl7xItqQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-imGl7xItqQ">
        <div class="abstract-display">
            <p>We introduce the Lennard-Jones layer (LJL) for the equalization of the density of 2D and 3D point clouds through systematically rearranging points without destroying their overall structure (distribution normalization). LJL simulates a dissipative process of repulsive and weakly attractive interactions between individual points by considering the nearest neighbor of each point at a given moment in time. This pushes the particles into a potential valley, reaching a well-defined stable configuration that approximates an equidistant sampling after the stabilization process. We apply LJLs to redistribute randomly generated point clouds into a randomized uniform distribution. Moreover, LJLs are embedded in the generation process of point cloud networks by adding them at later stages of the inference process. The improvements in 3D point cloud generation utilizing LJLs are evaluated qualitatively and quantitatively. Finally, we apply LJLs to improve the point distribution of a score-based 3D point cloud denoising network. In general, we demonstrate that LJLs are effective for distribution normalization which can be applied at negligible cost without retraining the given neural network.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-kfhoeZCeW7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/kfhoeZCeW7.html">Fine-tuning can cripple your foundation model; preserving features may be the solution</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jishnu Mukhoti &middot; Yarin Gal &middot; Philip Torr &middot; Puneet K. Dokania</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-kfhoeZCeW7"></div>

    <a href="paper_pages/kfhoeZCeW7.html">
        <img src="http://img.youtube.com/vi/VVG_KWi-BSM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-kfhoeZCeW7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-kfhoeZCeW7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-kfhoeZCeW7">
                Abstract <i id="caret-kfhoeZCeW7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-kfhoeZCeW7">
        <div class="abstract-display">
            <p>Pre-trained foundation models, due to their enormous capacity and exposure to vast amounts of data during pre-training, are known to have learned plenty of real-world concepts. An important step in making these pre-trained models effective on downstream tasks is to fine-tune them on related datasets. While various fine-tuning methods have been devised and have been shown to be highly effective, we observe that a fine-tuned model's ability to recognize concepts on tasks different from the downstream one is reduced significantly compared to its pre-trained counterpart. This is an undesirable effect of fine-tuning as a substantial amount of resources was used to learn these pre-trained concepts in the first place. We call this phenomenon "concept forgetting'' and via experiments show that most end-to-end fine-tuning approaches suffer heavily from this side effect. To this end, we propose a simple fix to this problem by designing a new fine-tuning method called LDIFS (short for $\ell_2$ distance in feature space) that, while learning new concepts related to the downstream task, allows a model to preserve its pre-trained knowledge as well. Through extensive experiments on 10 fine-tuning tasks we show that LDIFS significantly reduces concept forgetting. Additionally, we show that LDIFS is highly effective in performing continual fine-tuning on a sequence of tasks as well, in comparison with both fine-tuning as well as continual learning baselines.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-iulMde3dP1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/iulMde3dP1.html">What Has Been Overlooked in Contrastive Source-Free Domain Adaptation: Leveraging Source-Informed Latent Augmentation within Neighborhood Context</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wang &middot; Wonho Bae &middot; Jiahong Chen &middot; Kuangen Zhang &middot; Leonid Sigal &middot; Clarence W. de Silva</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-iulMde3dP1"></div>

    <a href="paper_pages/iulMde3dP1.html">
        <img src="http://img.youtube.com/vi/A0YLvomkOwU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-iulMde3dP1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-iulMde3dP1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-iulMde3dP1">
                Abstract <i id="caret-iulMde3dP1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-iulMde3dP1">
        <div class="abstract-display">
            <p>Source-free domain adaptation (SFDA) involves adapting a model originally trained using a labeled dataset (source domain) to perform effectively on an unlabeled dataset (target domain) without relying on any source data during adaptation. This adaptation is especially crucial when significant disparities in data distributions exist between the two domains and when there are privacy concerns regarding the source model's training data. The absence of access to source data during adaptation makes it challenging to analytically estimate the domain gap. To tackle this issue, various techniques have been proposed, such as unsupervised clustering, contrastive learning, and continual learning. In this paper, we first conduct an extensive theoretical analysis of SFDA based on contrastive learning, primarily because it has demonstrated superior performance compared to other techniques. Motivated by the obtained insights, we then introduce a straightforward yet highly effective latent augmentation method tailored for contrastive SFDA. This augmentation method leverages the dispersion of latent features within the neighborhood of the query sample, guided by the source pre-trained model, to enhance the informativeness of positive keys. Our approach, based on a single InfoNCE-based contrastive loss, outperforms state-of-the-art SFDA methods on widely recognized benchmark datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VzKXbCzNoU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VzKXbCzNoU.html">Efficient Parallelized Simulation of Cyber-Physical Systems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bas van der Heijden &middot; Laura Ferranti &middot; Jens Kober &middot; Robert Babuska</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VzKXbCzNoU"></div>

    <a href="paper_pages/VzKXbCzNoU.html">
        <img src="http://img.youtube.com/vi/I-1asHKBX6o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VzKXbCzNoU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VzKXbCzNoU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VzKXbCzNoU">
                Abstract <i id="caret-VzKXbCzNoU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VzKXbCzNoU">
        <div class="abstract-display">
            <p>Advancements in accelerated physics simulations have greatly reduced training times for reinforcement learning policies, yet the conventional step-by-step agent-simulator interaction undermines simulation accuracy. In the real-world, interactions are asynchronous, with sensing, acting and processing happening simultaneously. Failing to capture this widens the sim2real gap and results in suboptimal real-world performance. In this paper, we address the challenges of simulating realistic asynchronicity and delays within parallelized simulations, crucial to bridging the sim2real gap in complex cyber-physical systems. Our approach efficiently parallelizes cyber-physical system simulations on accelerator hardware, including physics, sensors, actuators, processing components and their asynchronous interactions. We extend existing accelerated physics simulations with latency simulation capabilities by constructing a `supergraph' that encodes all data dependencies across parallelized simulation steps, ensuring accurate simulation. By finding the smallest supergraph, we minimize redundant computation. We validate our approach on two real-world systems and perform an extensive ablation, demonstrating superior performance compared to baseline methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-RA4yRhjoXw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/RA4yRhjoXw.html">***FastDoc***: Domain-Specific Fast Continual Pre-training Technique using Document-Level Metadata and Taxonomy</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Abhilash Nandy &middot; Manav Nitin Kapadnis &middot; Sohan Patnaik &middot; Yash Parag Butala &middot; Pawan Goyal &middot; Niloy Ganguly</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-RA4yRhjoXw"></div>

    <a href="paper_pages/RA4yRhjoXw.html">
        <img src="https://drive.google.com/thumbnail?id=1ENnNnCpv_QCyUHmsAaDU0eteTOHIAwwg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-RA4yRhjoXw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-RA4yRhjoXw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-RA4yRhjoXw">
                Abstract <i id="caret-RA4yRhjoXw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-RA4yRhjoXw">
        <div class="abstract-display">
            <p>In this paper, we propose FastDoc (Fast Continual Pre-training Technique using Document Level Metadata and Taxonomy), a novel, compute-efficient framework that utilizes Document metadata and Domain-Specific Taxonomy as supervision signals to continually pre-train transformer encoder on a domain-specific corpus. The main innovation is that during domain-specific pretraining, an open-domain encoder is continually pre-trained using sentence-level embeddings as inputs (to accommodate long documents), however, fine-tuning is done with token-level embeddings as inputs to this encoder. We perform such domain-specific pre-training on three different domains namely customer support, scientific, and legal domains, and compare performance on 6 different downstream tasks and 9 different datasets. The novel use of document-level supervision along with sentence-level embedding input for pre-training reduces pre-training compute by around 1,000, 4,500, and 500 times compared to MLM and/or NSP in Customer Support, Scientific, and Legal Domains, respectively. The reduced training time does not lead to a deterioration in performance. In fact we show that FastDoc either outperforms or performs on par with several competitive transformer-based baselines in terms of character-level F1 scores and other automated metrics in the Customer Support, Scientific, and Legal Domains. Moreover, reduced training aids in mitigating the risk of catastrophic forgetting. Thus, unlike baselines, FastDoc shows a negligible drop in performance on open domain.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-CrpDwMFgxr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/CrpDwMFgxr.html">Linear Bandits with Memory</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Giulia Clerici &middot; Pierre Laforgue &middot; NicolÃ² Cesa-Bianchi</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-CrpDwMFgxr"></div>

    <a href="paper_pages/CrpDwMFgxr.html">
        <img src="http://img.youtube.com/vi/zJxDpa7dfYE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-CrpDwMFgxr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-CrpDwMFgxr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-CrpDwMFgxr">
                Abstract <i id="caret-CrpDwMFgxr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-CrpDwMFgxr">
        <div class="abstract-display">
            <p>Nonstationary phenomena, such as satiation effects in recommendations, have mostly been modeled using bandits with finitely many arms. However, the richer action space provided by linear bandits is often preferred in practice. In this work, we introduce a novel nonstationary linear bandit model, where current rewards are influenced by the learner's past actions in a fixed-size window. Our model, which recovers stationary linear bandits as a special case, leverages two parameters: the window size $m \ge 0$, and an exponent $\gamma$ that captures the rotting ($\gamma < 0)$ or rising ($\gamma > 0$) nature of the phenomenon. When both $m$ and $\gamma$ are known, we propose and analyze a variant of OFUL which minimizes regret against cyclic policies. By choosing the cycle length so as to trade-off approximation and estimation errors, we then prove a bound of order $\sqrt{d}\,(m+1)^{\frac{1}{2}+\max\{\gamma,0\}}\,T^{3/4}$ (ignoring log factors) on the regret against the optimal sequence of actions, where $T$ is the horizon and $d$ is the dimension of the linear action space. Through a bandit model selection approach, our results are then extended to the case where both $m$ and $\gamma$ are unknown. Finally, we complement our theoretical results with experiments comparing our approach to natural baselines.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-epcLNhkoEL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/epcLNhkoEL.html">Fixed Budget Best Arm Identification in Unimodal Bandits</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Debamita Ghosh &middot; Manjesh Kumar Hanawal &middot; Nikola Zlatanov</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-epcLNhkoEL"></div>

    <a href="paper_pages/epcLNhkoEL.html">
        <img src="https://drive.google.com/thumbnail?id=12DEUiyK-rFvhnR_sr5EE25x1Qs1p94UZ" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-epcLNhkoEL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-epcLNhkoEL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-epcLNhkoEL">
                Abstract <i id="caret-epcLNhkoEL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-epcLNhkoEL">
        <div class="abstract-display">
            <p>We consider the best arm identification problem in a fixed budget stochastic multi-armed bandit in which arm means exhibit unimodal structure, i.e., there is only one local maximum. We establish that the probability of misidentifying the optimal arm within a budget of $T$ is lower bounded as $\mathcal{O}\left(\exp\left\{-T/\bar{H}\right\}\right)$, where $\bar{H}$ depends on the sub-optimality gaps of arms in the neighborhood of the optimal arm. % where $\bar{H}\leq 2\Delta^{-2}$. In contrast to the lower bound for the unstructured case, the error exponent in this bound does not depend on the number of arms $K$ and is smaller by a factor $\log K$, which captures the gain achievable by exploiting the unimodal structure. We then develop an algorithm named {\it Fixed Budget Best Arm Unimodal Bandits ( FB-BAUB)} that exploits unimodality to achieve the gain. Specifically, we show that the error probability of \algo{} is upper bounded as $\mathcal{O}\left(\log_2 K\exp\left\{-T\Delta^2\right\}\right)$, where $\Delta$ is the gap between the neighboring arms and $\bar{H}\leq 2\Delta^{-2}$. We demonstrate that \algo{} outperforms the state-of-the-art algorithms through extensive simulations. Moreover, \algo{} is parameter-free and simple to implement.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-thfoUZugvS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/thfoUZugvS.html">Koopman Spectrum Nonlinear Regulators and Efficient Online Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Motoya Ohnishi &middot; Isao Ishikawa &middot; Kendall Lowrey &middot; Masahiro Ikeda &middot; Sham M. Kakade &middot; Yoshinobu Kawahara</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-thfoUZugvS"></div>

    <a href="paper_pages/thfoUZugvS.html">
        <img src="http://img.youtube.com/vi/uYLgQObi9P8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-thfoUZugvS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-thfoUZugvS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-thfoUZugvS">
                Abstract <i id="caret-thfoUZugvS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-thfoUZugvS">
        <div class="abstract-display">
            <p>Most modern reinforcement learning algorithms optimize a cumulative single-step cost along a trajectory.  The optimized motions are often âunnaturalâ, representing, for example, behaviors with sudden accelerations that waste energy and lack predictability.  In this work, we present a novel paradigm of controlling nonlinear systems via the minimization of the Koopman spectrum cost: a cost over the Koopman operator of the controlled dynamics.  This induces a broader class of dynamical behaviors that evolve over stable manifolds such as nonlinear oscillators, closed loops, and smooth movements.   We demonstrate that some dynamics characterizations that are not possible with a cumulative cost are feasible in this paradigm, which generalizes the classical eigenstructure and pole assignments to nonlinear decision making.   Moreover, we present a sample efficient online learning algorithm for our problem that enjoys a sub-linear regret bound under some structural assumptions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-wczqrpOrIc">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/wczqrpOrIc.html">LeanVec: Searching vectors faster by making them fit</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mariano Tepper &middot; Ishwar Singh Bhati &middot; Cecilia Aguerrebere &middot; Mark Hildebrand &middot; Theodore L. Willke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-wczqrpOrIc"></div>

    <a href="paper_pages/wczqrpOrIc.html">
        <img src="http://img.youtube.com/vi/-o1K3mwQE78/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-wczqrpOrIc" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-wczqrpOrIc" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-wczqrpOrIc">
                Abstract <i id="caret-wczqrpOrIc" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-wczqrpOrIc">
        <div class="abstract-display">
            <p>Modern deep learning models have the ability to generate high-dimensional vectors whose similarity reflects semantic resemblance.
Thus, similarity search, i.e., the operation of retrieving those vectors in a large collection that are similar to a given query, has become a critical component of a wide range of applications that demand highly accurate and timely answers. In this setting, the high vector dimensionality puts similarity search systems under compute and memory pressure, leading to subpar performance.
Additionally, cross-modal retrieval tasks have become increasingly common, e.g., where a user inputs a text query to find the most relevant images for that query. However, these queries often have different distributions than the database embeddings, making it challenging to achieve high accuracy. In this work, we present LeanVec, a framework that combines linear dimensionality reduction with vector quantization to accelerate similarity search on high-dimensional vectors while maintaining accuracy. We present LeanVec variants for in-distribution (ID) and out-of-distribution (OOD) queries. LeanVec-ID yields accuracies on par with those from recently introduced deep learning alternatives whose computational overhead precludes their usage in practice. LeanVec-OOD uses a novel technique for dimensionality reduction that considers the query and database distributions to simultaneously boost the accuracy and the performance of the framework even further (even presenting competitive results when the query and database distributions match). All in all, our extensive and varied experimental results show that LeanVec produces state-of-the-art results, with up to 3.7x improvement in search throughput and up to 4.9x faster index build time over the state of the art.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-KLojVqdj2y">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/KLojVqdj2y.html">Training Graph Neural Networks Subject to a Tight Lipschitz Constraint</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Simona Ioana Juvina &middot; Ana Antonia NeacÈu &middot; JÃ©rÃ´me Rony &middot; Jean-Christophe Pesquet &middot; Corneliu Burileanu &middot; Ismail Ben Ayed</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-KLojVqdj2y"></div>

    <a href="paper_pages/KLojVqdj2y.html">
        <img src="http://img.youtube.com/vi/_4AI1BmUnLo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-KLojVqdj2y" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-KLojVqdj2y" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-KLojVqdj2y">
                Abstract <i id="caret-KLojVqdj2y" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-KLojVqdj2y">
        <div class="abstract-display">
            <p>We propose a strategy for training a wide range of graph neural networks (GNNs) under tight Lipschitz bound constraints. 
Specifically, by leveraging graph spectral theory, we derive computationally tractable expressions of a tight Lipschitz constant. This allows us to propose a constrained-optimization approach to control the constant, ensuring robustness to adversarial perturbations. Unlike the existing methods for controlling the Lipschitz constant, our approach reduces the size of the handled matrices by a factor equal to the square of the number of nodes in the graph. We employ a stochastic projected subgradient algorithm, which operates in a block-coordinate manner, with the projection step performed via an accelerated iterative proximal algorithm.
We focus on defending against attacks that perturb features while keeping the topology of the graph constant. This contrasts with most of the existing defenses, which tackle perturbations of the graph structure. We report experiments on various datasets in the context of node classification tasks, showing the effectiveness of our constrained GNN model.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-o5kYH7bNe3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/o5kYH7bNe3.html">VisionAD, a software package of performant anomaly detection algorithms, and Proportion Localised, an interpretable metric</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander D. J. Taylor &middot; Phillip Tregidgo &middot; Jonathan James Morrison &middot; Neill D. F. Campbell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-o5kYH7bNe3"></div>

    <a href="paper_pages/o5kYH7bNe3.html">
        <img src="http://img.youtube.com/vi/tUqyAjONy8s/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-o5kYH7bNe3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-o5kYH7bNe3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-o5kYH7bNe3">
                Abstract <i id="caret-o5kYH7bNe3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-o5kYH7bNe3">
        <div class="abstract-display">
            <p>We release VisionAD, an anomaly detection library in the domain of images. The library forms the largest and most performant collection of such algorithms to date. Each algorithm is written through a standardised API, for ease of use. The library has a focus on fair benchmarking intended to mitigate the issue of cherry-picked results. It enables rapid experimentation and straightforward integration of new algorithms. In addition, we propose a new metric, Proportion Localised (PL). This reports the proportion of anomalies that are sufficiently localised via classifying each discrete anomaly as localised or not. The metric is far more intuitive as it has a real physical relation, meaning it is attractive to industry-based professionals. We also release the VisionADIndustrial (VADI) benchmark, a thorough benchmarking of the top anomaly detection algorithms. This benchmark calculates the mean across the pooled classes of the MVTec and VisA datasets. We are committed to hosting an updated version of this leaderboard online, and encourage researchers to add, tweak and improve algorithms to climb this leaderboard. VisionAD code is found at https://github.com/alext1995/VisionAD, and Proportion Localised code is found at https://github.com/alext1995/proportion_localised.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xNkASJL0F6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xNkASJL0F6.html">Dynamic Structure Estimation from Bandit Feedback using Nonvanishing Exponential Sums</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Motoya Ohnishi &middot; Isao Ishikawa &middot; Yuko Kuroki &middot; Masahiro Ikeda</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xNkASJL0F6"></div>

    <a href="paper_pages/xNkASJL0F6.html">
        <img src="http://img.youtube.com/vi/FpzWNtYQoBM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xNkASJL0F6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xNkASJL0F6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xNkASJL0F6">
                Abstract <i id="caret-xNkASJL0F6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xNkASJL0F6">
        <div class="abstract-display">
            <p>This work tackles the dynamic structure estimation problems for periodically behaved discrete dynamical system in the Euclidean space.  We assume the observations become sequentially available in a form of bandit feedback contaminated by a sub-Gaussian noise.  Under such fairly general assumptions on the noise distribution, we carefully identify a set of recoverable information of periodic structures.  Our main results are the (computation and sample) efficient algorithms that exploit asymptotic behaviors of exponential sums to effectively average out the noise effect while preventing the information to be estimated from vanishing.  In particular, the novel use of the Weyl sum, a variant of exponential sums, allows us to extract spectrum information for linear systems.  We provide sample complexity bounds for our algorithms, and we experimentally validate our theoretical claims on simulations of toy examples, including Cellular Automata.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zn3fB4VVF0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zn3fB4VVF0.html">Navigating Noise: A Study of How Noise Influences Generalisation and Calibration of Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Martin Ferianc &middot; Ondrej Bohdal &middot; Timothy Hospedales &middot; Miguel R. D. Rodrigues</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zn3fB4VVF0"></div>

    <a href="paper_pages/zn3fB4VVF0.html">
        <img src="http://img.youtube.com/vi/fvKvDGZdGL0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zn3fB4VVF0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zn3fB4VVF0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zn3fB4VVF0">
                Abstract <i id="caret-zn3fB4VVF0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zn3fB4VVF0">
        <div class="abstract-display">
            <p>Enhancing the generalisation abilities of neural networks (NNs) through integrating noise such as MixUp or Dropout during training has emerged as a powerful and adaptable technique. Despite the proven efficacy of noise in NN training, there is no consensus regarding which noise sources, types and placements yield maximal benefits in generalisation and confidence calibration. This study thoroughly explores diverse noise modalities to evaluate their impacts on NN's generalisation and calibration under in-distribution or out-of-distribution settings, paired with experiments investigating the metric landscapes of the learnt representations, across a spectrum of NN architectures, tasks, and datasets. Our study shows that AugMix and weak augmentation exhibit cross-task effectiveness in computer vision, emphasising the need to tailor noise to specific domains. Our findings emphasise the efficacy of combining noises and successful hyperparameter transfer within a single domain but the difficulties in transferring the benefits to other domains. Furthermore, the study underscores the complexity of simultaneously optimising for both generalisation and calibration, emphasising the need for practitioners to carefully consider noise combinations and hyperparameter tuning for optimal performance in specific tasks and datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-N0Sc0KY0AH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/N0Sc0KY0AH.html">Improving Subgraph-GNNs via Edge-Level Ego-Network Encodings</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nurudin Alvarez-Gonzalez &middot; Andreas Kaltenbrunner &middot; VicenÃ§ GÃ³mez</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-N0Sc0KY0AH"></div>

    <a href="paper_pages/N0Sc0KY0AH.html">
        <img src="http://img.youtube.com/vi/nlYwZ8FF9vI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-N0Sc0KY0AH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-N0Sc0KY0AH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-N0Sc0KY0AH">
                Abstract <i id="caret-N0Sc0KY0AH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-N0Sc0KY0AH">
        <div class="abstract-display">
            <p>We present a novel edge-level ego-network encoding for learning on graphs that can boost Message Passing Graph Neural Networks (MP-GNNs) by providing additional node and edge features or extending message-passing formats. The proposed encoding is sufficient to distinguish Strongly Regular Graphs, a family of challenging 3-WL equivalent graphs. We show theoretically that such encoding is more expressive than node-based sub-graph MP-GNNs. In an empirical evaluation on four benchmarks with 10 graph datasets, our results match or improve previous baselines on expressivity, graph classification, graph regression, and proximity tasks---while reducing memory usage by 18.1x in certain real-world settings.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3nprbNR3HB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3nprbNR3HB.html">ASPEST: Bridging the Gap Between Active Learning and Selective Prediction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jiefeng Chen &middot; Jinsung Yoon &middot; Sayna Ebrahimi &middot; Sercan O Arik &middot; Somesh Jha &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3nprbNR3HB"></div>

    <a href="paper_pages/3nprbNR3HB.html">
        <img src="https://drive.google.com/thumbnail?id=1mEZ1O_b6PKGBR2Tw3VTOpzUCDN6IiiZH" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3nprbNR3HB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3nprbNR3HB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3nprbNR3HB">
                Abstract <i id="caret-3nprbNR3HB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3nprbNR3HB">
        <div class="abstract-display">
            <p>Selective prediction aims to learn a reliable model that abstains from making predictions when uncertain. These predictions can then be deferred to humans for further evaluation. As an everlasting challenge for machine learning, in many real-world scenarios, the distribution of test data is different from the training data. This results in more inaccurate predictions, and often increased dependence on humans, which can be difficult and expensive. Active learning aims to lower the overall labeling effort, and hence human dependence, by querying the most informative examples. Selective prediction and active learning have been approached from different angles, with the connection between them missing. In this work, we introduce a new learning paradigm, active selective prediction, which aims to query more informative samples from the shifted target domain while increasing accuracy and coverage. For this new paradigm, we propose a simple yet effective approach, ASPEST, that utilizes ensembles of model snapshots with self-training with their aggregated outputs as pseudo labels. Extensive experiments on numerous image, text and structured datasets, which suffer from domain shifts, demonstrate that ASPEST can significantly outperform prior work on selective prediction and active learning (e.g. on the MNIST$\to$SVHN benchmark with the labeling budget of 100, ASPEST improves the AUACC metric from 79.36% to 88.84%) and achieves more optimal utilization of humans in the loop.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HVxumpoWBm">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HVxumpoWBm.html">One by One, Continual Coordinating with Humans via Hyper-Teammate Identification</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Cong Guan &middot; Feng Chen &middot; Ke Xue &middot; Chunpeng Fan &middot; Lichao Zhang &middot; Ziqian Zhang &middot; Pengyao Zhao &middot; Zongzhang Zhang &middot; Chao Qian &middot; Lei Yuan &middot; Yang Yu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HVxumpoWBm"></div>

    <a href="paper_pages/HVxumpoWBm.html">
        <img src="video_thumbnails/HVxumpoWBm.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HVxumpoWBm" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HVxumpoWBm" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HVxumpoWBm">
                Abstract <i id="caret-HVxumpoWBm" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HVxumpoWBm">
        <div class="abstract-display">
            <p>One of the primary objectives in modern artificial intelligence researches is to empower  agents to effectively coordinate with diverse teammates, particularly human teammates. Previous studies focused on training agents either with a fixed population of pre-generated teammates or through the co-evolution of distinct populations of agents and teammates. However, it is challenging to enumerate all possible teammates in advance, and it is costly, or even impractical to maintain such a sufficiently diverse population and repeatedly interact with previously encountered teammates. Additional design considerations, such as prioritized sampling, are also required to ensure efficient training. To address these challenges and obtain an efficient human-AI coordination paradigm, we propose a novel approach called \textbf{Concord}. Considering that human participants tend to occur in a sequential manner, we model the training process with different teammates as a continual learning framework, akin to how humans learn and adapt in the real world.  We propose a mechanism based on hyper-teammate identification to prevent catastrophic forgetting while promoting forward knowledge transfer.  Concretely, we introduce a teammate recognition module that captures the identification of corresponding teammates. Leveraging the identification, a well-coordinated AI policy can be generated via the hyper-network. The entire framework is trained in a decomposed policy gradient manner,  allowing for effective credit assignment among agents. This approach enables us to train agents with each generated teammate or humans one by one, ensuring that agents can coordinate effectively with concurrent teammates without forgetting previous knowledge. Our approach outperforms multiple baselines in various multi-agent benchmarks, either with generated human proxies or real human participants.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YCgX7sJRF1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YCgX7sJRF1.html">Adapting Contrastive Language-Image Pretrained (CLIP) Models for Out-of-Distribution Detection</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nikolas Adaloglou &middot; Felix Michels &middot; Tim Kaiser &middot; Markus Kollmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YCgX7sJRF1"></div>

    <a href="paper_pages/YCgX7sJRF1.html">
        <img src="http://img.youtube.com/vi/eVUKVfxpx8A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YCgX7sJRF1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YCgX7sJRF1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YCgX7sJRF1">
                Abstract <i id="caret-YCgX7sJRF1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YCgX7sJRF1">
        <div class="abstract-display">
            <p>We present a comprehensive experimental study on pre-trained feature extractors for visual out-of-distribution (OOD) detection, focusing on leveraging contrastive language-image pre-trained (CLIP) models. Without fine-tuning on the training data, we are able to establish a positive correlation ($R^2\geq0.92$) between in-distribution classification and unsupervised OOD detection for CLIP models in $4$ benchmarks. We further propose a new simple and scalable method called \textit{pseudo-label probing} (PLP) that adapts vision-language models for OOD detection. Given a set of label names of the training set, PLP trains a linear layer using the pseudo-labels derived from the text encoder of CLIP. Intriguingly, we show that without modifying the weights of CLIP or training additional image/text encoders (i) PLP outperforms the previous state-of-the-art on all $5$ large-scale benchmarks based on ImageNet, specifically by an average AUROC gain of 3.4\% using the largest CLIP model (ViT-G), (ii) linear probing outperforms fine-tuning by large margins for CLIP architectures (i.e. CLIP ViT-H achieves a mean gain of 7.3\% AUROC on average on all ImageNet-based benchmarks), and (iii) billion-parameter CLIP models still fail at detecting feature-based adversarially manipulated OOD images. The code is available at https://github.com/HHU-MMBS/plp-official-tmlr2024.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-N05OnQG1BA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/N05OnQG1BA.html">CoDeC: Communication-Efficient Decentralized Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sakshi Choudhary &middot; Sai Aparna Aketi &middot; Gobinda Saha &middot; Kaushik Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-N05OnQG1BA"></div>

    <a href="paper_pages/N05OnQG1BA.html">
        <img src="https://drive.google.com/thumbnail?id=1UPp5btj8j_JziRPeyWbEB6f7y_KBFsZY" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-N05OnQG1BA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-N05OnQG1BA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-N05OnQG1BA">
                Abstract <i id="caret-N05OnQG1BA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-N05OnQG1BA">
        <div class="abstract-display">
            <p>Training at the edge utilizes continuously evolving data generated at different locations. Privacy concerns prohibit the co-location of this spatially as well as temporally distributed data, deeming it crucial to design training algorithms that enable efficient continual learning
over decentralized private data. Decentralized learning allows serverless training with spatially distributed data. A fundamental barrier in such setups is the high bandwidth cost of communicating model updates between agents. Moreover, existing works under this training paradigm are not inherently suitable for learning a temporal sequence of tasks while retaining the previously acquired knowledge. In this work, we propose CoDeC, a novel communication-efficient decentralized continual learning algorithm that addresses these challenges. We mitigate catastrophic forgetting while learning a distributed task sequence by incorporating orthogonal gradient projection within a gossip-based decentralized learning algorithm. Further, CoDeC includes a novel lossless communication compression scheme based on the gradient subspaces. We theoretically analyze the convergence rate for our algorithm and demonstrate through an extensive set of experiments that CoDeC successfully learns distributed continual tasks with minimal forgetting. The proposed compression scheme results in up to 4.8Ã reduction in communication costs without any loss in performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-iwCBWULItx">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/iwCBWULItx.html">DeepReShape: Redesigning  Neural Networks for Efficient Private Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nandan Kumar Jha &middot; Brandon Reagen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-iwCBWULItx"></div>

    <a href="paper_pages/iwCBWULItx.html">
        <img src="https://drive.google.com/thumbnail?id=17byDYNIuiAYvdTQJJDv29UnK7XdCdwHQ" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-iwCBWULItx" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-iwCBWULItx" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-iwCBWULItx">
                Abstract <i id="caret-iwCBWULItx" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-iwCBWULItx">
        <div class="abstract-display">
            <p>Prior work on Private Inference (PI)---inferences performed directly on encrypted input---has focused on minimizing a network's ReLUs, which have been assumed to dominate PI latency rather than FLOPs. Recent work has shown that FLOPs for PI can no longer be ignored and incur high latency penalties. In this paper, we develop DeepReShape, a technique that optimizes neural network architectures under PI's constraints, optimizing for both ReLUs {\em and} FLOPs for the first time. The key insight is strategically allocating channels to position the network's ReLUs in order of their criticality to network accuracy, simultaneously optimizes ReLU and FLOPs efficiency. DeepReShape automates network development with an efficient process, and we call generated networks HybReNets. We evaluate DeepReShape using standard PI benchmarks and demonstrate a  2.1% accuracy gain with a 5.2$\times$ runtime improvement at iso-ReLU on CIFAR-100 and an 8.7$\times$ runtime improvement at iso-accuracy on TinyImageNet. Furthermore, we investigate the significance of network selection in prior ReLU optimizations and shed light on the key network attributes for superior PI performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-hFALpTb4fR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/hFALpTb4fR.html">LLM-grounded Diffusion: Enhancing Prompt Understanding of Text-to-Image Diffusion Models with Large Language Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Long Lian &middot; Boyi Li &middot; Adam Yala &middot; Trevor Darrell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-hFALpTb4fR"></div>

    <a href="paper_pages/hFALpTb4fR.html">
        <img src="video_thumbnails/hFALpTb4fR.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-hFALpTb4fR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-hFALpTb4fR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-hFALpTb4fR">
                Abstract <i id="caret-hFALpTb4fR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-hFALpTb4fR">
        <div class="abstract-display">
            <p>Recent advancements in text-to-image diffusion models have yielded impressive results in generating realistic and diverse images. However, these models still struggle with complex prompts, such as those that involve numeracy and spatial reasoning. This work proposes to enhance prompt understanding capabilities in diffusion models. Our method leverages a pretrained large language model (LLM) for grounded generation in a novel two-stage process. In the first stage, the LLM generates a scene layout that comprises captioned bounding boxes from a given prompt describing the desired image. In the second stage, a novel controller guides an off-the-shelf diffusion model for layout-grounded image generation. Both stages utilize existing pretrained models without additional model parameter optimization. Our method significantly outperforms the base diffusion model and several strong baselines in accurately generating images according to prompts that require various capabilities, doubling the generation accuracy across four tasks on average. Furthermore, our method enables instruction-based multi-round scene specification and can handle prompts in languages not supported by the underlying diffusion model. We anticipate that our method will unleash users' creativity by accurately following more complex prompts. Our code, demo, and benchmark are available at: https://llm-grounded-diffusion.github.io</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oYIjw37pTP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oYIjw37pTP.html">An optimal control perspective on diffusion-based generative modeling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Julius Berner &middot; Lorenz Richter &middot; Karen Ullrich</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oYIjw37pTP"></div>

    <a href="paper_pages/oYIjw37pTP.html">
        <img src="http://img.youtube.com/vi/wQpQg1xIlBA/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oYIjw37pTP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oYIjw37pTP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oYIjw37pTP">
                Abstract <i id="caret-oYIjw37pTP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oYIjw37pTP">
        <div class="abstract-display">
            <p>We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton--Jacobi--Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback--Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ux9BrxPCl8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ux9BrxPCl8.html">Grokking Beyond Neural Networks: An Empirical Exploration with Model Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jack William Miller &middot; Charles O'Neill &middot; Thang D Bui</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ux9BrxPCl8"></div>

    <a href="paper_pages/ux9BrxPCl8.html">
        <img src="http://img.youtube.com/vi/--RAHz68f3c/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ux9BrxPCl8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ux9BrxPCl8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ux9BrxPCl8">
                Abstract <i id="caret-ux9BrxPCl8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ux9BrxPCl8">
        <div class="abstract-display">
            <p>In some settings neural networks exhibit a phenomenon known as \textit{grokking}, where they achieve perfect or near-perfect accuracy on the validation set long after the same performance has been achieved on the training set. In this paper, we discover that grokking is not limited to neural networks but occurs in other settings such as Gaussian process (GP) classification, GP regression, linear regression and Bayesian neural networks. We also uncover a mechanism by which to induce grokking on algorithmic datasets via the addition of dimensions containing spurious information. The presence of the phenomenon in non-neural architectures shows that grokking is not restricted to settings considered in current theoretical and empirical studies. Instead, grokking may be possible in any model where solution search is guided by complexity and error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Jy2IgzjoFH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Jy2IgzjoFH.html">Hierarchical Neural Simulation-Based Inference Over Event Ensembles</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lukas Heinrich &middot; Siddharth Mishra-Sharma &middot; Chris Pollard &middot; Philipp Windischhofer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Jy2IgzjoFH"></div>

    <a href="paper_pages/Jy2IgzjoFH.html">
        <img src="video_thumbnails/Jy2IgzjoFH.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Jy2IgzjoFH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Jy2IgzjoFH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Jy2IgzjoFH">
                Abstract <i id="caret-Jy2IgzjoFH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Jy2IgzjoFH">
        <div class="abstract-display">
            <p>When analyzing real-world data it is common to work with event ensembles, which comprise sets of observations that collectively constrain the parameters of an underlying model of interest. Such models often have a hierarchical structure, where ``local'' parameters impact individual events and ``global'' parameters influence the entire dataset. We introduce practical approaches for frequentist and Bayesian dataset-wide probabilistic inference in cases where the likelihood is intractable, but simulations can be realized via a hierarchical forward model. We construct neural estimators for the likelihood(-ratio) or posterior and show that explicitly accounting for the model's hierarchical structure can lead to significantly tighter parameter constraints. We ground our discussion using case studies from the physical sciences, focusing on examples from particle physics and cosmology.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-yUmJ483OB0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/yUmJ483OB0.html">Predictive Pipelined Decoding: A Compute-Latency Trade-off for Exact LLM Decoding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Seongjun Yang &middot; Gibbeum Lee &middot; Jaewoong Cho &middot; Dimitris Papailiopoulos &middot; Kangwook Lee</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-yUmJ483OB0"></div>

    <a href="paper_pages/yUmJ483OB0.html">
        <img src="https://drive.google.com/thumbnail?id=1QHLv7n0iEdqyeyJz4Mh57WEH8cThZiaW" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-yUmJ483OB0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-yUmJ483OB0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-yUmJ483OB0">
                Abstract <i id="caret-yUmJ483OB0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-yUmJ483OB0">
        <div class="abstract-display">
            <p>This paper presents Predictive Pipelined Decoding (PPD), an approach that speeds up decoding in Large Language Models (LLMs) while maintaining the exact same output as the original decoding. Unlike conventional strategies, PPD employs additional compute resources to parallelize the initiation of subsequent token decoding during the current token decoding. This method reduces decoding latency and reshapes the understanding of trade-offs in LLM decoding strategies. We have developed a theoretical framework that allows us to analyze the trade-off between computation and latency. Using this framework, we can analytically estimate the potential reduction in latency associated with our proposed method, achieved through the assessment of the match rate, represented as $p_\text{correct}$. The results demonstrate that the use of extra computational resources has the potential to accelerate LLM decoding. Additionally, we implement PPD and conduct preliminary experiments to empirically validate its efficacy, addressing potential practical overheads not covered by theoretical analysis.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Nzy0XmCPuZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Nzy0XmCPuZ.html">Rotate the ReLU to Sparsify Deep Networks Implicitly</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nancy Nayak &middot; Sheetal Kalyani</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Nzy0XmCPuZ"></div>

    <a href="paper_pages/Nzy0XmCPuZ.html">
        <img src="http://img.youtube.com/vi/tLxNTUXtfyI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Nzy0XmCPuZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Nzy0XmCPuZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Nzy0XmCPuZ">
                Abstract <i id="caret-Nzy0XmCPuZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Nzy0XmCPuZ">
        <div class="abstract-display">
            <p>Compact and energy-efficient models have become essential in this era when deep learning-based solutions are widely used for various real-life tasks. In this paper, we propose rotating the ReLU activation to give an additional degree of freedom in conjunction with the appropriate initialization of the rotation. This combination leads to implicit sparsification without the use of a regularizer. We show that this rotated ReLU (RReLU) activation improves the representation capability of the parameters/filters in the network and eliminates those parameters/filters that are not crucial for the task, giving rise to significant savings in memory and computation. While the state-of-the-art regularization-based Network-Slimming method achieves $32.33\%$ saving in memory and $26.38\%$ saving in computation with ResNet-$164$, RReLU achieves a saving of $35.92\%$ in memory and $25.97\%$ in the computation with a better accuracy. The savings in memory and computation further increase by $64.67\%$ and $52.96\%$, respectively, with the introduction of $L_1$ regularization to the RReLU slopes. We note that the slopes of the rotated ReLU activations act as coarse feature extractors and can eliminate unnecessary features before retraining. Our studies indicate that features always choose to pass through a lesser number of filters. We demonstrate the results with popular datasets such as MNIST, CIFAR-10, CIFAR-100, SVHN, and Imagenet with different architectures, including Vision Transformers and EfficientNet. We also briefly study the impact of adversarial attacks on RReLU-based ResNets and observe that we get better adversarial accuracy for the architectures with RReLU than ReLU. We also demonstrate how this concept of rotation can be applied to the GELU and SiLU activation functions, commonly utilized in Transformer and EfficientNet architectures, respectively. The proposed method can be utilized by combining with other structural pruning methods resulting in better sparsity. For the GELU-based multi-layer perceptron (MLP) part of the Transformer, we obtain $2.6\%$ improvement in accuracy with $6.32\%$ saving in both memory and computation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Wqn8zirthg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Wqn8zirthg.html">DDLP: Unsupervised Object-centric Video Prediction with Deep Dynamic Latent Particles</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tal Daniel &middot; Aviv Tamar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Wqn8zirthg"></div>

    <a href="paper_pages/Wqn8zirthg.html">
        <img src="http://img.youtube.com/vi/3S2pKhi_ewY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Wqn8zirthg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Wqn8zirthg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Wqn8zirthg">
                Abstract <i id="caret-Wqn8zirthg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Wqn8zirthg">
        <div class="abstract-display">
            <p>We propose a new object-centric video prediction algorithm based on the deep latent particle (DLP) representation of Daniel and Tamar (2022). In comparison to existing slot- or patch-based representations, DLPs model the scene using a set of keypoints with learned parameters for properties such as position and size, and are both efficient and interpretable. Our method, \textit{deep dynamic latent particles} (DDLP), yields state-of-the-art object-centric video prediction results on several challenging datasets. The interpretable nature of DDLP allows us to perform ``what-if'' generation -- predict the consequence of changing properties of objects in the initial frames, and DLP's compact structure enables efficient diffusion-based unconditional video generation. Videos, code and pre-trained models are available: https://taldatech.github.io/ddlp-web</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tP1PBrMUlX">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tP1PBrMUlX.html">Synthesizing Libraries of Programs with Auxiliary Functions</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Habibur Rahman &middot; Thirupathi Reddy Emireddy &middot; Kenneth Tjhia &middot; Elham Parhizkar &middot; Levi Lelis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tP1PBrMUlX"></div>

    <a href="paper_pages/tP1PBrMUlX.html">
        <img src="http://img.youtube.com/vi/SJAAMtyqqnE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tP1PBrMUlX" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tP1PBrMUlX" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tP1PBrMUlX">
                Abstract <i id="caret-tP1PBrMUlX" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tP1PBrMUlX">
        <div class="abstract-display">
            <p>A common approach to program synthesis is to use a learned function to guide the search for a program that satisfies the user's intent. In this paper, we propose a method that offers search guidance, through a domain-dependent auxiliary function, that can be orthogonal to the guidance previous functions provide. Our method, which we call Auxiliary-Based Library Learning (Aulile), searches for a solution in the program space using a base algorithm. If this search does not produce a solution, Aulile enhances the language with a library of programs discovered in the search that optimizes for the auxiliary function. Then, it repeats the search with this library-augmented language. This process is repeated until a solution is found or the system reaches a timeout. We evaluate Aulile in string manipulation tasks. Aulile improved, in some cases by a large margin, the performance of several base algorithms that use different search and learning strategies: Bus, Bustle, Crossbeam, and Bee Search. Our results suggest that Aulile offers an effective method of injecting domain knowledge into existing systems through a library learning scheme that optimizes for an auxiliary function.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-7yswRA8zzw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/7yswRA8zzw.html">Pull-back Geometry of Persistent Homology Encodings</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shuang Liang &middot; Renata Turkes &middot; Jiayi Li &middot; Nina Otter &middot; Guido Montufar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-7yswRA8zzw"></div>

    <a href="paper_pages/7yswRA8zzw.html">
        <img src="http://img.youtube.com/vi/q4DctLOZZTs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-7yswRA8zzw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-7yswRA8zzw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-7yswRA8zzw">
                Abstract <i id="caret-7yswRA8zzw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-7yswRA8zzw">
        <div class="abstract-display">
            <p>Persistent homology (PH) is a method for generating topology-inspired representations of data. Empirical studies that investigate the properties of PH, such as its sensitivity to perturbations or ability to detect a feature of interest, commonly rely on training and testing an additional model on the basis of the PH representation. To gain more intrinsic insights about PH, independently of the choice of such a model, we propose a novel methodology based on the pull-back geometry that a PH encoding induces on the data manifold. The spectrum and eigenvectors of the induced metric help to identify the most and least significant information captured by PH. Furthermore, the pull-back norm of tangent vectors provides insights about the sensitivity of PH to a given perturbation, or its potential to detect a given feature of interest, and in turn its ability to solve a given classification or regression problem. Experimentally, the insights gained through our methodology align well with the existing knowledge about PH. Moreover, we show that the pull-back norm correlates with the performance on downstream tasks, and can therefore guide the choice of a suitable PH encoding.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YY2iA0hfia">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YY2iA0hfia.html">Does Representation Similarity Capture Function Similarity?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lucas Hayne &middot; Heejung Jung &middot; R. Carter</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YY2iA0hfia"></div>

    <a href="paper_pages/YY2iA0hfia.html">
        <img src="http://img.youtube.com/vi/9m9f45_72B0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YY2iA0hfia" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YY2iA0hfia" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YY2iA0hfia">
                Abstract <i id="caret-YY2iA0hfia" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YY2iA0hfia">
        <div class="abstract-display">
            <p>Representation similarity metrics are widely used to compare learned representations in neural networks, as is evident in extensive literature investigating metrics that accurately capture information encoded in representations. However, aiming to capture all of the information available in representations may have little to do with what information is actually used by the downstream network. One solution is to experiment with interventions on network function. By ablating groups of units thought to carry information and observing whether those ablations affect network performance, we can focus on an outcome that mechanistically links representations to function. In this paper, we systematically test representation similarity metrics to evaluate their sensitivity to functional changes induced by ablation. We use network performance changes after ablation as a way to measure the influence of representation on function. These measures of function allow us to test how well similarity metrics capture changes in network performance versus changes to linear decodability. Network performance measures index the information used by the downstream network, while linear decoding methods index available information in the representation. We show that all of the tested metrics are more sensitive to decodable features than network performance. When comparing these metrics, Procrustes and CKA outperform regularized CCA-based methods on average. Although Procrustes and CKA outperform on average, these metrics have a diminished advantage when looking at network performance. We provide ablation tests of the utility of different representational similarity metrics. Our results suggest that interpretability methods will be more effective if they are based on representational similarity metrics that have been evaluated using ablation tests.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0T2OTVCCC1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0T2OTVCCC1.html">Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">William Andersson &middot; Jakob Heiss &middot; Florian Krach &middot; Josef Teichmann</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0T2OTVCCC1"></div>

    <a href="paper_pages/0T2OTVCCC1.html">
        <img src="http://img.youtube.com/vi/PSglx3a3bBI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0T2OTVCCC1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0T2OTVCCC1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0T2OTVCCC1">
                Abstract <i id="caret-0T2OTVCCC1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0T2OTVCCC1">
        <div class="abstract-display">
            <p>The \emph{Path-Dependent Neural Jump Ordinary Differential Equation (PD-NJ-ODE)} is a model for predicting continuous-time stochastic processes with irregular and incomplete observations. In particular, the method learns optimal forecasts given irregularly sampled time series of incomplete past observations. So far the process itself and the coordinate-wise observation times were assumed to be independent and observations were assumed to be noiseless. In this work we discuss two extensions to lift these restrictions and provide theoretical guarantees as well as empirical examples for them. In particular, we can lift the assumption of independence by extending the theory to much more realistic settings of conditional independence without any need to change the algorithm. Moreover, we introduce a new loss function, which allows us to deal with noisy observations and explain why the previously used loss function did not lead to a consistent estimator.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9TqAUYB6tC">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9TqAUYB6tC.html">Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pulkit Gopalani &middot; Samyak Jha &middot; Anirbit Mukherjee</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9TqAUYB6tC"></div>

    <a href="paper_pages/9TqAUYB6tC.html">
        <img src="http://img.youtube.com/vi/aFZFph-k-EM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9TqAUYB6tC" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9TqAUYB6tC" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9TqAUYB6tC">
                Abstract <i id="caret-9TqAUYB6tC" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9TqAUYB6tC">
        <div class="abstract-display">
            <p>In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data with any number of gates with adequately smooth and bounded activations, like sigmoid and tanh, and for a class of distributions from which the initial weight is sampled. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show that the logistic loss function on any size neural net can be Frobenius norm regularized by a width-independent parameter such that the regularized loss is a ``Villani function'' -- and thus be able to build on recent progress with analyzing SGD on such objectives.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-uxNfN2PU1W">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/uxNfN2PU1W.html">Effective Latent Differential Equation Models via Attention and Multiple Shooting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">GermÃ¡n Abrevaya &middot; Mahta Ramezanian-Panahi &middot; Jean-Christophe Gagnon-Audet &middot; Pablo Polosecki &middot; Irina Rish &middot; Silvina Ponce Dawson &middot; Guillermo Cecchi &middot; Guillaume Dumas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-uxNfN2PU1W"></div>

    <a href="paper_pages/uxNfN2PU1W.html">
        <img src="http://img.youtube.com/vi/XYv10fuumCQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-uxNfN2PU1W" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-uxNfN2PU1W" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-uxNfN2PU1W">
                Abstract <i id="caret-uxNfN2PU1W" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-uxNfN2PU1W">
        <div class="abstract-display">
            <p>Scientific Machine Learning (SciML) is a burgeoning field that synergistically combines domain-aware and interpretable models with agnostic machine learning techniques. In this work, we introduce GOKU-UI, an evolution of the SciML generative model GOKU-nets. GOKU-UI not only broadens the original model's spectrum to incorporate other classes of differential equations, such as Stochastic Differential Equations (SDEs), but also integrates attention mechanisms and a novel multiple shooting training strategy in the latent space. These modifications have led to a significant increase in its performance in both reconstruction and forecast tasks, as demonstrated by our evaluation on simulated and empirical data. Specifically, GOKU-UI outperformed all baseline models on synthetic datasets even with a training set 16-fold smaller, underscoring its remarkable data efficiency. Furthermore, when applied to empirical human brain data, while incorporating stochastic Stuart-Landau oscillators into its dynamical core, our proposed enhancements markedly increased the model's effectiveness in capturing complex brain dynamics. GOKU-UI demonstrated a reconstruction error five times lower than other baselines, and the multiple shooting method reduced the GOKU-nets prediction error for future brain activity up to 15 seconds ahead. By training GOKU-UI on resting state fMRI data, we encoded whole-brain dynamics into a latent representation, learning a low-dimensional dynamical system model that could offer insights into brain functionality and open avenues for practical applications such as the classification of mental states or psychiatric conditions. Ultimately, our research provides further impetus for the field of Scientific Machine Learning, showcasing the potential for advancements when established scientific insights are interwoven with modern machine learning.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Uv3XVAEgG6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Uv3XVAEgG6.html">Kernel Normalized Convolutional Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reza Nasirigerdeh &middot; Reihaneh Torkzadehmahani &middot; Daniel Rueckert &middot; Georgios Kaissis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Uv3XVAEgG6"></div>

    <a href="paper_pages/Uv3XVAEgG6.html">
        <img src="http://img.youtube.com/vi/V7fQTc6MNSE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Uv3XVAEgG6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Uv3XVAEgG6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Uv3XVAEgG6">
                Abstract <i id="caret-Uv3XVAEgG6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Uv3XVAEgG6">
        <div class="abstract-display">
            <p>Existing convolutional neural network architectures frequently rely upon batch normalization (BatchNorm) to effectively train the model. BatchNorm, however, performs poorly with small batch sizes, and is inapplicable to differential privacy. To address these limitations, we propose the kernel normalization (KernelNorm) and kernel normalized convolutional layers, and incorporate them into kernel normalized convolutional networks (KNConvNets) as the main building blocks. We implement KNConvNets corresponding to the state-of-the-art ResNets while forgoing the BatchNorm layers. Through extensive experiments, we illustrate that KNConvNets achieve higher or competitive performance compared to the BatchNorm counterparts in image classification and semantic segmentation. They also significantly outperform their batch-independent competitors including those based on layer and group normalization in non-private and differentially private training. Given that, KernelNorm combines the batch-independence property of layer and group normalization with the performance advantage of BatchNorm.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-75OwvzZZBT">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/75OwvzZZBT.html">Bias Amplification Enhances Minority Group Performance</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gaotang Li &middot; Jiarui Liu &middot; Wei Hu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-75OwvzZZBT"></div>

    <a href="paper_pages/75OwvzZZBT.html">
        <img src="http://img.youtube.com/vi/SOze6QxCPgw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-75OwvzZZBT" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-75OwvzZZBT" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-75OwvzZZBT">
                Abstract <i id="caret-75OwvzZZBT" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-75OwvzZZBT">
        <div class="abstract-display">
            <p>Neural networks produced by standard training are known to suffer from poor accuracy on rare subgroups despite achieving high accuracy on average, due to the correlations between certain spurious features and labels. Previous approaches based on worst-group loss minimization (e.g. Group-DRO) are effective in improving worse-group accuracy but require expensive group annotations for all the training samples. In this paper, we focus on the more challenging and realistic setting where group annotations are only available on a small validation set or are not available at all. We propose BAM, a novel two-stage training algorithm: in the first stage, the model is trained using a bias amplification scheme via introducing a learnable auxiliary variable for each training sample; in the second stage, we upweight the samples that the bias-amplified model misclassifies, and then continue training the same model on the reweighted dataset. Empirically, BAM achieves competitive performance compared with existing methods evaluated on spurious correlation benchmarks in computer vision and natural language processing. Moreover, we find a simple stopping criterion based on minimum class accuracy difference that can remove the need for group annotations, with little or no loss in worst-group accuracy. We perform extensive analyses and ablations to verify the effectiveness and robustness of our algorithm in varying class and group imbalance ratios.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-eN9CjU3h1b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/eN9CjU3h1b.html">MMD-Regularized Unbalanced Optimal Transport</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Piyushi Manupriya &middot; SakethaNath Jagarlapudi &middot; Pratik Jawanpuria</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-eN9CjU3h1b"></div>

    <a href="paper_pages/eN9CjU3h1b.html">
        <img src="http://img.youtube.com/vi/FSJ4_GfLhHo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-eN9CjU3h1b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-eN9CjU3h1b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-eN9CjU3h1b">
                Abstract <i id="caret-eN9CjU3h1b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-eN9CjU3h1b">
        <div class="abstract-display">
            <p>We study the unbalanced optimal transport (UOT) problem, where the marginal constraints are enforced using Maximum Mean Discrepancy (MMD) regularization. Our work is motivated by the observation that the literature on UOT is focused on regularization based on $\phi$-divergence (e.g., KL divergence). Despite the popularity of MMD, its role as a regularizer in the context of UOT seems less understood. We begin by deriving a specific dual of MMD-regularized UOT (MMD-UOT), which helps us prove several useful properties. One interesting outcome of this duality result is that MMD-UOT induces novel metrics, which not only lift the ground metric like the Wasserstein but are also sample-wise efficient to estimate like the MMD. Further, for real-world applications involving non-discrete measures, we present an estimator for the transport plan that is supported only on the given ($m$) samples. Under certain conditions, we prove that the estimation error with this finitely-supported transport plan is also $\mathcal{O}(1/\sqrt{m})$. As far as we know, such error bounds that are free from the curse of dimensionality are not known for $\phi$-divergence regularized UOT. Finally, we discuss how the proposed estimator can be computed efficiently using accelerated gradient descent. Our experiments show that MMD-UOT consistently outperforms popular baselines, including KL-regularized UOT and MMD, in diverse machine learning applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-H2EeStRTQn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/H2EeStRTQn.html">Introducing "Forecast Utterance" for Conversational Data Science</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Md. Mahadi Hassan &middot; Alex Knipper &middot; Shubhra Kanti Karmaker Santu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-H2EeStRTQn"></div>

    <a href="paper_pages/H2EeStRTQn.html">
        <img src="http://img.youtube.com/vi/oAJwaVVJPI4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-H2EeStRTQn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-H2EeStRTQn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-H2EeStRTQn">
                Abstract <i id="caret-H2EeStRTQn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-H2EeStRTQn">
        <div class="abstract-display">
            <p>Envision an intelligent agent capable of assisting users in conducting forecasting tasks through intuitive, natural conversations, without requiring in-depth knowledge of the underlying machine learning (ML) processes. A significant challenge for the agent in this endeavor is to accurately comprehend the user's prediction goals and, consequently, formulate precise ML tasks. In this paper, we take a pioneering step towards this ambitious goal by introducing a new concept called Forecast Utterance and then focus on the automatic and accurate interpretation of users' prediction goals from these utterances. Specifically, we frame the task as a slot-filling problem, where each slot corresponds to a specific aspect of the goal prediction task. We then employ two zero-shot methods for solving the slot-filling task, namely: 1) Entity Extraction (EE), and 2) Question-Answering (QA) techniques. Our experiments, evaluated with three meticulously crafted data sets, validate the viability of our ambitious goal and demonstrate the effectiveness of both EE and QA techniques in interpreting Forecast Utterances.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dUVejidXO7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dUVejidXO7.html">Visual Prompt Based Personalized Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Guanghao Li &middot; Wansen Wu &middot; Yan Sun &middot; Li Shen &middot; Baoyuan Wu &middot; Dacheng Tao</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dUVejidXO7"></div>

    <a href="paper_pages/dUVejidXO7.html">
        <img src="http://img.youtube.com/vi/kzBMpZ7od1k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dUVejidXO7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dUVejidXO7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dUVejidXO7">
                Abstract <i id="caret-dUVejidXO7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dUVejidXO7">
        <div class="abstract-display">
            <p>As a popular paradigm of distributed learning, personalized federated learning (PFL) allows personalized models to improve generalization ability and robustness by utilizing knowledge from all distributed clients. Most existing PFL algorithms tackle personalization in a model-centric way, such as personalized layer partition, model regularization, and model interpolation, which all fail to take into account the data characteristics of distributed clients. In this paper, we propose a novel PFL framework for image classification tasks, dubbed pFedPT, that leverages personalized visual prompts to implicitly represent local data distribution information of clients and provides that information to the aggregation model to help with classification tasks. Specifically, in each round of pFedPT training, each client generates a local personalized prompt related to local data distribution. Then, the local model is trained on the input composed of raw data and a visual prompt to learn the distribution information contained in the prompt. During model testing, the aggregated model obtains client-specific knowledge of the data distributions based on the prompts, which can be seen as an adaptive fine-tuning of the aggregation model to improve model performances on different clients. Furthermore, the visual prompt can be added as an orthogonal method to implement personalization on the client for existing FL methods to boost their performance. Experiments on the CIFAR10 and CIFAR100 datasets show that pFedPT outperforms several state-of-the-art (SOTA) PFL algorithms by a large margin in various settings. The code is available at: https://github.com/hkgdifyu/pFedPT.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-n2YifD4Dxo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/n2YifD4Dxo.html">Are you using test log-likelihood correctly?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sameer Deshpande &middot; Soumya Ghosh &middot; Tin D. Nguyen &middot; Tamara Broderick</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-n2YifD4Dxo"></div>

    <a href="paper_pages/n2YifD4Dxo.html">
        <img src="https://drive.google.com/thumbnail?id=10Hg_OBUU52ARiWjDJK7q6fYHU74my8vX" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-n2YifD4Dxo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-n2YifD4Dxo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-n2YifD4Dxo">
                Abstract <i id="caret-n2YifD4Dxo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-n2YifD4Dxo">
        <div class="abstract-display">
            <p>Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JllRdycmLk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JllRdycmLk.html">The (Un)Scalability of Informed Heuristic Function Estimation in NP-Hard Search Problems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sumedh Pendurkar &middot; Taoan Huang &middot; Brendan Juba &middot; Jiapeng Zhang &middot; Sven Koenig &middot; Guni Sharon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JllRdycmLk"></div>

    <a href="paper_pages/JllRdycmLk.html">
        <img src="http://img.youtube.com/vi/jc4YN-Nt1RU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JllRdycmLk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JllRdycmLk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JllRdycmLk">
                Abstract <i id="caret-JllRdycmLk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JllRdycmLk">
        <div class="abstract-display">
            <p>The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with a completely informed heuristic function, A* can solve such problems in time complexity that is polynomial in the solution cost and branching factor. In light of this fact, we examine a line of recent publications that propose fitting deep neural networks to the completely informed heuristic function. We assert that these works suffer from inherent scalability limitations since --- under the assumption of NP $\not \subseteq$ P/poly --- such approaches result in either (a) network sizes that scale super-polynomially in the instance sizes or (b) the accuracy of the fitted deep neural networks scales inversely with the instance sizes. Complementing our theoretical claims, we provide experimental results for three representative NP-hard search problems. The results suggest that fitting deep neural networks to informed heuristic functions requires network sizes that grow quickly with the problem instance size. We conclude by suggesting that the research community should focus on scalable methods for integrating heuristic search with machine learning, as opposed to methods relying on informed heuristic estimation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jesKcQxQ7j">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jesKcQxQ7j.html">A Review of the Applications of Deep Learning-Based Emergent Communication</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Brendon Boldt &middot; David R Mortensen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jesKcQxQ7j"></div>

    <a href="paper_pages/jesKcQxQ7j.html">
        <img src="http://img.youtube.com/vi/vkL-hRSuWfk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jesKcQxQ7j" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jesKcQxQ7j" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jesKcQxQ7j">
                Abstract <i id="caret-jesKcQxQ7j" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jesKcQxQ7j">
        <div class="abstract-display">
            <p>Emergent communication, or emergent language, is the field of research which studies how human language-like communication systems emerge de novo in deep multi-agent reinforcement learning environments. The possibilities of replicating the emergence of a complex behavior like language have strong intuitive appeal, yet it is necessary to complement this with clear notions of how such research can be applicable to other fields of science, technology, and engineering. This paper comprehensively reviews the applications of emergent communication research across machine learning, natural language processing, linguistics, and cognitive science. Each application is illustrated with a description of its scope, an explication of emergent communication's unique role in addressing it, a summary of the extant literature working towards the application, and brief recommendations for near-term research directions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oyfRWeoUJY">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oyfRWeoUJY.html">Addressing caveats of neural persistence with deep graph persistence</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Leander Girrbach &middot; Anders Christensen &middot; Ole Winther &middot; Zeynep Akata &middot; A. Sophia Koepke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oyfRWeoUJY"></div>

    <a href="paper_pages/oyfRWeoUJY.html">
        <img src="http://img.youtube.com/vi/KfCpoPYK_CY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oyfRWeoUJY" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oyfRWeoUJY" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oyfRWeoUJY">
                Abstract <i id="caret-oyfRWeoUJY" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oyfRWeoUJY">
        <div class="abstract-display">
            <p>Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at  https://github.com/ExplainableML/Deep-Graph-Persistence.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4uflhObpcp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4uflhObpcp.html">UnIVAL: Unified Model for Image, Video, Audio and Language Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mustafa Shukor &middot; Corentin Dancette &middot; Alexandre Rame &middot; Matthieu Cord</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4uflhObpcp"></div>

    <a href="paper_pages/4uflhObpcp.html">
        <img src="http://img.youtube.com/vi/mYOun92st08/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4uflhObpcp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4uflhObpcp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4uflhObpcp">
                Abstract <i id="caret-4uflhObpcp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4uflhObpcp">
        <div class="abstract-display">
            <p>Large Language Models (LLMs) have made the ambitious quest for generalist agents significantly far from being a fantasy. A key hurdle for building such general models is the diversity and heterogeneity of tasks and modalities. A promising solution is unification, allowing the support of a myriad of tasks and modalities within one unified framework. While few large models (e.g., Flamingo (Alayrac et al. 2022)), trained on massive datasets, can support more than two modalities, current small to mid-scale unified models are still limited to 2 modalities, usually image-text or video-text. The question that we ask is: is it possible to build efficiently a unified model that can support all modalities? To answer this, we propose UnIVAL, a step further towards this ambitious goal. Without relying on fancy datasets sizes or models with billions of parameters, the ~ 0.25B parameter UnIVAL model goes beyond two modalities and unifies text, images, video, and audio into a single model. Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning. UnIVAL shows competitive performance to existing state-of-the-art approaches, across image and video-text tasks. The feature representations learned from image and video-text modalities,  allows the model to achieve competitive performance when finetuned on audio-text tasks, despite not being pretrained on audio. Thanks to the unified model, we propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-of-distribution generalization. Finally, we motivate unification by showing the synergy between tasks. The model weights and code are available at: https://github.com/mshukor/UnIVAL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lTOku838Zv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lTOku838Zv.html">Neural Implicit Manifold Learning for Topology-Aware Density Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Brendan Leigh Ross &middot; Gabriel Loaiza-Ganem &middot; Anthony L. Caterini &middot; Jesse C. Cresswell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lTOku838Zv"></div>

    <a href="paper_pages/lTOku838Zv.html">
        <img src="http://img.youtube.com/vi/f1a_8LoyZxw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lTOku838Zv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lTOku838Zv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lTOku838Zv">
                Abstract <i id="caret-lTOku838Zv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lTOku838Zv">
        <div class="abstract-display">
            <p>Natural data observed in $\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\mathcal{M}$, where $m < n$. This work focuses on the task of building theoretically principled generative models for such data. Current generative models learn $\mathcal{M}$ by mapping an $m$-dimensional latent variable through a neural network $f_\theta: \mathbb{R}^m \to \mathbb{R}^n$. These procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. We then learn the probability density within $\mathcal{M}$ with a constrained energy-based model, which employs a constrained variant of Langevin dynamics to train and sample from the learned manifold. In experiments on synthetic and natural data, we show that our model can learn manifold-supported distributions with complex topologies more accurately than pushforward models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-igDOV2KBwM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/igDOV2KBwM.html">On Perfect Clustering for Gaussian Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Juan Cuesta-Albertos &middot; Subhajit Dutta</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-igDOV2KBwM"></div>

    <a href="paper_pages/igDOV2KBwM.html">
        <img src="http://img.youtube.com/vi/NkV7sgdMioE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-igDOV2KBwM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-igDOV2KBwM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-igDOV2KBwM">
                Abstract <i id="caret-igDOV2KBwM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-igDOV2KBwM">
        <div class="abstract-display">
            <p>In this paper, we propose a data based transformation for infinite-dimensional Gaussian processes and derive its limit theorem. For a clustering problem using mixture models, an appropriate modification of this transformation asymptotically leads to perfect separation of the populations under rather general conditions, except the scenario in which differences between clusters depend only on the locations; in which case our procedure is useless. Theoretical properties related to label consistency are studied for the k-means clustering algorithm when used on this transformed data. Good empirical performance of the proposed methodology is demonstrated using simulated as well as benchmark data sets, when compared with some popular parametric and nonparametric methods for such functional data.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Q4aAITDgdP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Q4aAITDgdP.html">Learn the Time to Learn: Replay Scheduling in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Marcus Klasson &middot; Hedvig Kjellstrom &middot; Cheng Zhang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Q4aAITDgdP"></div>

    <a href="paper_pages/Q4aAITDgdP.html">
        <img src="http://img.youtube.com/vi/huCX46HqMl4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Q4aAITDgdP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Q4aAITDgdP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Q4aAITDgdP">
                Abstract <i id="caret-Q4aAITDgdP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Q4aAITDgdP">
        <div class="abstract-display">
            <p>Replay methods are known to be successful at mitigating catastrophic forgetting in continual learning scenarios despite having limited access to historical data. However, storing historical data is cheap in many real-world settings, yet replaying all historical data is often prohibited due to processing time constraints. In such settings, we propose that continual learning systems should learn the time to learn and schedule which tasks to replay at different time steps. We first demonstrate the benefits of our proposal by using Monte Carlo tree search to find a proper replay schedule, and show that the found replay schedules can outperform fixed scheduling policies when combined with various replay methods in different continual learning settings. Additionally, we propose a framework for learning replay scheduling policies with reinforcement learning. We show that the learned policies can generalize better in new continual learning scenarios compared to equally replaying all seen tasks, without added computational cost. Our study reveals the importance of learning the time to learn in continual learning, which brings current research closer to real-world needs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-RyZB4qXEgt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/RyZB4qXEgt.html">Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vincent Abbott</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-RyZB4qXEgt"></div>

    <a href="paper_pages/RyZB4qXEgt.html">
        <img src="http://img.youtube.com/vi/ghlIs8bVXU4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-RyZB4qXEgt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-RyZB4qXEgt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-RyZB4qXEgt">
                Abstract <i id="caret-RyZB4qXEgt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-RyZB4qXEgt">
        <div class="abstract-display">
            <p>Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation.

In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oud7Ny0KQy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oud7Ny0KQy.html">RIFLE: Imputation and Robust Inference from Low Order Marginals</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sina Baharlouei &middot; Sze-Chuan Suen &middot; Meisam Razaviyayn</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oud7Ny0KQy"></div>

    <a href="paper_pages/oud7Ny0KQy.html">
        <img src="http://img.youtube.com/vi/hS9d7RS7TBQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oud7Ny0KQy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oud7Ny0KQy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oud7Ny0KQy">
                Abstract <i id="caret-oud7Ny0KQy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oud7Ny0KQy">
        <div class="abstract-display">
            <p>The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for predicting the target variable in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. We compare RIFLE with state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) in numerical experiments. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-leqr0vQzeN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/leqr0vQzeN.html">A Robust Backpropagation-Free Framework for Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Timothy Zee &middot; Alex Ororbia &middot; Ankur Mali &middot; Ifeoma Nwogu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-leqr0vQzeN"></div>

    <a href="paper_pages/leqr0vQzeN.html">
        <img src="http://img.youtube.com/vi/bVOzZjMxGzo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-leqr0vQzeN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-leqr0vQzeN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-leqr0vQzeN">
                Abstract <i id="caret-leqr0vQzeN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-leqr0vQzeN">
        <div class="abstract-display">
            <p>While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients that are computed by backpropagation of errors (backprop). Gradients are required to obtain synaptic weight adjustments but require knowledge of feed forward activities in order to conduct backward propagation, a biologically implausible process. This is known as the "weight transport problem''. Therefore, in this work, we present a more biologically plausible approach towards solving the weight transport problem for image data. This approach, which we name the error-kernel driven activation alignment (EKDAA) algorithm, accomplishes through the introduction of locally derived error transmission kernels and error maps. Like standard deep learning networks, EKDAA performs the standard forward process via weights and activation functions; however, its backward error computation involves adaptive error kernels that propagate local error signals through the network. The efficacy of EKDAA is demonstrated by performing visual-recognition tasks on the Fashion MNIST, CIFAR-10 and SVHN benchmarks, along with demonstrating its ability to extract visual features from natural color images. Furthermore, in order to demonstrate its non-reliance on gradient computations, results are presented for an EKDAA-trained CNN that employs a non-differentiable activation function.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3taIQG4C7H">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3taIQG4C7H.html">Label Noise-Robust Learning using a Confidence-Based Sieving Strategy</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reihaneh Torkzadehmahani &middot; Reza Nasirigerdeh &middot; Daniel Rueckert &middot; Georgios Kaissis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3taIQG4C7H"></div>

    <a href="paper_pages/3taIQG4C7H.html">
        <img src="http://img.youtube.com/vi/LE9iD9hcAKc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3taIQG4C7H" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3taIQG4C7H" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3taIQG4C7H">
                Abstract <i id="caret-3taIQG4C7H" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3taIQG4C7H">
        <div class="abstract-display">
            <p>In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other state-of-the-art approaches, such as Co-teaching and DivideMix to further improve model performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4i1MXH8Sle">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4i1MXH8Sle.html">CAREER: A Foundation Model for Labor Sequence Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Keyon Vafa &middot; Emil Palikot &middot; Tianyu Du &middot; Ayush Kanodia &middot; Susan Athey &middot; David Blei</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4i1MXH8Sle"></div>

    <a href="paper_pages/4i1MXH8Sle.html">
        <img src="http://img.youtube.com/vi/BLgfbNeTLCI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4i1MXH8Sle" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4i1MXH8Sle" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4i1MXH8Sle">
                Abstract <i id="caret-4i1MXH8Sle" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4i1MXH8Sle">
        <div class="abstract-display">
            <p>Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-PEyVq0hlO3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/PEyVq0hlO3.html">Dual Cognitive Architecture: Incorporating Biases and Multi-Memory Systems for Lifelong Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shruthi Gowda &middot; Bahram Zonooz &middot; Elahe Arani</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-PEyVq0hlO3"></div>

    <a href="paper_pages/PEyVq0hlO3.html">
        <img src="http://img.youtube.com/vi/08tfpjvUGqs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-PEyVq0hlO3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-PEyVq0hlO3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-PEyVq0hlO3">
                Abstract <i id="caret-PEyVq0hlO3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-PEyVq0hlO3">
        <div class="abstract-display">
            <p>Artificial neural networks (ANNs) exhibit a narrow scope of expertise on stationary independent data. However, the data in the real world is continuous and dynamic, and ANNs must adapt to novel scenarios while also retaining the learned knowledge to become lifelong learners. The ability of humans to excel at these tasks can be attributed to multiple factors ranging from cognitive computational structures, cognitive biases, and the multi-memory systems in the brain. We incorporate key concepts from each of these to design a novel framework, Dual Cognitive Architecture (DUCA), which includes multiple sub-systems, implicit and explicit knowledge representation dichotomy, inductive bias, and a multi-memory system. DUCA shows improvement across different settings and datasets, and it also exhibits reduced task recency bias, without the need for extra information. To further test the versatility of lifelong learning methods on a challenging distribution shift, we introduce a novel domain-incremental dataset DN4IL. In addition to improving performance on existing benchmarks, DUCA also demonstrates superior performance on this complex dataset.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2uMnAwWnRy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2uMnAwWnRy.html">Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Lev Proleev &middot; Diana Mincu &middot; F Lee Hartsell &middot; Katherine A Heller &middot; Subhrajit Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2uMnAwWnRy"></div>

    <a href="paper_pages/2uMnAwWnRy.html">
        <img src="http://img.youtube.com/vi/sqDLDkbP2H0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2uMnAwWnRy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2uMnAwWnRy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2uMnAwWnRy">
                Abstract <i id="caret-2uMnAwWnRy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2uMnAwWnRy">
        <div class="abstract-display">
            <p>Multiple sclerosis is a disease that affects the brain and spinal cord, it can lead to severe disability and has no known cure. The majority of prior work in machine learning for multiple sclerosis has been centered around using Magnetic Resonance Imaging scans or laboratory tests; these modalities are both expensive to acquire and can be unreliable. In a recent paper it was shown that disease progression can be predicted effectively using performance outcome measures and demographic data. In our work we build on this to investigate the modeling side, using continuous time models to predict progression. We benchmark four continuous time models using a publicly available multiple sclerosis dataset. We find that the best continuous model is often able to outperform the best benchmarked discrete time model. We also carry out an extensive ablation to discover the sources of performance gains, we find that standardizing existing features leads to a larger performance increase than interpolating missing features.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-W0ehjkl9x7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/W0ehjkl9x7.html">DoCoM: Compressed Decentralized Optimization with Near-Optimal Sample Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chung-Yiu Yau &middot; Hoi To Wai</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-W0ehjkl9x7"></div>

    <a href="paper_pages/W0ehjkl9x7.html">
        <img src="http://img.youtube.com/vi/3ZNmkE9ryEs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-W0ehjkl9x7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-W0ehjkl9x7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-W0ehjkl9x7">
                Abstract <i id="caret-W0ehjkl9x7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-W0ehjkl9x7">
        <div class="abstract-display">
            <p>This paper proposes the Doubly Compressed Momentum-assisted stochastic gradient tracking algorithm (DoCoM) for communication-efficient decentralized optimization. The algorithm features two main ingredients to achieve a near-optimal sample complexity while allowing for communication compression. First, the algorithm tracks both the averaged iterate and stochastic gradient using compressed gossiping consensus. Second, a momentum step is incorporated for adaptive variance reduction with the local gradient estimates. We show that DoCoM finds a near-stationary solution at all participating agents satisfying $\mathbb{E}[ \| \nabla f( \theta ) \|^2 ] = {\cal O}( 1 / T^{2/3} )$ in $T$ iterations, where $f(\theta)$ is a smooth (possibly non-convex) objective function. Notice that the proof is achieved via analytically designing a new potential function that tightly tracks the one-iteration progress of DoCoM. As a corollary, our analysis also established the linear convergence of DoCoM to a global optimal solution for objective functions with the Polyak-Åojasiewicz condition. Numerical experiments demonstrate that our algorithm outperforms several state-of-the-art algorithms in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ySWQ6eXAKp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ySWQ6eXAKp.html">Not All Causal Inference is the Same</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej ZeÄeviÄ &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ySWQ6eXAKp"></div>

    <a href="paper_pages/ySWQ6eXAKp.html">
        <img src="http://img.youtube.com/vi/WSYtc-IUe3A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ySWQ6eXAKp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ySWQ6eXAKp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ySWQ6eXAKp">
                Abstract <i id="caret-ySWQ6eXAKp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ySWQ6eXAKp">
        <div class="abstract-display">
            <p>Neurally-parameterized Structural Causal Models in the Pearlian notion to causality, referred to as NCM, were recently introduced as a step towards next-generation learning systems. However, said NCM are only concerned with the learning aspect of causal inference
and totally miss out on the architecture aspect. That is, actual causal inference within NCM is intractable in that the NCM wonât return an answer to a query in polynomial time. This insight follows as corollary to the more general statement on the intractability of arbitrary structural causal model (SCM) parameterizations, which we prove in this work through classical 3-SAT reduction. Since future learning algorithms will be required to deal with both high dimensional data and highly complex mechanisms governing the data, we ultimately believe work on tractable inference for causality to be decisive. We also show that not all âcausalâ models are created equal. More specifically, there are models capable of answering causal queries that are not SCM, which we refer to as partially causal models
(PCM). We provide a tabular taxonomy in terms of tractability properties for all of the different model families, namely correlation-based, PCM and SCM. To conclude our work, we also provide some initial ideas on how to overcome parts of the intractability of causal inference
with SCM by showing an example of how parameterizing an SCM with SPN modules can at least allow for tractable mechanisms. With this work we hope that our insights can raise awareness for this novel research direction since achieving success with causality in real world downstream tasks will not only depend on learning correct models but also require having the practical ability to gain access to
model inferences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tv46tCzs83">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tv46tCzs83.html">Causal Parrots: Large Language Models May Talk Causality But Are Not Causal</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej ZeÄeviÄ &middot; Moritz Willig &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tv46tCzs83"></div>

    <a href="paper_pages/tv46tCzs83.html">
        <img src="http://img.youtube.com/vi/vbwrhbuvedE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tv46tCzs83" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tv46tCzs83" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tv46tCzs83">
                Abstract <i id="caret-tv46tCzs83" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tv46tCzs83">
        <div class="abstract-display">
            <p>Some argue scale is all what is needed to achieve AI, covering even causal models.
We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables.
We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained.
If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1irVjE7A3w">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1irVjE7A3w.html">Meta-Learning via Classifier(-free) Diffusion Guidance</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elvis Nava &middot; Seijin Kobayashi &middot; Yifei Yin &middot; Robert K. Katzschmann &middot; Benjamin F Grewe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1irVjE7A3w"></div>

    <a href="paper_pages/1irVjE7A3w.html">
        <img src="http://img.youtube.com/vi/O6lB2RaBh2k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1irVjE7A3w" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1irVjE7A3w" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1irVjE7A3w">
                Abstract <i id="caret-1irVjE7A3w" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1irVjE7A3w">
        <div class="abstract-display">
            <p>We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second "guidance" model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: "HyperCLIP"-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model ("HyperLDM"), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Tkvmt9nDmB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Tkvmt9nDmB.html">Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal Murali &middot; Aahlad Manas Puli &middot; Ke Yu &middot; Rajesh Ranganath &middot; kayhan Batmanghelich</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Tkvmt9nDmB"></div>

    <a href="paper_pages/Tkvmt9nDmB.html">
        <img src="http://img.youtube.com/vi/kkQ0IKukx5o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Tkvmt9nDmB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Tkvmt9nDmB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Tkvmt9nDmB">
                Abstract <i id="caret-Tkvmt9nDmB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Tkvmt9nDmB">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) are prone to learning spurious features that correlate with the label during training but are irrelevant to the learning problem. This hurts model generalization and poses problems when deploying them in safety-critical applications. This paper aims to better understand the effects of spurious features through the lens of the learning dynamics of the internal neurons during the training process. We make the following observations: (1) While previous works highlight the harmful effects of spurious features on the generalization ability of DNNs, we emphasize that not all spurious features are harmful. Spurious features can be "benign" or "harmful" depending on whether they are "harder" or "easier" to learn than the core features for a given model. This definition is model and dataset dependent. (2) We build upon this premise and use instance difficulty methods (like Prediction Depth) to quantify "easiness" for a given model and to identify this behavior during the training phase. (3) We empirically show that the harmful spurious features can be detected by observing the learning dynamics of the DNN's early layers. In other words, easy features learned by the initial layers of a DNN early during the training can (potentially) hurt model generalization. We verify our claims on medical and vision datasets, both simulated and real, and justify the empirical success of our hypothesis by showing the theoretical connections between Prediction Depth and information-theoretic concepts like $\mathcal{V}$-usable information. Lastly, our experiments show that monitoring only accuracy during training (as is common in machine learning pipelines) is insufficient to detect spurious features. We, therefore, highlight the need for monitoring early training dynamics using suitable instance difficulty metrics.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-pHCdMat0gI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/pHCdMat0gI.html">Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Antonio Longa &middot; Veronica Lachi &middot; Gabriele Santin &middot; Monica Bianchini &middot; Bruno Lepri &middot; Pietro Lio &middot; franco scarselli &middot; Andrea Passerini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-pHCdMat0gI"></div>

    <a href="paper_pages/pHCdMat0gI.html">
        <img src="http://img.youtube.com/vi/2ImatNxkKFY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-pHCdMat0gI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-pHCdMat0gI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-pHCdMat0gI">
                Abstract <i id="caret-pHCdMat0gI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-pHCdMat0gI">
        <div class="abstract-display">
            <p>Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y8RZoPjEUl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y8RZoPjEUl.html">Simulate Time-integrated Coarse-grained Molecular Dynamics with Multi-scale Graph Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xiang Fu &middot; Tian Xie &middot; Nathan J. Rebello &middot; Bradley Olsen &middot; Tommi S. Jaakkola</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y8RZoPjEUl"></div>

    <a href="paper_pages/y8RZoPjEUl.html">
        <img src="http://img.youtube.com/vi/l3aGVjQezsc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y8RZoPjEUl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y8RZoPjEUl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y8RZoPjEUl">
                Abstract <i id="caret-y8RZoPjEUl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y8RZoPjEUl">
        <div class="abstract-display">
            <p>Molecular dynamics (MD) simulation is essential for various scientific domains but computationally expensive. Learning-based force fields have made significant progress in accelerating ab-initio MD simulation but are not fast enough for many real-world applications due to slow inference for large systems and small time steps (femtosecond-level). We aim to address these challenges by learning a multi-scale graph neural network that directly simulates coarse-grained MD with a very large time step (nanosecond-level) and a novel refinement module based on diffusion models to mitigate simulation instability. The effectiveness of our method is demonstrated in two complex systems: single-chain coarse-grained polymers and multi-component Li-ion polymer electrolytes. For evaluation, we simulate trajectories much longer than the training trajectories for systems with different chemical compositions that the model is not trained on. Structural and dynamical properties can be accurately recovered at several orders of magnitude higher speed than classical force fields by getting out of the femtosecond regime. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-m8U9rSs6gU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/m8U9rSs6gU.html">Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Melika Behjati &middot; James Henderson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-m8U9rSs6gU"></div>

    <a href="paper_pages/m8U9rSs6gU.html">
        <img src="http://img.youtube.com/vi/KjAc20Co1Nk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-m8U9rSs6gU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-m8U9rSs6gU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-m8U9rSs6gU">
                Abstract <i id="caret-m8U9rSs6gU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-m8U9rSs6gU">
        <div class="abstract-display">
            <p>Characters do not convey meaning, but sequences of characters do.  We propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images.  We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers.  These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content, and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8L7Rh6FIXt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8L7Rh6FIXt.html">IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shivani Bathla &middot; Vinita Vasudevan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8L7Rh6FIXt"></div>

    <a href="paper_pages/8L7Rh6FIXt.html">
        <img src="http://img.youtube.com/vi/143xjwN-MSw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8L7Rh6FIXt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8L7Rh6FIXt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8L7Rh6FIXt">
                Abstract <i id="caret-8L7Rh6FIXt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8L7Rh6FIXt">
        <div class="abstract-display">
            <p>Exact computation of the partition function is known to be intractable, necessitating approximate inference techniques. Existing methods for approximate inference are slow to converge for many benchmarks. The control of accuracy-complexity trade-off is also non-trivial in many of these methods. We propose a novel  incremental build-infer-approximate (IBIA) framework for approximate inference that addresses these issues. In this framework, the probabilistic graphical model is converted into a  sequence of clique tree forests (SCTF) with bounded clique sizes.  We show that the SCTF can be used to efficiently compute the partition function. We propose two new algorithms which are used to construct the SCTF  and prove the correctness of both. The first is an algorithm for incremental construction of CTFs that is guaranteed to give a  valid CTF with bounded clique sizes and the second is an approximation algorithm that takes a calibrated CTF as input and yields a valid and calibrated CTF with reduced clique sizes as the output. We have evaluated our method using several benchmark sets from recent UAI competitions and our results show good accuracies with competitive runtimes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HqIuAzBxbh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HqIuAzBxbh.html">Consistent Collaborative Filtering via Tensor Decomposition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shiwen Zhao &middot; Guillermo Sapiro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HqIuAzBxbh"></div>

    <a href="paper_pages/HqIuAzBxbh.html">
        <img src="http://img.youtube.com/vi/MTHefLFLSZI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HqIuAzBxbh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HqIuAzBxbh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HqIuAzBxbh">
                Abstract <i id="caret-HqIuAzBxbh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HqIuAzBxbh">
        <div class="abstract-display">
            <p>Collaborative filtering is the de facto standard for analyzing usersâ activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zshemTAa6U">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zshemTAa6U.html">Test-Time Adaptation for Visual Document Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sayna Ebrahimi &middot; Sercan O Arik &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zshemTAa6U"></div>

    <a href="paper_pages/zshemTAa6U.html">
        <img src="video_thumbnails/zshemTAa6U.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zshemTAa6U" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zshemTAa6U" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zshemTAa6U">
                Abstract <i id="caret-zshemTAa6U" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zshemTAa6U">
        <div class="abstract-display">
            <p>For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\%  (ANLS score), respectively.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-f0FSDAy1bU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/f0FSDAy1bU.html">Faster Training of Neural ODEs Using GauÃâLegendre Quadrature</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-f0FSDAy1bU"></div>

    <a href="paper_pages/f0FSDAy1bU.html">
        <img src="http://img.youtube.com/vi/pKbLwsqy8aM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-f0FSDAy1bU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-f0FSDAy1bU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-f0FSDAy1bU">
                Abstract <i id="caret-f0FSDAy1bU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-f0FSDAy1bU">
        <div class="abstract-display">
            <p>Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using GauÃ-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VmyFF5lL3F">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VmyFF5lL3F.html">Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mauricio Delbracio &middot; Peyman Milanfar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VmyFF5lL3F"></div>

    <a href="paper_pages/VmyFF5lL3F.html">
        <img src="http://img.youtube.com/vi/_VfyR9ChOFk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VmyFF5lL3F" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VmyFF5lL3F" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VmyFF5lL3F">
                Abstract <i id="caret-VmyFF5lL3F" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VmyFF5lL3F">
        <div class="abstract-display">
            <p>Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.

Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically  an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality.

While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XNFo3dQiCJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XNFo3dQiCJ.html">Generalizability of Adversarial Robustness Under Distribution Shifts</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kumail Alhamoud &middot; Hasan Abed Al Kader Hammoud &middot; Motasem Alfarra &middot; Bernard Ghanem</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XNFo3dQiCJ"></div>

    <a href="paper_pages/XNFo3dQiCJ.html">
        <img src="http://img.youtube.com/vi/PL4PbCmjyno/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XNFo3dQiCJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XNFo3dQiCJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XNFo3dQiCJ">
                Abstract <i id="caret-XNFo3dQiCJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XNFo3dQiCJ">
        <div class="abstract-display">
            <p>Recent progress in empirical and certified robustness promises to deliver reliable and deployable Deep Neural Networks (DNNs). Despite that success, most existing evaluations of DNN robustness have been done on images sampled from the same distribution on which the model was trained on. However, in the real world, DNNs may be deployed in dynamic environments that exhibit significant distribution shifts. In this work, we take a first step towards thoroughly investigating the interplay between empirical and certified adversarial robustness on one hand and domain generalization on another. To do so, we train robust models on multiple domains and evaluate their accuracy and robustness on an unseen domain. We observe that: (1) both empirical and certified robustness generalize to unseen domains, and (2) the level of generalizability does not correlate well with input visual similarity, measured by the FID between source and target domains. We also extend our study to cover a real-world medical application, in which adversarial augmentation significantly boosts the generalization of robustness with minimal effect on clean data accuracy.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VV4zJwLwI7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VV4zJwLwI7.html">Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Junhyun Nam &middot; Sangwoo Mo &middot; Jaeho Lee &middot; Jinwoo Shin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VV4zJwLwI7"></div>

    <a href="paper_pages/VV4zJwLwI7.html">
        <img src="http://img.youtube.com/vi/RDhLKJnZTjE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VV4zJwLwI7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VV4zJwLwI7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VV4zJwLwI7">
                Abstract <i id="caret-VV4zJwLwI7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VV4zJwLwI7">
        <div class="abstract-display">
            <p>Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LKz5SqIXPJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LKz5SqIXPJ.html">On the Robustness of Dataset Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sebastian Szyller &middot; Rui Zhang &middot; Jian Liu &middot; N Asokan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LKz5SqIXPJ"></div>

    <a href="paper_pages/LKz5SqIXPJ.html">
        <img src="http://img.youtube.com/vi/jZ3Lw98gfv8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LKz5SqIXPJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LKz5SqIXPJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LKz5SqIXPJ">
                Abstract <i id="caret-LKz5SqIXPJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LKz5SqIXPJ">
        <div class="abstract-display">
            <p>Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification)  or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p28wv4G65d">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p28wv4G65d.html">SC2 Benchmark: Supervised Compression for Split Computing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yoshitomo Matsubara &middot; Ruihan Yang &middot; Marco Levorato &middot; Stephan Mandt</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p28wv4G65d"></div>

    <a href="paper_pages/p28wv4G65d.html">
        <img src="http://img.youtube.com/vi/uwwV_vAOvX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p28wv4G65d" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p28wv4G65d" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p28wv4G65d">
                Abstract <i id="caret-p28wv4G65d" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p28wv4G65d">
        <div class="abstract-display">
            <p>With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nfYwRIezvg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nfYwRIezvg.html">DORA: Exploring Outlier Representations in Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kirill Bykov &middot; Mayukh Deb &middot; Dennis Grinwald &middot; Klaus Robert Muller &middot; Marina MC HÃ¶hne</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nfYwRIezvg"></div>

    <a href="paper_pages/nfYwRIezvg.html">
        <img src="http://img.youtube.com/vi/k2tgN7YsjN8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nfYwRIezvg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nfYwRIezvg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nfYwRIezvg">
                Abstract <i id="caret-nfYwRIezvg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nfYwRIezvg">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vXSsTYs6ZB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vXSsTYs6ZB.html">LEAD: Min-Max Optimization from a Physical Perspective</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reyhane Askari Hemmat &middot; Amartya Mitra &middot; Guillaume Lajoie &middot; Ioannis Mitliagkas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vXSsTYs6ZB"></div>

    <a href="paper_pages/vXSsTYs6ZB.html">
        <img src="http://img.youtube.com/vi/EfwIc0GXb8E/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vXSsTYs6ZB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vXSsTYs6ZB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vXSsTYs6ZB">
                Abstract <i id="caret-vXSsTYs6ZB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vXSsTYs6ZB">
        <div class="abstract-display">
            <p>Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEADâs convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-g97OHbQyk1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/g97OHbQyk1.html">The Vendi Score: A Diversity Evaluation Metric for Machine Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dan Friedman &middot; Adji Bousso Dieng</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-g97OHbQyk1"></div>

    <a href="paper_pages/g97OHbQyk1.html">
        <img src="http://img.youtube.com/vi/r12fod3WZ78/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-g97OHbQyk1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-g97OHbQyk1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-g97OHbQyk1">
                Abstract <i id="caret-g97OHbQyk1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-g97OHbQyk1">
        <div class="abstract-display">
            <p>Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dXnccpSSYF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dXnccpSSYF.html">Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xueying Zhan &middot; Zeyu Dai &middot; Qingzhong Wang &middot; Qing Li &middot; Haoyi Xiong &middot; Dejing Dou &middot; Antoni B. Chan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dXnccpSSYF"></div>

    <a href="paper_pages/dXnccpSSYF.html">
        <img src="http://img.youtube.com/vi/HUXedZB47zc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dXnccpSSYF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dXnccpSSYF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dXnccpSSYF">
                Abstract <i id="caret-dXnccpSSYF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dXnccpSSYF">
        <div class="abstract-display">
            <p>Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators.  However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HVAeM6sNo8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HVAeM6sNo8.html">Robust Alzheimer's Progression Modeling using Cross-Domain Self-Supervised Deep Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saba Dadsetan &middot; Mohsen Hejrati &middot; Shandong Wu &middot; Somaye Hashemifar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HVAeM6sNo8"></div>

    <a href="paper_pages/HVAeM6sNo8.html">
        <img src="https://drive.google.com/thumbnail?id=1AXjAHw2Ef3Ni_uqZpoih9r72Jq-nHc5F" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HVAeM6sNo8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HVAeM6sNo8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HVAeM6sNo8">
                Abstract <i id="caret-HVAeM6sNo8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HVAeM6sNo8">
        <div class="abstract-display">
            <p>Developing successful artificial intelligence systems in practice depends on both robust deep learning models and large, high-quality data. However, acquiring and labeling data can be prohibitively expensive and time-consuming in many real-world applications, such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using medical images as input. We demonstrate that self-supervised pretraining can improve the prediction of Alzheimer's Disease progression from brain MRI. We also show that pretraining on extended (but not labeled) brain MRI data outperforms pretraining on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pretraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YwNrPLjHSL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YwNrPLjHSL.html">Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tian Yun &middot; Usha Bhalla &middot; Ellie Pavlick &middot; Chen Sun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YwNrPLjHSL"></div>

    <a href="paper_pages/YwNrPLjHSL.html">
        <img src="http://img.youtube.com/vi/qerql58NeeE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YwNrPLjHSL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YwNrPLjHSL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YwNrPLjHSL">
                Abstract <i id="caret-YwNrPLjHSL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YwNrPLjHSL">
        <div class="abstract-display">
            <p>Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive conceptsâsuch as colors, shapes, or the attributes of object partsâemerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap
first asks a VL model to generate concept activations with text prompts from a predefined list of primitive concepts, and then learns to construct an explicit composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to com-
posite concepts (e.g. a red-winged blackbird). We demonstrate that a composition model can be designed as a set operation, and show that a composition model is straightforward for machines to learn from ground truth primitive concepts (as a linear classifier). We thus
hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability of the VL modelsâ learned primitive concept representations. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However,
we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p7UTv2hWgM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p7UTv2hWgM.html">Stochastic gradient updates yield deep equilibrium kernels</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Russell Tsuchida &middot; Cheng Soon Ong</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p7UTv2hWgM"></div>

    <a href="paper_pages/p7UTv2hWgM.html">
        <img src="http://img.youtube.com/vi/Ab2KEE9OqEk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p7UTv2hWgM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p7UTv2hWgM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p7UTv2hWgM">
                Abstract <i id="caret-p7UTv2hWgM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p7UTv2hWgM">
        <div class="abstract-display">
            <p>Implicit deep learning allows one to compute with implicitly defined features, for example features that solve optimisation problems. We consider the problem of computing with implicitly defined features in a kernel regime. We call such a kernel a deep equilibrium kernel (DEKer). Specialising on a stochastic gradient descent (SGD) update rule applied to features (not weights) in a latent variable model, we find an exact deterministic update rule for the (DEKer) in a high dimensional limit. This derived update rule resembles previously introduced infinitely wide neural network kernels. To perform our analysis, we describe an alternative parameterisation of the link function of exponential families, a result that may be of independent interest. This new parameterisation allows us to draw new connections between a statistician's inverse link function and a machine learner's activation function. We describe an interesting property of SGD in this high dimensional limit: even though individual iterates are random vectors, inner products of any two iterates are deterministic, and can converge to a unique fixed point as the number of iterates increases. We find that the (DEKer) empirically outperforms related neural network kernels on a series of benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DJr6zorJM2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DJr6zorJM2.html">A Study of Biologically Plausible Neural Network: The Role and Interactions of Brain-Inspired Mechanisms in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fahad Sarfraz &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DJr6zorJM2"></div>

    <a href="paper_pages/DJr6zorJM2.html">
        <img src="http://img.youtube.com/vi/xh2iyEwLnSg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DJr6zorJM2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DJr6zorJM2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DJr6zorJM2">
                Abstract <i id="caret-DJr6zorJM2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DJr6zorJM2">
        <div class="abstract-display">
            <p>Humans excel at continually acquiring, consolidating, and retaining information from an ever-changing environment, whereas artificial neural networks (ANNs) exhibit catastrophic forgetting. There are considerable differences in the complexity of synapses, the processing of information, and the learning mechanisms in biological neural networks and their artificial counterparts, which may explain the mismatch in performance. We consider a biologically plausible framework that constitutes separate populations of exclusively excitatory and inhibitory neurons that adhere to Dale's principle, and the excitatory pyramidal neurons are augmented with dendritic-like structures for context-dependent processing of stimuli. We then conduct a comprehensive study on the role and interactions of different mechanisms inspired by the brain, including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations that accompanied the learning event. Our study suggests that the employing of multiple complementary mechanisms in a biologically plausible architecture, similar to the brain, may be effective in enabling continual learning in ANNs. \footnote{We will make the code available upon acceptance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2mZSlQscj3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2mZSlQscj3.html">Neural Monge Map estimation and its applications</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jiaojiao Fan &middot; Shu Liu &middot; Shaojun Ma &middot; Hao-Min Zhou &middot; Yongxin Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2mZSlQscj3"></div>

    <a href="paper_pages/2mZSlQscj3.html">
        <img src="http://img.youtube.com/vi/wIb2ZyieQPo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2mZSlQscj3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2mZSlQscj3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2mZSlQscj3">
                Abstract <i id="caret-2mZSlQscj3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2mZSlQscj3">
        <div class="abstract-display">
            <p>Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another.  Neural network-based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can be applied in large-scale settings. Furthermore, using the duality gap we prove rigorously \textit{a posteriori} error analysis for the method. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation, class-preserving map, and image inpainting tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-KxBQPz7HKh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/KxBQPz7HKh.html">Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Johanna Vielhaben &middot; Stefan Bluecher &middot; Nils Strodthoff</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-KxBQPz7HKh"></div>

    <a href="paper_pages/KxBQPz7HKh.html">
        <img src="http://img.youtube.com/vi/JZOzo-K05F0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-KxBQPz7HKh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-KxBQPz7HKh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-KxBQPz7HKh">
                Abstract <i id="caret-KxBQPz7HKh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-KxBQPz7HKh">
        <div class="abstract-display">
            <p>The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fvyh6mDWFr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fvyh6mDWFr.html">Understanding Noise-Augmented Training for Randomized Smoothing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ambar Pal &middot; Jeremias Sulam</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fvyh6mDWFr"></div>

    <a href="paper_pages/fvyh6mDWFr.html">
        <img src="http://img.youtube.com/vi/LzIoT5pX7pQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fvyh6mDWFr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fvyh6mDWFr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fvyh6mDWFr">
                Abstract <i id="caret-fvyh6mDWFr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fvyh6mDWFr">
        <div class="abstract-display">
            <p>Randomized smoothing is a technique for providing provable robustness guarantees against adversarial attacks while making minimal assumptions about a classifier. This method relies on taking a majority vote of any base classifier over multiple noise-perturbed inputs to obtain a smoothed classifier, and it remains the tool of choice to certify deep and complex neural network models. Nonetheless, non-trivial performance of such smoothed classifier crucially depends on the base model being trained on noise-augmented data, i.e., on a smoothed input distribution. While widely adopted in practice, it is still unclear how this noisy training of the base classifier precisely affects the risk of the robust smoothed classifier, leading to heuristics and tricks that are poorly understood. In this work we analyze these trade-offs theoretically in a binary classification setting, proving that these common observations are not universal. We show that, without making stronger distributional assumptions, no benefit can be expected from predictors trained with noise-augmentation, and we further characterize distributions where such benefit is obtained. Our analysis has direct implications to the practical deployment of randomized smoothing, and we illustrate some of these via experiments on CIFAR-10 and MNIST, as well as on synthetic datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VynY6Bk03b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VynY6Bk03b.html">How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jorge A Mendez &middot; ERIC EATON</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VynY6Bk03b"></div>

    <a href="paper_pages/VynY6Bk03b.html">
        <img src="http://img.youtube.com/vi/d6RSRnTvUfY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VynY6Bk03b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VynY6Bk03b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VynY6Bk03b">
                Abstract <i id="caret-VynY6Bk03b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VynY6Bk03b">
        <div class="abstract-display">
            <p>A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MRLHN4MSmA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MRLHN4MSmA.html">A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohamed Abdelhack &middot; Jiaming Zhang &middot; Sandhya Tripathi &middot; Bradley A Fritz &middot; Daniel Felsky &middot; Michael Avidan &middot; Yixin Chen &middot; Christopher Ryan King</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MRLHN4MSmA"></div>

    <a href="paper_pages/MRLHN4MSmA.html">
        <img src="http://img.youtube.com/vi/SI-5cuPJV9U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MRLHN4MSmA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MRLHN4MSmA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MRLHN4MSmA">
                Abstract <i id="caret-MRLHN4MSmA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MRLHN4MSmA">
        <div class="abstract-display">
            <p>Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high-quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low-quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of additional input. This is inspired by neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against data quality degradation, including additional missingness. These models are superior to imputation as they save on training time by entirely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. Our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gR9UVgH8PZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gR9UVgH8PZ.html">Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tiange Luo &middot; Honglak Lee &middot; Justin Johnson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gR9UVgH8PZ"></div>

    <a href="paper_pages/gR9UVgH8PZ.html">
        <img src="video_thumbnails/gR9UVgH8PZ.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gR9UVgH8PZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gR9UVgH8PZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gR9UVgH8PZ">
                Abstract <i id="caret-gR9UVgH8PZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gR9UVgH8PZ">
        <div class="abstract-display">
            <p>3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\textit{Text}$ $\Longleftrightarrow$ $\textit{Point Cloud}$ $\Longleftrightarrow$ $\textit{Program}$. We propose $\textbf{\textit{Neural Shape Compiler}}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\textit{Text}$ $\Longrightarrow$ $\textit{Point Cloud}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Text}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Program}$, and Point Cloud Completion tasks. Additionally, Neural Shape Compiler benefits from jointly training on all heterogeneous data and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-T1XtOqrVKn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/T1XtOqrVKn.html">Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Maurits Bleeker &middot; Andrew Yates &middot; Maarten de Rijke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-T1XtOqrVKn"></div>

    <a href="paper_pages/T1XtOqrVKn.html">
        <img src="http://img.youtube.com/vi/CrT7wlzY5K8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-T1XtOqrVKn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-T1XtOqrVKn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-T1XtOqrVKn">
                Abstract <i id="caret-T1XtOqrVKn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-T1XtOqrVKn">
        <div class="abstract-display">
            <p>To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. 
Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. 
Predictive features are features that correctly indicate the similarity between a query and a candidate item. 
However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and
negative pairs. 
We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose
sentence encoder, which prevents the image and caption encoder from suppressing
predictive features. 
We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a bound value while primarily optimizing for the contrastive loss. 
Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. 
Our experiments show that, unlike reconstructing the input caption in the input space, LTD reduces predictive feature suppression, measured by obtaining higher recall@k, r-precision, and nDCG scores than a contrastive ICR baseline.
Moreover, we show that LTD should be implemented as an optimization constraint instead
of a dual optimization objective. Finally, we show that LTD can be used with different
contrastive learning losses and a wide variety of resource-constrained ICR methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4eL6z9ziw7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4eL6z9ziw7.html">NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Patrick Feeney &middot; Sarah Schneider &middot; Panagiotis Lymperopoulos &middot; Liping Liu &middot; Matthias Scheutz &middot; Michael C Hughes</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4eL6z9ziw7"></div>

    <a href="paper_pages/4eL6z9ziw7.html">
        <img src="http://img.youtube.com/vi/d0AAH_eMPoQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4eL6z9ziw7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4eL6z9ziw7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4eL6z9ziw7">
                Abstract <i id="caret-4eL6z9ziw7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4eL6z9ziw7">
        <div class="abstract-display">
            <p>In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qdDmxzGuzu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qdDmxzGuzu.html">Reusable Options through Gradient-based Meta Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">David Kuric &middot; Herke van Hoof</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qdDmxzGuzu"></div>

    <a href="paper_pages/qdDmxzGuzu.html">
        <img src="http://img.youtube.com/vi/Dp5a20y9ohw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qdDmxzGuzu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qdDmxzGuzu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qdDmxzGuzu">
                Abstract <i id="caret-qdDmxzGuzu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qdDmxzGuzu">
        <div class="abstract-display">
            <p>Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding a reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior methods developed for this setting. Additionally, we perform ablations to quantify the impact of using gradient-based meta-learning as well as other proposed changes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MTFf1rDDEI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MTFf1rDDEI.html">Successor Feature Representations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chris Reinke &middot; Xavier Alameda-Pineda</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MTFf1rDDEI"></div>

    <a href="paper_pages/MTFf1rDDEI.html">
        <img src="http://img.youtube.com/vi/RYemlh2NSzQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MTFf1rDDEI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MTFf1rDDEI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MTFf1rDDEI">
                Abstract <i id="caret-MTFf1rDDEI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MTFf1rDDEI">
        <div class="abstract-display">
            <p>Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nHfPXl1ly7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nHfPXl1ly7.html">A Kernel Perspective on Behavioural Metrics for Markov Decision Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pablo Samuel Castro &middot; Tyler Kastner &middot; Prakash Panangaden &middot; Mark Rowland</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nHfPXl1ly7"></div>

    <a href="paper_pages/nHfPXl1ly7.html">
        <img src="http://img.youtube.com/vi/or5W73cn-WQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nHfPXl1ly7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nHfPXl1ly7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nHfPXl1ly7">
                Abstract <i id="caret-nHfPXl1ly7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nHfPXl1ly7">
        <div class="abstract-display">
            <p>We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We define a new metric under this lens that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective enables us to provide new theoretical results, including value-function bounds and low-distortion finite-dimensional Euclidean embeddings, which are crucial when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y4CGF1A8VG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y4CGF1A8VG.html">Machine Explanations and Human Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chacha Chen &middot; Shi Feng &middot; Amit Sharma &middot; Chenhao Tan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y4CGF1A8VG"></div>

    <a href="paper_pages/y4CGF1A8VG.html">
        <img src="http://img.youtube.com/vi/-hNKPaX7L4o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y4CGF1A8VG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y4CGF1A8VG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y4CGF1A8VG">
                Abstract <i id="caret-y4CGF1A8VG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y4CGF1A8VG">
        <div class="abstract-display">
            <p>Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-a0T3nOP9sB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/a0T3nOP9sB.html">Adaptive patch foraging in deep reinforcement learning agents</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nathan Wispinski &middot; Andrew Butcher &middot; Kory Wallace Mathewson &middot; Craig S Chapman &middot; Matthew Botvinick &middot; Patrick M. Pilarski</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-a0T3nOP9sB"></div>

    <a href="paper_pages/a0T3nOP9sB.html">
        <img src="http://img.youtube.com/vi/5PfxPj5Jzwo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-a0T3nOP9sB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-a0T3nOP9sB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-a0T3nOP9sB">
                Abstract <i id="caret-a0T3nOP9sB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-a0T3nOP9sB">
        <div class="abstract-display">
            <p>Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-onufdyHvqN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/onufdyHvqN.html">Private Multi-Task Learning: Formulation and Applications to Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shengyuan Hu &middot; Steven Wu &middot; Virginia Smith</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-onufdyHvqN"></div>

    <a href="paper_pages/onufdyHvqN.html">
        <img src="https://drive.google.com/thumbnail?id=1J35lwtPfLtEF3HpomNKYc3CzEW6nhgu6" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-onufdyHvqN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-onufdyHvqN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-onufdyHvqN">
                Abstract <i id="caret-onufdyHvqN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-onufdyHvqN">
        <div class="abstract-display">
            <p>Many problems in machine learning rely on multi-task learning (MTL), in which the goal is to solve multiple related machine learning tasks simultaneously. MTL is particularly relevant for privacy-sensitive applications in areas such as healthcare, finance, and IoT computing,
where sensitive data from multiple, varied sources are shared for the purpose of learning. In this work, we formalize notions of client-level privacy for MTL via billboard privacy (BP), a relaxation of differential privacy for mechanism design and distributed optimization. We then propose an algorithm for mean-regularized MTL, an objective commonly used for applications in personalized federated learning, subject to BP. We analyze our objective and solver, providing certifiable guarantees on both privacy and utility. Empirically, we find that our method provides improved privacy/utility trade-offs relative to global baselines across common federated learning benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9aXKUJEKwV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9aXKUJEKwV.html">Learning to Look by Self-Prediction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Koichi Grimes &middot; Joseph Varughese Modayil &middot; Piotr W Mirowski &middot; Dushyant Rao &middot; Raia Hadsell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9aXKUJEKwV"></div>

    <a href="paper_pages/9aXKUJEKwV.html">
        <img src="https://drive.google.com/thumbnail?id=1iOFC1IWk0Jx-poBZW0lh5FcTmT55BdDw" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9aXKUJEKwV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9aXKUJEKwV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9aXKUJEKwV">
                Abstract <i id="caret-9aXKUJEKwV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9aXKUJEKwV">
        <div class="abstract-display">
            <p>We present a method for learning active vision skills, to move the camera to observe a robot's sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies' precision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TNocbXm5MZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TNocbXm5MZ.html">Guaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alex Lamb &middot; Riashat Islam &middot; Yonathan Efroni &middot; Aniket Rajiv Didolkar &middot; Dipendra Misra &middot; Dylan J Foster &middot; Lekan P Molu &middot; Rajan Chari &middot; Akshay Krishnamurthy &middot; John Langford</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TNocbXm5MZ"></div>

    <a href="paper_pages/TNocbXm5MZ.html">
        <img src="http://img.youtube.com/vi/prS5EG9dLVg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TNocbXm5MZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TNocbXm5MZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TNocbXm5MZ">
                Abstract <i id="caret-TNocbXm5MZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TNocbXm5MZ">
        <div class="abstract-display">
            <p>In many sequential decision-making tasks, the agent is not able to model the full complexity of the world, which consists of multitudes of relevant and irrelevant information. For example, a person walking along a city street who tries to model all aspects of the world would quickly be overwhelmed by a multitude of shops, cars, and people moving in and out of view, each following their own complex and inscrutable dynamics.  Is it possible to turn the agent's firehose of sensory information into a minimal latent state that is both necessary and sufficient for an agent to successfully act in the world? We formulate this question concretely, and propose the Agent Control-Endogenous State Discovery algorithm (AC-State), which has theoretical guarantees and is practically demonstrated to discover the minimal control-endogenous latent state which contains all of the information necessary for controlling the agent, while fully discarding all irrelevant information.    This algorithm consists of a multi-step inverse model (predicting actions from distant observations) with an information bottleneck.  AC-State enables localization, exploration, and navigation without reward or demonstrations.  We demonstrate the discovery of the control-endogenous latent state in three domains: localizing a robot arm with distractions (e.g., changing lighting conditions and background), exploring a maze alongside other agents, and navigating in the Matterport house simulator.  </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-5aYGXxByI6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/5aYGXxByI6.html">MASIF: Meta-learned Algorithm Selection using Implicit Fidelity Information</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tim Ruhkopf &middot; Aditya Mohan &middot; Difan Deng &middot; Alexander Tornede &middot; Frank Hutter &middot; Marius Lindauer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-5aYGXxByI6"></div>

    <a href="paper_pages/5aYGXxByI6.html">
        <img src="http://img.youtube.com/vi/4qXRyRjJPIY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-5aYGXxByI6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-5aYGXxByI6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-5aYGXxByI6">
                Abstract <i id="caret-5aYGXxByI6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-5aYGXxByI6">
        <div class="abstract-display">
            <p>Selecting a well-performing algorithm for a given task or dataset can be time-consuming and
tedious, but is crucial for the successful day-to-day business of developing new AI & ML
applications. Algorithm Selection (AS) mitigates this through a meta-model leveraging
meta-information about previous tasks. However, most of the available AS methods are
error-prone because they characterize a task by either cheap-to-compute properties of the
dataset or evaluations of cheap proxy algorithms, called landmarks. In this work, we extend
the classical AS data setup to include multi-fidelity information and empirically demonstrate
how meta-learning on algorithmsâ learning behaviour allows us to exploit cheap test-time
evidence effectively and combat myopia significantly. We further postulate a budget-regret
trade-off w.r.t. the selection process. Our new selector MASIF is able to jointly interpret
online evidence on a task in form of varying-length learning curves without any parametric
assumption by leveraging a transformer-based encoder. This opens up new possibilities for
guided rapid prototyping in data science on cheaply observed partial learning curves.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-NrfSRtTpN5">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/NrfSRtTpN5.html">Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hong-Xing Yu &middot; Michelle Guo &middot; Alireza Fathi &middot; Yen-Yu Chang &middot; Eric Ryan Chan &middot; Ruohan Gao &middot; Thomas Funkhouser &middot; Jiajun Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-NrfSRtTpN5"></div>

    <a href="paper_pages/NrfSRtTpN5.html">
        <img src="http://img.youtube.com/vi/BqKiO5GDtH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-NrfSRtTpN5" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-NrfSRtTpN5" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-NrfSRtTpN5">
                Abstract <i id="caret-NrfSRtTpN5" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-NrfSRtTpN5">
        <div class="abstract-display">
            <p>Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Oq5XKRVYpQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Oq5XKRVYpQ.html">Graph-based Multi-ODE Neural Networks for Spatio-Temporal Traffic Forecasting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zibo Liu &middot; Parshin Shojaee &middot; Chandan K. Reddy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Oq5XKRVYpQ"></div>

    <a href="paper_pages/Oq5XKRVYpQ.html">
        <img src="http://img.youtube.com/vi/00SItN8IP-M/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Oq5XKRVYpQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Oq5XKRVYpQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Oq5XKRVYpQ">
                Abstract <i id="caret-Oq5XKRVYpQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Oq5XKRVYpQ">
        <div class="abstract-display">
            <p>There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however,  remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. 
Current works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-WN1O2MJDST">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/WN1O2MJDST.html">Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vijaya Raghavan T Ramkumar &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-WN1O2MJDST"></div>

    <a href="paper_pages/WN1O2MJDST.html">
        <img src="http://img.youtube.com/vi/efulZvJBZ04/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-WN1O2MJDST" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-WN1O2MJDST" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-WN1O2MJDST">
                Abstract <i id="caret-WN1O2MJDST" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-WN1O2MJDST">
        <div class="abstract-display">
            <p>Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce "Learn, Unlearn, and Relearn (LURE)" an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-v5jwDLqfQo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/v5jwDLqfQo.html">Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wu &middot; David Pichler &middot; Daniel Marley &middot; Naira Hovakimyan &middot; David A Wilson &middot; Jennifer Hobbs</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-v5jwDLqfQo"></div>

    <a href="paper_pages/v5jwDLqfQo.html">
        <img src="http://img.youtube.com/vi/2xaKxUpY4iQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-v5jwDLqfQo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-v5jwDLqfQo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-v5jwDLqfQo">
                Abstract <i id="caret-v5jwDLqfQo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-v5jwDLqfQo">
        <div class="abstract-display">
            <p>A key challenge for much of the machine learning work on remote sensing and earth observation data is the difficulty in acquiring large amounts of accurately labeled data. This is particularly true for semantic segmentation tasks, which are much less common in the remote sensing domain because of the incredible difficulty in collecting precise, accurate, pixel-level annotations at scale. Recent efforts have addressed these challenges both through the creation of supervised datasets as well as the application of self-supervised methods. We continue these efforts on both fronts. First, we generate and release an improved version of the Agriculture-Vision dataset  (Chiu et al., 2020b) to include raw, full-field imagery for greater experimental flexibility. Second, we extend this dataset with the release of 3600 large, high-resolution (10cm/pixel), full-field, red-green-blue and near-infrared images for pre-training. Third, we incorporate the Pixel-to-Propagation Module Xie et al. (2021b) originally built on the SimCLR framework into the framework of MoCo-V2 Chen et al.(2020b). Finally, we demonstrate the usefulness of this data by benchmarking different contrastive learning approaches on both downstream classification and semantic segmentation tasks. We explore both CNN and Swin Transformer Liu et al. (2021a) architectures within different frameworks based on MoCo-V2. Together, these approaches enable us to better detect key agricultural patterns of interest across a field from aerial imagery so that farmers may be alerted to problematic areas in a timely fashion to inform their management decisions. Furthermore, the release of these datasets will support numerous avenues of research for computer vision in remote sensing for agriculture.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EiX2L4sDPG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EiX2L4sDPG.html">VN-Transformer: Rotation-Equivariant Attention for Vector Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Serge Assaad &middot; Carlton Downey &middot; Rami Al-Rfou' &middot; Nigamaa Nayakanti &middot; Benjamin Sapp</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EiX2L4sDPG"></div>

    <a href="paper_pages/EiX2L4sDPG.html">
        <img src="http://img.youtube.com/vi/1KrPzUKwSL8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EiX2L4sDPG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EiX2L4sDPG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EiX2L4sDPG">
                Abstract <i id="caret-EiX2L4sDPG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EiX2L4sDPG">
        <div class="abstract-display">
            <p>Rotation equivariance is a desirable property in many practical applications such as motion forecasting and 3D perception, where it can offer benefits like sample efficiency, better generalization, and robustness to input perturbations.
Vector Neurons (VN) is a recently developed framework offering a simple yet effective approach for deriving rotation-equivariant analogs of standard machine learning operations by extending one-dimensional scalar neurons to three-dimensional "vector neurons."
We introduce a novel "VN-Transformer" architecture to address several shortcomings of the current VN models. Our contributions are:
(i) we derive a rotation-equivariant attention mechanism which eliminates the need for the heavy feature preprocessing required by the original Vector Neurons models; (ii) we extend the VN framework to support non-spatial attributes, expanding the applicability of these models to real-world datasets; (iii) we derive a rotation-equivariant mechanism for multi-scale reduction of point-cloud resolution, greatly speeding up inference and training; (iv) we show that small tradeoffs in equivariance ($\epsilon$-approximate equivariance) can be used to obtain large improvements in numerical stability and training robustness on accelerated hardware, and we bound the propagation of equivariance violations in our models.
Finally, we apply our VN-Transformer to 3D shape classification and motion forecasting with compelling results.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jdGMBgYvfX">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jdGMBgYvfX.html">UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Francisca Vasconcelos &middot; Bobby He &middot; Nalini M Singh &middot; Yee Whye Teh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jdGMBgYvfX"></div>

    <a href="paper_pages/jdGMBgYvfX.html">
        <img src="http://img.youtube.com/vi/cD7Wx4F_EjQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jdGMBgYvfX" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jdGMBgYvfX" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jdGMBgYvfX">
                Abstract <i id="caret-jdGMBgYvfX" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jdGMBgYvfX">
        <div class="abstract-display">
            <p>Implicit neural representations (INRs) have achieved impressive results for scene reconstruction and computer graphics, where their performance has primarily been assessed on reconstruction accuracy. As INRs make their way into other domains, where model predictions inform high-stakes decision-making, uncertainty quantification of INR inference is becoming critical. To that end, we study a Bayesian reformulation of INRs, UncertaINR, in the context of computed tomography, and evaluate several Bayesian deep learning implementations in terms of accuracy and calibration.  We find that they achieve well-calibrated uncertainty, while retaining accuracy competitive with other classical, INR-based, and CNN-based reconstruction techniques. Contrary to common intuition in the Bayesian deep learning literature, we find that INRs obtain the best calibration with computationally efficient Monte Carlo dropout, outperforming Hamiltonian Monte Carlo and deep ensembles. Moreover, in contrast to the best-performing prior approaches, UncertaINR does not require a large training dataset, but only a handful of validation images.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-SM1BkjGePI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/SM1BkjGePI.html">Bridging performance gap between minimal and maximal SVM models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ondrej Such &middot; RenÃ© Fabricius</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-SM1BkjGePI"></div>

    <a href="paper_pages/SM1BkjGePI.html">
        <img src="http://img.youtube.com/vi/jWAfN4deoC8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-SM1BkjGePI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-SM1BkjGePI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-SM1BkjGePI">
                Abstract <i id="caret-SM1BkjGePI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-SM1BkjGePI">
        <div class="abstract-display">
            <p>Multi-class support vector machine (SVM) models are typically built using all possible pairs of binary SVM in a one-against-one fashion. This requires too much computation for datasets with hundreds or thousands of classes,  which motivates the search for multi-class models that do not use all pairwise SVM.  Our models correspond to the choice of the model graph, whose vertices correspond to classes and edges represent which pairwise SVMs are trained. We conduct experiments to uncover metrical and topological properties that impact the accuracy of a multi-class SVM model. Based on their results we propose a way to construct intermediate multi-class SVM models. The key insight is that for model graphs of diameter two, we can estimate missing pairwise probabilities from the known ones thus transforming the computation of posteriors to the usual complete (maximal) case. Our proposed algorithm allows one to reduce computational effort by 50-80% while keeping accuracy near, or even above that of a softmax classifier. In our work we use convolutional data sets, which have multiple advantages for benchmarking multi-class SVM models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mySiFHCeAl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mySiFHCeAl.html">Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Amirali Aghazadeh &middot; Nived Rajaraman &middot; Tony Tu &middot; Kannan Ramchandran</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mySiFHCeAl"></div>

    <a href="paper_pages/mySiFHCeAl.html">
        <img src="http://img.youtube.com/vi/ER12pwvxTSU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mySiFHCeAl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mySiFHCeAl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mySiFHCeAl">
                Abstract <i id="caret-mySiFHCeAl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mySiFHCeAl">
        <div class="abstract-display">
            <p>Data-driven machine learning models are being increasingly employed in several important inference problems in biology, chemistry, and physics, which require learning over combinatorial spaces. Recent empirical evidence (see, e.g., ~\cite{tseng2020fourier,aghazadeh2021epistatic,ha2021adaptive}) suggests that regularizing the spectral representation of such models improves their generalization power when labeled data is scarce. However, despite these empirical studies, the theoretical underpinning of when and how spectral regularization enables improved generalization is poorly understood. In this paper, we focus on learning pseudo-Boolean functions and demonstrate that regularizing the empirical mean squared error by the $L_1$ norm of the spectral transform of the learned function reshapes the loss landscape and allows for data-frugal learning under a restricted secant condition on the learner's empirical error measured against the ground truth function. Under a weaker quadratic growth condition, we show that stationary points, which also approximately interpolate the training data points achieve statistically optimal generalization performance. Complementing our theory, we empirically demonstrate that running gradient descent on the regularized loss results in a better generalization performance compared to baseline algorithms in several data-scarce real-world problems.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3gfpBR1ncr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3gfpBR1ncr.html">On Characterizing the Trade-off in Invariant Representation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bashir Sadeghi &middot; Sepehr Dehdashtian &middot; Vishnu Boddeti</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3gfpBR1ncr"></div>

    <a href="paper_pages/3gfpBR1ncr.html">
        <img src="http://img.youtube.com/vi/bjeLIWoiTT8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3gfpBR1ncr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3gfpBR1ncr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3gfpBR1ncr">
                Abstract <i id="caret-3gfpBR1ncr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3gfpBR1ncr">
        <div class="abstract-display">
            <p>Many applications of representation learning, such as privacy preservation, algorithmic fairness, and domain adaptation, desire explicit control over semantic information being discarded. This goal is formulated as satisfying two objectives: maximizing utility for predicting a target attribute while simultaneously being invariant (independent) to a known semantic attribute. Solutions to invariant representation learning (IRepL) problems lead to a trade-off between utility and invariance when they are competing. While existing works study bounds on this trade-off, two questions remain outstanding: 1) What is the exact trade-off between utility and invariance? and 2) What are the encoders (mapping the data to a representation) that achieve the trade-off, and how can we estimate it from training data? This paper addresses these questions for IRepLs in reproducing kernel Hilbert spaces (RKHS)s. Under the assumption that the distribution of a low-dimensional projection of high-dimensional data is approximately normal, we derive a closed-form solution for the global optima of the underlying optimization problem for encoders in RKHSs. This yields closed formulae for a near-optimal trade-off, corresponding optimal representation dimensionality, and the corresponding encoder(s). We also numerically quantify the trade-off on representative problems and compare them to those achieved by baseline IRepL algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-d3rHk4VAf0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/d3rHk4VAf0.html">A Ranking Game for Imitation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Harshit Sikchi &middot; Akanksha Saran &middot; Wonjoon Goo &middot; Scott Niekum</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-d3rHk4VAf0"></div>

    <a href="paper_pages/d3rHk4VAf0.html">
        <img src="http://img.youtube.com/vi/gTf8WoYUOH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-d3rHk4VAf0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-d3rHk4VAf0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-d3rHk4VAf0">
                Abstract <i id="caret-d3rHk4VAf0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-d3rHk4VAf0">
        <div class="abstract-display">
            <p>We propose a new framework for imitation learning---treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-P9Cj6RJmN2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/P9Cj6RJmN2.html">A Stochastic Optimization Framework for Fair Risk Minimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Andrew Lowy &middot; Sina Baharlouei &middot; Rakesh Pavan &middot; Meisam Razaviyayn &middot; Ahmad Beirami</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-P9Cj6RJmN2"></div>

    <a href="paper_pages/P9Cj6RJmN2.html">
        <img src="video_thumbnails/P9Cj6RJmN2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-P9Cj6RJmN2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-P9Cj6RJmN2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-P9Cj6RJmN2">
                Abstract <i id="caret-P9Cj6RJmN2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-P9Cj6RJmN2">
        <div class="abstract-display">
            <p>Despite the success of large-scale empirical risk minimization (ERM) at achieving high accuracy across a variety of machine learning tasks, fair ERM is hindered by the incompatibility of fairness constraints with stochastic optimization. We consider the problem of fair classification with discrete sensitive attributes and potentially large models and data sets, requiring stochastic solvers. Existing in-processing fairness algorithms are either impractical in the large-scale setting because they require large batches of data at each iteration or they are not guaranteed to converge. In this paper, we develop the first stochastic in-processing fairness algorithm with guaranteed convergence. For demographic parity, equalized odds, and equal opportunity notions of fairness, we provide slight variations of our algorithmâcalled FERMIâand prove that each of these variations converges in stochastic optimization with any batch size. Empirically, we show that FERMI is amenable to stochastic solvers with multiple (non-binary) sensitive attributes and non-binary targets, performing well even with minibatch size as small as one. Extensive experiments show that FERMI achieves the most favorable tradeoffs between fairness violation and test accuracy across all tested setups compared with state-of-the-art baselines for demographic parity, equalized odds, equal opportunity. These benefits are especially significant with small batch sizes and for non-binary classification with large number of sensitive attributes, making FERMI a practical, scalable fairness algorithm. The code for all of the experiments in this paper is available at:
https://github.com/optimization-for-data-driven-science/FERMI</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VW4IrC0n0M">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VW4IrC0n0M.html">An approximate sampler for energy-based models with divergence diagnostics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bryan Eikema &middot; GermÃ¡n Kruszewski &middot; Christopher R Dance &middot; Hady Elsahar &middot; Marc Dymetman</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VW4IrC0n0M"></div>

    <a href="paper_pages/VW4IrC0n0M.html">
        <img src="video_thumbnails/VW4IrC0n0M.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VW4IrC0n0M" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VW4IrC0n0M" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VW4IrC0n0M">
                Abstract <i id="caret-VW4IrC0n0M" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VW4IrC0n0M">
        <div class="abstract-display">
            <p>Energy-based models (EBMs) allow flexible specifications of probability distributions. However, sampling from EBMs is non-trivial, usually requiring approximate techniques such as Markov chain Monte Carlo (MCMC). A major downside of MCMC sampling is that it is often impossible to compute the divergence of the sampling distribution from the target distribution: therefore, the quality of the samples cannot be guaranteed. Here, we introduce quasi-rejection sampling (QRS), a simple extension of rejection sampling that performs approximate sampling, but, crucially, does provide divergence diagnostics (in terms of f-divergences, such as KL divergence and total variation distance). We apply QRS to sampling from discrete EBMs over text for controlled generation. We show that we can sample from such EBMs with arbitrary precision in exchange for sampling efficiency and quantify the trade-off between the two by means of the aforementioned diagnostics. 
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LHAbHkt6Aq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LHAbHkt6Aq.html">A Crisis In Simulation-Based Inference? Beware, Your Posterior Approximations Can Be Unfaithful</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joeri Hermans &middot; Arnaud Delaunoy &middot; FranÃ§ois Rozet &middot; Antoine Wehenkel &middot; Volodimir Begy &middot; Gilles Louppe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LHAbHkt6Aq"></div>

    <a href="paper_pages/LHAbHkt6Aq.html">
        <img src="http://img.youtube.com/vi/sLM0JBbSjLw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LHAbHkt6Aq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LHAbHkt6Aq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LHAbHkt6Aq">
                Abstract <i id="caret-LHAbHkt6Aq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LHAbHkt6Aq">
        <div class="abstract-display">
            <p>We present extensive empirical evidence showing that current Bayesian simulation-based inference algorithms can produce computationally unfaithful posterior approximations. Our results show that all benchmarked algorithms -- (S)NPE, (S)NRE, SNL and variants of ABC -- can yield overconfident posterior approximations, which makes them unreliable for scientific use cases and falsificationist inquiry. Failing to address this issue may reduce the range of applicability of simulation-based inference. For this reason, we argue that research efforts should be made towards theoretical and methodological developments of conservative approximate inference algorithms and present research directions towards this objective. In this regard, we show empirical evidence that ensembling posterior surrogates provides more reliable approximations and mitigates the issue.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-myjAVQrRxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/myjAVQrRxS.html">Dropped Scheduled Task: Mitigating Negative Transfer in Multi-task Learning using Dynamic Task Dropping</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Aakarsh Malhotra &middot; Mayank Vatsa &middot; Richa Singh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-myjAVQrRxS"></div>

    <a href="paper_pages/myjAVQrRxS.html">
        <img src="http://img.youtube.com/vi/NZrnPHDFNTM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-myjAVQrRxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-myjAVQrRxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-myjAVQrRxS">
                Abstract <i id="caret-myjAVQrRxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-myjAVQrRxS">
        <div class="abstract-display">
            <p>In Multi-Task Learning (MTL), K distinct tasks are jointly optimized. With the varying nature and complexities of tasks, few tasks might dominate learning. For other tasks, their respective performances may get compromised due to a negative transfer from dominant tasks. We propose a Dropped-Scheduled Task (DST) algorithm, which probabilistically âdropsâ specific tasks during joint optimization while scheduling others to reduce negative transfer. For each task, a scheduling probability is decided based on four different metrics: (i) task depth, (ii) number of ground-truth samples per task, (iii) amount of training completed, and (iv) task stagnancy. Based on the scheduling probability, specific tasks get joint computation cycles while others are âdroppedâ. To demonstrate the effectiveness of the proposed DST algorithm, we perform multi-task learning on three applications and two architectures. Across unilateral (single input) and bilateral (multiple input) multi-task net- works, the chosen applications are (a) face (AFLW), (b) fingerprint (IIITD MOLF, MUST, and NIST SD27), and (c) character recognition (Omniglot) applications. Experimental results show that the proposed DST algorithm has the minimum negative transfer and overall least errors across different state-of-the-art algorithms and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-K6g4MbAC1r">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/K6g4MbAC1r.html">Investigating Action Encodings in Recurrent Neural Networks in Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Kyle Schlegel &middot; Volodymyr Tkachuk &middot; Adam M White &middot; Martha White</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-K6g4MbAC1r"></div>

    <a href="paper_pages/K6g4MbAC1r.html">
        <img src="http://img.youtube.com/vi/83vBK8DIdEY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-K6g4MbAC1r" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-K6g4MbAC1r" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-K6g4MbAC1r">
                Abstract <i id="caret-K6g4MbAC1r" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-K6g4MbAC1r">
        <div class="abstract-display">
            <p>Building and maintaining state to learn policies and value functions is critical for deploying reinforcement learning (RL) agents in the real world. Recurrent neural networks (RNNs) have become a key point of interest for the state-building problem, and several large-scale reinforcement learning agents incorporate recurrent networks. While RNNs have become a mainstay in many RL applications, many key design choices and implementation details responsible for performance improvements are often not reported. In this work, we discuss one axis on which RNN architectures can be (and have been) modified for use in RL. Specifically, we look at how action information can be incorporated into the state update function of a recurrent cell. We discuss several choices in using action information and empirically evaluate the resulting architectures on a set of illustrative domains. Finally, we discuss future work in developing recurrent cells and discuss challenges specific to the RL setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QaDevCcmcg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QaDevCcmcg.html">Uncertainty-Based Active Learning for Reading Comprehension</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wang &middot; Jie Shen &middot; Xiaofei Ma &middot; Andrew Arnold</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QaDevCcmcg"></div>

    <a href="paper_pages/QaDevCcmcg.html">
        <img src="http://img.youtube.com/vi/oRrMip1MWbY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QaDevCcmcg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QaDevCcmcg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QaDevCcmcg">
                Abstract <i id="caret-QaDevCcmcg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QaDevCcmcg">
        <div class="abstract-display">
            <p>Recent years have witnessed a surge of successful applications of machine reading comprehension. Of central importance to these tasks is the availability of massive amount of labeled data, which facilitates training of large-scale neural networks. However, in many real-world problems, annotated data are expensive to gather not only because of time cost and budget, but also  of certain domain-specific restrictions such as privacy for healthcare data. In this regard, we propose an uncertainty-based active learning algorithm for reading comprehension, which interleaves data annotation and model updating to mitigate the demand of labeling. Our key techniques are two-fold: 1) an unsupervised uncertainty-based sampling scheme that queries the labels of the most informative instances with respect to the currently learned model; and 2) an adaptive loss minimization paradigm that simultaneously fits the data and controls the degree of model updating. We demonstrate on  benchmark datasets that 25% less labeled samples suffice to guarantee similar, or even improved performance. Our results show strong evidence that for label-demanding scenarios, the proposed approach offers a practical guide on data collection and model training. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EYrRzKPinA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EYrRzKPinA.html">On a continuous time model of gradient descent dynamics and instability in deep learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mihaela Rosca &middot; Yan Wu &middot; Chongli Qin &middot; Benoit Dherin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EYrRzKPinA"></div>

    <a href="paper_pages/EYrRzKPinA.html">
        <img src="http://img.youtube.com/vi/UKHCH8ZdH1Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EYrRzKPinA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EYrRzKPinA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EYrRzKPinA">
                Abstract <i id="caret-EYrRzKPinA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EYrRzKPinA">
        <div class="abstract-display">
            <p>The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oq3tx5kinu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oq3tx5kinu.html">Active Learning of Ordinal Embeddings: A User Study on Football Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Christoffer LÃ¶ffler &middot; Kion Fallah &middot; Stefano Fenu &middot; Dario Zanca &middot; Bjoern Eskofier &middot; Christopher John Rozell &middot; Christopher Mutschler</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oq3tx5kinu"></div>

    <a href="paper_pages/oq3tx5kinu.html">
        <img src="http://img.youtube.com/vi/xqOJAtjxjKE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oq3tx5kinu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oq3tx5kinu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oq3tx5kinu">
                Abstract <i id="caret-oq3tx5kinu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oq3tx5kinu">
        <div class="abstract-display">
            <p>Humans innately measure distance between instances in an unlabeled dataset using an unknown similarity function. Distance metrics can only serve as proxy for similarity in information retrieval of similar instances. Learning a good similarity function from human annotations improves the quality of retrievals. This work uses deep metric learning to learn these user-defined similarity functions from few annotations for a large football trajectory dataset.
We adapt an entropy-based active learning method with recent work from triplet mining to collect easy-to-answer but still informative annotations from human participants and use them to train a deep convolutional network that generalizes to unseen samples. 
Our user study shows that our approach improves the quality of the information retrieval compared to a previous deep metric learning approach that relies on a Siamese network. Specifically, we shed light on the strengths and weaknesses of passive sampling heuristics and active learners alike by analyzing the participants' response efficacy. To this end, we collect accuracy, algorithmic time complexity, the participants' fatigue and time-to-response, qualitative self-assessment and statements, as well as the effects of mixed-expertise annotators and their consistency on model performance and transfer-learning.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Lgs5pQ1v30">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Lgs5pQ1v30.html">FedShuffle:  Recipes for Better Use of Local Work in Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Samuel HorvÃ¡th &middot; Maziar Sanjabi &middot; Lin Xiao &middot; Peter RichtÃ¡rik &middot; Michael Rabbat</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Lgs5pQ1v30"></div>

    <a href="paper_pages/Lgs5pQ1v30.html">
        <img src="http://img.youtube.com/vi/jGVbs3Jl1K0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Lgs5pQ1v30" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Lgs5pQ1v30" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Lgs5pQ1v30">
                Abstract <i id="caret-Lgs5pQ1v30" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Lgs5pQ1v30">
        <div class="abstract-display">
            <p>The practice of applying several local updates before aggregation across clients has been empirically shown to be a successful approach to overcoming the communication bottleneck in Federated Learning (FL). Such methods are usually implemented by having clients perform one or more epochs of local training per round while randomly reshuffling their finite dataset in each epoch. Data imbalance, where clients have different numbers of local training samples, is ubiquitous in FL applications, resulting in different clients performing different numbers of local updates in each round. In this work, we propose a general recipe, FedShuffle, that better utilizes the local updates in FL, especially in this regime encompassing random reshuffling and heterogeneity. FedShuffle is the first local update method with theoretical convergence guarantees that incorporates random reshuffling, data imbalance, and client sampling â features that are essential in large-scale cross-device FL. We present a comprehensive theoretical analysis of FedShuffle and show, both theoretically and empirically, that it does not suffer from the objective function mismatch that is present in FL methods that assume homogeneous updates in heterogeneous FL setups, such as FedAvg (McMahan et al., 2017). In addition, by combining the ingredients above, FedShuffle improves upon FedNova (Wang et al., 2020), which was previously proposed to solve this mismatch. Similar to Mime (Karimireddy et al., 2020), we show that FedShuffle with momentum variance reduction (Cutkosky & Orabona, 2019) improves upon non-local methods under a Hessian similarity assumption.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MHOAEiTlen">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MHOAEiTlen.html">DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">kaichen zhou &middot; Lanqing HONG &middot; Shoukang Hu &middot; Fengwei Zhou &middot; Binxin Ru &middot; Jiashi Feng &middot; Zhenguo Li</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MHOAEiTlen"></div>

    <a href="paper_pages/MHOAEiTlen.html">
        <img src="https://drive.google.com/thumbnail?id=1LYpQU2zJkzK6BBQPV1JZXNUU4mkcMtMr" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MHOAEiTlen" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MHOAEiTlen" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MHOAEiTlen">
                Abstract <i id="caret-MHOAEiTlen" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MHOAEiTlen">
        <div class="abstract-display">
            <p>Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). Although many strategies have been developed for automating these components in separation, joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often suffers from the low-performance correlation between the searching and retraining stages. An end-to-end solution that integrates the AutoML components and returns a ready-to-use model at the end of the search is desirable. In view of these, we propose DHA, which achieves joint optimization of Data augmentation policy, Hyper-parameter, and Architecture. Specifically, end-to-end NAS is achieved in a differentiable manner by optimizing a compressed lower-dimensional feature space, while DA policy and HPO are regarded as dynamic schedulers, which adapt themselves to the update of network parameters and network architecture at the same time. Experiments show that DHA achieves state-of-the-art (SOTA) results on various datasets and search spaces. To the best of our knowledge, we are the first to efficiently and jointly optimize DA policy, NAS, and HPO in an end-to-end manner without retraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vUuHPRrWs2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vUuHPRrWs2.html">Practicality of generalization guarantees for unsupervised domain adaptation with neural networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Adam Breitholtz &middot; Fredrik Daniel Johansson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vUuHPRrWs2"></div>

    <a href="paper_pages/vUuHPRrWs2.html">
        <img src="video_thumbnails/vUuHPRrWs2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vUuHPRrWs2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vUuHPRrWs2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vUuHPRrWs2">
                Abstract <i id="caret-vUuHPRrWs2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vUuHPRrWs2">
        <div class="abstract-display">
            <p>Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. 
For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment.
However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions.
In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain shift. To overcome this and arrive at the tightest possible results, we combine each bound with recent data-dependent PAC-Bayes analysis, greatly improving the guarantees. We find that, when domain overlap can be assumed, a simple importance weighting extension of previous work provides the tightest estimable bound. Finally, we study which terms dominate the bounds and identify possible directions for further improvement. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Sh3RF9JowK">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Sh3RF9JowK.html">Learning Algorithms for Markovian Bandits:\\Is Posterior Sampling more Scalable than Optimism?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nicolas Gast &middot; Bruno Gaujal &middot; Kimang Khun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Sh3RF9JowK"></div>

    <a href="paper_pages/Sh3RF9JowK.html">
        <img src="http://img.youtube.com/vi/Ii2773_g3po/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Sh3RF9JowK" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Sh3RF9JowK" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Sh3RF9JowK">
                Abstract <i id="caret-Sh3RF9JowK" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Sh3RF9JowK">
        <div class="abstract-display">
            <p>In this paper, we study the scalability of model-based algorithms learning the optimal policy of a discounted \blue{rested} Markovian bandit  problem with $n$ arms. There are two categories of model-based reinforcement learning algorithms: Bayesian algorithms (like PSRL), and optimistic algorithms (like UCRL2 or UCBVI).  A naive application of these  algorithms is not scalable because  the state-space is exponential in $n$. In this paper, we construct variants of these algorithms specially tailored to Markovian bandits (MB) that we call MB-PSRL, MB-UCRL2, and MB-UCBVI. \blue{We consider an episodic setting with geometrically distributed episode length, and measure the performance of the algorithm in terms of regret (Bayesian regret for MB-PSRL and expected regret for MB-UCRL2 and MB-UCBVI)}. We prove that, for this setting, all algorithms have a low regret in $\tilde{O}(S\sqrt{nK})$ -- where $K$ is the number of episodes, $n$ is the number of arms and $S$ is the number of states of each arm. Up to a factor $\sqrt{S}$, these regrets match the \blue{Bayesian minimax regret} lower bound of $\Omega(\sqrt{SnK})$ that we also derive.

Even if their theoretical regrets are comparable, the {\it time complexities} of these  algorithms vary greatly: We show that MB-UCRL2, as well as all  algorithms that use bonuses on transition matrices have a { time} complexity  that grows  exponentially in $n$.  In contrast, MB-UCBVI does not use bonuses on transition matrices and we show that  it can be implemented efficiently, with a time complexity linear in $n$. Our numerical experiments show, however, that its empirical regret is large. Our Bayesian algorithm, MB-PSRL, enjoys the best of both worlds: its running time is linear in the number of arms and its empirical regret is the smallest of all algorithms.
This is a new addition in the understanding of the power of Bayesian algorithms, that can often be  tailored to the structure of the problems to learn.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mbwm7NdkpO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mbwm7NdkpO.html">Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohammad Ali Alomrani &middot; Reza Moravej &middot; Elias Boutros Khalil</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mbwm7NdkpO"></div>

    <a href="paper_pages/mbwm7NdkpO.html">
        <img src="http://img.youtube.com/vi/PoMrl5rjQ3U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mbwm7NdkpO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mbwm7NdkpO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mbwm7NdkpO">
                Abstract <i id="caret-mbwm7NdkpO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mbwm7NdkpO">
        <div class="abstract-display">
            <p>The challenge in the widely applicable online matching problem lies in making irrevocable assignments while there is uncertainty about future inputs. Most theoretically-grounded policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform consistently better than classical baseline algorithms on four synthetic and real-world datasets. On average, our proposed models improve the matching quality by 3-10% on a variety of synthetic and real-world datasets.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aIoEkwc2oB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aIoEkwc2oB.html">INR-V: A Continuous Representation Space for Video-based Generative Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bipasha Sen &middot; Aditya Agarwal &middot; Vinay P Namboodiri &middot; C.V. Jawahar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aIoEkwc2oB"></div>

    <a href="paper_pages/aIoEkwc2oB.html">
        <img src="http://img.youtube.com/vi/ViIwnu5vcck/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aIoEkwc2oB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aIoEkwc2oB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aIoEkwc2oB">
                Abstract <i id="caret-aIoEkwc2oB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aIoEkwc2oB">
        <div class="abstract-display">
            <p>Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lCPOHiztuw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lCPOHiztuw.html">Direct Molecular Conformation Generation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jinhua Zhu &middot; Yingce Xia &middot; Chang Liu &middot; Lijun Wu &middot; Shufang Xie &middot; Yusong Wang &middot; Tong Wang &middot; Tao Qin &middot; Wengang Zhou &middot; Houqiang Li &middot; Haiguang Liu &middot; Tie-Yan Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lCPOHiztuw"></div>

    <a href="paper_pages/lCPOHiztuw.html">
        <img src="https://drive.google.com/thumbnail?id=1p_-NHOWBH3oiPFuaJiskXYWGdmRmwtLK" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lCPOHiztuw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lCPOHiztuw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lCPOHiztuw">
                Abstract <i id="caret-lCPOHiztuw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lCPOHiztuw">
        <div class="abstract-display">
            <p>Molecular conformation generation aims to generate three-dimensional coordinates of all the atoms in a molecule and is an important task in bioinformatics and pharmacology. Previous methods usually first predict the interatomic distances, the gradients of interatomic distances or the local structures (e.g., torsion angles) of a molecule, and then reconstruct its 3D conformation. How to directly generate the conformation without the above intermediate values is not fully explored. In this work, we propose a method that directly predicts the coordinates of atoms: (1) the loss function is invariant to roto-translation of coordinates and permutation of symmetric atoms; (2) the newly proposed model adaptively aggregates the bond and atom information and iteratively refines the coordinates of the generated conformation. Our method achieves the best results on GEOM-QM9 and GEOM-Drugs datasets. Further analysis shows that our generated conformations have closer properties (e.g., HOMO-LUMO gap) with the groundtruth conformations. In addition, our method improves molecular docking by providing better initial conformations. All the results demonstrate the effectiveness of our method and the great potential of the direct approach. The code is released at  \url{https://github.com/DirectMolecularConfGen/DMCG}.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6qMKztPn0n">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6qMKztPn0n.html">Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fan Wang &middot; Hao Tian &middot; Haoyi Xiong &middot; Hua Wu &middot; Jie Fu &middot; Yang Cao &middot; Yu Kang &middot; Haifeng Wang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6qMKztPn0n"></div>

    <a href="paper_pages/6qMKztPn0n.html">
        <img src="http://img.youtube.com/vi/8EA8KqlCRzY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6qMKztPn0n" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6qMKztPn0n" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6qMKztPn0n">
                Abstract <i id="caret-6qMKztPn0n" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6qMKztPn0n">
        <div class="abstract-display">
            <p>Artificial neural networks (ANNs) are typically confined to accomplishing pre-defined tasks by learning a set of static parameters. In contrast, biological neural networks (BNNs) can adapt to various new tasks by continually updating the neural connections based on the inputs, which is aligned with the paradigm of learning effective learning rules in addition to static parameters, \textit{e.g.}, meta-learning. Among various biologically inspired learning rules, Hebbian plasticity updates the neural network weights using local signals without the guide of an explicit target function, thus enabling an agent to learn automatically without human efforts. However, typical plastic ANNs using a large amount of meta-parameters violate the nature of the genomics bottleneck and potentially deteriorate the generalization capacity. This work proposes a new learning paradigm decomposing those connection-dependent plasticity rules into neuron-dependent rules thus accommodating $\Theta(n^2)$ learnable parameters with only $\Theta(n)$ meta-parameters. We also thoroughly study the effect of different neural modulation on plasticity. Our algorithms are tested in challenging random 2D maze environments, where the agents have to use their past experiences to shape the neural connections and improve their performances for the future. The results of our experiment validate the following: 1. Plasticity can be adopted to continually update a randomly initialized RNN to surpass pre-trained, more sophisticated recurrent models, especially when coming to long-term memorization. 2. Following the genomics bottleneck, the proposed decomposed plasticity can be comparable to or even more effective than canonical plasticity rules in some instances.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-M8D5iZsnrO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/M8D5iZsnrO.html">TITRATED: Learned Human Driving Behavior without Infractions via Amortized Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vasileios Lioutas &middot; Adam Scibior &middot; Frank Wood</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-M8D5iZsnrO"></div>

    <a href="paper_pages/M8D5iZsnrO.html">
        <img src="http://img.youtube.com/vi/AMeZtzQxhX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-M8D5iZsnrO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-M8D5iZsnrO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-M8D5iZsnrO">
                Abstract <i id="caret-M8D5iZsnrO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-M8D5iZsnrO">
        <div class="abstract-display">
            <p>Models of human driving behavior have long been used for prediction in autonomous vehicles, but recently have also started being used to create non-playable characters for driving simulations. While such models are in many respects realistic, they tend to suffer from unacceptably high rates of driving infractions, such as collisions or off-road driving, particularly when deployed in map locations with road geometries dissimilar to the training dataset. In this paper we present a novel method for fine-tuning a foundation model of human driving behavior to novel locations where human demonstrations are not available which reduces the incidence of such infractions. The method relies on inference in the foundation model to generate infraction-free trajectories as well as additional penalties applied when fine-tuning the amortized inference behavioral model. We demonstrate this "titration" technique using the ITRA foundation behavior model trained on the INTERACTION dataset when transferring to CARLA map locations. We demonstrate a 76-86% reduction in infraction rate and provide evidence that further gains are possible with more computation or better inference algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lE7K4n1Esk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lE7K4n1Esk.html">On the Adversarial Robustness of Vision Transformers</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Rulin Shao &middot; Zhouxing Shi &middot; Jinfeng Yi &middot; Pin-Yu Chen &middot; Cho-Jui Hsieh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lE7K4n1Esk"></div>

    <a href="paper_pages/lE7K4n1Esk.html">
        <img src="http://img.youtube.com/vi/paMjHR5ufRs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lE7K4n1Esk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lE7K4n1Esk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lE7K4n1Esk">
                Abstract <i id="caret-lE7K4n1Esk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lE7K4n1Esk">
        <div class="abstract-display">
            <p>Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides a comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various white-box and transfer attack settings, we find that ViTs possess better adversarial robustness when compared with MLP-Mixer and convolutional neural networks (CNNs) including ConvNeXt, and this observation also holds for certified robustness. Through frequency analysis and feature visualization, we summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less high-frequency patterns that have spurious correlation,  which helps explain why ViTs are less sensitive to high-frequency perturbations than CNNs and MLP-Mixer, and there is a high correlation between how much the model learns high-frequency features and its robustness against different frequency-based perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning high-frequency features in ViTs can improve classification accuracy but at the cost of adversarial robustness. 3) Modern CNN designs that borrow techniques from ViTs including activation function, layer norm, larger kernel size to imitate the global attention, and patchify the images as inputs, etc., could help bridge the performance gap between ViTs and CNNs not only in terms of performance, but also certified and empirical adversarial robustness. Moreover, we show adversarial training is also applicable to ViT for training robust models, and sharpness-aware minimization can also help improve robustness, while pre-training with clean images on larger datasets does not significantly improve adversarial robustness. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XsPopigZXV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XsPopigZXV.html">FLEA: Provably Robust Fair Multisource Learning from Unreliable Training Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Eugenia Iofinova &middot; Nikola Konstantinov &middot; Christoph H Lampert</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XsPopigZXV"></div>

    <a href="paper_pages/XsPopigZXV.html">
        <img src="video_thumbnails/XsPopigZXV.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XsPopigZXV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XsPopigZXV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XsPopigZXV">
                Abstract <i id="caret-XsPopigZXV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XsPopigZXV">
        <div class="abstract-display">
            <p>Fairness-aware learning aims at constructing classifiers that not only make accurate predictions, but also do not discriminate against specific groups. It is a fast-growing area of machine learning with far-reaching societal impact. However, existing fair learning methods are vulnerable to accidental or malicious artifacts in the training data, which can cause them to unknowingly produce unfair classifiers. In this work we address the problem of fair learning from unreliable training data in the robust multisource setting, where the available training data comes from multiple sources, a fraction of which might not be representative of the true data distribution. We introduce FLEA, a filtering-based algorithm that identifies and suppresses those data sources that would have a negative impact on fairness or accuracy if they were used for training. As such, FLEA is not a replacement of prior fairness-aware learning methods but rather an augmentation that makes any of them robust against unreliable training data. We show the effectiveness of our approach by a diverse range of experiments on multiple datasets. Additionally, we prove formally that âgiven enough dataâ FLEA protects the learner against corruptions as long as the fraction of affected data sources is less than half. Our source code and documentation are available at https://github.com/ISTAustria-CVML/FLEA.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gCmQK6McbR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gCmQK6McbR.html">HEAT: Hyperedge Attention Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dobrik Georgiev Georgiev &middot; Marc Brockschmidt &middot; Miltiadis Allamanis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gCmQK6McbR"></div>

    <a href="paper_pages/gCmQK6McbR.html">
        <img src="http://img.youtube.com/vi/q0oFjmxz_60/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gCmQK6McbR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gCmQK6McbR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gCmQK6McbR">
                Abstract <i id="caret-gCmQK6McbR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gCmQK6McbR">
        <div class="abstract-display">
            <p>Learning from structured data is a core machine learning task. Commonly, such data is represented as graphs, which normally only consider (typed) binary relationships between pairs of nodes. This is a substantial limitation for many domains with highly-structured data. One important such domain is source code, where hypergraph-based representations can better capture the semantically rich and structured nature of code.
In this work, we present HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes contribute. It can be viewed as a generalization of both message passing neural networks and Transformers. We evaluate HEAT on knowledge base completion and on bug detection and repair using a novel hypergraph representation of programs. In both settings, it outperforms strong baselines, indicating its power and generality.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-e7mYYMSyZH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/e7mYYMSyZH.html">On the Convergence of Shallow Neural Network Training with Randomly Masked Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fangshuo Liao &middot; Anastasios Kyrillidis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-e7mYYMSyZH"></div>

    <a href="paper_pages/e7mYYMSyZH.html">
        <img src="http://img.youtube.com/vi/8dR4tcfOTkE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-e7mYYMSyZH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-e7mYYMSyZH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-e7mYYMSyZH">
                Abstract <i id="caret-e7mYYMSyZH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-e7mYYMSyZH">
        <div class="abstract-display">
            <p>With the motive of training all the parameters of a neural network, we study why and when one can achieve this by iteratively creating, training, and combining randomly selected subnetworks. Such scenarios have either implicitly or explicitly emerged in the recent literature: see e.g., the Dropout family of regularization techniques, or some distributed ML training protocols that reduce communication/computation complexities, such as the Independent Subnet Training protocol. While these methods are studied empirically and utilized in practice, they often enjoy partial or no theoretical support, especially when applied on neural network-based objectives.

In this manuscript, our focus is on overparameterized single hidden layer neural networks with ReLU activations in the lazy training regime. By carefully analyzing $i)$ the subnetworks' neural tangent kernel, $ii)$ the surrogate functions' gradient, and $iii)$ how we sample and combine the surrogate functions, we prove linear convergence rate of the training error --up to a neighborhood around the optimal point-- for an overparameterized single-hidden layer perceptron with a regression loss. Our analysis reveals a dependency of the size of the neighborhood around the optimal point on the number of surrogate models and the number of local training steps for each selected subnetwork. Moreover, the considered framework generalizes and provides new insights on dropout training, multi-sample dropout training, as well as Independent Subnet Training; for each case, we provide convergence results as corollaries of our main theorem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qzM1Tw5i7N">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qzM1Tw5i7N.html">SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">ZHUOWEI WANG &middot; Jing Jiang &middot; Bo Han &middot; Lei Feng &middot; Bo An &middot; Gang Niu &middot; Guodong Long</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qzM1Tw5i7N"></div>

    <a href="paper_pages/qzM1Tw5i7N.html">
        <img src="http://img.youtube.com/vi/sKDRt9GNLTs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qzM1Tw5i7N" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qzM1Tw5i7N" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qzM1Tw5i7N">
                Abstract <i id="caret-qzM1Tw5i7N" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qzM1Tw5i7N">
        <div class="abstract-display">
            <p>Deep learning with noisy labels is a challenging task, which has received much attention from the machine learning and computer vision communities. Recent prominent methods that build on a specific sample selection (SS) strategy and a specific semi-supervised learning (SSL) model achieved state-of-the-art performance. Intuitively, better performance could be achieved if stronger SS strategies and SSL models are employed. Following this intuition, one might easily derive various effective noisy-label learning methods using different combinations of SS strategies and SSL models, which is, however, simply reinventing the wheel in essence. To prevent this problem, we propose SemiNLL, a versatile framework that investigates how to naturally combine different SS and SSL components based on their effects and efficiencies. We conduct a systematic and detailed analysis of the combinations of possible components based on our framework. Our framework can absorb various SS strategies and SSL backbones, utilizing their power to achieve promising performance. The instantiations of our framework demonstrate substantial improvements over state-of-the-art methods on benchmark-simulated and real-world datasets with noisy labels.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ywr5sWqQt4">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ywr5sWqQt4.html">A Comprehensive Study of Real-Time Object Detection Networks Across Multiple Domains: A Survey</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elahe Arani &middot; Shruthi Gowda &middot; Ratnajit Mukherjee &middot; Omar Magdy &middot; Senthilkumar Sockalingam Kathiresan &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ywr5sWqQt4"></div>

    <a href="paper_pages/ywr5sWqQt4.html">
        <img src="http://img.youtube.com/vi/-Z_DEE96VM0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ywr5sWqQt4" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ywr5sWqQt4" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ywr5sWqQt4">
                Abstract <i id="caret-ywr5sWqQt4" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ywr5sWqQt4">
        <div class="abstract-display">
            <p>Deep neural network based object detectors are continuously evolving and are used in a multitude of applications, each having its own set of requirements. While safety-critical applications need high accuracy and reliability, low-latency tasks need resource and energy-efficient networks. Real-time detection networks, which are a necessity in high-impact real-world applications, are continuously proposed but they overemphasize the improvements in accuracy and speed while other capabilities such as versatility, robustness, resource, and energy efficiency are omitted. A reference benchmark for existing networks does not exist nor does a standard evaluation guideline for designing new networks, which results in ambiguous and inconsistent comparisons. We, therefore, conduct a comprehensive study on multiple real-time detection networks (anchor-based, keypoint-based, and transformer-based) on a wide range of datasets and report results on an extensive set of metrics. We also study the impact of variables such as image size, anchor dimensions, confidence thresholds, and architecture layers on the overall performance. We analyze the robustness of detection networks against distribution shift, natural corruptions, and adversarial attacks. Also, we provide the calibration analysis to gauge the reliability of the predictions. Finally, to highlight the real-world impact, we conduct two unique case studies, on autonomous driving and healthcare application. To further gauge the capability of networks in critical real-time applications, we report the performance after deploying the detection networks on edge devices. Our extensive empirical study can act as a guideline for the industrial community to make an informed choice on the existing networks. We also hope to inspire the research community towards a new direction of design and evaluation of networks that focuses on the bigger and holistic overview for a far-reaching impact.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0nEZCVshxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0nEZCVshxS.html">Diagnosing and Fixing Manifold Overfitting in Deep Generative Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gabriel Loaiza-Ganem &middot; Brendan Leigh Ross &middot; Jesse C Cresswell &middot; Anthony L. Caterini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0nEZCVshxS"></div>

    <a href="paper_pages/0nEZCVshxS.html">
        <img src="http://img.youtube.com/vi/-2YaUfMlwrU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0nEZCVshxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0nEZCVshxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0nEZCVshxS">
                Abstract <i id="caret-0nEZCVshxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0nEZCVshxS">
        <div class="abstract-display">
            <p>Likelihood-based, or explicit, deep generative models use neural networks to construct flexible high-dimensional densities. This formulation directly contradicts the manifold hypothesis, which states that observed data lies on a low-dimensional manifold embedded in high-dimensional ambient space. In this paper we investigate the pathologies of maximum-likelihood training in the presence of this dimensionality mismatch. We formally prove that degenerate optima are achieved wherein the manifold itself is learned but not the distribution on it, a phenomenon we call manifold overfitting. We propose a class of two-step procedures consisting of a dimensionality reduction step followed by maximum-likelihood density estimation, and prove that they recover the data-generating distribution in the nonparametric regime, thus avoiding manifold overfitting. We also show that these procedures enable density estimation on the manifolds learned by implicit models, such as generative adversarial networks, hence addressing a major shortcoming of these models. Several recently proposed methods are instances of our two-step procedures; we thus unify, extend, and theoretically justify a large class of models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8GvRCWKHIL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8GvRCWKHIL.html">Optimal Client Sampling for Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Wenlin Chen &middot; Samuel HorvÃ¡th &middot; Peter RichtÃ¡rik</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8GvRCWKHIL"></div>

    <a href="paper_pages/8GvRCWKHIL.html">
        <img src="http://img.youtube.com/vi/lhLJL1FJ_OE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8GvRCWKHIL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8GvRCWKHIL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8GvRCWKHIL">
                Abstract <i id="caret-8GvRCWKHIL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8GvRCWKHIL">
        <div class="abstract-display">
            <p>It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with "important" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2EOVIvRXlv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2EOVIvRXlv.html">Ranking Recovery under Privacy Considerations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Minoh Jeong &middot; Alex Dytso &middot; Martina Cardone</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2EOVIvRXlv"></div>

    <a href="paper_pages/2EOVIvRXlv.html">
        <img src="video_thumbnails/2EOVIvRXlv.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2EOVIvRXlv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2EOVIvRXlv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2EOVIvRXlv">
                Abstract <i id="caret-2EOVIvRXlv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2EOVIvRXlv">
        <div class="abstract-display">
            <p>We consider the private ranking recovery problem, where a data collector seeks to estimate the permutation/ranking of a data vector given a randomized (privatized) version of it. We aim to establish fundamental trade-offs between the performance of the estimation task, measured in terms of probability of error, and the level of privacy that can be guaranteed when the noise mechanism consists of adding artificial noise. Towards this end, we show the optimality of a low-complexity decision rule (referred to as linear decoder) for the estimation task, under several noise distributions widely used in the privacy literature (e.g., Gaussian, Laplace, and generalized normal model). We derive the Taylor series of the probability of error, which yields its first and second-order approximations when such a linear decoder is employed.  We quantify the guaranteed level of privacy using differential privacy (DP) types of metrics, such as $\epsilon$-DP and $(\alpha,\epsilon)$-RÃ©nyi DP. Finally, we put together the results to characterize trade-offs between privacy and probability of error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aRsLetumx1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aRsLetumx1.html">How Expressive are Transformers in Spectral Domain for Graphs?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Anson Bastos &middot; Abhishek Nadgeri &middot; Kuldeep Singh &middot; Hiroki Kanezashi &middot; Toyotaro Suzumura &middot; Isaiah Onando Mulang'</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aRsLetumx1"></div>

    <a href="paper_pages/aRsLetumx1.html">
        <img src="http://img.youtube.com/vi/7JNDYQuRSas/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aRsLetumx1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aRsLetumx1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aRsLetumx1">
                Abstract <i id="caret-aRsLetumx1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aRsLetumx1">
        <div class="abstract-display">
            <p>The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to investigate if spectral analysis of the transformer will reveal insights into its expressive power. Similar studies already established that spectral analysis of Graph neural networks (GNNs) provides extra perspectives on their expressiveness. 
In this work, we systematically study and establish the link between the spatial and spectral domain in the realm of the transformer. We further provide a theoretical analysis that the spatial attention mechanism in the transformer cannot effectively capture the desired frequency response, thus, inherently limiting its expressiveness in spectral space. Therefore, we propose FeTA, a framework that aims to perform attention over the entire graph spectrum (i.e. actual frequency components of the graph) analogous to the attention in spatial space. 
Empirical results suggest that FeTA provides homogeneous performance gain against vanilla transformer across all tasks on standard benchmarks and can easily be extended to GNN-based models with low-pass characteristics (e.g., GAT). </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-h1zuM6cXpH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/h1zuM6cXpH.html">Zero-Shot Learning with Common Sense Knowledge Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal V. Nayak &middot; Stephen Bach</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-h1zuM6cXpH"></div>

    <a href="paper_pages/h1zuM6cXpH.html">
        <img src="http://img.youtube.com/vi/VXt3MucMWvY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-h1zuM6cXpH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-h1zuM6cXpH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-h1zuM6cXpH">
                Abstract <i id="caret-h1zuM6cXpH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-h1zuM6cXpH">
        <div class="abstract-display">
            <p>Zero-shot learning relies on semantic class representations such as hand-engineered attributes or learned embeddings to predict classes without any labeled examples. We propose to learn class representations by embedding nodes from common sense knowledge graphs in a vector space. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a general-purpose framework with a novel transformer graph convolutional network (TrGCN) for generating class representations. Our proposed TrGCN architecture computes non-linear combinations of node neighbourhoods. Our results show that ZSL-KG improves over existing WordNet-based methods on five out of six zero-shot benchmark datasets in language and vision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xyt4wfdo4J">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xyt4wfdo4J.html">Iterative State Estimation in Non-linear Dynamical Systems Using Approximate Expectation Propagation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sanket Kamthe &middot; So Takao &middot; Shakir Mohamed &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xyt4wfdo4J"></div>

    <a href="paper_pages/xyt4wfdo4J.html">
        <img src="http://img.youtube.com/vi/FrTY04gXErY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xyt4wfdo4J" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xyt4wfdo4J" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xyt4wfdo4J">
                Abstract <i id="caret-xyt4wfdo4J" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xyt4wfdo4J">
        <div class="abstract-display">
            <p>Bayesian inference in non-linear dynamical systems seeks to find good posterior approximations of a latent state given a sequence of observations. Gaussian filters and smoothers, including the (extended/unscented) Kalman filter/smoother, which are commonly used in engineering applications, yield Gaussian posteriors on the latent state. While they are computationally efficient, they are often criticised for their crude approximation of the posterior state distribution. In this paper, we address this criticism by proposing a message passing scheme for iterative state estimation in non-linear dynamical systems, which yields more informative (Gaussian) posteriors on the latent states.  Our message passing scheme is based on expectation propagation (EP). We prove that classical Rauch--Tung--Striebel (RTS) smoothers, such as the extended Kalman smoother (EKS) or the unscented Kalman smoother (UKS), are special cases of our message passing scheme. Running the message passing scheme more than once can lead to significant improvements of the classical RTS smoothers, so that more informative state estimates can be obtained. We address potential convergence issues of EP by generalising our state estimation framework to damped updates and the consideration of general $\alpha$-divergences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ggPhsYCsm9">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ggPhsYCsm9.html">NeSF: Neural Semantic Fields for Generalizable Semantic Segmentation of 3D Scenes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Suhani Vora &middot; Noha Radwan &middot; Klaus Greff &middot; Henning Meyer &middot; Kyle Genova &middot; Mehdi S. M. Sajjadi &middot; Etienne Pot &middot; Andrea Tagliasacchi &middot; Daniel Duckworth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ggPhsYCsm9"></div>

    <a href="paper_pages/ggPhsYCsm9.html">
        <img src="http://img.youtube.com/vi/odg-L-fG7Wo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ggPhsYCsm9" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ggPhsYCsm9" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ggPhsYCsm9">
                Abstract <i id="caret-ggPhsYCsm9" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ggPhsYCsm9">
        <div class="abstract-display">
            <p>We present NeSF, a method for producing 3D semantic fields from posed RGB images alone. In place of classical 3D representations, our method builds on recent work in neural fields wherein 3D structure is captured by point-wise functions. We leverage this methodology to recover 3D density fields upon which we then train a 3D semantic segmentation model supervised by posed 2D semantic maps. Despite being trained on 2D signals alone, our method is able to generate 3D-consistent semantic maps from novel camera poses and can be queried at arbitrary 3D points. Notably, NeSF is compatible with any method producing a density field. Our empirical analysis demonstrates comparable quality to competitive 2D and 3D semantic segmentation baselines on complex, realistically-rendered scenes and significantly outperforms a comparable neural radiance field-based method on a series of tasks requiring 3D reasoning. Our method is the first to learn semantics by recognizing patterns in the geometry stored within a 3D neural field representation. NeSF is trained using purely 2D signals and requires as few as one labeled image per-scene at train time. No semantic input is required for inference on novel scenes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tnPjQpYk7D">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tnPjQpYk7D.html">Multi-Agent Off-Policy TDC with Near-Optimal Sample and Communication Complexities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ziyi Chen &middot; Yi Zhou &middot; Rong-Rong Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tnPjQpYk7D"></div>

    <a href="paper_pages/tnPjQpYk7D.html">
        <img src="http://img.youtube.com/vi/BCYEaLGtTNE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tnPjQpYk7D" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tnPjQpYk7D" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tnPjQpYk7D">
                Abstract <i id="caret-tnPjQpYk7D" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tnPjQpYk7D">
        <div class="abstract-display">
            <p>The finite-time convergence of off-policy temporal difference (TD) learning has been comprehensively studied recently. However, such a type of convergence has not been established for off-policy TD learning in the multi-agent setting, which covers broader reinforcement learning applications and is fundamentally more challenging. This work develops a decentralized TD with correction (TDC) algorithm for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithm avoids sharing the actions, policies and rewards of the agents, and adopts mini-batch sampling to reduce the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-time sample complexity of our algorithm for achieving an $\epsilon$-accurate solution is in the order of $\mathcal{O}\big(\frac{M\ln\epsilon^{-1}}{\epsilon(1-\sigma_2)^2}\big)$, where $M$ denotes the total number of agents and $\sigma_2$ is a network parameter. This matches the sample complexity of the centralized TDC. Moreover, our algorithm achieves the optimal communication complexity $\mathcal{O}\big(\frac{\sqrt{M}\ln\epsilon^{-1}}{1-\sigma_2}\big)$ for synchronizing the value function parameters, which is order-wise lower than the communication complexity of the existing decentralized TD(0). Numerical simulations corroborate our theoretical findings. </p>
        </div>
    </div>
</div>
                    </div>
                </div>
            </div>

        <script>
            function listmode(){
                $(".cards_img").hide();
                $(".pp-card").addClass("pp-mode-list").removeClass("pp-mode-compact");
            }
            function compactmode(){
                $(".cards_img").show();
                $(".pp-card").removeClass("pp-mode-list").addClass("pp-mode-compact");
            }
        </script>


<script>
    $(document).ready(function() {
        $(".abstract-link").on('click', function(e){
            var target = $(e.target).find("i")
            target.toggleClass("fa-caret-right");
            target.toggleClass("fa-caret-up");
        })
        touchup();
        /* touchup events currently adds dates to cached virtualcards for events */
    })

</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
  "tex2jax": {
    "inlineMath": [["$","$"], ["\(","\)"]],
    "displayMath": [["\[","\]"]],
    "processEscapes": true
  }
}
);
var jq2 = $;
</script>

<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>