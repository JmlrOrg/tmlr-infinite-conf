<!DOCTYPE html>
<html lang="en" style="scroll-padding-top: 70px;">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">
    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="/static/expo/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/css/bootstrap-select.min.css">
    <link rel="stylesheet" href="cards.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">

    <script src="https://code.jquery.com/jquery-3.6.1.min.js"
            integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>
    </script>

    <script>
        if (typeof jQuery === 'undefined') {
            var script = document.createElement('script');
            script.type = 'text/javascript';
            script.src = "/static/core/js/jquery-3.6.1.min.js";
            document.head.appendChild(script);
        }
    </script>

    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.13.14/dist/js/bootstrap-select.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/corejs-typeahead/1.3.1/typeahead.bundle.min.js" integrity="sha512-lEb9Vp/rkl9g2E/LdHIMFTqz21+LA79f84gqP75fbimHqVTu6483JG1AwJlWLLQ8ezTehty78fObKupq3HSHPQ==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>
    <script src="/static/virtual/js/virtual.js"></script>

    <link rel="stylesheet" href="virtual.css">

    <style>
    body {
        background: #f6f6f6;
    }
    </style>

</head>

<body>
<!-- NAV -->

<!--
<nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="/">
            <img src="/static/core/img/ICML-logo.svg" height="40px">
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item ">
                    <a class="nav-link" href="/virtual/2022/events/tutorial">Tutorials</a>
                </li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Main Conference
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                        <a class="dropdown-item" href="/virtual/2022/events/oral">Orals</a>
                        <div class="dropdown-divider"></div>
                        <a class="dropdown-item" href="/virtual/2022/papers.html">Papers</a>
                    </div>
                </li>
            </ul>
    </div>
    </div>
</nav>
-->

    <!-- NAV -->

    <nav class="navbar sticky-top navbar-expand-lg navbar-light mr-auto" id="main-nav">
    <div class="container-fluid">
        <a class="navbar-brand" href="">
            <img src="tmlr_logo.jpeg" height="40px">
            Transactions on Machine Learning Research
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
        aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse text-right flex-grow-1" id="navbarNav">
        <ul class="navbar-nav ml-auto">

            <!--
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button"
                data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                Main Conference
                </a>
                <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/oral">Orals</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/events/spotlight">Spotlights</a>
                    <div class="dropdown-divider"></div>
                    <a class="dropdown-item" href="/virtual/2023/papers.html">Papers</a>
                </div>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../">All Papers</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="">Papers with Videos</a>
            </li>
            -->

            <!--
            <li class="nav-item">
                <a class="nav-link" href="../featured_papers.html">Featured Papers</a>
            </li>
            -->

    <!--
    <li class="nav-item ">
        <a class="nav-link" href="/virtual/2023/search"><i class="fas fa-search"></i> &nbsp;</a>
    </li>
    -->
        </ul>
    </div>
</div>
</nav>



    <div class="container">
        <br />
        <div class="row">
            <div class="col-md-12"></div>
            <div class="title-centered" style="text-align:center">TMLR Infinite Conference</div>
        </div>
    </div>

        <div class="row">
            <div class="col-sm-12">
                <div style="max-width: 1500px; margin:auto; border">
                    <div class="grid-displaycards">
                        <div class="displaycards touchup-date" id="event-DPvwr4HJdt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DPvwr4HJdt.html">On the Choice of Learning Rate for Local SGD</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Lukas Balles &middot; Prabhu Teja S &middot; Cedric Archambeau</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DPvwr4HJdt"></div>

    <a href="paper_pages/DPvwr4HJdt.html">
        <img src="http://img.youtube.com/vi/0D5B1ysq5Zg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DPvwr4HJdt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DPvwr4HJdt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DPvwr4HJdt">
                Abstract <i id="caret-DPvwr4HJdt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DPvwr4HJdt">
        <div class="abstract-display">
            <p>Distributed data-parallel optimization accelerates the training of neural networks, but requires constant synchronization of gradients between the workers, which can become a bottleneck. One way to reduce communication overhead is to use Local SGD, where each
worker asynchronously takes multiple local gradient steps, after which the model weights are averaged. In this work, we discuss the choice of learning rate for Local SGD, showing that it faces an intricate trade-off. Unlike in the synchronous case, its gradient estimate is
biased, with the bias dependent on the learning rate itself. Thus using learning rate scaling techniques designed for faster convergence in the synchronous case with Local SGD results in a performance degradation as previously observed. To analyze the manifestation of this bias, we study convergence behaviour of Local SGD and synchronous data-parallel SGD when using their optimal learning rates. Our experiments show that the optimal learning rate for Local SGD differs substantially from that of SGD, and when using it the performance of Local SGD matches that of SGD. However, this performance comes at the cost of added training iterations, rendering Local SGD faster than SGD only when communication is much more time-consuming than computation. This suggests that Local SGD may be of limited practical utility.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-eN9CjU3h1b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/eN9CjU3h1b.html">MMD-Regularized Unbalanced Optimal Transport</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Piyushi Manupriya &middot; SakethaNath Jagarlapudi &middot; Pratik Jawanpuria</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-eN9CjU3h1b"></div>

    <a href="paper_pages/eN9CjU3h1b.html">
        <img src="http://img.youtube.com/vi/FSJ4_GfLhHo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-eN9CjU3h1b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-eN9CjU3h1b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-eN9CjU3h1b">
                Abstract <i id="caret-eN9CjU3h1b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-eN9CjU3h1b">
        <div class="abstract-display">
            <p>We study the unbalanced optimal transport (UOT) problem, where the marginal constraints are enforced using Maximum Mean Discrepancy (MMD) regularization. Our work is motivated by the observation that the literature on UOT is focused on regularization based on $\phi$-divergence (e.g., KL divergence). Despite the popularity of MMD, its role as a regularizer in the context of UOT seems less understood. We begin by deriving a specific dual of MMD-regularized UOT (MMD-UOT), which helps us prove several useful properties. One interesting outcome of this duality result is that MMD-UOT induces novel metrics, which not only lift the ground metric like the Wasserstein but are also sample-wise efficient to estimate like the MMD. Further, for real-world applications involving non-discrete measures, we present an estimator for the transport plan that is supported only on the given ($m$) samples. Under certain conditions, we prove that the estimation error with this finitely-supported transport plan is also $\mathcal{O}(1/\sqrt{m})$. As far as we know, such error bounds that are free from the curse of dimensionality are not known for $\phi$-divergence regularized UOT. Finally, we discuss how the proposed estimator can be computed efficiently using accelerated gradient descent. Our experiments show that MMD-UOT consistently outperforms popular baselines, including KL-regularized UOT and MMD, in diverse machine learning applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-n2YifD4Dxo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/n2YifD4Dxo.html">Are you using test log-likelihood correctly?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sameer Deshpande &middot; Soumya Ghosh &middot; Tin D. Nguyen &middot; Tamara Broderick</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-n2YifD4Dxo"></div>

    <a href="paper_pages/n2YifD4Dxo.html">
        <img src="https://drive.google.com/thumbnail?id=10Hg_OBUU52ARiWjDJK7q6fYHU74my8vX" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-n2YifD4Dxo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-n2YifD4Dxo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-n2YifD4Dxo">
                Abstract <i id="caret-n2YifD4Dxo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-n2YifD4Dxo">
        <div class="abstract-display">
            <p>Test log-likelihood is commonly used to compare different models of the same data or different approximate inference algorithms for fitting the same probabilistic model. We present simple examples demonstrating how comparisons based on test log-likelihood can contradict comparisons according to other objectives. Specifically, our examples show that (i) approximate Bayesian inference algorithms that attain higher test log-likelihoods need not also yield more accurate posterior approximations and (ii) conclusions about forecast accuracy based on test log-likelihood comparisons may not agree with conclusions based on root mean squared error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JllRdycmLk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JllRdycmLk.html">The (Un)Scalability of Informed Heuristic Function Estimation in NP-Hard Search Problems</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sumedh Pendurkar &middot; Taoan Huang &middot; Brendan Juba &middot; Jiapeng Zhang &middot; Sven Koenig &middot; Guni Sharon</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JllRdycmLk"></div>

    <a href="paper_pages/JllRdycmLk.html">
        <img src="http://img.youtube.com/vi/jc4YN-Nt1RU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JllRdycmLk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JllRdycmLk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JllRdycmLk">
                Abstract <i id="caret-JllRdycmLk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JllRdycmLk">
        <div class="abstract-display">
            <p>The A* algorithm is commonly used to solve NP-hard combinatorial optimization problems. When provided with a completely informed heuristic function, A* can solve such problems in time complexity that is polynomial in the solution cost and branching factor. In light of this fact, we examine a line of recent publications that propose fitting deep neural networks to the completely informed heuristic function. We assert that these works suffer from inherent scalability limitations since --- under the assumption of NP $\not \subseteq$ P/poly --- such approaches result in either (a) network sizes that scale super-polynomially in the instance sizes or (b) the accuracy of the fitted deep neural networks scales inversely with the instance sizes. Complementing our theoretical claims, we provide experimental results for three representative NP-hard search problems. The results suggest that fitting deep neural networks to informed heuristic functions requires network sizes that grow quickly with the problem instance size. We conclude by suggesting that the research community should focus on scalable methods for integrating heuristic search with machine learning, as opposed to methods relying on informed heuristic estimation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YVPb6tyRJu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YVPb6tyRJu.html">FREED++: Improving RL Agents for Fragment-Based Molecule Generation by Thorough Reproduction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Telepov &middot; Artem Tsypin &middot; Kuzma Khrabrov &middot; Sergey Yakukhnov &middot; Pavel Strashnov &middot; Petr Zhilyaev &middot; Egor Rumiantsev &middot; Daniel Ezhov &middot; Manvel Avetisian &middot; Olga Popova &middot; Artur Kadurin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YVPb6tyRJu"></div>

    <a href="paper_pages/YVPb6tyRJu.html">
        <img src="http://img.youtube.com/vi/BctJymnJfJg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YVPb6tyRJu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YVPb6tyRJu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YVPb6tyRJu">
                Abstract <i id="caret-YVPb6tyRJu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YVPb6tyRJu">
        <div class="abstract-display">
            <p>A rational design of new therapeutic drugs aims to find a molecular structure with desired biological functionality, e.g., an ability to activate or suppress a specific protein via binding to it.
Molecular docking is a common technique for evaluating protein-molecule interactions.
Recently, Reinforcement Learning (RL) has emerged as a promising approach to generating molecules with the docking score (DS) as a reward.
In this work, we reproduce, scrutinize and improve the recent RL model for molecule generation called FREED (Yang et al., 2021).
Extensive evaluation of the proposed method reveals several limitations and challenges despite the outstanding results reported for three target proteins.
Our contributions include fixing numerous implementation bugs and simplifying the model while increasing its quality, significantly extending experiments, and conducting an accurate comparison with current state-of-the-art methods for protein-conditioned molecule generation.
We show that the resulting fixed model is capable of producing molecules with superior docking scores compared to alternative approaches.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oyfRWeoUJY">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oyfRWeoUJY.html">Addressing caveats of neural persistence with deep graph persistence</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Leander Girrbach &middot; Anders Christensen &middot; Ole Winther &middot; Zeynep Akata &middot; A. Sophia Koepke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oyfRWeoUJY"></div>

    <a href="paper_pages/oyfRWeoUJY.html">
        <img src="http://img.youtube.com/vi/KfCpoPYK_CY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oyfRWeoUJY" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oyfRWeoUJY" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oyfRWeoUJY">
                Abstract <i id="caret-oyfRWeoUJY" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oyfRWeoUJY">
        <div class="abstract-display">
            <p>Neural Persistence is a prominent measure for quantifying neural network complexity, proposed in the emerging field of topological data analysis in deep learning. In this work, however, we find both theoretically and empirically that the variance of network weights and spatial concentration of large weights are the main factors that impact neural persistence. Whilst this captures useful information for linear classifiers, we find that no relevant spatial structure is present in later layers of deep neural networks, making neural persistence roughly equivalent to the variance of weights. Additionally, the proposed averaging procedure across layers for deep neural networks does not consider interaction between layers. Based on our analysis, we propose an extension of the filtration underlying neural persistence to the whole neural network instead of single layers, which is equivalent to calculating neural persistence on one particular matrix. This yields our deep graph persistence measure, which implicitly incorporates persistent paths through the network and alleviates variance-related issues through standardisation. Code is available at  https://github.com/ExplainableML/Deep-Graph-Persistence.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4uflhObpcp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4uflhObpcp.html">UnIVAL: Unified Model for Image, Video, Audio and Language Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mustafa Shukor &middot; Corentin Dancette &middot; Alexandre Rame &middot; Matthieu Cord</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4uflhObpcp"></div>

    <a href="paper_pages/4uflhObpcp.html">
        <img src="http://img.youtube.com/vi/mYOun92st08/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4uflhObpcp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4uflhObpcp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4uflhObpcp">
                Abstract <i id="caret-4uflhObpcp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4uflhObpcp">
        <div class="abstract-display">
            <p>Large Language Models (LLMs) have made the ambitious quest for generalist agents significantly far from being a fantasy. A key hurdle for building such general models is the diversity and heterogeneity of tasks and modalities. A promising solution is unification, allowing the support of a myriad of tasks and modalities within one unified framework. While few large models (e.g., Flamingo (Alayrac et al. 2022)), trained on massive datasets, can support more than two modalities, current small to mid-scale unified models are still limited to 2 modalities, usually image-text or video-text. The question that we ask is: is it possible to build efficiently a unified model that can support all modalities? To answer this, we propose UnIVAL, a step further towards this ambitious goal. Without relying on fancy datasets sizes or models with billions of parameters, the ~ 0.25B parameter UnIVAL model goes beyond two modalities and unifies text, images, video, and audio into a single model. Our model is efficiently pretrained on many tasks, based on task balancing and multimodal curriculum learning. UnIVAL shows competitive performance to existing state-of-the-art approaches, across image and video-text tasks. The feature representations learned from image and video-text modalities,  allows the model to achieve competitive performance when finetuned on audio-text tasks, despite not being pretrained on audio. Thanks to the unified model, we propose a novel study on multimodal model merging via weight interpolation of models trained on different multimodal tasks, showing their benefits in particular for out-of-distribution generalization. Finally, we motivate unification by showing the synergy between tasks. The model weights and code are available at: https://github.com/mshukor/UnIVAL.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lTOku838Zv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lTOku838Zv.html">Neural Implicit Manifold Learning for Topology-Aware Density Estimation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Brendan Leigh Ross &middot; Gabriel Loaiza-Ganem &middot; Anthony L. Caterini &middot; Jesse C. Cresswell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lTOku838Zv"></div>

    <a href="paper_pages/lTOku838Zv.html">
        <img src="http://img.youtube.com/vi/f1a_8LoyZxw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lTOku838Zv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lTOku838Zv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lTOku838Zv">
                Abstract <i id="caret-lTOku838Zv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lTOku838Zv">
        <div class="abstract-display">
            <p>Natural data observed in $\mathbb{R}^n$ is often constrained to an $m$-dimensional manifold $\mathcal{M}$, where $m < n$. This work focuses on the task of building theoretically principled generative models for such data. Current generative models learn $\mathcal{M}$ by mapping an $m$-dimensional latent variable through a neural network $f_\theta: \mathbb{R}^m \to \mathbb{R}^n$. These procedures, which we call pushforward models, incur a straightforward limitation: manifolds cannot in general be represented with a single parameterization, meaning that attempts to do so will incur either computational instability or the inability to learn probability densities within the manifold. To remedy this problem, we propose to model $\mathcal{M}$ as a neural implicit manifold: the set of zeros of a neural network. We then learn the probability density within $\mathcal{M}$ with a constrained energy-based model, which employs a constrained variant of Langevin dynamics to train and sample from the learned manifold. In experiments on synthetic and natural data, we show that our model can learn manifold-supported distributions with complex topologies more accurately than pushforward models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-igDOV2KBwM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/igDOV2KBwM.html">On Perfect Clustering for Gaussian Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Juan Cuesta-Albertos &middot; Subhajit Dutta</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-igDOV2KBwM"></div>

    <a href="paper_pages/igDOV2KBwM.html">
        <img src="http://img.youtube.com/vi/NkV7sgdMioE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-igDOV2KBwM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-igDOV2KBwM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-igDOV2KBwM">
                Abstract <i id="caret-igDOV2KBwM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-igDOV2KBwM">
        <div class="abstract-display">
            <p>In this paper, we propose a data based transformation for infinite-dimensional Gaussian processes and derive its limit theorem. For a clustering problem using mixture models, an appropriate modification of this transformation asymptotically leads to perfect separation of the populations under rather general conditions, except the scenario in which differences between clusters depend only on the locations; in which case our procedure is useless. Theoretical properties related to label consistency are studied for the k-means clustering algorithm when used on this transformed data. Good empirical performance of the proposed methodology is demonstrated using simulated as well as benchmark data sets, when compared with some popular parametric and nonparametric methods for such functional data.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Q4aAITDgdP">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Q4aAITDgdP.html">Learn the Time to Learn: Replay Scheduling in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Marcus Klasson &middot; Hedvig Kjellstrom &middot; Cheng Zhang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Q4aAITDgdP"></div>

    <a href="paper_pages/Q4aAITDgdP.html">
        <img src="http://img.youtube.com/vi/huCX46HqMl4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Q4aAITDgdP" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Q4aAITDgdP" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Q4aAITDgdP">
                Abstract <i id="caret-Q4aAITDgdP" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Q4aAITDgdP">
        <div class="abstract-display">
            <p>Replay methods are known to be successful at mitigating catastrophic forgetting in continual learning scenarios despite having limited access to historical data. However, storing historical data is cheap in many real-world settings, yet replaying all historical data is often prohibited due to processing time constraints. In such settings, we propose that continual learning systems should learn the time to learn and schedule which tasks to replay at different time steps. We first demonstrate the benefits of our proposal by using Monte Carlo tree search to find a proper replay schedule, and show that the found replay schedules can outperform fixed scheduling policies when combined with various replay methods in different continual learning settings. Additionally, we propose a framework for learning replay scheduling policies with reinforcement learning. We show that the learned policies can generalize better in new continual learning scenarios compared to equally replaying all seen tasks, without added computational cost. Our study reveals the importance of learning the time to learn in continual learning, which brings current research closer to real-world needs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-RyZB4qXEgt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/RyZB4qXEgt.html">Neural Circuit Diagrams: Robust Diagrams for the Communication, Implementation, and Analysis of Deep Learning Architectures</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vincent Abbott</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-RyZB4qXEgt"></div>

    <a href="paper_pages/RyZB4qXEgt.html">
        <img src="http://img.youtube.com/vi/ghlIs8bVXU4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-RyZB4qXEgt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-RyZB4qXEgt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-RyZB4qXEgt">
                Abstract <i id="caret-RyZB4qXEgt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-RyZB4qXEgt">
        <div class="abstract-display">
            <p>Diagrams matter. Unfortunately, the deep learning community has no standard method for diagramming architectures. The current combination of linear algebra notation and ad-hoc diagrams fails to offer the necessary precision to understand architectures in all their detail. However, this detail is critical for faithful implementation, mathematical analysis, further innovation, and ethical assurances. I present neural circuit diagrams, a graphical language tailored to the needs of communicating deep learning architectures. Neural circuit diagrams naturally keep track of the changing arrangement of data, precisely show how operations are broadcast over axes, and display the critical parallel behavior of linear operations. A lingering issue with existing diagramming methods is the inability to simultaneously express the detail of axes and the free arrangement of data, which neural circuit diagrams solve. Their compositional structure is analogous to code, creating a close correspondence between diagrams and implementation.

In this work, I introduce neural circuit diagrams for an audience of machine learning researchers. After introducing neural circuit diagrams, I cover a host of architectures to show their utility and breed familiarity. This includes the transformer architecture, convolution (and its difficult-to-explain extensions), residual networks, the U-Net, and the vision transformer. I include a Jupyter notebook that provides evidence for the close correspondence between diagrams and code. Finally, I examine backpropagation using neural circuit diagrams. I show their utility in providing mathematical insight and analyzing algorithms' time and space complexities.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oud7Ny0KQy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oud7Ny0KQy.html">RIFLE: Imputation and Robust Inference from Low Order Marginals</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sina Baharlouei &middot; Sze-Chuan Suen &middot; Meisam Razaviyayn</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oud7Ny0KQy"></div>

    <a href="paper_pages/oud7Ny0KQy.html">
        <img src="http://img.youtube.com/vi/hS9d7RS7TBQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oud7Ny0KQy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oud7Ny0KQy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oud7Ny0KQy">
                Abstract <i id="caret-oud7Ny0KQy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oud7Ny0KQy">
        <div class="abstract-display">
            <p>The ubiquity of missing values in real-world datasets poses a challenge for statistical inference and can prevent similar datasets from being analyzed in the same study, precluding many existing datasets from being used for new analyses. While an extensive collection of packages and algorithms have been developed for data imputation, the overwhelming majority perform poorly if there are many missing values and low sample sizes, which are unfortunately common characteristics in empirical data. Such low-accuracy estimations adversely affect the performance of downstream statistical models. We develop a statistical inference framework for predicting the target variable in the presence of missing data without imputation. Our framework, RIFLE (Robust InFerence via Low-order moment Estimations), estimates low-order moments of the underlying data distribution with corresponding confidence intervals to learn a distributionally robust model. We specialize our framework to linear regression and normal discriminant analysis, and we provide convergence and performance guarantees. This framework can also be adapted to impute missing data. We compare RIFLE with state-of-the-art approaches (including MICE, Amelia, MissForest, KNN-imputer, MIDA, and Mean Imputer) in numerical experiments. Our experiments demonstrate that RIFLE outperforms other benchmark algorithms when the percentage of missing values is high and/or when the number of data points is relatively small. RIFLE is publicly available</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JwGKVpRfVD">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JwGKVpRfVD.html">SkillS: Adaptive Skill Sequencing for Efficient Temporally-Extended Exploration</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Giulia Vezzani &middot; Dhruva Tirumala &middot; Markus Wulfmeier &middot; Dushyant Rao &middot; Abbas Abdolmaleki &middot; Ben Moran &middot; Tuomas Haarnoja &middot; Jan Humplik &middot; Roland Hafner &middot; Michael Neunert &middot; Claudio Fantacci &middot; Tim Hertweck &middot; Thomas Lampe &middot; Fereshteh Sadeghi &middot; Nicolas Heess &middot; Martin Riedmiller</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JwGKVpRfVD"></div>

    <a href="paper_pages/JwGKVpRfVD.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JwGKVpRfVD" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JwGKVpRfVD" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JwGKVpRfVD">
                Abstract <i id="caret-JwGKVpRfVD" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JwGKVpRfVD">
        <div class="abstract-display">
            <p>The ability to effectively reuse prior knowledge is a key requirement when building general and flexible Reinforcement Learning (RL) agents. Skill reuse is one of the most common approaches, but current methods have considerable limitations. For example, fine-tuning an existing policy frequently fails, as the policy can degrade rapidly early in training. In a similar vein, distillation of expert behavior can lead to poor results when given sub-optimal experts. We compare several common approaches for skill transfer on multiple domains including changes in task and system dynamics. We identify how existing methods fail and introduce an alternative approach to mitigate these problems. Our approach learns to sequence temporally-extended skills for exploration but learns the final policy directly from the raw experience. This conceptual split enables rapid adaptation and thus efficient data collection but without constraining the final solution. It significantly outperforms many classical methods across a suite of evaluation tasks and we use a broad set of ablations to highlight the importance of different components of our method.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-61TKzU9B96">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/61TKzU9B96.html">An Optical Control Environment for  Benchmarking Reinforcement Learning Algorithms</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">ABULIKEMU ABUDUWEILI &middot; Changliu Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-61TKzU9B96"></div>

    <a href="paper_pages/61TKzU9B96.html">
        <img src="tmlr_logo.jpeg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-61TKzU9B96" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-61TKzU9B96" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-61TKzU9B96">
                Abstract <i id="caret-61TKzU9B96" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-61TKzU9B96">
        <div class="abstract-display">
            <p>Deep reinforcement learning has the potential to address various scientific problems. In this paper, we implement an optics simulation environment for reinforcement learning based controllers. The environment captures the essence of nonconvexity, nonlinearity, and time-dependent noise inherent in optical systems, offering a more realistic setting. 
Subsequently, we provide the benchmark results of several reinforcement learning algorithms on the proposed simulation environment. The experimental findings demonstrate the superiority of off-policy reinforcement learning approaches over traditional control algorithms in navigating the intricacies of complex optical control environments.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-leqr0vQzeN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/leqr0vQzeN.html">A Robust Backpropagation-Free Framework for Images</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Timothy Zee &middot; Alex Ororbia &middot; Ankur Mali &middot; Ifeoma Nwogu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-leqr0vQzeN"></div>

    <a href="paper_pages/leqr0vQzeN.html">
        <img src="http://img.youtube.com/vi/bVOzZjMxGzo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-leqr0vQzeN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-leqr0vQzeN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-leqr0vQzeN">
                Abstract <i id="caret-leqr0vQzeN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-leqr0vQzeN">
        <div class="abstract-display">
            <p>While current deep learning algorithms have been successful for a wide variety of artificial intelligence (AI) tasks, including those involving structured image data, they present deep neurophysiological conceptual issues due to their reliance on the gradients that are computed by backpropagation of errors (backprop). Gradients are required to obtain synaptic weight adjustments but require knowledge of feed forward activities in order to conduct backward propagation, a biologically implausible process. This is known as the "weight transport problem''. Therefore, in this work, we present a more biologically plausible approach towards solving the weight transport problem for image data. This approach, which we name the error-kernel driven activation alignment (EKDAA) algorithm, accomplishes through the introduction of locally derived error transmission kernels and error maps. Like standard deep learning networks, EKDAA performs the standard forward process via weights and activation functions; however, its backward error computation involves adaptive error kernels that propagate local error signals through the network. The efficacy of EKDAA is demonstrated by performing visual-recognition tasks on the Fashion MNIST, CIFAR-10 and SVHN benchmarks, along with demonstrating its ability to extract visual features from natural color images. Furthermore, in order to demonstrate its non-reliance on gradient computations, results are presented for an EKDAA-trained CNN that employs a non-differentiable activation function.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3taIQG4C7H">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3taIQG4C7H.html">Label Noise-Robust Learning using a Confidence-Based Sieving Strategy</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reihaneh Torkzadehmahani &middot; Reza Nasirigerdeh &middot; Daniel Rueckert &middot; Georgios Kaissis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3taIQG4C7H"></div>

    <a href="paper_pages/3taIQG4C7H.html">
        <img src="http://img.youtube.com/vi/LE9iD9hcAKc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3taIQG4C7H" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3taIQG4C7H" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3taIQG4C7H">
                Abstract <i id="caret-3taIQG4C7H" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3taIQG4C7H">
        <div class="abstract-display">
            <p>In learning tasks with label noise, improving model robustness against overfitting is a pivotal challenge because the model eventually memorizes labels, including the noisy ones. Identifying the samples with noisy labels and preventing the model from learning them is a promising approach to address this challenge. When training with noisy labels, the per-class confidence scores of the model, represented by the class probabilities, can be reliable criteria for assessing whether the input label is the true label or the corrupted one. In this work, we exploit this observation and propose a novel discriminator metric called confidence error and a sieving strategy called CONFES to differentiate between the clean and noisy samples effectively. We provide theoretical guarantees on the probability of error for our proposed metric. Then, we experimentally illustrate the superior performance of our proposed approach compared to recent studies on various settings, such as synthetic and real-world label noise. Moreover, we show CONFES can be combined with other state-of-the-art approaches, such as Co-teaching and DivideMix to further improve model performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4i1MXH8Sle">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4i1MXH8Sle.html">CAREER: A Foundation Model for Labor Sequence Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Keyon Vafa &middot; Emil Palikot &middot; Tianyu Du &middot; Ayush Kanodia &middot; Susan Athey &middot; David Blei</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4i1MXH8Sle"></div>

    <a href="paper_pages/4i1MXH8Sle.html">
        <img src="http://img.youtube.com/vi/BLgfbNeTLCI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4i1MXH8Sle" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4i1MXH8Sle" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4i1MXH8Sle">
                Abstract <i id="caret-4i1MXH8Sle" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4i1MXH8Sle">
        <div class="abstract-display">
            <p>Labor economists regularly analyze employment data by fitting predictive models to small, carefully constructed longitudinal survey datasets. Although machine learning methods offer promise for such problems, these survey datasets are too small to take advantage of them. In recent years large datasets of online resumes have also become available, providing data about the career trajectories of millions of individuals. However, standard econometric models cannot take advantage of their scale or incorporate them into the analysis of survey data. To this end we develop CAREER, a foundation model for job sequences. CAREER is first fit to large, passively-collected resume data and then fine-tuned to smaller, better-curated datasets for economic inferences. We fit CAREER to a dataset of 24 million job sequences from resumes, and adjust it on small longitudinal survey datasets. We find that CAREER forms accurate predictions of job sequences, outperforming econometric baselines on three widely-used economics datasets. We further find that CAREER can be used to form good predictions of other downstream variables. For example, incorporating CAREER into a wage model provides better predictions than the econometric models currently in use.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2uMnAwWnRy">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2uMnAwWnRy.html">Benchmarking Continuous Time Models for Predicting Multiple Sclerosis Progression</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Lev Proleev &middot; Diana Mincu &middot; F Lee Hartsell &middot; Katherine A Heller &middot; Subhrajit Roy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2uMnAwWnRy"></div>

    <a href="paper_pages/2uMnAwWnRy.html">
        <img src="http://img.youtube.com/vi/sqDLDkbP2H0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2uMnAwWnRy" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2uMnAwWnRy" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2uMnAwWnRy">
                Abstract <i id="caret-2uMnAwWnRy" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2uMnAwWnRy">
        <div class="abstract-display">
            <p>Multiple sclerosis is a disease that affects the brain and spinal cord, it can lead to severe disability and has no known cure. The majority of prior work in machine learning for multiple sclerosis has been centered around using Magnetic Resonance Imaging scans or laboratory tests; these modalities are both expensive to acquire and can be unreliable. In a recent paper it was shown that disease progression can be predicted effectively using performance outcome measures and demographic data. In our work we build on this to investigate the modeling side, using continuous time models to predict progression. We benchmark four continuous time models using a publicly available multiple sclerosis dataset. We find that the best continuous model is often able to outperform the best benchmarked discrete time model. We also carry out an extensive ablation to discover the sources of performance gains, we find that standardizing existing features leads to a larger performance increase than interpolating missing features.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-W0ehjkl9x7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/W0ehjkl9x7.html">DoCoM: Compressed Decentralized Optimization with Near-Optimal Sample Complexity</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chung-Yiu Yau &middot; Hoi To Wai</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-W0ehjkl9x7"></div>

    <a href="paper_pages/W0ehjkl9x7.html">
        <img src="http://img.youtube.com/vi/3ZNmkE9ryEs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-W0ehjkl9x7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-W0ehjkl9x7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-W0ehjkl9x7">
                Abstract <i id="caret-W0ehjkl9x7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-W0ehjkl9x7">
        <div class="abstract-display">
            <p>This paper proposes the Doubly Compressed Momentum-assisted stochastic gradient tracking algorithm (DoCoM) for communication-efficient decentralized optimization. The algorithm features two main ingredients to achieve a near-optimal sample complexity while allowing for communication compression. First, the algorithm tracks both the averaged iterate and stochastic gradient using compressed gossiping consensus. Second, a momentum step is incorporated for adaptive variance reduction with the local gradient estimates. We show that DoCoM finds a near-stationary solution at all participating agents satisfying $\mathbb{E}[ \| \nabla f( \theta ) \|^2 ] = {\cal O}( 1 / T^{2/3} )$ in $T$ iterations, where $f(\theta)$ is a smooth (possibly non-convex) objective function. Notice that the proof is achieved via analytically designing a new potential function that tightly tracks the one-iteration progress of DoCoM. As a corollary, our analysis also established the linear convergence of DoCoM to a global optimal solution for objective functions with the Polyak-ojasiewicz condition. Numerical experiments demonstrate that our algorithm outperforms several state-of-the-art algorithms in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ySWQ6eXAKp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ySWQ6eXAKp.html">Not All Causal Inference is the Same</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej Zeevi &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ySWQ6eXAKp"></div>

    <a href="paper_pages/ySWQ6eXAKp.html">
        <img src="http://img.youtube.com/vi/WSYtc-IUe3A/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ySWQ6eXAKp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ySWQ6eXAKp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ySWQ6eXAKp">
                Abstract <i id="caret-ySWQ6eXAKp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ySWQ6eXAKp">
        <div class="abstract-display">
            <p>Neurally-parameterized Structural Causal Models in the Pearlian notion to causality, referred to as NCM, were recently introduced as a step towards next-generation learning systems. However, said NCM are only concerned with the learning aspect of causal inference
and totally miss out on the architecture aspect. That is, actual causal inference within NCM is intractable in that the NCM wont return an answer to a query in polynomial time. This insight follows as corollary to the more general statement on the intractability of arbitrary structural causal model (SCM) parameterizations, which we prove in this work through classical 3-SAT reduction. Since future learning algorithms will be required to deal with both high dimensional data and highly complex mechanisms governing the data, we ultimately believe work on tractable inference for causality to be decisive. We also show that not all causal models are created equal. More specifically, there are models capable of answering causal queries that are not SCM, which we refer to as partially causal models
(PCM). We provide a tabular taxonomy in terms of tractability properties for all of the different model families, namely correlation-based, PCM and SCM. To conclude our work, we also provide some initial ideas on how to overcome parts of the intractability of causal inference
with SCM by showing an example of how parameterizing an SCM with SPN modules can at least allow for tractable mechanisms. With this work we hope that our insights can raise awareness for this novel research direction since achieving success with causality in real world downstream tasks will not only depend on learning correct models but also require having the practical ability to gain access to
model inferences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tv46tCzs83">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tv46tCzs83.html">Causal Parrots: Large Language Models May Talk Causality But Are Not Causal</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matej Zeevi &middot; Moritz Willig &middot; Devendra Singh Dhami &middot; Kristian Kersting</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tv46tCzs83"></div>

    <a href="paper_pages/tv46tCzs83.html">
        <img src="http://img.youtube.com/vi/vbwrhbuvedE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tv46tCzs83" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tv46tCzs83" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tv46tCzs83">
                Abstract <i id="caret-tv46tCzs83" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tv46tCzs83">
        <div class="abstract-display">
            <p>Some argue scale is all what is needed to achieve AI, covering even causal models.
We make it clear that large language models (LLMs) cannot be causal and give reason onto why sometimes we might feel otherwise. To this end, we define and exemplify a new subgroup of Structural Causal Model (SCM) that we call meta SCM which encode causal facts about other SCM within their variables.
We conjecture that in the cases where LLM succeed in doing causal inference, underlying was a respective meta SCM that exposed correlations between causal facts in natural language on whose data the LLM was ultimately trained.
If our hypothesis holds true, then this would imply that LLMs are like parrots in that they simply recite the causal knowledge embedded in the data. Our empirical analysis provides favoring evidence that current LLMs are even weak `causal parrots.'</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-1irVjE7A3w">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/1irVjE7A3w.html">Meta-Learning via Classifier(-free) Diffusion Guidance</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elvis Nava &middot; Seijin Kobayashi &middot; Yifei Yin &middot; Robert K. Katzschmann &middot; Benjamin F Grewe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-1irVjE7A3w"></div>

    <a href="paper_pages/1irVjE7A3w.html">
        <img src="http://img.youtube.com/vi/O6lB2RaBh2k/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-1irVjE7A3w" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-1irVjE7A3w" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-1irVjE7A3w">
                Abstract <i id="caret-1irVjE7A3w" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-1irVjE7A3w">
        <div class="abstract-display">
            <p>We introduce meta-learning algorithms that perform zero-shot weight-space adaptation of neural network models to unseen tasks. Our methods repurpose the popular generative image synthesis techniques of natural language guidance and diffusion models to generate neural network weights adapted for tasks. We first train an unconditional generative hypernetwork model to produce neural network weights; then we train a second "guidance" model that, given a natural language task description, traverses the hypernetwork latent space to find high-performance task-adapted weights in a zero-shot manner. We explore two alternative approaches for latent space guidance: "HyperCLIP"-based classifier guidance and a conditional Hypernetwork Latent Diffusion Model ("HyperLDM"), which we show to benefit from the classifier-free guidance technique common in image generation. Finally, we demonstrate that our approaches outperform existing multi-task and meta-learning methods in a series of zero-shot learning experiments on our Meta-VQA dataset.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Tkvmt9nDmB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Tkvmt9nDmB.html">Beyond Distribution Shift: Spurious Features Through the Lens of Training Dynamics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal Murali &middot; Aahlad Manas Puli &middot; Ke Yu &middot; Rajesh Ranganath &middot; kayhan Batmanghelich</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Tkvmt9nDmB"></div>

    <a href="paper_pages/Tkvmt9nDmB.html">
        <img src="http://img.youtube.com/vi/kkQ0IKukx5o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Tkvmt9nDmB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Tkvmt9nDmB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Tkvmt9nDmB">
                Abstract <i id="caret-Tkvmt9nDmB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Tkvmt9nDmB">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) are prone to learning spurious features that correlate with the label during training but are irrelevant to the learning problem. This hurts model generalization and poses problems when deploying them in safety-critical applications. This paper aims to better understand the effects of spurious features through the lens of the learning dynamics of the internal neurons during the training process. We make the following observations: (1) While previous works highlight the harmful effects of spurious features on the generalization ability of DNNs, we emphasize that not all spurious features are harmful. Spurious features can be "benign" or "harmful" depending on whether they are "harder" or "easier" to learn than the core features for a given model. This definition is model and dataset dependent. (2) We build upon this premise and use instance difficulty methods (like Prediction Depth) to quantify "easiness" for a given model and to identify this behavior during the training phase. (3) We empirically show that the harmful spurious features can be detected by observing the learning dynamics of the DNN's early layers. In other words, easy features learned by the initial layers of a DNN early during the training can (potentially) hurt model generalization. We verify our claims on medical and vision datasets, both simulated and real, and justify the empirical success of our hypothesis by showing the theoretical connections between Prediction Depth and information-theoretic concepts like $\mathcal{V}$-usable information. Lastly, our experiments show that monitoring only accuracy during training (as is common in machine learning pipelines) is insufficient to detect spurious features. We, therefore, highlight the need for monitoring early training dynamics using suitable instance difficulty metrics.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-pHCdMat0gI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/pHCdMat0gI.html">Graph Neural Networks for Temporal Graphs: State of the Art, Open Challenges, and Opportunities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Antonio Longa &middot; Veronica Lachi &middot; Gabriele Santin &middot; Monica Bianchini &middot; Bruno Lepri &middot; Pietro Lio &middot; franco scarselli &middot; Andrea Passerini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-pHCdMat0gI"></div>

    <a href="paper_pages/pHCdMat0gI.html">
        <img src="http://img.youtube.com/vi/2ImatNxkKFY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-pHCdMat0gI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-pHCdMat0gI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-pHCdMat0gI">
                Abstract <i id="caret-pHCdMat0gI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-pHCdMat0gI">
        <div class="abstract-display">
            <p>Graph Neural Networks (GNNs) have become the leading paradigm for learning on (static) graph-structured data. However, many real-world systems are dynamic in nature, since the graph and node/edge attributes change over time. In recent years, GNN-based models for temporal graphs have emerged as a promising area of research to extend the capabilities of GNNs. In this work, we provide the first comprehensive overview of the current state-of-the-art of temporal GNN, introducing a rigorous formalization of learning settings and tasks and a novel taxonomy categorizing existing approaches in terms of how the temporal aspect is represented and processed. We conclude the survey with a discussion of the most relevant open challenges for the field, from both research and application perspectives.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y8RZoPjEUl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y8RZoPjEUl.html">Simulate Time-integrated Coarse-grained Molecular Dynamics with Multi-scale Graph Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xiang Fu &middot; Tian Xie &middot; Nathan J. Rebello &middot; Bradley Olsen &middot; Tommi S. Jaakkola</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y8RZoPjEUl"></div>

    <a href="paper_pages/y8RZoPjEUl.html">
        <img src="http://img.youtube.com/vi/l3aGVjQezsc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y8RZoPjEUl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y8RZoPjEUl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y8RZoPjEUl">
                Abstract <i id="caret-y8RZoPjEUl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y8RZoPjEUl">
        <div class="abstract-display">
            <p>Molecular dynamics (MD) simulation is essential for various scientific domains but computationally expensive. Learning-based force fields have made significant progress in accelerating ab-initio MD simulation but are not fast enough for many real-world applications due to slow inference for large systems and small time steps (femtosecond-level). We aim to address these challenges by learning a multi-scale graph neural network that directly simulates coarse-grained MD with a very large time step (nanosecond-level) and a novel refinement module based on diffusion models to mitigate simulation instability. The effectiveness of our method is demonstrated in two complex systems: single-chain coarse-grained polymers and multi-component Li-ion polymer electrolytes. For evaluation, we simulate trajectories much longer than the training trajectories for systems with different chemical compositions that the model is not trained on. Structural and dynamical properties can be accurately recovered at several orders of magnitude higher speed than classical force fields by getting out of the femtosecond regime. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-m8U9rSs6gU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/m8U9rSs6gU.html">Inducing Meaningful Units from Character Sequences with Dynamic Capacity Slot Attention</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Melika Behjati &middot; James Henderson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-m8U9rSs6gU"></div>

    <a href="paper_pages/m8U9rSs6gU.html">
        <img src="http://img.youtube.com/vi/KjAc20Co1Nk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-m8U9rSs6gU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-m8U9rSs6gU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-m8U9rSs6gU">
                Abstract <i id="caret-m8U9rSs6gU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-m8U9rSs6gU">
        <div class="abstract-display">
            <p>Characters do not convey meaning, but sequences of characters do.  We propose an unsupervised distributional method to learn the abstract meaning-bearing units in a sequence of characters. Rather than segmenting the sequence, our Dynamic Capacity Slot Attention model discovers continuous representations of the objects in the sequence, extending an architecture for object discovery in images.  We train our model on different languages and evaluate the quality of the obtained representations with forward and reverse probing classifiers.  These experiments show that our model succeeds in discovering units which are similar to those proposed previously in form, content, and level of abstraction, and which show promise for capturing meaningful information at a higher level of abstraction.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0XBuaxqEcG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0XBuaxqEcG.html">Execution-based Code Generation using Deep Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Parshin Shojaee &middot; Aneesh Jain &middot; Sindhu Tipirneni &middot; Chandan K. Reddy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0XBuaxqEcG"></div>

    <a href="paper_pages/0XBuaxqEcG.html">
        <img src="http://img.youtube.com/vi/EuwuzyRDC30/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0XBuaxqEcG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0XBuaxqEcG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0XBuaxqEcG">
                Abstract <i id="caret-0XBuaxqEcG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0XBuaxqEcG">
        <div class="abstract-display">
            <p>The utilization of programming language (PL) models, pre-trained on large-scale code corpora, as a means of automating software engineering processes has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting unique sequence-level characteristics of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that synergistically combines pre-trained PL models with Proximal Policy Optimization (PPO) which is a widely used deep reinforcement learning technique. By utilizing non-differentiable feedback from code execution and structure alignment, PPOCoder seamlessly integrates external code-specific knowledge into the model optimization process. It's important to note that PPOCoder is a task-agnostic and model-agnostic framework that can be used across different code generation tasks and PLs. Extensive experiments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, achieving significant improvements in compilation success rates and functional correctness across different PLs.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8L7Rh6FIXt">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8L7Rh6FIXt.html">IBIA: An Incremental Build-Infer-Approximate Framework for Approximate Inference of Partition Function</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shivani Bathla &middot; Vinita Vasudevan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8L7Rh6FIXt"></div>

    <a href="paper_pages/8L7Rh6FIXt.html">
        <img src="http://img.youtube.com/vi/143xjwN-MSw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8L7Rh6FIXt" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8L7Rh6FIXt" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8L7Rh6FIXt">
                Abstract <i id="caret-8L7Rh6FIXt" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8L7Rh6FIXt">
        <div class="abstract-display">
            <p>Exact computation of the partition function is known to be intractable, necessitating approximate inference techniques. Existing methods for approximate inference are slow to converge for many benchmarks. The control of accuracy-complexity trade-off is also non-trivial in many of these methods. We propose a novel  incremental build-infer-approximate (IBIA) framework for approximate inference that addresses these issues. In this framework, the probabilistic graphical model is converted into a  sequence of clique tree forests (SCTF) with bounded clique sizes.  We show that the SCTF can be used to efficiently compute the partition function. We propose two new algorithms which are used to construct the SCTF  and prove the correctness of both. The first is an algorithm for incremental construction of CTFs that is guaranteed to give a  valid CTF with bounded clique sizes and the second is an approximation algorithm that takes a calibrated CTF as input and yields a valid and calibrated CTF with reduced clique sizes as the output. We have evaluated our method using several benchmark sets from recent UAI competitions and our results show good accuracies with competitive runtimes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HqIuAzBxbh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HqIuAzBxbh.html">Consistent Collaborative Filtering via Tensor Decomposition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shiwen Zhao &middot; Guillermo Sapiro</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HqIuAzBxbh"></div>

    <a href="paper_pages/HqIuAzBxbh.html">
        <img src="http://img.youtube.com/vi/MTHefLFLSZI/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HqIuAzBxbh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HqIuAzBxbh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HqIuAzBxbh">
                Abstract <i id="caret-HqIuAzBxbh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HqIuAzBxbh">
        <div class="abstract-display">
            <p>Collaborative filtering is the de facto standard for analyzing users activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library https://github.com/apple/ml-sad.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-zshemTAa6U">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/zshemTAa6U.html">Test-Time Adaptation for Visual Document Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sayna Ebrahimi &middot; Sercan O Arik &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-zshemTAa6U"></div>

    <a href="paper_pages/zshemTAa6U.html">
        <img src="video_thumbnails/zshemTAa6U.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-zshemTAa6U" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-zshemTAa6U" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-zshemTAa6U">
                Abstract <i id="caret-zshemTAa6U" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-zshemTAa6U">
        <div class="abstract-display">
            <p>For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\%  (ANLS score), respectively.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-f0FSDAy1bU">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/f0FSDAy1bU.html">Faster Training of Neural ODEs Using GauLegendre Quadrature</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alexander Luke Ian Norcliffe &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-f0FSDAy1bU"></div>

    <a href="paper_pages/f0FSDAy1bU.html">
        <img src="http://img.youtube.com/vi/pKbLwsqy8aM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-f0FSDAy1bU" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-f0FSDAy1bU" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-f0FSDAy1bU">
                Abstract <i id="caret-f0FSDAy1bU" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-f0FSDAy1bU">
        <div class="abstract-display">
            <p>Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VmyFF5lL3F">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VmyFF5lL3F.html">Inversion by Direct Iteration: An Alternative to Denoising Diffusion for Image Restoration</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mauricio Delbracio &middot; Peyman Milanfar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VmyFF5lL3F"></div>

    <a href="paper_pages/VmyFF5lL3F.html">
        <img src="http://img.youtube.com/vi/_VfyR9ChOFk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VmyFF5lL3F" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VmyFF5lL3F" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VmyFF5lL3F">
                Abstract <i id="caret-VmyFF5lL3F" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VmyFF5lL3F">
        <div class="abstract-display">
            <p>Inversion by Direct Iteration (InDI) is a new formulation for supervised image restoration that avoids the so-called ``regression to the mean'' effect and produces more realistic and detailed images than existing regression-based methods. It does this by gradually improving image quality in small steps, similar to generative denoising diffusion models.

Image restoration is an ill-posed problem where multiple high-quality images are plausible reconstructions of a given low-quality input. Therefore, the outcome of a single step regression model is typically  an aggregate of all possible explanations, therefore lacking details and realism. The main advantage of InDI is that it does not try to predict the clean target image in a single step but instead gradually improves the image in small steps, resulting in better perceptual quality.

While generative denoising diffusion models also work in small steps, our formulation is distinct in that it does not require knowledge of any analytic form of the degradation process. Instead, we directly learn an iterative restoration process from low-quality and high-quality paired examples. InDI can be applied to virtually any image degradation, given paired training data. In conditional denoising diffusion image restoration the denoising network generates the restored image by repeatedly denoising an initial image of pure noise, conditioned on the degraded input. Contrary to conditional denoising formulations, InDI directly proceeds by iteratively restoring the input low-quality image, producing high-quality results on a variety of image restoration tasks, including motion and out-of-focus deblurring, super-resolution, compression artifact removal, and denoising.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XNFo3dQiCJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XNFo3dQiCJ.html">Generalizability of Adversarial Robustness Under Distribution Shifts</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kumail Alhamoud &middot; Hasan Abed Al Kader Hammoud &middot; Motasem Alfarra &middot; Bernard Ghanem</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XNFo3dQiCJ"></div>

    <a href="paper_pages/XNFo3dQiCJ.html">
        <img src="http://img.youtube.com/vi/PL4PbCmjyno/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XNFo3dQiCJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XNFo3dQiCJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XNFo3dQiCJ">
                Abstract <i id="caret-XNFo3dQiCJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XNFo3dQiCJ">
        <div class="abstract-display">
            <p>Recent progress in empirical and certified robustness promises to deliver reliable and deployable Deep Neural Networks (DNNs). Despite that success, most existing evaluations of DNN robustness have been done on images sampled from the same distribution on which the model was trained on. However, in the real world, DNNs may be deployed in dynamic environments that exhibit significant distribution shifts. In this work, we take a first step towards thoroughly investigating the interplay between empirical and certified adversarial robustness on one hand and domain generalization on another. To do so, we train robust models on multiple domains and evaluate their accuracy and robustness on an unseen domain. We observe that: (1) both empirical and certified robustness generalize to unseen domains, and (2) the level of generalizability does not correlate well with input visual similarity, measured by the FID between source and target domains. We also extend our study to cover a real-world medical application, in which adversarial augmentation significantly boosts the generalization of robustness with minimal effect on clean data accuracy.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VV4zJwLwI7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VV4zJwLwI7.html">Breaking the Spurious Causality of Conditional Generation via Fairness Intervention with Corrective Sampling</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Junhyun Nam &middot; Sangwoo Mo &middot; Jaeho Lee &middot; Jinwoo Shin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VV4zJwLwI7"></div>

    <a href="paper_pages/VV4zJwLwI7.html">
        <img src="http://img.youtube.com/vi/RDhLKJnZTjE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VV4zJwLwI7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VV4zJwLwI7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VV4zJwLwI7">
                Abstract <i id="caret-VV4zJwLwI7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VV4zJwLwI7">
        <div class="abstract-display">
            <p>Trying to capture the sample-label relationship, conditional generative models often end up inheriting the spurious correlation in the training dataset, giving label-conditional distributions that are severely imbalanced in another latent attribute. To mitigate such undesirable correlations engraved into generative models, which we call spurious causality, we propose a general two-step strategy. (a) Fairness Intervention (FI): Emphasize the minority samples that are hard to be generated due to the spurious correlation in the training dataset. (b) Corrective Sampling (CS): Filter the generated samples explicitly to follow the desired label-conditional latent attribute distribution. We design the fairness intervention for various degrees of supervision on the spurious attribute, including unsupervised, weakly-supervised, and semi-supervised scenarios. Our experimental results show that the proposed FICS can successfully resolve the spurious correlation in generated samples on various datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LKz5SqIXPJ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LKz5SqIXPJ.html">On the Robustness of Dataset Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sebastian Szyller &middot; Rui Zhang &middot; Jian Liu &middot; N Asokan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LKz5SqIXPJ"></div>

    <a href="paper_pages/LKz5SqIXPJ.html">
        <img src="http://img.youtube.com/vi/jZ3Lw98gfv8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LKz5SqIXPJ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LKz5SqIXPJ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LKz5SqIXPJ">
                Abstract <i id="caret-LKz5SqIXPJ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LKz5SqIXPJ">
        <div class="abstract-display">
            <p>Machine learning (ML) models are costly to train as they can require a significant amount of data, computational resources and technical expertise. Thus, they constitute valuable intellectual property that needs protection from adversaries wanting to steal them. Ownership verification techniques allow the victims of model stealing attacks to demonstrate that a suspect model was in fact stolen from theirs. Although a number of ownership verification techniques based on watermarking or fingerprinting have been proposed, most of them fall short either in terms of security guarantees (well-equipped adversaries can evade verification)  or computational cost. A fingerprinting technique, Dataset Inference (DI) has been shown to offer better robustness and efficiency than prior methods. The authors of DI provided a correctness proof for linear (suspect) models. However, in a subspace of the same setting, we prove that DI suffers from high false positives (FPs) -- it can incorrectly identify an independent model trained with non-overlapping data from the same distribution as stolen. We further prove that DI also triggers FPs in realistic, non-linear suspect models. We then confirm empirically that DI in the black-box setting leads to FPs, with high confidence. Second, we show that DI also suffers from false negatives (FNs) -- an adversary can fool DI by regularising a stolen model's decision boundaries using adversarial training, thereby leading to an FN. To this end, we demonstrate that black-box DI fails to identify a model adversarially trained from a stolen dataset -- the setting where DI is the hardest to evade. Finally, we discuss the implications of our findings, the viability of fingerprinting-based ownership verification in general, and suggest directions for future work.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p28wv4G65d">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p28wv4G65d.html">SC2 Benchmark: Supervised Compression for Split Computing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Yoshitomo Matsubara &middot; Ruihan Yang &middot; Marco Levorato &middot; Stephan Mandt</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p28wv4G65d"></div>

    <a href="paper_pages/p28wv4G65d.html">
        <img src="http://img.youtube.com/vi/uwwV_vAOvX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p28wv4G65d" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p28wv4G65d" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p28wv4G65d">
                Abstract <i id="caret-p28wv4G65d" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p28wv4G65d">
        <div class="abstract-display">
            <p>With the increasing demand for deep learning models on mobile devices, splitting neural network computation between the device and a more powerful edge server has become an attractive solution. However, existing split computing approaches often underperform compared to a naive baseline of remote computation on compressed data. Recent studies propose learning compressed representations that contain more relevant information for supervised downstream tasks, showing improved tradeoffs between compressed data size and supervised performance. However, existing evaluation metrics only provide an incomplete picture of split computing. This study introduces supervised compression for split computing (SC2) and proposes new evaluation criteria: minimizing computation on the mobile device, minimizing transmitted data size, and maximizing model accuracy. We conduct a comprehensive benchmark study using 10 baseline methods, three computer vision tasks, and over 180 trained models, and discuss various aspects of SC2. We also release our code and sc2bench, a Python package for future research on SC2. Our proposed metrics and package will help researchers better understand the tradeoffs of supervised compression in split computing.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nfYwRIezvg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nfYwRIezvg.html">DORA: Exploring Outlier Representations in Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Kirill Bykov &middot; Mayukh Deb &middot; Dennis Grinwald &middot; Klaus Robert Muller &middot; Marina MC Hhne</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nfYwRIezvg"></div>

    <a href="paper_pages/nfYwRIezvg.html">
        <img src="http://img.youtube.com/vi/k2tgN7YsjN8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nfYwRIezvg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nfYwRIezvg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nfYwRIezvg">
                Abstract <i id="caret-nfYwRIezvg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nfYwRIezvg">
        <div class="abstract-display">
            <p>Deep Neural Networks (DNNs) excel at learning complex abstractions within their internal representations. However, the concepts they learn remain opaque, a problem that becomes particularly acute when models unintentionally learn spurious correlations. In this work, we present DORA (Data-agnOstic Representation Analysis), the first data-agnostic framework for analyzing the representational space of DNNs. Central to our framework is the proposed Extreme-Activation (EA) distance measure, which assesses similarities between representations by analyzing their activation patterns on data points that cause the highest level of activation. As spurious correlations often manifest in features of data that are anomalous to the desired task, such as watermarks or artifacts, we demonstrate that internal representations capable of detecting such artifactual concepts can be found by analyzing relationships within neural representations. We validate the EA metric quantitatively, demonstrating its effectiveness both in controlled scenarios and real-world applications. Finally, we provide practical examples from popular Computer Vision models to illustrate that representations identified as outliers using the EA metric often correspond to undesired and spurious concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vXSsTYs6ZB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vXSsTYs6ZB.html">LEAD: Min-Max Optimization from a Physical Perspective</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Reyhane Askari Hemmat &middot; Amartya Mitra &middot; Guillaume Lajoie &middot; Ioannis Mitliagkas</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vXSsTYs6ZB"></div>

    <a href="paper_pages/vXSsTYs6ZB.html">
        <img src="http://img.youtube.com/vi/EfwIc0GXb8E/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vXSsTYs6ZB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vXSsTYs6ZB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vXSsTYs6ZB">
                Abstract <i id="caret-vXSsTYs6ZB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vXSsTYs6ZB">
        <div class="abstract-display">
            <p>Adversarial formulations such as generative adversarial networks (GANs) have rekindled interest in two-player min-max games. A central obstacle in the optimization of such games is the rotational dynamics that hinder their convergence. In this paper, we show that game optimization shares dynamic properties with particle systems subject to multiple forces, and one can leverage tools from physics to improve optimization dynamics. Inspired by the physical framework, we propose LEAD, an optimizer for min-max games. Next, using Lyapunov stability theory and spectral analysis, we study LEADs convergence properties in continuous and discrete time settings for a class of quadratic min-max games to demonstrate linear convergence to the Nash equilibrium. Finally, we empirically evaluate our method on synthetic setups and CIFAR-10 image generation to demonstrate improvements in GAN training.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-g97OHbQyk1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/g97OHbQyk1.html">The Vendi Score: A Diversity Evaluation Metric for Machine Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dan Friedman &middot; Adji Bousso Dieng</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-g97OHbQyk1"></div>

    <a href="paper_pages/g97OHbQyk1.html">
        <img src="http://img.youtube.com/vi/r12fod3WZ78/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-g97OHbQyk1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-g97OHbQyk1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-g97OHbQyk1">
                Abstract <i id="caret-g97OHbQyk1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-g97OHbQyk1">
        <div class="abstract-display">
            <p>Diversity is an important criterion for many areas of machine learning (ML), including generative modeling and dataset curation. However, existing metrics for measuring diversity are often domain-specific and limited in flexibility. In this paper we address the diversity evaluation problem by proposing the Vendi Score, which connects and extends ideas from ecology and quantum statistical mechanics to ml. The Vendi Score is defined as the exponential of the Shannon entropy of the eigenvalues of a similarity matrix. This matrix is induced by a user-defined similarity function applied to the sample to be evaluated for diversity. In taking a similarity function as input, the Vendi Score enables its user to specify any desired form of diversity. Importantly, unlike many existing metrics in ML, the Vendi Score does not require a reference dataset or distribution over samples or labels, it is therefore general and applicable to any generative model, decoding algorithm, and dataset from any domain where similarity can be defined. We showcase the Vendi Score on molecular generative modeling where we found it addresses shortcomings of the current diversity metric of choice in that domain. We also applied the Vendi Score to generative models of images and decoding algorithms of text where we found it confirms known results about diversity in those domains. Furthermore, we used the Vendi Score to measure mode collapse, a known shortcoming of generative adversarial networks (GANs). In particular, the Vendi Score revealed that even GANs that capture all the modes of a labelled dataset can be less diverse than the original dataset. Finally, the interpretability of the Vendi Score allowed us to diagnose several benchmark ML datasets for diversity, opening the door for diversity-informed data augmentation.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-dXnccpSSYF">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/dXnccpSSYF.html">Pareto Optimization for Active Learning under Out-of-Distribution Data Scenarios</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Xueying Zhan &middot; Zeyu Dai &middot; Qingzhong Wang &middot; Qing Li &middot; Haoyi Xiong &middot; Dejing Dou &middot; Antoni B. Chan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-dXnccpSSYF"></div>

    <a href="paper_pages/dXnccpSSYF.html">
        <img src="http://img.youtube.com/vi/HUXedZB47zc/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-dXnccpSSYF" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-dXnccpSSYF" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-dXnccpSSYF">
                Abstract <i id="caret-dXnccpSSYF" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-dXnccpSSYF">
        <div class="abstract-display">
            <p>Pool-based Active Learning (AL) has proven successful in minimizing labeling costs by sequentially selecting the most informative unlabeled data from large pool and querying their labels from an oracle or annotators.  However, existing AL sampling schemes may not perform well in out-of-distribution (OOD) data scenarios, where the unlabeled data pool contains samples that do not belong to the pre-defined categories of the target task. Achieving strong AL performance under OOD data scenarios presents a challenge due to the inherent conflict between AL sampling strategies and OOD data detection. For instance, both more informative in-distribution (ID) data and OOD data in an unlabeled data pool would be assigned high informativeness scores (e.g., high entropy) during AL processes. To address this dilemma, we propose a Monte-Carlo Pareto Optimization for Active Learning (POAL) sampling scheme, which selects optimal subsets of unlabeled samples with fixed batch size from the unlabeled data pool. We formulate the AL sampling task as a multi-objective optimization problem and employ Pareto optimization based on two conflicting objectives: (1) the conventional AL sampling scheme (e.g., maximum entropy) and (2) the confidence of excluding OOD data samples. Experimental results demonstrate the effectiveness of our POAL approach on classical Machine Learning (ML) and Deep Learning (DL) tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-HVAeM6sNo8">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/HVAeM6sNo8.html">Robust Alzheimer's Progression Modeling using Cross-Domain Self-Supervised Deep Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Saba Dadsetan &middot; Mohsen Hejrati &middot; Shandong Wu &middot; Somaye Hashemifar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-HVAeM6sNo8"></div>

    <a href="paper_pages/HVAeM6sNo8.html">
        <img src="https://drive.google.com/thumbnail?id=1AXjAHw2Ef3Ni_uqZpoih9r72Jq-nHc5F" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-HVAeM6sNo8" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-HVAeM6sNo8" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-HVAeM6sNo8">
                Abstract <i id="caret-HVAeM6sNo8" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-HVAeM6sNo8">
        <div class="abstract-display">
            <p>Developing successful artificial intelligence systems in practice depends on both robust deep learning models and large, high-quality data. However, acquiring and labeling data can be prohibitively expensive and time-consuming in many real-world applications, such as clinical disease models. Self-supervised learning has demonstrated great potential in increasing model accuracy and robustness in small data regimes. In addition, many clinical imaging and disease modeling applications rely heavily on regression of continuous quantities. However, the applicability of self-supervised learning for these medical-imaging regression tasks has not been extensively studied. In this study, we develop a cross-domain self-supervised learning approach for disease prognostic modeling as a regression problem using medical images as input. We demonstrate that self-supervised pretraining can improve the prediction of Alzheimer's Disease progression from brain MRI. We also show that pretraining on extended (but not labeled) brain MRI data outperforms pretraining on natural images. We further observe that the highest performance is achieved when both natural images and extended brain-MRI data are used for pretraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-YwNrPLjHSL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/YwNrPLjHSL.html">Do Vision-Language Pretrained Models Learn Composable Primitive Concepts?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tian Yun &middot; Usha Bhalla &middot; Ellie Pavlick &middot; Chen Sun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-YwNrPLjHSL"></div>

    <a href="paper_pages/YwNrPLjHSL.html">
        <img src="http://img.youtube.com/vi/qerql58NeeE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-YwNrPLjHSL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-YwNrPLjHSL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-YwNrPLjHSL">
                Abstract <i id="caret-YwNrPLjHSL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-YwNrPLjHSL">
        <div class="abstract-display">
            <p>Vision-language (VL) pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on unlabeled image and caption pairs from the internet. In this paper, we study whether representations of primitive conceptssuch as colors, shapes, or the attributes of object partsemerge automatically within these pretrained VL models. We propose a two-step framework, Compositional Concept Mapping (CompMap), to investigate this. CompMap
first asks a VL model to generate concept activations with text prompts from a predefined list of primitive concepts, and then learns to construct an explicit composition model that maps the primitive concept activations (e.g. the likelihood of black tail or red wing) to com-
posite concepts (e.g. a red-winged blackbird). We demonstrate that a composition model can be designed as a set operation, and show that a composition model is straightforward for machines to learn from ground truth primitive concepts (as a linear classifier). We thus
hypothesize that if primitive concepts indeed emerge in a VL pretrained model, its primitive concept activations can be used to learn a composition model similar to the one designed by experts. We propose a quantitative metric to measure the degree of similarity, and refer to the metric as the interpretability of the VL models learned primitive concept representations. We also measure the classification accuracy when using the primitive concept activations and the learned composition model to predict the composite concepts, and refer to it as the usefulness metric. Our study reveals that state-of-the-art VL pretrained models learn primitive concepts that are highly useful for fine-grained visual recognition on the CUB dataset, and compositional generalization tasks on the MIT-States dataset. However,
we observe that the learned composition models have low interpretability in our qualitative analyses. Our results reveal the limitations of existing VL models, and the necessity of pretraining objectives that encourage the acquisition of primitive concepts.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-p7UTv2hWgM">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/p7UTv2hWgM.html">Stochastic gradient updates yield deep equilibrium kernels</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Russell Tsuchida &middot; Cheng Soon Ong</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-p7UTv2hWgM"></div>

    <a href="paper_pages/p7UTv2hWgM.html">
        <img src="http://img.youtube.com/vi/Ab2KEE9OqEk/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-p7UTv2hWgM" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-p7UTv2hWgM" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-p7UTv2hWgM">
                Abstract <i id="caret-p7UTv2hWgM" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-p7UTv2hWgM">
        <div class="abstract-display">
            <p>Implicit deep learning allows one to compute with implicitly defined features, for example features that solve optimisation problems. We consider the problem of computing with implicitly defined features in a kernel regime. We call such a kernel a deep equilibrium kernel (DEKer). Specialising on a stochastic gradient descent (SGD) update rule applied to features (not weights) in a latent variable model, we find an exact deterministic update rule for the (DEKer) in a high dimensional limit. This derived update rule resembles previously introduced infinitely wide neural network kernels. To perform our analysis, we describe an alternative parameterisation of the link function of exponential families, a result that may be of independent interest. This new parameterisation allows us to draw new connections between a statistician's inverse link function and a machine learner's activation function. We describe an interesting property of SGD in this high dimensional limit: even though individual iterates are random vectors, inner products of any two iterates are deterministic, and can converge to a unique fixed point as the number of iterates increases. We find that the (DEKer) empirically outperforms related neural network kernels on a series of benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-DJr6zorJM2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/DJr6zorJM2.html">A Study of Biologically Plausible Neural Network: The Role and Interactions of Brain-Inspired Mechanisms in Continual Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fahad Sarfraz &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-DJr6zorJM2"></div>

    <a href="paper_pages/DJr6zorJM2.html">
        <img src="http://img.youtube.com/vi/xh2iyEwLnSg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-DJr6zorJM2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-DJr6zorJM2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-DJr6zorJM2">
                Abstract <i id="caret-DJr6zorJM2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-DJr6zorJM2">
        <div class="abstract-display">
            <p>Humans excel at continually acquiring, consolidating, and retaining information from an ever-changing environment, whereas artificial neural networks (ANNs) exhibit catastrophic forgetting. There are considerable differences in the complexity of synapses, the processing of information, and the learning mechanisms in biological neural networks and their artificial counterparts, which may explain the mismatch in performance. We consider a biologically plausible framework that constitutes separate populations of exclusively excitatory and inhibitory neurons that adhere to Dale's principle, and the excitatory pyramidal neurons are augmented with dendritic-like structures for context-dependent processing of stimuli. We then conduct a comprehensive study on the role and interactions of different mechanisms inspired by the brain, including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations that accompanied the learning event. Our study suggests that the employing of multiple complementary mechanisms in a biologically plausible architecture, similar to the brain, may be effective in enabling continual learning in ANNs. \footnote{We will make the code available upon acceptance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2mZSlQscj3">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2mZSlQscj3.html">Neural Monge Map estimation and its applications</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jiaojiao Fan &middot; Shu Liu &middot; Shaojun Ma &middot; Hao-Min Zhou &middot; Yongxin Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2mZSlQscj3"></div>

    <a href="paper_pages/2mZSlQscj3.html">
        <img src="http://img.youtube.com/vi/wIb2ZyieQPo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2mZSlQscj3" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2mZSlQscj3" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2mZSlQscj3">
                Abstract <i id="caret-2mZSlQscj3" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2mZSlQscj3">
        <div class="abstract-display">
            <p>Monge map refers to the optimal transport map between two probability distributions and provides a principled approach to transform one distribution to another.  Neural network-based optimal transport map solver has gained great attention in recent years. Along this line, we present a scalable algorithm for computing the neural Monge map between two probability distributions. Our algorithm is based on a weak form of the optimal transport problem, thus it only requires samples from the marginals instead of their analytic expressions, and can be applied in large-scale settings. Furthermore, using the duality gap we prove rigorously \textit{a posteriori} error analysis for the method. Our algorithm is suitable for general cost functions, compared with other existing methods for estimating Monge maps using samples, which are usually for quadratic costs. The performance of our algorithms is demonstrated through a series of experiments with both synthetic and realistic data, including text-to-image generation, class-preserving map, and image inpainting tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-KxBQPz7HKh">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/KxBQPz7HKh.html">Multi-dimensional concept discovery (MCD): A unifying framework with completeness guarantees</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Johanna Vielhaben &middot; Stefan Bluecher &middot; Nils Strodthoff</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-KxBQPz7HKh"></div>

    <a href="paper_pages/KxBQPz7HKh.html">
        <img src="http://img.youtube.com/vi/JZOzo-K05F0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-KxBQPz7HKh" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-KxBQPz7HKh" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-KxBQPz7HKh">
                Abstract <i id="caret-KxBQPz7HKh" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-KxBQPz7HKh">
        <div class="abstract-display">
            <p>The completeness axiom renders the explanation of a post-hoc eXplainable AI (XAI) method only locally faithful to the model, i.e. for a single decision. For the trustworthy application of XAI, in particular for high-stake decisions, a more global model understanding is required. To this end, concept-based methods have been proposed, which are however not guaranteed to be bound to the actual model reasoning. To circumvent this problem, we propose Multi-dimensional Concept Discovery (MCD) as an extension of previous approaches that fulfills a completeness relation on the level of concepts. Our method starts from general linear subspaces as concepts and does neither require reinforcing concept interpretability nor re-training of model parts. We propose sparse subspace clustering to discover improved concepts and fully leverage the potential of multi-dimensional subspaces. MCD offers two complementary analysis tools for concepts in input space: (1) concept activation maps, that show where a concept is expressed within a sample, allowing for concept characterization through prototypical samples, and (2) concept relevance heatmaps, that decompose the model decision into concept contributions. Both tools together enable a detailed global understanding of the model reasoning, which is guaranteed to relate to the model via a completeness relation. Thus, MCD paves the way towards more trustworthy concept-based XAI. We empirically demonstrate the superiority of MCD against more constrained concept definitions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-fvyh6mDWFr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/fvyh6mDWFr.html">Understanding Noise-Augmented Training for Randomized Smoothing</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ambar Pal &middot; Jeremias Sulam</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-fvyh6mDWFr"></div>

    <a href="paper_pages/fvyh6mDWFr.html">
        <img src="http://img.youtube.com/vi/LzIoT5pX7pQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-fvyh6mDWFr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-fvyh6mDWFr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-fvyh6mDWFr">
                Abstract <i id="caret-fvyh6mDWFr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-fvyh6mDWFr">
        <div class="abstract-display">
            <p>Randomized smoothing is a technique for providing provable robustness guarantees against adversarial attacks while making minimal assumptions about a classifier. This method relies on taking a majority vote of any base classifier over multiple noise-perturbed inputs to obtain a smoothed classifier, and it remains the tool of choice to certify deep and complex neural network models. Nonetheless, non-trivial performance of such smoothed classifier crucially depends on the base model being trained on noise-augmented data, i.e., on a smoothed input distribution. While widely adopted in practice, it is still unclear how this noisy training of the base classifier precisely affects the risk of the robust smoothed classifier, leading to heuristics and tricks that are poorly understood. In this work we analyze these trade-offs theoretically in a binary classification setting, proving that these common observations are not universal. We show that, without making stronger distributional assumptions, no benefit can be expected from predictors trained with noise-augmentation, and we further characterize distributions where such benefit is obtained. Our analysis has direct implications to the practical deployment of randomized smoothing, and we illustrate some of these via experiments on CIFAR-10 and MNIST, as well as on synthetic datasets.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VynY6Bk03b">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VynY6Bk03b.html">How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jorge A Mendez &middot; ERIC EATON</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VynY6Bk03b"></div>

    <a href="paper_pages/VynY6Bk03b.html">
        <img src="http://img.youtube.com/vi/d6RSRnTvUfY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VynY6Bk03b" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VynY6Bk03b" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VynY6Bk03b">
                Abstract <i id="caret-VynY6Bk03b" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VynY6Bk03b">
        <div class="abstract-display">
            <p>A major goal of artificial intelligence (AI) is to create an agent capable of acquiring a general understanding of the world. Such an agent would require the ability to continually accumulate and build upon its knowledge as it encounters new experiences. Lifelong or continual learning addresses this setting, whereby an agent faces a continual stream of problems and must strive to capture the knowledge necessary for solving each new task it encounters. If the agent is capable of accumulating knowledge in some form of compositional representation, it could then selectively reuse and combine relevant pieces of knowledge to construct novel solutions. Despite the intuitive appeal of this simple idea, the literatures on lifelong learning and compositional learning have proceeded largely separately. In an effort to promote developments that bridge between the two fields, this article surveys their respective research landscapes and discusses existing and future connections between them.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MRLHN4MSmA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MRLHN4MSmA.html">A Modulation Layer to Increase Neural Network Robustness Against Data Quality Issues</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohamed Abdelhack &middot; Jiaming Zhang &middot; Sandhya Tripathi &middot; Bradley A Fritz &middot; Daniel Felsky &middot; Michael Avidan &middot; Yixin Chen &middot; Christopher Ryan King</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MRLHN4MSmA"></div>

    <a href="paper_pages/MRLHN4MSmA.html">
        <img src="http://img.youtube.com/vi/SI-5cuPJV9U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MRLHN4MSmA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MRLHN4MSmA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MRLHN4MSmA">
                Abstract <i id="caret-MRLHN4MSmA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MRLHN4MSmA">
        <div class="abstract-display">
            <p>Data missingness and quality are common problems in machine learning, especially for high-stakes applications such as healthcare. Developers often train machine learning models on carefully curated datasets using only high-quality data; however, this reduces the utility of such models in production environments. We propose a novel neural network modification to mitigate the impacts of low-quality and missing data which involves replacing the fixed weights of a fully-connected layer with a function of additional input. This is inspired by neuromodulation in biological neural networks where the cortex can up- and down-regulate inputs based on their reliability and the presence of other data. In testing, with reliability scores as a modulating signal, models with modulating layers were found to be more robust against data quality degradation, including additional missingness. These models are superior to imputation as they save on training time by entirely skipping the imputation process and further allow the introduction of other data quality measures that imputation cannot handle. Our results suggest that explicitly accounting for reduced information quality with a modulating fully connected layer can enable the deployment of artificial intelligence systems in real-time applications.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gR9UVgH8PZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gR9UVgH8PZ.html">Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tiange Luo &middot; Honglak Lee &middot; Justin Johnson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gR9UVgH8PZ"></div>

    <a href="paper_pages/gR9UVgH8PZ.html">
        <img src="video_thumbnails/gR9UVgH8PZ.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gR9UVgH8PZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gR9UVgH8PZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gR9UVgH8PZ">
                Abstract <i id="caret-gR9UVgH8PZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gR9UVgH8PZ">
        <div class="abstract-display">
            <p>3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\textit{Text}$ $\Longleftrightarrow$ $\textit{Point Cloud}$ $\Longleftrightarrow$ $\textit{Program}$. We propose $\textbf{\textit{Neural Shape Compiler}}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\textit{Text}$ $\Longrightarrow$ $\textit{Point Cloud}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Text}$, $\textit{Point Cloud}$ $\Longrightarrow$ $\textit{Program}$, and Point Cloud Completion tasks. Additionally, Neural Shape Compiler benefits from jointly training on all heterogeneous data and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-T1XtOqrVKn">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/T1XtOqrVKn.html">Reducing Predictive Feature Suppression in Resource-Constrained Contrastive Image-Caption Retrieval</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Maurits Bleeker &middot; Andrew Yates &middot; Maarten de Rijke</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-T1XtOqrVKn"></div>

    <a href="paper_pages/T1XtOqrVKn.html">
        <img src="http://img.youtube.com/vi/CrT7wlzY5K8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-T1XtOqrVKn" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-T1XtOqrVKn" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-T1XtOqrVKn">
                Abstract <i id="caret-T1XtOqrVKn" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-T1XtOqrVKn">
        <div class="abstract-display">
            <p>To train image-caption retrieval (ICR) methods, contrastive loss functions are a common choice for optimization functions. 
Unfortunately, contrastive ICR methods are vulnerable to predictive feature suppression. 
Predictive features are features that correctly indicate the similarity between a query and a candidate item. 
However, in the presence of multiple predictive features during training, encoder models tend to suppress redundant predictive features, since these features are not needed to learn to discriminate between positive and
negative pairs. 
We introduce an approach to reduce predictive feature suppression for resource-constrained ICR methods: latent target decoding (LTD). We add an additional decoder to the contrastive ICR framework, to reconstruct the input caption in a latent space of a general-purpose
sentence encoder, which prevents the image and caption encoder from suppressing
predictive features. 
We implement the LTD objective as an optimization constraint, to ensure that the reconstruction loss is below a bound value while primarily optimizing for the contrastive loss. 
Importantly, LTD does not depend on additional training data or expensive (hard) negative mining strategies. 
Our experiments show that, unlike reconstructing the input caption in the input space, LTD reduces predictive feature suppression, measured by obtaining higher recall@k, r-precision, and nDCG scores than a contrastive ICR baseline.
Moreover, we show that LTD should be implemented as an optimization constraint instead
of a dual optimization objective. Finally, we show that LTD can be used with different
contrastive learning losses and a wide variety of resource-constrained ICR methods.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-4eL6z9ziw7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/4eL6z9ziw7.html">NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Patrick Feeney &middot; Sarah Schneider &middot; Panagiotis Lymperopoulos &middot; Liping Liu &middot; Matthias Scheutz &middot; Michael C Hughes</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-4eL6z9ziw7"></div>

    <a href="paper_pages/4eL6z9ziw7.html">
        <img src="http://img.youtube.com/vi/d0AAH_eMPoQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-4eL6z9ziw7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-4eL6z9ziw7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-4eL6z9ziw7">
                Abstract <i id="caret-4eL6z9ziw7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-4eL6z9ziw7">
        <div class="abstract-display">
            <p>In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects of varying size within the complex 3D scene that may impact gameplay. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. Further multimodal novelty detection experiments suggest that methods that fuse both visual and symbolic information can improve time until detection as well as overall discrimination. Finally, our evaluation of recent generalized category discovery methods suggests that adapting to new imbalanced categories in complex scenes remains an exciting open problem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qdDmxzGuzu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qdDmxzGuzu.html">Reusable Options through Gradient-based Meta Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">David Kuric &middot; Herke van Hoof</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qdDmxzGuzu"></div>

    <a href="paper_pages/qdDmxzGuzu.html">
        <img src="http://img.youtube.com/vi/Dp5a20y9ohw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qdDmxzGuzu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qdDmxzGuzu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qdDmxzGuzu">
                Abstract <i id="caret-qdDmxzGuzu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qdDmxzGuzu">
        <div class="abstract-display">
            <p>Hierarchical methods in reinforcement learning have the potential to reduce the amount of decisions that the agent needs to perform when learning new tasks. However, finding a reusable useful temporal abstractions that facilitate fast learning remains a challenging problem. Recently, several deep learning approaches were proposed to learn such temporal abstractions in the form of options in an end-to-end manner. In this work, we point out several shortcomings of these methods and discuss their potential negative consequences. Subsequently, we formulate the desiderata for reusable options and use these to frame the problem of learning options as a gradient-based meta-learning problem. This allows us to formulate an objective that explicitly incentivizes options which allow a higher-level decision maker to adjust in few steps to different tasks. Experimentally, we show that our method is able to learn transferable components which accelerate learning and performs better than existing prior methods developed for this setting. Additionally, we perform ablations to quantify the impact of using gradient-based meta-learning as well as other proposed changes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MTFf1rDDEI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MTFf1rDDEI.html">Successor Feature Representations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chris Reinke &middot; Xavier Alameda-Pineda</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MTFf1rDDEI"></div>

    <a href="paper_pages/MTFf1rDDEI.html">
        <img src="http://img.youtube.com/vi/RYemlh2NSzQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MTFf1rDDEI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MTFf1rDDEI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MTFf1rDDEI">
                Abstract <i id="caret-MTFf1rDDEI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MTFf1rDDEI">
        <div class="abstract-display">
            <p>Transfer in Reinforcement Learning aims to improve learning performance on target tasks using knowledge from experienced source tasks. Successor Representations (SR) and their extension Successor Features (SF) are prominent transfer mechanisms in domains where reward functions change between tasks. They reevaluate the expected return of previously learned policies in a new target task to transfer their knowledge. The SF framework extended SR by linearly decomposing rewards into successor features and a reward weight vector allowing their application in high-dimensional tasks. But this came with the cost of having a linear relationship between reward functions and successor features, limiting its application to tasks where such a linear relationship exists. We propose a novel formulation of SR based on learning the cumulative discounted probability of successor features, called Successor Feature Representations (SFR). Crucially, SFR allows to reevaluate the expected return of policies for general reward functions. We introduce different SFR variations, prove its convergence, and provide a guarantee on its transfer performance. Experimental evaluations based on SFR with function approximation demonstrate its advantage over SF not only for general reward functions, but also in the case of linearly decomposable reward functions.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-nHfPXl1ly7">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/nHfPXl1ly7.html">A Kernel Perspective on Behavioural Metrics for Markov Decision Processes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Pablo Samuel Castro &middot; Tyler Kastner &middot; Prakash Panangaden &middot; Mark Rowland</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-nHfPXl1ly7"></div>

    <a href="paper_pages/nHfPXl1ly7.html">
        <img src="http://img.youtube.com/vi/or5W73cn-WQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-nHfPXl1ly7" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-nHfPXl1ly7" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-nHfPXl1ly7">
                Abstract <i id="caret-nHfPXl1ly7" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-nHfPXl1ly7">
        <div class="abstract-display">
            <p>We present a novel perspective on behavioural metrics for Markov decision processes via the use of positive definite kernels. We define a new metric under this lens that is provably equivalent to the recently introduced MICo distance (Castro et al., 2021). The kernel perspective enables us to provide new theoretical results, including value-function bounds and low-distortion finite-dimensional Euclidean embeddings, which are crucial when using behavioural metrics for reinforcement learning representations. We complement our theory with strong empirical results that demonstrate the effectiveness of these methods in practice.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-y4CGF1A8VG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/y4CGF1A8VG.html">Machine Explanations and Human Understanding</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Chacha Chen &middot; Shi Feng &middot; Amit Sharma &middot; Chenhao Tan</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-y4CGF1A8VG"></div>

    <a href="paper_pages/y4CGF1A8VG.html">
        <img src="http://img.youtube.com/vi/-hNKPaX7L4o/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-y4CGF1A8VG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-y4CGF1A8VG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-y4CGF1A8VG">
                Abstract <i id="caret-y4CGF1A8VG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-y4CGF1A8VG">
        <div class="abstract-display">
            <p>Explanations are hypothesized to improve human understanding of machine learning models and achieve a variety of desirable outcomes, ranging from model debugging to enhancing human decision making. However, empirical studies have found mixed and even negative results. An open question, therefore, is under what conditions explanations can improve human understanding and in what way. To address this question, we first identify three core concepts that cover most existing quantitative measures of understanding: task decision boundary, model decision boundary, and model error. Using adapted causal diagrams, we provide a formal characterization of the relationship between these concepts and human approximations (i.e., understanding) of them. The relationship varies by the level of human intuition in different task types, such as emulation and discovery, which are often ignored when building or evaluating explanation methods. Our key result is that human intuitions are necessary for generating and evaluating machine explanations in human-AI decision making: without assumptions about human intuitions, explanations may improve human understanding of model decision boundary, but cannot improve human understanding of task decision boundary or model error. To validate our theoretical claims, we conduct human subject studies to show the importance of human intuitions. Together with our theoretical contributions, we provide a new paradigm for designing behavioral studies towards a rigorous view of the role of machine explanations across different tasks of human-AI decision making.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-a0T3nOP9sB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/a0T3nOP9sB.html">Adaptive patch foraging in deep reinforcement learning agents</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nathan Wispinski &middot; Andrew Butcher &middot; Kory Wallace Mathewson &middot; Craig S Chapman &middot; Matthew Botvinick &middot; Patrick M. Pilarski</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-a0T3nOP9sB"></div>

    <a href="paper_pages/a0T3nOP9sB.html">
        <img src="http://img.youtube.com/vi/5PfxPj5Jzwo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-a0T3nOP9sB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-a0T3nOP9sB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-a0T3nOP9sB">
                Abstract <i id="caret-a0T3nOP9sB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-a0T3nOP9sB">
        <div class="abstract-display">
            <p>Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests that agents interacting in complex environments with ecologically valid pressures arrive at common solutions, suggesting the emergence of foundational computations behind adaptive, intelligent behavior in both biological and artificial agents.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-onufdyHvqN">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/onufdyHvqN.html">Private Multi-Task Learning: Formulation and Applications to Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Shengyuan Hu &middot; Steven Wu &middot; Virginia Smith</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-onufdyHvqN"></div>

    <a href="paper_pages/onufdyHvqN.html">
        <img src="https://drive.google.com/thumbnail?id=1J35lwtPfLtEF3HpomNKYc3CzEW6nhgu6" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-onufdyHvqN" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-onufdyHvqN" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-onufdyHvqN">
                Abstract <i id="caret-onufdyHvqN" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-onufdyHvqN">
        <div class="abstract-display">
            <p>Many problems in machine learning rely on multi-task learning (MTL), in which the goal is to solve multiple related machine learning tasks simultaneously. MTL is particularly relevant for privacy-sensitive applications in areas such as healthcare, finance, and IoT computing,
where sensitive data from multiple, varied sources are shared for the purpose of learning. In this work, we formalize notions of client-level privacy for MTL via billboard privacy (BP), a relaxation of differential privacy for mechanism design and distributed optimization. We then propose an algorithm for mean-regularized MTL, an objective commonly used for applications in personalized federated learning, subject to BP. We analyze our objective and solver, providing certifiable guarantees on both privacy and utility. Empirically, we find that our method provides improved privacy/utility trade-offs relative to global baselines across common federated learning benchmarks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-9aXKUJEKwV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/9aXKUJEKwV.html">Learning to Look by Self-Prediction</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Koichi Grimes &middot; Joseph Varughese Modayil &middot; Piotr W Mirowski &middot; Dushyant Rao &middot; Raia Hadsell</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-9aXKUJEKwV"></div>

    <a href="paper_pages/9aXKUJEKwV.html">
        <img src="https://drive.google.com/thumbnail?id=1iOFC1IWk0Jx-poBZW0lh5FcTmT55BdDw" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-9aXKUJEKwV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-9aXKUJEKwV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-9aXKUJEKwV">
                Abstract <i id="caret-9aXKUJEKwV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-9aXKUJEKwV">
        <div class="abstract-display">
            <p>We present a method for learning active vision skills, to move the camera to observe a robot's sensors from informative points of view, without external rewards or labels. We do this by jointly training a visual predictor network, which predicts future returns of the sensors using pixels, and a camera control agent, which we reward using the negative error of the predictor. The agent thus moves the camera to points of view that are most predictive for a chosen sensor, which we select using a conditioning input to the agent. We observe that despite this noisy learned reward function, the learned policies a exhibit competence by reliably framing the sensor in a specific location in the view, an emergent location which we call a behavioral fovea. We find that replacing the conventional camera with a foveal camera further increases the policies' precision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-TNocbXm5MZ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/TNocbXm5MZ.html">Guaranteed Discovery of Control-Endogenous Latent States with Multi-Step Inverse Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Alex Lamb &middot; Riashat Islam &middot; Yonathan Efroni &middot; Aniket Rajiv Didolkar &middot; Dipendra Misra &middot; Dylan J Foster &middot; Lekan P Molu &middot; Rajan Chari &middot; Akshay Krishnamurthy &middot; John Langford</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-TNocbXm5MZ"></div>

    <a href="paper_pages/TNocbXm5MZ.html">
        <img src="http://img.youtube.com/vi/prS5EG9dLVg/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-TNocbXm5MZ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-TNocbXm5MZ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-TNocbXm5MZ">
                Abstract <i id="caret-TNocbXm5MZ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-TNocbXm5MZ">
        <div class="abstract-display">
            <p>In many sequential decision-making tasks, the agent is not able to model the full complexity of the world, which consists of multitudes of relevant and irrelevant information. For example, a person walking along a city street who tries to model all aspects of the world would quickly be overwhelmed by a multitude of shops, cars, and people moving in and out of view, each following their own complex and inscrutable dynamics.  Is it possible to turn the agent's firehose of sensory information into a minimal latent state that is both necessary and sufficient for an agent to successfully act in the world? We formulate this question concretely, and propose the Agent Control-Endogenous State Discovery algorithm (AC-State), which has theoretical guarantees and is practically demonstrated to discover the minimal control-endogenous latent state which contains all of the information necessary for controlling the agent, while fully discarding all irrelevant information.    This algorithm consists of a multi-step inverse model (predicting actions from distant observations) with an information bottleneck.  AC-State enables localization, exploration, and navigation without reward or demonstrations.  We demonstrate the discovery of the control-endogenous latent state in three domains: localizing a robot arm with distractions (e.g., changing lighting conditions and background), exploring a maze alongside other agents, and navigating in the Matterport house simulator.  </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-5aYGXxByI6">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/5aYGXxByI6.html">MASIF: Meta-learned Algorithm Selection using Implicit Fidelity Information</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Tim Ruhkopf &middot; Aditya Mohan &middot; Difan Deng &middot; Alexander Tornede &middot; Frank Hutter &middot; Marius Lindauer</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-5aYGXxByI6"></div>

    <a href="paper_pages/5aYGXxByI6.html">
        <img src="http://img.youtube.com/vi/4qXRyRjJPIY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-5aYGXxByI6" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-5aYGXxByI6" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-5aYGXxByI6">
                Abstract <i id="caret-5aYGXxByI6" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-5aYGXxByI6">
        <div class="abstract-display">
            <p>Selecting a well-performing algorithm for a given task or dataset can be time-consuming and
tedious, but is crucial for the successful day-to-day business of developing new AI & ML
applications. Algorithm Selection (AS) mitigates this through a meta-model leveraging
meta-information about previous tasks. However, most of the available AS methods are
error-prone because they characterize a task by either cheap-to-compute properties of the
dataset or evaluations of cheap proxy algorithms, called landmarks. In this work, we extend
the classical AS data setup to include multi-fidelity information and empirically demonstrate
how meta-learning on algorithms learning behaviour allows us to exploit cheap test-time
evidence effectively and combat myopia significantly. We further postulate a budget-regret
trade-off w.r.t. the selection process. Our new selector MASIF is able to jointly interpret
online evidence on a task in form of varying-length learning curves without any parametric
assumption by leveraging a transformer-based encoder. This opens up new possibilities for
guided rapid prototyping in data science on cheaply observed partial learning curves.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-NrfSRtTpN5">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/NrfSRtTpN5.html">Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Hong-Xing Yu &middot; Michelle Guo &middot; Alireza Fathi &middot; Yen-Yu Chang &middot; Eric Ryan Chan &middot; Ruohan Gao &middot; Thomas Funkhouser &middot; Jiajun Wu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-NrfSRtTpN5"></div>

    <a href="paper_pages/NrfSRtTpN5.html">
        <img src="http://img.youtube.com/vi/BqKiO5GDtH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-NrfSRtTpN5" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-NrfSRtTpN5" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-NrfSRtTpN5">
                Abstract <i id="caret-NrfSRtTpN5" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-NrfSRtTpN5">
        <div class="abstract-display">
            <p>Photorealistic object appearance modeling from 2D images is a constant topic in vision and graphics. While neural implicit methods (such as Neural Radiance Fields) have shown high-fidelity view synthesis results, they cannot relight the captured objects. More recent neural inverse rendering approaches have enabled object relighting, but they represent surface properties as simple BRDFs, and therefore cannot handle translucent objects. We propose Object-Centric Neural Scattering Functions (OSFs) for learning to reconstruct object appearance from only images. OSFs not only support free-viewpoint object relighting, but also can model both opaque and translucent objects. While accurately modeling subsurface light transport for translucent objects can be highly complex and even intractable for neural methods, OSFs learn to approximate the radiance transfer from a distant light to an outgoing direction at any spatial location. This approximation avoids explicitly modeling complex subsurface scattering, making learning a neural implicit model tractable. Experiments on real and synthetic data show that OSFs accurately reconstruct appearances for both opaque and translucent objects, allowing faithful free-viewpoint relighting as well as scene composition. In our supplementary material, we include a video for an overview. Project website with video results: https://kovenyu.com/OSF/</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-JwDpZSv3yz">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/JwDpZSv3yz.html">SPADE: Semi-supervised Anomaly Detection under Distribution Mismatch</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jinsung Yoon &middot; Kihyuk Sohn &middot; Chun-Liang Li &middot; Sercan O Arik &middot; Tomas Pfister</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-JwDpZSv3yz"></div>

    <a href="paper_pages/JwDpZSv3yz.html">
        <img src="https://drive.google.com/thumbnail?id=1UvqBpvcPw3XQISI5ZI-upYdPlOUNqcvi" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-JwDpZSv3yz" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-JwDpZSv3yz" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-JwDpZSv3yz">
                Abstract <i id="caret-JwDpZSv3yz" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-JwDpZSv3yz">
        <div class="abstract-display">
            <p>Semi-supervised anomaly detection is a common problem, as often the datasets containing anomalies are partially labeled. We propose a canonical framework: Semi-supervised Pseudo-labeler Anomaly Detection with Ensembling (SPADE) that isn't limited by the assumption that labeled and unlabeled data come from the same distribution. Indeed, the assumption is often violated in many applications -- for example, the labeled data may contain only anomalies unlike unlabeled data, or unlabeled data may contain different types of anomalies, or labeled data may contain only `easy-to-label' samples. SPADE utilizes an ensemble of one class classifiers as the pseudo-labeler to improve the robustness of pseudo-labeling with distribution mismatch. Partial matching is proposed to automatically select the critical hyper-parameters for pseudo-labeling without validation data, which is crucial with limited labeled data. SPADE shows state-of-the-art semi-supervised anomaly detection performance across a wide range of scenarios with distribution mismatch in both tabular and image domains. In some common real-world settings such as model facing new types of unlabeled anomalies, SPADE outperforms the state-of-the-art alternatives by 5% AUC in average.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Oq5XKRVYpQ">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Oq5XKRVYpQ.html">Graph-based Multi-ODE Neural Networks for Spatio-Temporal Traffic Forecasting</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Zibo Liu &middot; Parshin Shojaee &middot; Chandan K. Reddy</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Oq5XKRVYpQ"></div>

    <a href="paper_pages/Oq5XKRVYpQ.html">
        <img src="http://img.youtube.com/vi/00SItN8IP-M/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Oq5XKRVYpQ" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Oq5XKRVYpQ" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Oq5XKRVYpQ">
                Abstract <i id="caret-Oq5XKRVYpQ" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Oq5XKRVYpQ">
        <div class="abstract-display">
            <p>There is a recent surge in the development of spatio-temporal forecasting models in the transportation domain. Long-range traffic forecasting, however,  remains a challenging task due to the intricate and extensive spatio-temporal correlations observed in traffic networks. 
Current works primarily rely on road networks with graph structures and learn representations using graph neural networks (GNNs), but this approach suffers from over-smoothing problem in deep architectures. To tackle this problem, recent methods introduced the combination of GNNs with residual connections or neural ordinary differential equations (ODE). However, current graph ODE models face two key limitations in feature extraction: (1) they lean towards global temporal patterns, overlooking local patterns that are important for unexpected events; and (2) they lack dynamic semantic edges in their architectural design. In this paper, we propose a novel architecture called Graph-based Multi-ODE Neural Networks (GRAM-ODE) which is designed with multiple connective ODE-GNN modules to learn better representations by capturing different views of complex local and global dynamic spatio-temporal dependencies. We also add some techniques like shared weights and divergence constraints into the intermediate layers of distinct ODE-GNN modules to further improve their communication towards the forecasting task. Our extensive set of experiments conducted on six real-world datasets demonstrate the superior performance of GRAM-ODE compared with state-of-the-art baselines as well as the contribution of different components to the overall performance. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-WN1O2MJDST">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/WN1O2MJDST.html">Learn, Unlearn and Relearn: An Online Learning Paradigm for Deep Neural Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vijaya Raghavan T Ramkumar &middot; Elahe Arani &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-WN1O2MJDST"></div>

    <a href="paper_pages/WN1O2MJDST.html">
        <img src="http://img.youtube.com/vi/efulZvJBZ04/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-WN1O2MJDST" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-WN1O2MJDST" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-WN1O2MJDST">
                Abstract <i id="caret-WN1O2MJDST" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-WN1O2MJDST">
        <div class="abstract-display">
            <p>Deep neural networks (DNNs) are often trained on the premise that the complete training data set is provided ahead of time. However, in real-world scenarios, data often arrive in chunks over time. This leads to important considerations about the optimal strategy for training DNNs, such as whether to fine-tune them with each chunk of incoming data (warm-start) or to retrain them from scratch with the entire corpus of data whenever a new chunk is available. While employing the latter for training can be resource-intensive, recent work has pointed out the lack of generalization in warm-start models. Therefore, to strike a balance between efficiency and generalization, we introduce "Learn, Unlearn, and Relearn (LURE)" an online learning paradigm for DNNs. LURE interchanges between the unlearning phase, which selectively forgets the undesirable information in the model through weight reinitialization in a data-dependent manner, and the relearning phase, which emphasizes learning on generalizable features. We show that our training paradigm provides consistent performance gains across datasets in both classification and few-shot settings. We further show that it leads to more robust and well-calibrated models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-v5jwDLqfQo">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/v5jwDLqfQo.html">Extended Agriculture-Vision: An Extension of a Large Aerial Image Dataset for Agricultural Pattern Analysis</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wu &middot; David Pichler &middot; Daniel Marley &middot; Naira Hovakimyan &middot; David A Wilson &middot; Jennifer Hobbs</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-v5jwDLqfQo"></div>

    <a href="paper_pages/v5jwDLqfQo.html">
        <img src="http://img.youtube.com/vi/2xaKxUpY4iQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-v5jwDLqfQo" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-v5jwDLqfQo" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-v5jwDLqfQo">
                Abstract <i id="caret-v5jwDLqfQo" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-v5jwDLqfQo">
        <div class="abstract-display">
            <p>A key challenge for much of the machine learning work on remote sensing and earth observation data is the difficulty in acquiring large amounts of accurately labeled data. This is particularly true for semantic segmentation tasks, which are much less common in the remote sensing domain because of the incredible difficulty in collecting precise, accurate, pixel-level annotations at scale. Recent efforts have addressed these challenges both through the creation of supervised datasets as well as the application of self-supervised methods. We continue these efforts on both fronts. First, we generate and release an improved version of the Agriculture-Vision dataset  (Chiu et al., 2020b) to include raw, full-field imagery for greater experimental flexibility. Second, we extend this dataset with the release of 3600 large, high-resolution (10cm/pixel), full-field, red-green-blue and near-infrared images for pre-training. Third, we incorporate the Pixel-to-Propagation Module Xie et al. (2021b) originally built on the SimCLR framework into the framework of MoCo-V2 Chen et al.(2020b). Finally, we demonstrate the usefulness of this data by benchmarking different contrastive learning approaches on both downstream classification and semantic segmentation tasks. We explore both CNN and Swin Transformer Liu et al. (2021a) architectures within different frameworks based on MoCo-V2. Together, these approaches enable us to better detect key agricultural patterns of interest across a field from aerial imagery so that farmers may be alerted to problematic areas in a timely fashion to inform their management decisions. Furthermore, the release of these datasets will support numerous avenues of research for computer vision in remote sensing for agriculture.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EiX2L4sDPG">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EiX2L4sDPG.html">VN-Transformer: Rotation-Equivariant Attention for Vector Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Serge Assaad &middot; Carlton Downey &middot; Rami Al-Rfou' &middot; Nigamaa Nayakanti &middot; Benjamin Sapp</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EiX2L4sDPG"></div>

    <a href="paper_pages/EiX2L4sDPG.html">
        <img src="http://img.youtube.com/vi/1KrPzUKwSL8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EiX2L4sDPG" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EiX2L4sDPG" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EiX2L4sDPG">
                Abstract <i id="caret-EiX2L4sDPG" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EiX2L4sDPG">
        <div class="abstract-display">
            <p>Rotation equivariance is a desirable property in many practical applications such as motion forecasting and 3D perception, where it can offer benefits like sample efficiency, better generalization, and robustness to input perturbations.
Vector Neurons (VN) is a recently developed framework offering a simple yet effective approach for deriving rotation-equivariant analogs of standard machine learning operations by extending one-dimensional scalar neurons to three-dimensional "vector neurons."
We introduce a novel "VN-Transformer" architecture to address several shortcomings of the current VN models. Our contributions are:
(i) we derive a rotation-equivariant attention mechanism which eliminates the need for the heavy feature preprocessing required by the original Vector Neurons models; (ii) we extend the VN framework to support non-spatial attributes, expanding the applicability of these models to real-world datasets; (iii) we derive a rotation-equivariant mechanism for multi-scale reduction of point-cloud resolution, greatly speeding up inference and training; (iv) we show that small tradeoffs in equivariance ($\epsilon$-approximate equivariance) can be used to obtain large improvements in numerical stability and training robustness on accelerated hardware, and we bound the propagation of equivariance violations in our models.
Finally, we apply our VN-Transformer to 3D shape classification and motion forecasting with compelling results.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-jdGMBgYvfX">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/jdGMBgYvfX.html">UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Francisca Vasconcelos &middot; Bobby He &middot; Nalini M Singh &middot; Yee Whye Teh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-jdGMBgYvfX"></div>

    <a href="paper_pages/jdGMBgYvfX.html">
        <img src="http://img.youtube.com/vi/cD7Wx4F_EjQ/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-jdGMBgYvfX" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-jdGMBgYvfX" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-jdGMBgYvfX">
                Abstract <i id="caret-jdGMBgYvfX" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-jdGMBgYvfX">
        <div class="abstract-display">
            <p>Implicit neural representations (INRs) have achieved impressive results for scene reconstruction and computer graphics, where their performance has primarily been assessed on reconstruction accuracy. As INRs make their way into other domains, where model predictions inform high-stakes decision-making, uncertainty quantification of INR inference is becoming critical. To that end, we study a Bayesian reformulation of INRs, UncertaINR, in the context of computed tomography, and evaluate several Bayesian deep learning implementations in terms of accuracy and calibration.  We find that they achieve well-calibrated uncertainty, while retaining accuracy competitive with other classical, INR-based, and CNN-based reconstruction techniques. Contrary to common intuition in the Bayesian deep learning literature, we find that INRs obtain the best calibration with computationally efficient Monte Carlo dropout, outperforming Hamiltonian Monte Carlo and deep ensembles. Moreover, in contrast to the best-performing prior approaches, UncertaINR does not require a large training dataset, but only a handful of validation images.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gZna3IiGfl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gZna3IiGfl.html">Mean-field analysis for heavy ball methods: Dropout-stability, connectivity, and global convergence</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Diyuan Wu &middot; Vyacheslav Kungurtsev &middot; Marco Mondelli</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gZna3IiGfl"></div>

    <a href="paper_pages/gZna3IiGfl.html">
        <img src="video_thumbnails/gZna3IiGfl.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gZna3IiGfl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gZna3IiGfl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gZna3IiGfl">
                Abstract <i id="caret-gZna3IiGfl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gZna3IiGfl">
        <div class="abstract-display">
            <p>The stochastic heavy ball method (SHB), also known as stochastic gradient descent (SGD) with Polyak's momentum, is widely used in training neural networks. However, despite the remarkable success of such algorithm in practice, its theoretical characterization remains limited. In this paper, we focus on neural networks with two and three layers and provide a rigorous understanding of the properties of the solutions found by SHB: \emph{(i)} stability after dropping out part of the neurons, \emph{(ii)} connectivity along a low-loss path, and \emph{(iii)} convergence to the global optimum.
To achieve this goal, we take a mean-field view and relate the SHB dynamics to a certain partial differential equation in the limit of large network widths. This mean-field perspective has inspired a recent line of work focusing on SGD while, in contrast, our paper considers an algorithm with momentum. More specifically, after proving existence and uniqueness of the limit differential equations, we show convergence to the global optimum and give a quantitative bound between the mean-field limit and the SHB dynamics of a finite-width network. Armed with this last bound, we are able to establish the dropout-stability and connectivity of SHB solutions. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-SM1BkjGePI">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/SM1BkjGePI.html">Bridging performance gap between minimal and maximal SVM models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ondrej Such &middot; Ren Fabricius</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-SM1BkjGePI"></div>

    <a href="paper_pages/SM1BkjGePI.html">
        <img src="http://img.youtube.com/vi/jWAfN4deoC8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-SM1BkjGePI" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-SM1BkjGePI" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-SM1BkjGePI">
                Abstract <i id="caret-SM1BkjGePI" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-SM1BkjGePI">
        <div class="abstract-display">
            <p>Multi-class support vector machine (SVM) models are typically built using all possible pairs of binary SVM in a one-against-one fashion. This requires too much computation for datasets with hundreds or thousands of classes,  which motivates the search for multi-class models that do not use all pairwise SVM.  Our models correspond to the choice of the model graph, whose vertices correspond to classes and edges represent which pairwise SVMs are trained. We conduct experiments to uncover metrical and topological properties that impact the accuracy of a multi-class SVM model. Based on their results we propose a way to construct intermediate multi-class SVM models. The key insight is that for model graphs of diameter two, we can estimate missing pairwise probabilities from the known ones thus transforming the computation of posteriors to the usual complete (maximal) case. Our proposed algorithm allows one to reduce computational effort by 50-80% while keeping accuracy near, or even above that of a softmax classifier. In our work we use convolutional data sets, which have multiple advantages for benchmarking multi-class SVM models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mySiFHCeAl">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mySiFHCeAl.html">Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Amirali Aghazadeh &middot; Nived Rajaraman &middot; Tony Tu &middot; Kannan Ramchandran</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mySiFHCeAl"></div>

    <a href="paper_pages/mySiFHCeAl.html">
        <img src="http://img.youtube.com/vi/ER12pwvxTSU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mySiFHCeAl" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mySiFHCeAl" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mySiFHCeAl">
                Abstract <i id="caret-mySiFHCeAl" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mySiFHCeAl">
        <div class="abstract-display">
            <p>Data-driven machine learning models are being increasingly employed in several important inference problems in biology, chemistry, and physics, which require learning over combinatorial spaces. Recent empirical evidence (see, e.g., ~\cite{tseng2020fourier,aghazadeh2021epistatic,ha2021adaptive}) suggests that regularizing the spectral representation of such models improves their generalization power when labeled data is scarce. However, despite these empirical studies, the theoretical underpinning of when and how spectral regularization enables improved generalization is poorly understood. In this paper, we focus on learning pseudo-Boolean functions and demonstrate that regularizing the empirical mean squared error by the $L_1$ norm of the spectral transform of the learned function reshapes the loss landscape and allows for data-frugal learning under a restricted secant condition on the learner's empirical error measured against the ground truth function. Under a weaker quadratic growth condition, we show that stationary points, which also approximately interpolate the training data points achieve statistically optimal generalization performance. Complementing our theory, we empirically demonstrate that running gradient descent on the regularized loss results in a better generalization performance compared to baseline algorithms in several data-scarce real-world problems.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-3gfpBR1ncr">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/3gfpBR1ncr.html">On Characterizing the Trade-off in Invariant Representation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bashir Sadeghi &middot; Sepehr Dehdashtian &middot; Vishnu Boddeti</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-3gfpBR1ncr"></div>

    <a href="paper_pages/3gfpBR1ncr.html">
        <img src="http://img.youtube.com/vi/bjeLIWoiTT8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-3gfpBR1ncr" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-3gfpBR1ncr" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-3gfpBR1ncr">
                Abstract <i id="caret-3gfpBR1ncr" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-3gfpBR1ncr">
        <div class="abstract-display">
            <p>Many applications of representation learning, such as privacy preservation, algorithmic fairness, and domain adaptation, desire explicit control over semantic information being discarded. This goal is formulated as satisfying two objectives: maximizing utility for predicting a target attribute while simultaneously being invariant (independent) to a known semantic attribute. Solutions to invariant representation learning (IRepL) problems lead to a trade-off between utility and invariance when they are competing. While existing works study bounds on this trade-off, two questions remain outstanding: 1) What is the exact trade-off between utility and invariance? and 2) What are the encoders (mapping the data to a representation) that achieve the trade-off, and how can we estimate it from training data? This paper addresses these questions for IRepLs in reproducing kernel Hilbert spaces (RKHS)s. Under the assumption that the distribution of a low-dimensional projection of high-dimensional data is approximately normal, we derive a closed-form solution for the global optima of the underlying optimization problem for encoders in RKHSs. This yields closed formulae for a near-optimal trade-off, corresponding optimal representation dimensionality, and the corresponding encoder(s). We also numerically quantify the trade-off on representative problems and compare them to those achieved by baseline IRepL algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-d3rHk4VAf0">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/d3rHk4VAf0.html">A Ranking Game for Imitation Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Harshit Sikchi &middot; Akanksha Saran &middot; Wonjoon Goo &middot; Scott Niekum</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-d3rHk4VAf0"></div>

    <a href="paper_pages/d3rHk4VAf0.html">
        <img src="http://img.youtube.com/vi/gTf8WoYUOH8/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-d3rHk4VAf0" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-d3rHk4VAf0" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-d3rHk4VAf0">
                Abstract <i id="caret-d3rHk4VAf0" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-d3rHk4VAf0">
        <div class="abstract-display">
            <p>We propose a new framework for imitation learning---treating imitation as a two-player ranking-based game between a policy and a reward. In this game, the reward agent learns to satisfy pairwise performance rankings between behaviors, while the policy agent learns to maximize this reward. In imitation learning, near-optimal expert data can be difficult to obtain, and even in the limit of infinite data cannot imply a total ordering over trajectories as preferences can. On the other hand, learning from preferences alone is challenging as a large number of preferences are required to infer a high-dimensional reward function, though preference data is typically much easier to collect than expert demonstrations. The classical inverse reinforcement learning (IRL) formulation learns from expert demonstrations but provides no mechanism to incorporate learning from offline preferences and vice versa. We instantiate the proposed ranking-game framework with a novel ranking loss giving an algorithm that can simultaneously learn from expert demonstrations and preferences, gaining the advantages of both modalities. Our experiments show that the proposed method achieves state-of-the-art sample efficiency and can solve previously unsolvable tasks in the Learning from Observation (LfO) setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-P9Cj6RJmN2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/P9Cj6RJmN2.html">A Stochastic Optimization Framework for Fair Risk Minimization</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Andrew Lowy &middot; Sina Baharlouei &middot; Rakesh Pavan &middot; Meisam Razaviyayn &middot; Ahmad Beirami</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-P9Cj6RJmN2"></div>

    <a href="paper_pages/P9Cj6RJmN2.html">
        <img src="video_thumbnails/P9Cj6RJmN2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-P9Cj6RJmN2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-P9Cj6RJmN2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-P9Cj6RJmN2">
                Abstract <i id="caret-P9Cj6RJmN2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-P9Cj6RJmN2">
        <div class="abstract-display">
            <p>Despite the success of large-scale empirical risk minimization (ERM) at achieving high accuracy across a variety of machine learning tasks, fair ERM is hindered by the incompatibility of fairness constraints with stochastic optimization. We consider the problem of fair classification with discrete sensitive attributes and potentially large models and data sets, requiring stochastic solvers. Existing in-processing fairness algorithms are either impractical in the large-scale setting because they require large batches of data at each iteration or they are not guaranteed to converge. In this paper, we develop the first stochastic in-processing fairness algorithm with guaranteed convergence. For demographic parity, equalized odds, and equal opportunity notions of fairness, we provide slight variations of our algorithmcalled FERMIand prove that each of these variations converges in stochastic optimization with any batch size. Empirically, we show that FERMI is amenable to stochastic solvers with multiple (non-binary) sensitive attributes and non-binary targets, performing well even with minibatch size as small as one. Extensive experiments show that FERMI achieves the most favorable tradeoffs between fairness violation and test accuracy across all tested setups compared with state-of-the-art baselines for demographic parity, equalized odds, equal opportunity. These benefits are especially significant with small batch sizes and for non-binary classification with large number of sensitive attributes, making FERMI a practical, scalable fairness algorithm. The code for all of the experiments in this paper is available at:
https://github.com/optimization-for-data-driven-science/FERMI</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-VW4IrC0n0M">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/VW4IrC0n0M.html">An approximate sampler for energy-based models with divergence diagnostics</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bryan Eikema &middot; Germn Kruszewski &middot; Christopher R Dance &middot; Hady Elsahar &middot; Marc Dymetman</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-VW4IrC0n0M"></div>

    <a href="paper_pages/VW4IrC0n0M.html">
        <img src="video_thumbnails/VW4IrC0n0M.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-VW4IrC0n0M" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-VW4IrC0n0M" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-VW4IrC0n0M">
                Abstract <i id="caret-VW4IrC0n0M" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-VW4IrC0n0M">
        <div class="abstract-display">
            <p>Energy-based models (EBMs) allow flexible specifications of probability distributions. However, sampling from EBMs is non-trivial, usually requiring approximate techniques such as Markov chain Monte Carlo (MCMC). A major downside of MCMC sampling is that it is often impossible to compute the divergence of the sampling distribution from the target distribution: therefore, the quality of the samples cannot be guaranteed. Here, we introduce quasi-rejection sampling (QRS), a simple extension of rejection sampling that performs approximate sampling, but, crucially, does provide divergence diagnostics (in terms of f-divergences, such as KL divergence and total variation distance). We apply QRS to sampling from discrete EBMs over text for controlled generation. We show that we can sample from such EBMs with arbitrary precision in exchange for sampling efficiency and quantify the trade-off between the two by means of the aforementioned diagnostics. 
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-LHAbHkt6Aq">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/LHAbHkt6Aq.html">A Crisis In Simulation-Based Inference? Beware, Your Posterior Approximations Can Be Unfaithful</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Joeri Hermans &middot; Arnaud Delaunoy &middot; Franois Rozet &middot; Antoine Wehenkel &middot; Volodimir Begy &middot; Gilles Louppe</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-LHAbHkt6Aq"></div>

    <a href="paper_pages/LHAbHkt6Aq.html">
        <img src="http://img.youtube.com/vi/sLM0JBbSjLw/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-LHAbHkt6Aq" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-LHAbHkt6Aq" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-LHAbHkt6Aq">
                Abstract <i id="caret-LHAbHkt6Aq" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-LHAbHkt6Aq">
        <div class="abstract-display">
            <p>We present extensive empirical evidence showing that current Bayesian simulation-based inference algorithms can produce computationally unfaithful posterior approximations. Our results show that all benchmarked algorithms -- (S)NPE, (S)NRE, SNL and variants of ABC -- can yield overconfident posterior approximations, which makes them unreliable for scientific use cases and falsificationist inquiry. Failing to address this issue may reduce the range of applicability of simulation-based inference. For this reason, we argue that research efforts should be made towards theoretical and methodological developments of conservative approximate inference algorithms and present research directions towards this objective. In this regard, we show empirical evidence that ensembling posterior surrogates provides more reliable approximations and mitigates the issue.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-myjAVQrRxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/myjAVQrRxS.html">Dropped Scheduled Task: Mitigating Negative Transfer in Multi-task Learning using Dynamic Task Dropping</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Aakarsh Malhotra &middot; Mayank Vatsa &middot; Richa Singh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-myjAVQrRxS"></div>

    <a href="paper_pages/myjAVQrRxS.html">
        <img src="http://img.youtube.com/vi/NZrnPHDFNTM/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-myjAVQrRxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-myjAVQrRxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-myjAVQrRxS">
                Abstract <i id="caret-myjAVQrRxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-myjAVQrRxS">
        <div class="abstract-display">
            <p>In Multi-Task Learning (MTL), K distinct tasks are jointly optimized. With the varying nature and complexities of tasks, few tasks might dominate learning. For other tasks, their respective performances may get compromised due to a negative transfer from dominant tasks. We propose a Dropped-Scheduled Task (DST) algorithm, which probabilistically drops specific tasks during joint optimization while scheduling others to reduce negative transfer. For each task, a scheduling probability is decided based on four different metrics: (i) task depth, (ii) number of ground-truth samples per task, (iii) amount of training completed, and (iv) task stagnancy. Based on the scheduling probability, specific tasks get joint computation cycles while others are dropped. To demonstrate the effectiveness of the proposed DST algorithm, we perform multi-task learning on three applications and two architectures. Across unilateral (single input) and bilateral (multiple input) multi-task net- works, the chosen applications are (a) face (AFLW), (b) fingerprint (IIITD MOLF, MUST, and NIST SD27), and (c) character recognition (Omniglot) applications. Experimental results show that the proposed DST algorithm has the minimum negative transfer and overall least errors across different state-of-the-art algorithms and tasks.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-K6g4MbAC1r">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/K6g4MbAC1r.html">Investigating Action Encodings in Recurrent Neural Networks in Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Matthew Kyle Schlegel &middot; Volodymyr Tkachuk &middot; Adam M White &middot; Martha White</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-K6g4MbAC1r"></div>

    <a href="paper_pages/K6g4MbAC1r.html">
        <img src="http://img.youtube.com/vi/83vBK8DIdEY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-K6g4MbAC1r" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-K6g4MbAC1r" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-K6g4MbAC1r">
                Abstract <i id="caret-K6g4MbAC1r" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-K6g4MbAC1r">
        <div class="abstract-display">
            <p>Building and maintaining state to learn policies and value functions is critical for deploying reinforcement learning (RL) agents in the real world. Recurrent neural networks (RNNs) have become a key point of interest for the state-building problem, and several large-scale reinforcement learning agents incorporate recurrent networks. While RNNs have become a mainstay in many RL applications, many key design choices and implementation details responsible for performance improvements are often not reported. In this work, we discuss one axis on which RNN architectures can be (and have been) modified for use in RL. Specifically, we look at how action information can be incorporated into the state update function of a recurrent cell. We discuss several choices in using action information and empirically evaluate the resulting architectures on a set of illustrative domains. Finally, we discuss future work in developing recurrent cells and discuss challenges specific to the RL setting.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-QaDevCcmcg">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/QaDevCcmcg.html">Uncertainty-Based Active Learning for Reading Comprehension</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jing Wang &middot; Jie Shen &middot; Xiaofei Ma &middot; Andrew Arnold</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-QaDevCcmcg"></div>

    <a href="paper_pages/QaDevCcmcg.html">
        <img src="http://img.youtube.com/vi/oRrMip1MWbY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-QaDevCcmcg" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-QaDevCcmcg" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-QaDevCcmcg">
                Abstract <i id="caret-QaDevCcmcg" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-QaDevCcmcg">
        <div class="abstract-display">
            <p>Recent years have witnessed a surge of successful applications of machine reading comprehension. Of central importance to these tasks is the availability of massive amount of labeled data, which facilitates training of large-scale neural networks. However, in many real-world problems, annotated data are expensive to gather not only because of time cost and budget, but also  of certain domain-specific restrictions such as privacy for healthcare data. In this regard, we propose an uncertainty-based active learning algorithm for reading comprehension, which interleaves data annotation and model updating to mitigate the demand of labeling. Our key techniques are two-fold: 1) an unsupervised uncertainty-based sampling scheme that queries the labels of the most informative instances with respect to the currently learned model; and 2) an adaptive loss minimization paradigm that simultaneously fits the data and controls the degree of model updating. We demonstrate on  benchmark datasets that 25% less labeled samples suffice to guarantee similar, or even improved performance. Our results show strong evidence that for label-demanding scenarios, the proposed approach offers a practical guide on data collection and model training. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-EYrRzKPinA">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/EYrRzKPinA.html">On a continuous time model of gradient descent dynamics and instability in deep learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mihaela Rosca &middot; Yan Wu &middot; Chongli Qin &middot; Benoit Dherin</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-EYrRzKPinA"></div>

    <a href="paper_pages/EYrRzKPinA.html">
        <img src="http://img.youtube.com/vi/UKHCH8ZdH1Y/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-EYrRzKPinA" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-EYrRzKPinA" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-EYrRzKPinA">
                Abstract <i id="caret-EYrRzKPinA" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-EYrRzKPinA">
        <div class="abstract-display">
            <p>The recipe behind the success of deep learning has been the combination of neural networks and gradient-based optimization. Understanding the behavior of gradient descent however, and particularly its instability, has lagged behind its empirical success. To add to the theoretical tools available to study gradient descent we propose the principal flow (PF), a continuous time flow that approximates gradient descent dynamics. To our knowledge, the PF is the only continuous flow that captures the divergent and oscillatory behaviors of gradient descent, including escaping local minima and saddle points. Through its dependence on the eigendecomposition of the Hessian the PF sheds light on the recently observed edge of stability phenomena in deep learning. Using our new understanding of instability we propose a learning rate adaptation method which enables us to control the trade-off between training stability and test set evaluation performance.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oq3tx5kinu">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oq3tx5kinu.html">Active Learning of Ordinal Embeddings: A User Study on Football Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Christoffer Lffler &middot; Kion Fallah &middot; Stefano Fenu &middot; Dario Zanca &middot; Bjoern Eskofier &middot; Christopher John Rozell &middot; Christopher Mutschler</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oq3tx5kinu"></div>

    <a href="paper_pages/oq3tx5kinu.html">
        <img src="http://img.youtube.com/vi/xqOJAtjxjKE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oq3tx5kinu" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oq3tx5kinu" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oq3tx5kinu">
                Abstract <i id="caret-oq3tx5kinu" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oq3tx5kinu">
        <div class="abstract-display">
            <p>Humans innately measure distance between instances in an unlabeled dataset using an unknown similarity function. Distance metrics can only serve as proxy for similarity in information retrieval of similar instances. Learning a good similarity function from human annotations improves the quality of retrievals. This work uses deep metric learning to learn these user-defined similarity functions from few annotations for a large football trajectory dataset.
We adapt an entropy-based active learning method with recent work from triplet mining to collect easy-to-answer but still informative annotations from human participants and use them to train a deep convolutional network that generalizes to unseen samples. 
Our user study shows that our approach improves the quality of the information retrieval compared to a previous deep metric learning approach that relies on a Siamese network. Specifically, we shed light on the strengths and weaknesses of passive sampling heuristics and active learners alike by analyzing the participants' response efficacy. To this end, we collect accuracy, algorithmic time complexity, the participants' fatigue and time-to-response, qualitative self-assessment and statements, as well as the effects of mixed-expertise annotators and their consistency on model performance and transfer-learning.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Lgs5pQ1v30">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Lgs5pQ1v30.html">FedShuffle:  Recipes for Better Use of Local Work in Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Samuel Horvth &middot; Maziar Sanjabi &middot; Lin Xiao &middot; Peter Richtrik &middot; Michael Rabbat</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Lgs5pQ1v30"></div>

    <a href="paper_pages/Lgs5pQ1v30.html">
        <img src="http://img.youtube.com/vi/jGVbs3Jl1K0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Lgs5pQ1v30" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Lgs5pQ1v30" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Lgs5pQ1v30">
                Abstract <i id="caret-Lgs5pQ1v30" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Lgs5pQ1v30">
        <div class="abstract-display">
            <p>The practice of applying several local updates before aggregation across clients has been empirically shown to be a successful approach to overcoming the communication bottleneck in Federated Learning (FL). Such methods are usually implemented by having clients perform one or more epochs of local training per round while randomly reshuffling their finite dataset in each epoch. Data imbalance, where clients have different numbers of local training samples, is ubiquitous in FL applications, resulting in different clients performing different numbers of local updates in each round. In this work, we propose a general recipe, FedShuffle, that better utilizes the local updates in FL, especially in this regime encompassing random reshuffling and heterogeneity. FedShuffle is the first local update method with theoretical convergence guarantees that incorporates random reshuffling, data imbalance, and client sampling  features that are essential in large-scale cross-device FL. We present a comprehensive theoretical analysis of FedShuffle and show, both theoretically and empirically, that it does not suffer from the objective function mismatch that is present in FL methods that assume homogeneous updates in heterogeneous FL setups, such as FedAvg (McMahan et al., 2017). In addition, by combining the ingredients above, FedShuffle improves upon FedNova (Wang et al., 2020), which was previously proposed to solve this mismatch. Similar to Mime (Karimireddy et al., 2020), we show that FedShuffle with momentum variance reduction (Cutkosky & Orabona, 2019) improves upon non-local methods under a Hessian similarity assumption.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-MHOAEiTlen">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/MHOAEiTlen.html">DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">kaichen zhou &middot; Lanqing HONG &middot; Shoukang Hu &middot; Fengwei Zhou &middot; Binxin Ru &middot; Jiashi Feng &middot; Zhenguo Li</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-MHOAEiTlen"></div>

    <a href="paper_pages/MHOAEiTlen.html">
        <img src="https://drive.google.com/thumbnail?id=1LYpQU2zJkzK6BBQPV1JZXNUU4mkcMtMr" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-MHOAEiTlen" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-MHOAEiTlen" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-MHOAEiTlen">
                Abstract <i id="caret-MHOAEiTlen" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-MHOAEiTlen">
        <div class="abstract-display">
            <p>Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). Although many strategies have been developed for automating these components in separation, joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often suffers from the low-performance correlation between the searching and retraining stages. An end-to-end solution that integrates the AutoML components and returns a ready-to-use model at the end of the search is desirable. In view of these, we propose DHA, which achieves joint optimization of Data augmentation policy, Hyper-parameter, and Architecture. Specifically, end-to-end NAS is achieved in a differentiable manner by optimizing a compressed lower-dimensional feature space, while DA policy and HPO are regarded as dynamic schedulers, which adapt themselves to the update of network parameters and network architecture at the same time. Experiments show that DHA achieves state-of-the-art (SOTA) results on various datasets and search spaces. To the best of our knowledge, we are the first to efficiently and jointly optimize DA policy, NAS, and HPO in an end-to-end manner without retraining.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-vUuHPRrWs2">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/vUuHPRrWs2.html">Practicality of generalization guarantees for unsupervised domain adaptation with neural networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Adam Breitholtz &middot; Fredrik Daniel Johansson</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-vUuHPRrWs2"></div>

    <a href="paper_pages/vUuHPRrWs2.html">
        <img src="video_thumbnails/vUuHPRrWs2.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-vUuHPRrWs2" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-vUuHPRrWs2" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-vUuHPRrWs2">
                Abstract <i id="caret-vUuHPRrWs2" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-vUuHPRrWs2">
        <div class="abstract-display">
            <p>Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. 
For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment.
However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions.
In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain shift. To overcome this and arrive at the tightest possible results, we combine each bound with recent data-dependent PAC-Bayes analysis, greatly improving the guarantees. We find that, when domain overlap can be assumed, a simple importance weighting extension of previous work provides the tightest estimable bound. Finally, we study which terms dominate the bounds and identify possible directions for further improvement. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-Sh3RF9JowK">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/Sh3RF9JowK.html">Learning Algorithms for Markovian Bandits:\\Is Posterior Sampling more Scalable than Optimism?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nicolas Gast &middot; Bruno Gaujal &middot; Kimang Khun</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-Sh3RF9JowK"></div>

    <a href="paper_pages/Sh3RF9JowK.html">
        <img src="http://img.youtube.com/vi/Ii2773_g3po/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-Sh3RF9JowK" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-Sh3RF9JowK" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-Sh3RF9JowK">
                Abstract <i id="caret-Sh3RF9JowK" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-Sh3RF9JowK">
        <div class="abstract-display">
            <p>In this paper, we study the scalability of model-based algorithms learning the optimal policy of a discounted \blue{rested} Markovian bandit  problem with $n$ arms. There are two categories of model-based reinforcement learning algorithms: Bayesian algorithms (like PSRL), and optimistic algorithms (like UCRL2 or UCBVI).  A naive application of these  algorithms is not scalable because  the state-space is exponential in $n$. In this paper, we construct variants of these algorithms specially tailored to Markovian bandits (MB) that we call MB-PSRL, MB-UCRL2, and MB-UCBVI. \blue{We consider an episodic setting with geometrically distributed episode length, and measure the performance of the algorithm in terms of regret (Bayesian regret for MB-PSRL and expected regret for MB-UCRL2 and MB-UCBVI)}. We prove that, for this setting, all algorithms have a low regret in $\tilde{O}(S\sqrt{nK})$ -- where $K$ is the number of episodes, $n$ is the number of arms and $S$ is the number of states of each arm. Up to a factor $\sqrt{S}$, these regrets match the \blue{Bayesian minimax regret} lower bound of $\Omega(\sqrt{SnK})$ that we also derive.

Even if their theoretical regrets are comparable, the {\it time complexities} of these  algorithms vary greatly: We show that MB-UCRL2, as well as all  algorithms that use bonuses on transition matrices have a { time} complexity  that grows  exponentially in $n$.  In contrast, MB-UCBVI does not use bonuses on transition matrices and we show that  it can be implemented efficiently, with a time complexity linear in $n$. Our numerical experiments show, however, that its empirical regret is large. Our Bayesian algorithm, MB-PSRL, enjoys the best of both worlds: its running time is linear in the number of arms and its empirical regret is the smallest of all algorithms.
This is a new addition in the understanding of the power of Bayesian algorithms, that can often be  tailored to the structure of the problems to learn.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-mbwm7NdkpO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/mbwm7NdkpO.html">Deep Policies for Online Bipartite Matching: A Reinforcement Learning Approach</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Mohammad Ali Alomrani &middot; Reza Moravej &middot; Elias Boutros Khalil</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-mbwm7NdkpO"></div>

    <a href="paper_pages/mbwm7NdkpO.html">
        <img src="http://img.youtube.com/vi/PoMrl5rjQ3U/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-mbwm7NdkpO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-mbwm7NdkpO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-mbwm7NdkpO">
                Abstract <i id="caret-mbwm7NdkpO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-mbwm7NdkpO">
        <div class="abstract-display">
            <p>The challenge in the widely applicable online matching problem lies in making irrevocable assignments while there is uncertainty about future inputs. Most theoretically-grounded policies are myopic or greedy in nature. In real-world applications where the matching process is repeated on a regular basis, the underlying data distribution can be leveraged for better decision-making. We present an end-to-end Reinforcement Learning framework for deriving better matching policies based on trial-and-error on historical data. We devise a set of neural network architectures, design feature representations, and empirically evaluate them across two online matching problems: Edge-Weighted Online Bipartite Matching and Online Submodular Bipartite Matching. We show that most of the learning approaches perform consistently better than classical baseline algorithms on four synthetic and real-world datasets. On average, our proposed models improve the matching quality by 3-10% on a variety of synthetic and real-world datasets.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aIoEkwc2oB">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aIoEkwc2oB.html">INR-V: A Continuous Representation Space for Video-based Generative Tasks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Bipasha Sen &middot; Aditya Agarwal &middot; Vinay P Namboodiri &middot; C.V. Jawahar</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aIoEkwc2oB"></div>

    <a href="paper_pages/aIoEkwc2oB.html">
        <img src="http://img.youtube.com/vi/ViIwnu5vcck/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aIoEkwc2oB" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aIoEkwc2oB" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aIoEkwc2oB">
                Abstract <i id="caret-aIoEkwc2oB" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aIoEkwc2oB">
        <div class="abstract-display">
            <p>Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the baselines on several of these demonstrated tasks, clearly showing the potential of the proposed representation space.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lCPOHiztuw">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lCPOHiztuw.html">Direct Molecular Conformation Generation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Jinhua Zhu &middot; Yingce Xia &middot; Chang Liu &middot; Lijun Wu &middot; Shufang Xie &middot; Yusong Wang &middot; Tong Wang &middot; Tao Qin &middot; Wengang Zhou &middot; Houqiang Li &middot; Haiguang Liu &middot; Tie-Yan Liu</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lCPOHiztuw"></div>

    <a href="paper_pages/lCPOHiztuw.html">
        <img src="https://drive.google.com/thumbnail?id=1p_-NHOWBH3oiPFuaJiskXYWGdmRmwtLK" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lCPOHiztuw" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lCPOHiztuw" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lCPOHiztuw">
                Abstract <i id="caret-lCPOHiztuw" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lCPOHiztuw">
        <div class="abstract-display">
            <p>Molecular conformation generation aims to generate three-dimensional coordinates of all the atoms in a molecule and is an important task in bioinformatics and pharmacology. Previous methods usually first predict the interatomic distances, the gradients of interatomic distances or the local structures (e.g., torsion angles) of a molecule, and then reconstruct its 3D conformation. How to directly generate the conformation without the above intermediate values is not fully explored. In this work, we propose a method that directly predicts the coordinates of atoms: (1) the loss function is invariant to roto-translation of coordinates and permutation of symmetric atoms; (2) the newly proposed model adaptively aggregates the bond and atom information and iteratively refines the coordinates of the generated conformation. Our method achieves the best results on GEOM-QM9 and GEOM-Drugs datasets. Further analysis shows that our generated conformations have closer properties (e.g., HOMO-LUMO gap) with the groundtruth conformations. In addition, our method improves molecular docking by providing better initial conformations. All the results demonstrate the effectiveness of our method and the great potential of the direct approach. The code is released at  \url{https://github.com/DirectMolecularConfGen/DMCG}.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-oRjk5V9eDp">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/oRjk5V9eDp.html">Bayesian Methods for Constraint Inference in Reinforcement Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dimitris Papadimitriou &middot; Usman Anwar &middot; Daniel S. Brown</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-oRjk5V9eDp"></div>

    <a href="paper_pages/oRjk5V9eDp.html">
        <img src="https://drive.google.com/thumbnail?id=1_DMCjrmn5FygavUND1e71qJeNEK_Utch" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-oRjk5V9eDp" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-oRjk5V9eDp" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-oRjk5V9eDp">
                Abstract <i id="caret-oRjk5V9eDp" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-oRjk5V9eDp">
        <div class="abstract-display">
            <p>Learning constraints from demonstrations provides a natural and efficient way to improve the safety of AI systems; however, prior work only considers learning a single, point-estimate of the constraints. By contrast, we consider the problem of inferring constraints from demonstrations using a Bayesian perspective. We propose Bayesian Inverse Constraint Reinforcement Learning (BICRL), a novel approach that infers a posterior probability distribution over constraints from demonstrated trajectories. The main advantages of BICRL, compared to prior constraint inference algorithms, are (1) the freedom to infer constraints from partial trajectories and even from disjoint state-action pairs,  (2) the ability to infer constraints from suboptimal demonstrations and in stochastic environments, and (3) the opportunity to use the posterior distribution over constraints in order to implement active learning and robust policy optimization techniques. We show that BICRL outperforms pre-existing constraint learning approaches, leading to more accurate constraint inference and consequently safer policies. We further propose Hierarchical BICRL that infers constraints locally in sub-spaces of the entire domain and then composes global constraint estimates leading to accurate and computationally efficient constraint estimation.  </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-6qMKztPn0n">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/6qMKztPn0n.html">Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fan Wang &middot; Hao Tian &middot; Haoyi Xiong &middot; Hua Wu &middot; Jie Fu &middot; Yang Cao &middot; Yu Kang &middot; Haifeng Wang</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-6qMKztPn0n"></div>

    <a href="paper_pages/6qMKztPn0n.html">
        <img src="http://img.youtube.com/vi/8EA8KqlCRzY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-6qMKztPn0n" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-6qMKztPn0n" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-6qMKztPn0n">
                Abstract <i id="caret-6qMKztPn0n" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-6qMKztPn0n">
        <div class="abstract-display">
            <p>Artificial neural networks (ANNs) are typically confined to accomplishing pre-defined tasks by learning a set of static parameters. In contrast, biological neural networks (BNNs) can adapt to various new tasks by continually updating the neural connections based on the inputs, which is aligned with the paradigm of learning effective learning rules in addition to static parameters, \textit{e.g.}, meta-learning. Among various biologically inspired learning rules, Hebbian plasticity updates the neural network weights using local signals without the guide of an explicit target function, thus enabling an agent to learn automatically without human efforts. However, typical plastic ANNs using a large amount of meta-parameters violate the nature of the genomics bottleneck and potentially deteriorate the generalization capacity. This work proposes a new learning paradigm decomposing those connection-dependent plasticity rules into neuron-dependent rules thus accommodating $\Theta(n^2)$ learnable parameters with only $\Theta(n)$ meta-parameters. We also thoroughly study the effect of different neural modulation on plasticity. Our algorithms are tested in challenging random 2D maze environments, where the agents have to use their past experiences to shape the neural connections and improve their performances for the future. The results of our experiment validate the following: 1. Plasticity can be adopted to continually update a randomly initialized RNN to surpass pre-trained, more sophisticated recurrent models, especially when coming to long-term memorization. 2. Following the genomics bottleneck, the proposed decomposed plasticity can be comparable to or even more effective than canonical plasticity rules in some instances.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-M8D5iZsnrO">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/M8D5iZsnrO.html">TITRATED: Learned Human Driving Behavior without Infractions via Amortized Inference</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Vasileios Lioutas &middot; Adam Scibior &middot; Frank Wood</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-M8D5iZsnrO"></div>

    <a href="paper_pages/M8D5iZsnrO.html">
        <img src="http://img.youtube.com/vi/AMeZtzQxhX4/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-M8D5iZsnrO" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-M8D5iZsnrO" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-M8D5iZsnrO">
                Abstract <i id="caret-M8D5iZsnrO" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-M8D5iZsnrO">
        <div class="abstract-display">
            <p>Models of human driving behavior have long been used for prediction in autonomous vehicles, but recently have also started being used to create non-playable characters for driving simulations. While such models are in many respects realistic, they tend to suffer from unacceptably high rates of driving infractions, such as collisions or off-road driving, particularly when deployed in map locations with road geometries dissimilar to the training dataset. In this paper we present a novel method for fine-tuning a foundation model of human driving behavior to novel locations where human demonstrations are not available which reduces the incidence of such infractions. The method relies on inference in the foundation model to generate infraction-free trajectories as well as additional penalties applied when fine-tuning the amortized inference behavioral model. We demonstrate this "titration" technique using the ITRA foundation behavior model trained on the INTERACTION dataset when transferring to CARLA map locations. We demonstrate a 76-86% reduction in infraction rate and provide evidence that further gains are possible with more computation or better inference algorithms.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-lE7K4n1Esk">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/lE7K4n1Esk.html">On the Adversarial Robustness of Vision Transformers</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Rulin Shao &middot; Zhouxing Shi &middot; Jinfeng Yi &middot; Pin-Yu Chen &middot; Cho-Jui Hsieh</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-lE7K4n1Esk"></div>

    <a href="paper_pages/lE7K4n1Esk.html">
        <img src="http://img.youtube.com/vi/paMjHR5ufRs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-lE7K4n1Esk" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-lE7K4n1Esk" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-lE7K4n1Esk">
                Abstract <i id="caret-lE7K4n1Esk" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-lE7K4n1Esk">
        <div class="abstract-display">
            <p>Following the success in advancing natural language processing and understanding, transformers are expected to bring revolutionary changes to computer vision. This work provides a comprehensive study on the robustness of vision transformers (ViTs) against adversarial perturbations. Tested on various white-box and transfer attack settings, we find that ViTs possess better adversarial robustness when compared with MLP-Mixer and convolutional neural networks (CNNs) including ConvNeXt, and this observation also holds for certified robustness. Through frequency analysis and feature visualization, we summarize the following main observations contributing to the improved robustness of ViTs: 1) Features learned by ViTs contain less high-frequency patterns that have spurious correlation,  which helps explain why ViTs are less sensitive to high-frequency perturbations than CNNs and MLP-Mixer, and there is a high correlation between how much the model learns high-frequency features and its robustness against different frequency-based perturbations. 2) Introducing convolutional or tokens-to-token blocks for learning high-frequency features in ViTs can improve classification accuracy but at the cost of adversarial robustness. 3) Modern CNN designs that borrow techniques from ViTs including activation function, layer norm, larger kernel size to imitate the global attention, and patchify the images as inputs, etc., could help bridge the performance gap between ViTs and CNNs not only in terms of performance, but also certified and empirical adversarial robustness. Moreover, we show adversarial training is also applicable to ViT for training robust models, and sharpness-aware minimization can also help improve robustness, while pre-training with clean images on larger datasets does not significantly improve adversarial robustness. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-XsPopigZXV">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/XsPopigZXV.html">FLEA: Provably Robust Fair Multisource Learning from Unreliable Training Data</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Eugenia Iofinova &middot; Nikola Konstantinov &middot; Christoph H Lampert</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-XsPopigZXV"></div>

    <a href="paper_pages/XsPopigZXV.html">
        <img src="video_thumbnails/XsPopigZXV.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-XsPopigZXV" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-XsPopigZXV" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-XsPopigZXV">
                Abstract <i id="caret-XsPopigZXV" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-XsPopigZXV">
        <div class="abstract-display">
            <p>Fairness-aware learning aims at constructing classifiers that not only make accurate predictions, but also do not discriminate against specific groups. It is a fast-growing area of machine learning with far-reaching societal impact. However, existing fair learning methods are vulnerable to accidental or malicious artifacts in the training data, which can cause them to unknowingly produce unfair classifiers. In this work we address the problem of fair learning from unreliable training data in the robust multisource setting, where the available training data comes from multiple sources, a fraction of which might not be representative of the true data distribution. We introduce FLEA, a filtering-based algorithm that identifies and suppresses those data sources that would have a negative impact on fairness or accuracy if they were used for training. As such, FLEA is not a replacement of prior fairness-aware learning methods but rather an augmentation that makes any of them robust against unreliable training data. We show the effectiveness of our approach by a diverse range of experiments on multiple datasets. Additionally, we prove formally that given enough data FLEA protects the learner against corruptions as long as the fraction of affected data sources is less than half. Our source code and documentation are available at https://github.com/ISTAustria-CVML/FLEA.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-gCmQK6McbR">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/gCmQK6McbR.html">HEAT: Hyperedge Attention Networks</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Dobrik Georgiev Georgiev &middot; Marc Brockschmidt &middot; Miltiadis Allamanis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-gCmQK6McbR"></div>

    <a href="paper_pages/gCmQK6McbR.html">
        <img src="http://img.youtube.com/vi/q0oFjmxz_60/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-gCmQK6McbR" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-gCmQK6McbR" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-gCmQK6McbR">
                Abstract <i id="caret-gCmQK6McbR" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-gCmQK6McbR">
        <div class="abstract-display">
            <p>Learning from structured data is a core machine learning task. Commonly, such data is represented as graphs, which normally only consider (typed) binary relationships between pairs of nodes. This is a substantial limitation for many domains with highly-structured data. One important such domain is source code, where hypergraph-based representations can better capture the semantically rich and structured nature of code.
In this work, we present HEAT, a neural model capable of representing typed and qualified hypergraphs, where each hyperedge explicitly qualifies how participating nodes contribute. It can be viewed as a generalization of both message passing neural networks and Transformers. We evaluate HEAT on knowledge base completion and on bug detection and repair using a novel hypergraph representation of programs. In both settings, it outperforms strong baselines, indicating its power and generality.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-e7mYYMSyZH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/e7mYYMSyZH.html">On the Convergence of Shallow Neural Network Training with Randomly Masked Neurons</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Fangshuo Liao &middot; Anastasios Kyrillidis</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-e7mYYMSyZH"></div>

    <a href="paper_pages/e7mYYMSyZH.html">
        <img src="http://img.youtube.com/vi/8dR4tcfOTkE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-e7mYYMSyZH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-e7mYYMSyZH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-e7mYYMSyZH">
                Abstract <i id="caret-e7mYYMSyZH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-e7mYYMSyZH">
        <div class="abstract-display">
            <p>With the motive of training all the parameters of a neural network, we study why and when one can achieve this by iteratively creating, training, and combining randomly selected subnetworks. Such scenarios have either implicitly or explicitly emerged in the recent literature: see e.g., the Dropout family of regularization techniques, or some distributed ML training protocols that reduce communication/computation complexities, such as the Independent Subnet Training protocol. While these methods are studied empirically and utilized in practice, they often enjoy partial or no theoretical support, especially when applied on neural network-based objectives.

In this manuscript, our focus is on overparameterized single hidden layer neural networks with ReLU activations in the lazy training regime. By carefully analyzing $i)$ the subnetworks' neural tangent kernel, $ii)$ the surrogate functions' gradient, and $iii)$ how we sample and combine the surrogate functions, we prove linear convergence rate of the training error --up to a neighborhood around the optimal point-- for an overparameterized single-hidden layer perceptron with a regression loss. Our analysis reveals a dependency of the size of the neighborhood around the optimal point on the number of surrogate models and the number of local training steps for each selected subnetwork. Moreover, the considered framework generalizes and provides new insights on dropout training, multi-sample dropout training, as well as Independent Subnet Training; for each case, we provide convergence results as corollaries of our main theorem.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-qzM1Tw5i7N">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/qzM1Tw5i7N.html">SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">ZHUOWEI WANG &middot; Jing Jiang &middot; Bo Han &middot; Lei Feng &middot; Bo An &middot; Gang Niu &middot; Guodong Long</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-qzM1Tw5i7N"></div>

    <a href="paper_pages/qzM1Tw5i7N.html">
        <img src="http://img.youtube.com/vi/sKDRt9GNLTs/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-qzM1Tw5i7N" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-qzM1Tw5i7N" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-qzM1Tw5i7N">
                Abstract <i id="caret-qzM1Tw5i7N" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-qzM1Tw5i7N">
        <div class="abstract-display">
            <p>Deep learning with noisy labels is a challenging task, which has received much attention from the machine learning and computer vision communities. Recent prominent methods that build on a specific sample selection (SS) strategy and a specific semi-supervised learning (SSL) model achieved state-of-the-art performance. Intuitively, better performance could be achieved if stronger SS strategies and SSL models are employed. Following this intuition, one might easily derive various effective noisy-label learning methods using different combinations of SS strategies and SSL models, which is, however, simply reinventing the wheel in essence. To prevent this problem, we propose SemiNLL, a versatile framework that investigates how to naturally combine different SS and SSL components based on their effects and efficiencies. We conduct a systematic and detailed analysis of the combinations of possible components based on our framework. Our framework can absorb various SS strategies and SSL backbones, utilizing their power to achieve promising performance. The instantiations of our framework demonstrate substantial improvements over state-of-the-art methods on benchmark-simulated and real-world datasets with noisy labels.
</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ywr5sWqQt4">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ywr5sWqQt4.html">A Comprehensive Study of Real-Time Object Detection Networks Across Multiple Domains: A Survey</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Elahe Arani &middot; Shruthi Gowda &middot; Ratnajit Mukherjee &middot; Omar Magdy &middot; Senthilkumar Sockalingam Kathiresan &middot; Bahram Zonooz</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ywr5sWqQt4"></div>

    <a href="paper_pages/ywr5sWqQt4.html">
        <img src="http://img.youtube.com/vi/-Z_DEE96VM0/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ywr5sWqQt4" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ywr5sWqQt4" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ywr5sWqQt4">
                Abstract <i id="caret-ywr5sWqQt4" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ywr5sWqQt4">
        <div class="abstract-display">
            <p>Deep neural network based object detectors are continuously evolving and are used in a multitude of applications, each having its own set of requirements. While safety-critical applications need high accuracy and reliability, low-latency tasks need resource and energy-efficient networks. Real-time detection networks, which are a necessity in high-impact real-world applications, are continuously proposed but they overemphasize the improvements in accuracy and speed while other capabilities such as versatility, robustness, resource, and energy efficiency are omitted. A reference benchmark for existing networks does not exist nor does a standard evaluation guideline for designing new networks, which results in ambiguous and inconsistent comparisons. We, therefore, conduct a comprehensive study on multiple real-time detection networks (anchor-based, keypoint-based, and transformer-based) on a wide range of datasets and report results on an extensive set of metrics. We also study the impact of variables such as image size, anchor dimensions, confidence thresholds, and architecture layers on the overall performance. We analyze the robustness of detection networks against distribution shift, natural corruptions, and adversarial attacks. Also, we provide the calibration analysis to gauge the reliability of the predictions. Finally, to highlight the real-world impact, we conduct two unique case studies, on autonomous driving and healthcare application. To further gauge the capability of networks in critical real-time applications, we report the performance after deploying the detection networks on edge devices. Our extensive empirical study can act as a guideline for the industrial community to make an informed choice on the existing networks. We also hope to inspire the research community towards a new direction of design and evaluation of networks that focuses on the bigger and holistic overview for a far-reaching impact.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-0nEZCVshxS">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/0nEZCVshxS.html">Diagnosing and Fixing Manifold Overfitting in Deep Generative Models</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Gabriel Loaiza-Ganem &middot; Brendan Leigh Ross &middot; Jesse C Cresswell &middot; Anthony L. Caterini</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-0nEZCVshxS"></div>

    <a href="paper_pages/0nEZCVshxS.html">
        <img src="http://img.youtube.com/vi/-2YaUfMlwrU/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-0nEZCVshxS" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-0nEZCVshxS" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-0nEZCVshxS">
                Abstract <i id="caret-0nEZCVshxS" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-0nEZCVshxS">
        <div class="abstract-display">
            <p>Likelihood-based, or explicit, deep generative models use neural networks to construct flexible high-dimensional densities. This formulation directly contradicts the manifold hypothesis, which states that observed data lies on a low-dimensional manifold embedded in high-dimensional ambient space. In this paper we investigate the pathologies of maximum-likelihood training in the presence of this dimensionality mismatch. We formally prove that degenerate optima are achieved wherein the manifold itself is learned but not the distribution on it, a phenomenon we call manifold overfitting. We propose a class of two-step procedures consisting of a dimensionality reduction step followed by maximum-likelihood density estimation, and prove that they recover the data-generating distribution in the nonparametric regime, thus avoiding manifold overfitting. We also show that these procedures enable density estimation on the manifolds learned by implicit models, such as generative adversarial networks, hence addressing a major shortcoming of these models. Several recently proposed methods are instances of our two-step procedures; we thus unify, extend, and theoretically justify a large class of models.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-8GvRCWKHIL">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/8GvRCWKHIL.html">Optimal Client Sampling for Federated Learning</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Wenlin Chen &middot; Samuel Horvth &middot; Peter Richtrik</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-8GvRCWKHIL"></div>

    <a href="paper_pages/8GvRCWKHIL.html">
        <img src="http://img.youtube.com/vi/lhLJL1FJ_OE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-8GvRCWKHIL" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-8GvRCWKHIL" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-8GvRCWKHIL">
                Abstract <i id="caret-8GvRCWKHIL" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-8GvRCWKHIL">
        <div class="abstract-display">
            <p>It is well understood that client-master communication can be a primary bottleneck in federated learning (FL). In this work, we address this issue with a novel client subsampling scheme, where we restrict the number of clients allowed to communicate their updates back to the master node. In each communication round, all participating clients compute their updates, but only the ones with "important" updates communicate back to the master. We show that importance can be measured using only the norm of the update and give a formula for optimal client participation. This formula minimizes the distance between the full update, where all clients participate, and our limited update, where the number of participating clients is restricted. In addition, we provide a simple algorithm that approximates the optimal formula for client participation, which allows for secure aggregation and stateless clients, and thus does not compromise client privacy. We show both theoretically and empirically that for Distributed SGD (DSGD) and Federated Averaging (FedAvg), the performance of our approach can be close to full participation and superior to the baseline where participating clients are sampled uniformly. Moreover, our approach is orthogonal to and compatible with existing methods for reducing communication overhead, such as local methods and communication compression methods. </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-2EOVIvRXlv">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/2EOVIvRXlv.html">Ranking Recovery under Privacy Considerations</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Minoh Jeong &middot; Alex Dytso &middot; Martina Cardone</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-2EOVIvRXlv"></div>

    <a href="paper_pages/2EOVIvRXlv.html">
        <img src="video_thumbnails/2EOVIvRXlv.png" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-2EOVIvRXlv" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-2EOVIvRXlv" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-2EOVIvRXlv">
                Abstract <i id="caret-2EOVIvRXlv" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-2EOVIvRXlv">
        <div class="abstract-display">
            <p>We consider the private ranking recovery problem, where a data collector seeks to estimate the permutation/ranking of a data vector given a randomized (privatized) version of it. We aim to establish fundamental trade-offs between the performance of the estimation task, measured in terms of probability of error, and the level of privacy that can be guaranteed when the noise mechanism consists of adding artificial noise. Towards this end, we show the optimality of a low-complexity decision rule (referred to as linear decoder) for the estimation task, under several noise distributions widely used in the privacy literature (e.g., Gaussian, Laplace, and generalized normal model). We derive the Taylor series of the probability of error, which yields its first and second-order approximations when such a linear decoder is employed.  We quantify the guaranteed level of privacy using differential privacy (DP) types of metrics, such as $\epsilon$-DP and $(\alpha,\epsilon)$-Rnyi DP. Finally, we put together the results to characterize trade-offs between privacy and probability of error.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-aRsLetumx1">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/aRsLetumx1.html">How Expressive are Transformers in Spectral Domain for Graphs?</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Anson Bastos &middot; Abhishek Nadgeri &middot; Kuldeep Singh &middot; Hiroki Kanezashi &middot; Toyotaro Suzumura &middot; Isaiah Onando Mulang'</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-aRsLetumx1"></div>

    <a href="paper_pages/aRsLetumx1.html">
        <img src="http://img.youtube.com/vi/7JNDYQuRSas/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-aRsLetumx1" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-aRsLetumx1" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-aRsLetumx1">
                Abstract <i id="caret-aRsLetumx1" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-aRsLetumx1">
        <div class="abstract-display">
            <p>The recent works proposing transformer-based models for graphs have proven the inadequacy of Vanilla Transformer for graph representation learning. To understand this inadequacy, there is a need to investigate if spectral analysis of the transformer will reveal insights into its expressive power. Similar studies already established that spectral analysis of Graph neural networks (GNNs) provides extra perspectives on their expressiveness. 
In this work, we systematically study and establish the link between the spatial and spectral domain in the realm of the transformer. We further provide a theoretical analysis that the spatial attention mechanism in the transformer cannot effectively capture the desired frequency response, thus, inherently limiting its expressiveness in spectral space. Therefore, we propose FeTA, a framework that aims to perform attention over the entire graph spectrum (i.e. actual frequency components of the graph) analogous to the attention in spatial space. 
Empirical results suggest that FeTA provides homogeneous performance gain against vanilla transformer across all tasks on standard benchmarks and can easily be extended to GNN-based models with low-pass characteristics (e.g., GAT). </p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-h1zuM6cXpH">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/h1zuM6cXpH.html">Zero-Shot Learning with Common Sense Knowledge Graphs</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Nihal V. Nayak &middot; Stephen Bach</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-h1zuM6cXpH"></div>

    <a href="paper_pages/h1zuM6cXpH.html">
        <img src="http://img.youtube.com/vi/VXt3MucMWvY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-h1zuM6cXpH" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-h1zuM6cXpH" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-h1zuM6cXpH">
                Abstract <i id="caret-h1zuM6cXpH" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-h1zuM6cXpH">
        <div class="abstract-display">
            <p>Zero-shot learning relies on semantic class representations such as hand-engineered attributes or learned embeddings to predict classes without any labeled examples. We propose to learn class representations by embedding nodes from common sense knowledge graphs in a vector space. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a general-purpose framework with a novel transformer graph convolutional network (TrGCN) for generating class representations. Our proposed TrGCN architecture computes non-linear combinations of node neighbourhoods. Our results show that ZSL-KG improves over existing WordNet-based methods on five out of six zero-shot benchmark datasets in language and vision.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-xyt4wfdo4J">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/xyt4wfdo4J.html">Iterative State Estimation in Non-linear Dynamical Systems Using Approximate Expectation Propagation</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Sanket Kamthe &middot; So Takao &middot; Shakir Mohamed &middot; Marc Peter Deisenroth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-xyt4wfdo4J"></div>

    <a href="paper_pages/xyt4wfdo4J.html">
        <img src="http://img.youtube.com/vi/FrTY04gXErY/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-xyt4wfdo4J" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-xyt4wfdo4J" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-xyt4wfdo4J">
                Abstract <i id="caret-xyt4wfdo4J" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-xyt4wfdo4J">
        <div class="abstract-display">
            <p>Bayesian inference in non-linear dynamical systems seeks to find good posterior approximations of a latent state given a sequence of observations. Gaussian filters and smoothers, including the (extended/unscented) Kalman filter/smoother, which are commonly used in engineering applications, yield Gaussian posteriors on the latent state. While they are computationally efficient, they are often criticised for their crude approximation of the posterior state distribution. In this paper, we address this criticism by proposing a message passing scheme for iterative state estimation in non-linear dynamical systems, which yields more informative (Gaussian) posteriors on the latent states.  Our message passing scheme is based on expectation propagation (EP). We prove that classical Rauch--Tung--Striebel (RTS) smoothers, such as the extended Kalman smoother (EKS) or the unscented Kalman smoother (UKS), are special cases of our message passing scheme. Running the message passing scheme more than once can lead to significant improvements of the classical RTS smoothers, so that more informative state estimates can be obtained. We address potential convergence issues of EP by generalising our state estimation framework to damped updates and the consideration of general $\alpha$-divergences.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-ggPhsYCsm9">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/ggPhsYCsm9.html">NeSF: Neural Semantic Fields for Generalizable Semantic Segmentation of 3D Scenes</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Suhani Vora &middot; Noha Radwan &middot; Klaus Greff &middot; Henning Meyer &middot; Kyle Genova &middot; Mehdi S. M. Sajjadi &middot; Etienne Pot &middot; Andrea Tagliasacchi &middot; Daniel Duckworth</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-ggPhsYCsm9"></div>

    <a href="paper_pages/ggPhsYCsm9.html">
        <img src="http://img.youtube.com/vi/odg-L-fG7Wo/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-ggPhsYCsm9" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-ggPhsYCsm9" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-ggPhsYCsm9">
                Abstract <i id="caret-ggPhsYCsm9" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-ggPhsYCsm9">
        <div class="abstract-display">
            <p>We present NeSF, a method for producing 3D semantic fields from posed RGB images alone. In place of classical 3D representations, our method builds on recent work in neural fields wherein 3D structure is captured by point-wise functions. We leverage this methodology to recover 3D density fields upon which we then train a 3D semantic segmentation model supervised by posed 2D semantic maps. Despite being trained on 2D signals alone, our method is able to generate 3D-consistent semantic maps from novel camera poses and can be queried at arbitrary 3D points. Notably, NeSF is compatible with any method producing a density field. Our empirical analysis demonstrates comparable quality to competitive 2D and 3D semantic segmentation baselines on complex, realistically-rendered scenes and significantly outperforms a comparable neural radiance field-based method on a series of tasks requiring 3D reasoning. Our method is the first to learn semantics by recognizing patterns in the geometry stored within a 3D neural field representation. NeSF is trained using purely 2D signals and requires as few as one labeled image per-scene at train time. No semantic input is required for inference on novel scenes.</p>
        </div>
    </div>
</div>

<div class="displaycards touchup-date" id="event-tnPjQpYk7D">
    <div style="width:80%;margin:auto;">
        <a class="small-title" href="paper_pages/tnPjQpYk7D.html">Multi-Agent Off-Policy TDC with Near-Optimal Sample and Communication Complexities</a>
    </div>
    <div class="type_display_name_minus_type"></div>
    <div class="author-str">Ziyi Chen &middot; Yi Zhou &middot; Rong-Rong Chen</div>
    <div class="author-str higher"></div>
    <div class="text-muted touchup-date-div" id="touchup-date-event-tnPjQpYk7D"></div>

    <a href="paper_pages/tnPjQpYk7D.html">
        <img src="http://img.youtube.com/vi/BCYEaLGtTNE/0.jpg" class="social-img-thumb rounded" alt="thumbnail"/>
    </a>

    <div class="abstract-section">
        <div>
            <a id="abstract-link-tnPjQpYk7D" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-tnPjQpYk7D" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-tnPjQpYk7D">
                Abstract <i id="caret-tnPjQpYk7D" class="fas fa-caret-right"></i>
            </a>
        </div>
    </div>

    <div class="collapse" id="collapse-event-abstract-tnPjQpYk7D">
        <div class="abstract-display">
            <p>The finite-time convergence of off-policy temporal difference (TD) learning has been comprehensively studied recently. However, such a type of convergence has not been established for off-policy TD learning in the multi-agent setting, which covers broader reinforcement learning applications and is fundamentally more challenging. This work develops a decentralized TD with correction (TDC) algorithm for multi-agent off-policy TD learning under Markovian sampling. In particular, our algorithm avoids sharing the actions, policies and rewards of the agents, and adopts mini-batch sampling to reduce the sampling variance and communication frequency. Under Markovian sampling and linear function approximation, we proved that the finite-time sample complexity of our algorithm for achieving an $\epsilon$-accurate solution is in the order of $\mathcal{O}\big(\frac{M\ln\epsilon^{-1}}{\epsilon(1-\sigma_2)^2}\big)$, where $M$ denotes the total number of agents and $\sigma_2$ is a network parameter. This matches the sample complexity of the centralized TDC. Moreover, our algorithm achieves the optimal communication complexity $\mathcal{O}\big(\frac{\sqrt{M}\ln\epsilon^{-1}}{1-\sigma_2}\big)$ for synchronizing the value function parameters, which is order-wise lower than the communication complexity of the existing decentralized TD(0). Numerical simulations corroborate our theoretical findings. </p>
        </div>
    </div>
</div>
                    </div>
                </div>
            </div>

        <script>
            function listmode(){
                $(".cards_img").hide();
                $(".pp-card").addClass("pp-mode-list").removeClass("pp-mode-compact");
            }
            function compactmode(){
                $(".cards_img").show();
                $(".pp-card").removeClass("pp-mode-list").addClass("pp-mode-compact");
            }
        </script>


<script>
    $(document).ready(function() {
        $(".abstract-link").on('click', function(e){
            var target = $(e.target).find("i")
            target.toggleClass("fa-caret-right");
            target.toggleClass("fa-caret-up");
        })
        touchup();
        /* touchup events currently adds dates to cached virtualcards for events */
    })

</script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
  "tex2jax": {
    "inlineMath": [["$","$"], ["\(","\)"]],
    "displayMath": [["\[","\]"]],
    "processEscapes": true
  }
}
);
var jq2 = $;
</script>

<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

</body>
</html>